Iteration [1]: Loss = 0.669347882270813
Iteration [2]: Loss = 0.6292165517807007
Iteration [3]: Loss = 0.6480051279067993
Iteration [4]: Loss = 0.6675164103507996
Iteration [5]: Loss = 0.6546475291252136
Iteration [6]: Loss = 0.6352559328079224
Iteration [7]: Loss = 0.6522085070610046
Iteration [8]: Loss = 0.6497706174850464
Iteration [9]: Loss = 0.6551029682159424
Iteration [10]: Loss = 0.6474621891975403
Iteration [11]: Loss = 0.6605892181396484
Iteration [12]: Loss = 0.6421532034873962
Iteration [13]: Loss = 0.6396073698997498
Iteration [14]: Loss = 0.6303669214248657
Iteration [15]: Loss = 0.6293890476226807
Iteration [16]: Loss = 0.6268820762634277
Iteration [17]: Loss = 5.358480930328369
Iteration [18]: Loss = 0.6444162130355835
Iteration [19]: Loss = 0.6477363109588623
Iteration [20]: Loss = 0.6488890051841736
Iteration [21]: Loss = 9.834832191467285
Iteration [22]: Loss = 0.673832356929779
Iteration [23]: Loss = 0.6857455968856812
Iteration [24]: Loss = 0.6713101863861084
Iteration [25]: Loss = 5.130800247192383
Iteration [26]: Loss = 0.6617465019226074
Iteration [27]: Loss = 5.161237716674805
Iteration [28]: Loss = 0.6364650726318359
Iteration [29]: Loss = 0.6552429795265198
Iteration [30]: Loss = 0.6949449181556702
Iteration [31]: Loss = 0.6616290211677551
Iteration [32]: Loss = 0.695318877696991
Iteration [33]: Loss = 0.6833969354629517
Iteration [34]: Loss = 0.7135366201400757
Iteration [35]: Loss = 0.7135219573974609
Iteration [36]: Loss = 0.6843064427375793
Iteration [37]: Loss = 0.6708133816719055
Iteration [38]: Loss = 0.6645734310150146
Iteration [39]: Loss = 0.7004691362380981
Iteration [40]: Loss = 0.6822260022163391
Iteration [41]: Loss = 5.0525922775268555
Iteration [42]: Loss = 4.838990211486816
Iteration [43]: Loss = 0.6745505332946777
Iteration [44]: Loss = 0.6584599018096924
Iteration [45]: Loss = 0.6623837947845459
Iteration [46]: Loss = 0.683129072189331
Iteration [47]: Loss = 0.6433183550834656
Iteration [48]: Loss = 0.6454278826713562
Iteration [49]: Loss = 0.6361178755760193
Iteration [50]: Loss = 0.6489881277084351
Iteration [51]: Loss = 5.200809478759766
Iteration [52]: Loss = 0.6623929738998413
Iteration [53]: Loss = 0.6671885251998901
Iteration [54]: Loss = 0.6558494567871094
Iteration [55]: Loss = 0.6489316821098328
Iteration [56]: Loss = 0.6481677293777466
Iteration [57]: Loss = 5.307498931884766
Iteration [58]: Loss = 0.6289535760879517
Iteration [59]: Loss = 0.6321282982826233
Iteration [60]: Loss = 0.6341896057128906
Iteration [61]: Loss = 0.6382429599761963
Iteration [62]: Loss = 0.6341988444328308
Iteration [63]: Loss = 0.6371325254440308
Iteration [64]: Loss = 0.6422267556190491
Iteration [65]: Loss = 5.275082588195801
Iteration [66]: Loss = 0.6454043388366699
Iteration [67]: Loss = 0.6437760591506958
Iteration [68]: Loss = 0.6527830958366394
Iteration [69]: Loss = 0.6609197854995728
Iteration [70]: Loss = 0.6636235117912292
Iteration [71]: Loss = 0.6514858603477478
Iteration [72]: Loss = 0.6478123068809509
Iteration [73]: Loss = 5.34145975112915
Iteration [74]: Loss = 0.6421654224395752
Iteration [75]: Loss = 0.6600977182388306
Iteration [76]: Loss = 0.6642413139343262
Iteration [77]: Loss = 0.6422591209411621
Iteration [78]: Loss = 0.6508079767227173
Iteration [79]: Loss = 0.6400761008262634
Iteration [80]: Loss = 0.6444454193115234
Iteration [81]: Loss = 0.648760974407196
Iteration [82]: Loss = 5.200945854187012
Iteration [83]: Loss = 0.6586207151412964
Iteration [84]: Loss = 0.6574026346206665
Iteration [85]: Loss = 0.6587530970573425
Iteration [86]: Loss = 0.6559485793113708
Iteration [87]: Loss = 0.6632764339447021
Iteration [88]: Loss = 0.6503123044967651
Iteration [89]: Loss = 0.6436582803726196
Iteration [90]: Loss = 0.6377459168434143
Iteration [91]: Loss = 0.6449295282363892
Iteration [92]: Loss = 0.6393100619316101
Iteration [93]: Loss = 0.63880455493927
Iteration [94]: Loss = 0.6453812718391418
Iteration [95]: Loss = 0.6349673867225647
Iteration [96]: Loss = 5.291986465454102
Iteration [97]: Loss = 0.6149287223815918
Iteration [98]: Loss = 0.6343690156936646
Iteration [99]: Loss = 0.621501088142395
Iteration [100]: Loss = 0.6244009733200073
Iteration [101]: Loss = 0.637421727180481
Iteration [102]: Loss = 0.6444345712661743
Iteration [103]: Loss = 0.6370212435722351
Iteration [104]: Loss = 0.6509283185005188
Iteration [105]: Loss = 0.6406492590904236
Iteration [106]: Loss = 5.300510883331299
Iteration [107]: Loss = 0.6439288854598999
Iteration [108]: Loss = 0.635991096496582
Iteration [109]: Loss = 5.354023456573486
Iteration [110]: Loss = 0.6246801614761353
Iteration [111]: Loss = 0.6390482187271118
Iteration [112]: Loss = 0.6085865497589111
Iteration [113]: Loss = 5.302480220794678
Iteration [114]: Loss = 0.6283526420593262
Iteration [115]: Loss = 5.336337089538574
Iteration [116]: Loss = 5.41256046295166
Iteration [117]: Loss = 0.6103154420852661
Iteration [118]: Loss = 0.6285082101821899
Iteration [119]: Loss = 0.6405905485153198
Iteration [120]: Loss = 0.6404675841331482
Iteration [121]: Loss = 0.6392405033111572
Iteration [122]: Loss = 0.6610028743743896
Iteration [123]: Loss = 0.6543067693710327
Iteration [124]: Loss = 0.6469183564186096
Iteration [125]: Loss = 5.226214408874512
Iteration [126]: Loss = 0.6351377964019775
Iteration [127]: Loss = 0.6360855102539062
Iteration [128]: Loss = 0.6448121666908264
Iteration [129]: Loss = 0.6156598329544067
Iteration [130]: Loss = 0.6175720691680908
Iteration [131]: Loss = 0.6257126331329346
Iteration [132]: Loss = 0.6263161897659302
Iteration [133]: Loss = 5.350785732269287
Iteration [134]: Loss = 0.6238176822662354
Iteration [135]: Loss = 0.6335716247558594
Iteration [136]: Loss = 0.6455390453338623
Iteration [137]: Loss = 0.6370188593864441
Iteration [138]: Loss = 0.6275935173034668
Iteration [139]: Loss = 0.6226311922073364
Iteration [140]: Loss = 0.6188452243804932
Iteration [141]: Loss = 0.618169903755188
Iteration [142]: Loss = 0.6311200261116028
Iteration [143]: Loss = 0.6442843675613403
Iteration [144]: Loss = 0.6380126476287842
Iteration [145]: Loss = 0.6689766645431519
Iteration [146]: Loss = 0.653447151184082
Iteration [147]: Loss = 0.6542161703109741
Iteration [148]: Loss = 0.6696144938468933
Iteration [149]: Loss = 5.089550018310547
Iteration [150]: Loss = 5.247018814086914
Iteration [151]: Loss = 0.6521726250648499
Iteration [152]: Loss = 5.22303581237793
Iteration [153]: Loss = 0.6516087651252747
Iteration [154]: Loss = 0.6510645151138306
Iteration [155]: Loss = 5.235755443572998
Iteration [156]: Loss = 0.6485852599143982
Iteration [157]: Loss = 0.6240608096122742
Iteration [158]: Loss = 0.6121037006378174
Iteration [159]: Loss = 0.6239694356918335
Iteration [160]: Loss = 0.6358486413955688
Iteration [161]: Loss = 0.637342095375061
Iteration [162]: Loss = 0.635388195514679
Iteration [163]: Loss = 0.6309524774551392
Iteration [164]: Loss = 5.336332321166992
Iteration [165]: Loss = 0.6404427886009216
Iteration [166]: Loss = 0.6572416424751282
Iteration [167]: Loss = 5.185178279876709
Iteration [168]: Loss = 5.177840232849121
Iteration [169]: Loss = 0.6544662714004517
Iteration [170]: Loss = 0.6405631303787231
Iteration [171]: Loss = 0.6536533236503601
Iteration [172]: Loss = 0.6610954999923706
Iteration [173]: Loss = 5.179981708526611
Iteration [174]: Loss = 0.6668145656585693
Iteration [175]: Loss = 0.670275092124939
Iteration [176]: Loss = 0.6708928346633911
Iteration [177]: Loss = 0.6571803092956543
Iteration [178]: Loss = 0.657673716545105
Iteration [179]: Loss = 0.656894326210022
Iteration [180]: Loss = 5.246273517608643
Iteration [181]: Loss = 5.402541637420654
Iteration [182]: Loss = 0.6303040981292725
Iteration [183]: Loss = 0.6444882154464722
Iteration [184]: Loss = 5.315441608428955
Iteration [185]: Loss = 5.276096343994141
Iteration [186]: Loss = 0.6430250406265259
Iteration [187]: Loss = 0.6510025262832642
Iteration [188]: Loss = 0.6484794616699219
Iteration [189]: Loss = 5.312363624572754
Iteration [190]: Loss = 0.635663628578186
Iteration [191]: Loss = 0.6252104043960571
Iteration [192]: Loss = 0.6350953578948975
Iteration [193]: Loss = 5.29058313369751
Iteration [194]: Loss = 0.6428649425506592
Iteration [195]: Loss = 5.247958183288574
Iteration [196]: Loss = 0.6438162326812744
Iteration [197]: Loss = 0.6464090347290039
Iteration [198]: Loss = 0.6557046175003052
Iteration [199]: Loss = 0.6530460119247437
Iteration [200]: Loss = 0.6507169604301453
Iteration [201]: Loss = 0.6513671875
Iteration [202]: Loss = 0.6413940191268921
Iteration [203]: Loss = 0.6295570731163025
Iteration [204]: Loss = 0.6191587448120117
Iteration [205]: Loss = 0.6134510040283203
Iteration [206]: Loss = 0.6190202832221985
Iteration [207]: Loss = 0.619326114654541
Iteration [208]: Loss = 0.6210458278656006
Iteration [209]: Loss = 0.6281335353851318
Iteration [210]: Loss = 0.6255427598953247
Iteration [211]: Loss = 0.6126366257667542
Iteration [212]: Loss = 0.6240921020507812
Iteration [213]: Loss = 0.6231954097747803
Iteration [214]: Loss = 5.396292686462402
Iteration [215]: Loss = 0.6249388456344604
Iteration [216]: Loss = 0.6187328696250916
Iteration [217]: Loss = 0.6247626543045044
Iteration [218]: Loss = 0.6158110499382019
Iteration [219]: Loss = 0.6132658123970032
Iteration [220]: Loss = 0.6179866790771484
Iteration [221]: Loss = 0.6199737787246704
Iteration [222]: Loss = 0.6144839525222778
Iteration [223]: Loss = 0.6154053807258606
Iteration [224]: Loss = 0.6154958605766296
Iteration [225]: Loss = 0.6176894903182983
Iteration [226]: Loss = 5.413716793060303
Iteration [227]: Loss = 5.445680618286133
Iteration [228]: Loss = 0.6142285466194153
Iteration [229]: Loss = 0.6113203763961792
Iteration [230]: Loss = 0.6231191158294678
Iteration [231]: Loss = 0.6218342185020447
Iteration [232]: Loss = 0.6233844757080078
Iteration [233]: Loss = 5.400101184844971
Iteration [234]: Loss = 0.620549201965332
Iteration [235]: Loss = 0.6191787719726562
Iteration [236]: Loss = 0.6194536685943604
Iteration [237]: Loss = 0.6196047067642212
Iteration [238]: Loss = 0.6270475387573242
Iteration [239]: Loss = 0.61956387758255
Iteration [240]: Loss = 0.6194139719009399
Iteration [241]: Loss = 0.6191836595535278
Iteration [242]: Loss = 0.6195422410964966
Iteration [243]: Loss = 0.6164724230766296
Iteration [244]: Loss = 0.6180326342582703
Iteration [245]: Loss = 5.417440414428711
Iteration [246]: Loss = 0.6223411560058594
Iteration [247]: Loss = 0.6242716312408447
Iteration [248]: Loss = 5.3800740242004395
Iteration [249]: Loss = 0.623737096786499
Iteration [250]: Loss = 0.625752329826355
Iteration [251]: Loss = 0.6256891489028931
Iteration [252]: Loss = 5.3697190284729
Iteration [253]: Loss = 0.6267218589782715
Iteration [254]: Loss = 0.6273753643035889
Iteration [255]: Loss = 0.6278554797172546
Iteration [256]: Loss = 0.6281787753105164
Iteration [257]: Loss = 0.6301798820495605
Iteration [258]: Loss = 0.6284140944480896
Iteration [259]: Loss = 5.354288101196289
Iteration [260]: Loss = 5.367692947387695
Iteration [261]: Loss = 0.6301450133323669
Iteration [262]: Loss = 0.6311008334159851
Iteration [263]: Loss = 0.6290334463119507
Iteration [264]: Loss = 0.6324354410171509
Iteration [265]: Loss = 0.632850170135498
Iteration [266]: Loss = 5.342351913452148
Iteration [267]: Loss = 0.6311413645744324
Iteration [268]: Loss = 0.6321560144424438
Iteration [269]: Loss = 0.6324511766433716
Iteration [270]: Loss = 0.6330181360244751
Iteration [271]: Loss = 0.6332355737686157
Iteration [272]: Loss = 0.6333286762237549
Iteration [273]: Loss = 0.6333096027374268
Iteration [274]: Loss = 5.324431896209717
Iteration [275]: Loss = 0.6334785223007202
Iteration [276]: Loss = 0.6338375210762024
Iteration [277]: Loss = 0.6342945694923401
Iteration [278]: Loss = 0.6341538429260254
Iteration [279]: Loss = 0.6341365575790405
Iteration [280]: Loss = 0.6340166330337524
Iteration [281]: Loss = 0.6346818208694458
Iteration [282]: Loss = 0.6335101127624512
Iteration [283]: Loss = 0.633140504360199
Iteration [284]: Loss = 0.6331088542938232
Iteration [285]: Loss = 0.6322058439254761
Iteration [286]: Loss = 0.6316533088684082
Iteration [287]: Loss = 0.6310508847236633
Iteration [288]: Loss = 0.6304199695587158
Iteration [289]: Loss = 0.6298062205314636
Iteration [290]: Loss = 0.6291599869728088
Iteration [291]: Loss = 0.6284844279289246
Iteration [292]: Loss = 0.6277824640274048
Iteration [293]: Loss = 0.6266859769821167
Iteration [294]: Loss = 0.6263102293014526
Iteration [295]: Loss = 5.371781349182129
Iteration [296]: Loss = 0.6254405975341797
Iteration [297]: Loss = 0.6252551078796387
Iteration [298]: Loss = 0.6249960660934448
Iteration [299]: Loss = 0.6246706247329712
Iteration [300]: Loss = 0.6242853403091431
Iteration [301]: Loss = 0.623846173286438
Iteration [302]: Loss = 5.385485649108887
Iteration [303]: Loss = 0.6234961748123169
Iteration [304]: Loss = 0.6235295534133911
Iteration [305]: Loss = 0.6234687566757202
Iteration [306]: Loss = 5.385705947875977
Iteration [307]: Loss = 0.6237571835517883
Iteration [308]: Loss = 0.6240589022636414
Iteration [309]: Loss = 0.6242408752441406
Iteration [310]: Loss = 0.6243147850036621
Iteration [311]: Loss = 0.6242910027503967
Iteration [312]: Loss = 0.6241791248321533
Iteration [313]: Loss = 0.6239877939224243
Iteration [314]: Loss = 0.6237247586250305
Iteration [315]: Loss = 5.385250091552734
Iteration [316]: Loss = 0.6236678957939148
Iteration [317]: Loss = 0.6238226890563965
Iteration [318]: Loss = 0.6238725781440735
Iteration [319]: Loss = 0.6238276958465576
Iteration [320]: Loss = 0.6236972808837891
Iteration [321]: Loss = 0.6234898567199707
Iteration [322]: Loss = 0.6232128143310547
Iteration [323]: Loss = 0.622873067855835
Iteration [324]: Loss = 0.6224768757820129
Iteration [325]: Loss = 0.6220296621322632
Iteration [326]: Loss = 0.6215366125106812
Iteration [327]: Loss = 0.621002197265625
Iteration [328]: Loss = 0.620430588722229
Iteration [329]: Loss = 0.6198254823684692
Iteration [330]: Loss = 0.6191901564598083
Iteration [331]: Loss = 0.6185277700424194
Iteration [332]: Loss = 0.6178410053253174
Iteration [333]: Loss = 0.617132306098938
Iteration [334]: Loss = 0.6164038777351379
Iteration [335]: Loss = 0.6156578063964844
Iteration [336]: Loss = 0.614895761013031
Iteration [337]: Loss = 0.6141196489334106
Iteration [338]: Loss = 0.6133763194084167
Iteration [339]: Loss = 0.6126435995101929
Iteration [340]: Loss = 5.45855188369751
Iteration [341]: Loss = 0.6117680668830872
Iteration [342]: Loss = 0.6115666031837463
Iteration [343]: Loss = 0.6113039255142212
Iteration [344]: Loss = 0.6109858751296997
Iteration [345]: Loss = 0.610617995262146
Iteration [346]: Loss = 0.6102051138877869
Iteration [347]: Loss = 0.60975182056427
Iteration [348]: Loss = 0.6092621088027954
Iteration [349]: Loss = 0.6087394952774048
Iteration [350]: Loss = 0.6081873178482056
Iteration [351]: Loss = 0.6076084971427917
Iteration [352]: Loss = 0.607005774974823
Iteration [353]: Loss = 5.494495391845703
Iteration [354]: Loss = 5.494683742523193
Iteration [355]: Loss = 5.491434574127197
Iteration [356]: Loss = 0.6090188026428223
Iteration [357]: Loss = 0.608583390712738
Iteration [358]: Loss = 0.6092091202735901
Iteration [359]: Loss = 0.6096944212913513
Iteration [360]: Loss = 0.610052764415741
Iteration [361]: Loss = 0.6102964878082275
Iteration [362]: Loss = 5.468034744262695
Iteration [363]: Loss = 0.6110712289810181
Iteration [364]: Loss = 0.6115646958351135
Iteration [365]: Loss = 0.6119306683540344
Iteration [366]: Loss = 5.4567341804504395
Iteration [367]: Loss = 0.6129102110862732
Iteration [368]: Loss = 0.6134889721870422
Iteration [369]: Loss = 0.613932192325592
Iteration [370]: Loss = 0.6142529249191284
Iteration [371]: Loss = 0.6144630908966064
Iteration [372]: Loss = 0.6145734190940857
Iteration [373]: Loss = 0.6145936250686646
Iteration [374]: Loss = 5.4415740966796875
Iteration [375]: Loss = 0.614982008934021
Iteration [376]: Loss = 5.4365997314453125
Iteration [377]: Loss = 0.6160984039306641
Iteration [378]: Loss = 0.616732656955719
Iteration [379]: Loss = 0.6172263622283936
Iteration [380]: Loss = 0.6175930500030518
Iteration [381]: Loss = 0.6178449988365173
Iteration [382]: Loss = 0.6169780492782593
Iteration [383]: Loss = 0.6170328855514526
Iteration [384]: Loss = 0.6170033812522888
Iteration [385]: Loss = 0.6168980598449707
Iteration [386]: Loss = 0.6167240142822266
Iteration [387]: Loss = 0.6164883375167847
Iteration [388]: Loss = 0.6161969900131226
Iteration [389]: Loss = 0.6158554553985596
Iteration [390]: Loss = 0.6154687404632568
Iteration [391]: Loss = 5.438322067260742
Iteration [392]: Loss = 0.6151628494262695
Iteration [393]: Loss = 0.6151940822601318
Iteration [394]: Loss = 0.6151437759399414
Iteration [395]: Loss = 0.6150199770927429
Iteration [396]: Loss = 0.6148297786712646
Iteration [397]: Loss = 0.6145799160003662
Iteration [398]: Loss = 5.446043968200684
Iteration [399]: Loss = 0.6140724420547485
Iteration [400]: Loss = 5.4437079429626465
Iteration [401]: Loss = 10.264732360839844
Iteration [402]: Loss = 0.6163535714149475
Iteration [403]: Loss = 5.421507358551025
Iteration [404]: Loss = 0.6193125247955322
Iteration [405]: Loss = 0.6207220554351807
Iteration [406]: Loss = 0.621920108795166
Iteration [407]: Loss = 0.6229267120361328
Iteration [408]: Loss = 0.6237602233886719
Iteration [409]: Loss = 0.6244372129440308
Iteration [410]: Loss = 5.375368595123291
Iteration [411]: Loss = 5.3694610595703125
Iteration [412]: Loss = 0.6272224187850952
Iteration [413]: Loss = 0.6283263564109802
Iteration [414]: Loss = 0.6292476058006287
Iteration [415]: Loss = 0.6300037503242493
Iteration [416]: Loss = 0.6306107640266418
Iteration [417]: Loss = 0.6310827732086182
Iteration [418]: Loss = 0.6314329504966736
Iteration [419]: Loss = 0.6316731572151184
Iteration [420]: Loss = 5.332880020141602
Iteration [421]: Loss = 5.329263210296631
Iteration [422]: Loss = 5.323225975036621
Iteration [423]: Loss = 0.6347198486328125
Iteration [424]: Loss = 0.6358493566513062
Iteration [425]: Loss = 0.6367936730384827
Iteration [426]: Loss = 0.6375704407691956
Iteration [427]: Loss = 0.6381956338882446
Iteration [428]: Loss = 5.290940284729004
Iteration [429]: Loss = 0.6395740509033203
Iteration [430]: Loss = 5.281158447265625
Iteration [431]: Loss = 0.6414030194282532
Iteration [432]: Loss = 0.6423214673995972
Iteration [433]: Loss = 0.6430747509002686
Iteration [434]: Loss = 0.6436784267425537
Iteration [435]: Loss = 5.25807523727417
Iteration [436]: Loss = 0.6450153589248657
Iteration [437]: Loss = 0.6459223031997681
Iteration [438]: Loss = 0.6464231014251709
Iteration [439]: Loss = 0.6468069553375244
Iteration [440]: Loss = 0.6470850706100464
Iteration [441]: Loss = 0.6472679376602173
Iteration [442]: Loss = 0.647364616394043
Iteration [443]: Loss = 0.6473836302757263
Iteration [444]: Loss = 0.6473325490951538
Iteration [445]: Loss = 0.6472183465957642
Iteration [446]: Loss = 0.6470470428466797
Iteration [447]: Loss = 0.6468244194984436
Iteration [448]: Loss = 0.6465554237365723
Iteration [449]: Loss = 0.6462447643280029
Iteration [450]: Loss = 5.247650146484375
Iteration [451]: Loss = 0.6459894180297852
Iteration [452]: Loss = 5.247005462646484
Iteration [453]: Loss = 0.6464211940765381
Iteration [454]: Loss = 0.6438434720039368
Iteration [455]: Loss = 0.6440515518188477
Iteration [456]: Loss = 0.6441716551780701
Iteration [457]: Loss = 0.6442121863365173
Iteration [458]: Loss = 0.6451684832572937
Iteration [459]: Loss = 0.6450595259666443
Iteration [460]: Loss = 0.6448801755905151
Iteration [461]: Loss = 0.6437243223190308
Iteration [462]: Loss = 0.643470287322998
Iteration [463]: Loss = 0.6431734561920166
Iteration [464]: Loss = 0.6428381204605103
Iteration [465]: Loss = 0.6424680948257446
Iteration [466]: Loss = 0.6420667171478271
Iteration [467]: Loss = 0.6416373252868652
Iteration [468]: Loss = 0.641182541847229
Iteration [469]: Loss = 5.278738021850586
Iteration [470]: Loss = 0.640684962272644
Iteration [471]: Loss = 0.6405993700027466
Iteration [472]: Loss = 0.6404547095298767
Iteration [473]: Loss = 0.6402565836906433
Iteration [474]: Loss = 0.6400103569030762
Iteration [475]: Loss = 0.6397207975387573
Iteration [476]: Loss = 0.6393922567367554
Iteration [477]: Loss = 0.6390284299850464
Iteration [478]: Loss = 0.6386330127716064
Iteration [479]: Loss = 0.6382089853286743
Iteration [480]: Loss = 5.296543121337891
Iteration [481]: Loss = 0.6377660632133484
Iteration [482]: Loss = 5.296868324279785
Iteration [483]: Loss = 0.6380563378334045
Iteration [484]: Loss = 5.2932257652282715
Iteration [485]: Loss = 5.289419651031494
Iteration [486]: Loss = 5.283627033233643
Iteration [487]: Loss = 0.6411584615707397
Iteration [488]: Loss = 0.6422301530838013
Iteration [489]: Loss = 0.6431301236152649
Iteration [490]: Loss = 0.6438750624656677
Iteration [491]: Loss = 0.6444796919822693
Iteration [492]: Loss = 0.6449576616287231
Iteration [493]: Loss = 0.645321249961853
Iteration [494]: Loss = 0.6455815434455872
Iteration [495]: Loss = 5.24854040145874
Iteration [496]: Loss = 0.6462974548339844
Iteration [497]: Loss = 5.242728233337402
Iteration [498]: Loss = 0.6475049257278442
Iteration [499]: Loss = 0.6481411457061768
Iteration [500]: Loss = 0.6486473083496094
Iteration [501]: Loss = 5.229060649871826
Iteration [502]: Loss = 0.6497805118560791
Iteration [503]: Loss = 0.6503841876983643
Iteration [504]: Loss = 0.6508258581161499
Iteration [505]: Loss = 0.6511563062667847
Iteration [506]: Loss = 0.6513923406600952
Iteration [507]: Loss = 0.6515432000160217
Iteration [508]: Loss = 5.213873386383057
Iteration [509]: Loss = 0.6520447731018066
Iteration [510]: Loss = 0.6523683667182922
Iteration [511]: Loss = 0.6525982618331909
Iteration [512]: Loss = 0.6527434587478638
Iteration [513]: Loss = 0.6528123617172241
Iteration [514]: Loss = 0.6528123021125793
Iteration [515]: Loss = 0.6527501344680786
Iteration [516]: Loss = 5.207921981811523
Iteration [517]: Loss = 0.6528879404067993
Iteration [518]: Loss = 0.6530567407608032
Iteration [519]: Loss = 0.6531468033790588
Iteration [520]: Loss = 0.6531659364700317
Iteration [521]: Loss = 0.6531209945678711
Iteration [522]: Loss = 0.6530182361602783
Iteration [523]: Loss = 0.6528635025024414
Iteration [524]: Loss = 0.6526618003845215
Iteration [525]: Loss = 5.2091779708862305
Iteration [526]: Loss = 9.764087677001953
Iteration [527]: Loss = 0.6534523963928223
Iteration [528]: Loss = 0.6541948914527893
Iteration [529]: Loss = 0.6548038721084595
Iteration [530]: Loss = 0.6552921533584595
Iteration [531]: Loss = 0.6556715369224548
Iteration [532]: Loss = 0.6559526920318604
Iteration [533]: Loss = 0.6561449766159058
Iteration [534]: Loss = 0.6562572717666626
Iteration [535]: Loss = 0.6562972664833069
Iteration [536]: Loss = 0.6562721729278564
Iteration [537]: Loss = 0.6561883091926575
Iteration [538]: Loss = 0.656051516532898
Iteration [539]: Loss = 0.6558668613433838
Iteration [540]: Loss = 0.6556392908096313
Iteration [541]: Loss = 5.191880226135254
Iteration [542]: Loss = 0.653862476348877
Iteration [543]: Loss = 0.6539005041122437
Iteration [544]: Loss = 5.2006425857543945
Iteration [545]: Loss = 5.2096848487854
Iteration [546]: Loss = 0.6549395322799683
Iteration [547]: Loss = 0.655514121055603
Iteration [548]: Loss = 0.6559790968894958
Iteration [549]: Loss = 0.6563543081283569
Iteration [550]: Loss = 0.6566188335418701
Iteration [551]: Loss = 0.6568713188171387
Iteration [552]: Loss = 0.6569941639900208
Iteration [553]: Loss = 0.6570016145706177
Iteration [554]: Loss = 0.6569051742553711
Iteration [555]: Loss = 0.656715452671051
Iteration [556]: Loss = 0.6564728021621704
Iteration [557]: Loss = 5.187254905700684
Iteration [558]: Loss = 0.6564214825630188
Iteration [559]: Loss = 5.185093402862549
Iteration [560]: Loss = 0.6571493148803711
Iteration [561]: Loss = 5.187632083892822
Iteration [562]: Loss = 0.6574650406837463
Iteration [563]: Loss = 0.6590919494628906
Iteration [564]: Loss = 0.6586140394210815
Iteration [565]: Loss = 0.658980131149292
Iteration [566]: Loss = 0.6589431166648865
Iteration [567]: Loss = 5.170311450958252
Iteration [568]: Loss = 0.6620229482650757
Iteration [569]: Loss = 0.664703369140625
Iteration [570]: Loss = 0.6636602282524109
Iteration [571]: Loss = 0.6578792333602905
Iteration [572]: Loss = 0.6716078519821167
Iteration [573]: Loss = 5.110762596130371
Iteration [574]: Loss = 0.6598243713378906
Iteration [575]: Loss = 5.146075248718262
Iteration [576]: Loss = 0.650000810623169
Iteration [577]: Loss = 0.6566364169120789
Iteration [578]: Loss = 0.6578904390335083
Iteration [579]: Loss = 0.6638128161430359
Iteration [580]: Loss = 0.6674835681915283
Iteration [581]: Loss = 0.6671028733253479
Iteration [582]: Loss = 0.6678327322006226
Iteration [583]: Loss = 0.6560598611831665
Iteration [584]: Loss = 0.6889303922653198
Iteration [585]: Loss = 0.676063597202301
Iteration [586]: Loss = 0.6794071793556213
Iteration [587]: Loss = 0.6756630539894104
Iteration [588]: Loss = 0.6552624702453613
Iteration [589]: Loss = 0.6546883583068848
Iteration [590]: Loss = 0.6727374792098999
Iteration [591]: Loss = 0.658171534538269
Iteration [592]: Loss = 0.6750507354736328
Iteration [593]: Loss = 5.11541223526001
Iteration [594]: Loss = 0.6601879596710205
Iteration [595]: Loss = 0.6841058135032654
Iteration [596]: Loss = 0.6973856687545776
Iteration [597]: Loss = 0.678209125995636
Iteration [598]: Loss = 0.681454062461853
Iteration [599]: Loss = 0.6928941011428833
Iteration [600]: Loss = 0.6892774105072021
Iteration [601]: Loss = 4.973061561584473
Iteration [602]: Loss = 0.6463817358016968
Iteration [603]: Loss = 0.6338629722595215
Iteration [604]: Loss = 0.652873158454895
Iteration [605]: Loss = 5.18167781829834
Iteration [606]: Loss = 0.6658164858818054
Iteration [607]: Loss = 0.6564240455627441
Iteration [608]: Loss = 0.6615598201751709
Iteration [609]: Loss = 0.6521705985069275
Iteration [610]: Loss = 0.6425955295562744
Iteration [611]: Loss = 0.6419132351875305
Iteration [612]: Loss = 0.6388409733772278
Iteration [613]: Loss = 0.6492204070091248
Iteration [614]: Loss = 5.274353504180908
Iteration [615]: Loss = 0.6456975340843201
Iteration [616]: Loss = 0.6434041261672974
Iteration [617]: Loss = 0.6506882309913635
Iteration [618]: Loss = 0.6591662168502808
Iteration [619]: Loss = 5.1461944580078125
Iteration [620]: Loss = 0.656578779220581
Iteration [621]: Loss = 0.6609177589416504
Iteration [622]: Loss = 0.6553518772125244
Iteration [623]: Loss = 0.6570863723754883
Iteration [624]: Loss = 0.6519718766212463
Iteration [625]: Loss = 5.189882278442383
Iteration [626]: Loss = 5.183331489562988
Iteration [627]: Loss = 0.6596089601516724
Iteration [628]: Loss = 0.6601917743682861
Iteration [629]: Loss = 0.667696475982666
Iteration [630]: Loss = 0.6577765941619873
Iteration [631]: Loss = 5.18788480758667
Iteration [632]: Loss = 0.6590395569801331
Iteration [633]: Loss = 0.6570484638214111
Iteration [634]: Loss = 0.6530200242996216
Iteration [635]: Loss = 0.6530224084854126
Iteration [636]: Loss = 0.6586256623268127
Iteration [637]: Loss = 5.301168441772461
Iteration [638]: Loss = 0.6477058529853821
Iteration [639]: Loss = 0.6485632061958313
Iteration [640]: Loss = 0.6515445113182068
Iteration [641]: Loss = 0.6520013213157654
Iteration [642]: Loss = 5.18875789642334
Iteration [643]: Loss = 5.1861162185668945
Iteration [644]: Loss = 0.6571859121322632
Iteration [645]: Loss = 0.6578454375267029
Iteration [646]: Loss = 0.6583695411682129
Iteration [647]: Loss = 0.6587710976600647
Iteration [648]: Loss = 0.6590622663497925
Iteration [649]: Loss = 0.6608239412307739
Iteration [650]: Loss = 0.6601846218109131
Iteration [651]: Loss = 0.6601970195770264
Iteration [652]: Loss = 0.6601500511169434
Iteration [653]: Loss = 0.6600496768951416
Iteration [654]: Loss = 0.6599012613296509
Iteration [655]: Loss = 0.6597095727920532
Iteration [656]: Loss = 0.6594787836074829
Iteration [657]: Loss = 0.6592127084732056
Iteration [658]: Loss = 0.6589152812957764
Iteration [659]: Loss = 0.6590532660484314
Iteration [660]: Loss = 0.6585429906845093
Iteration [661]: Loss = 0.658164381980896
Iteration [662]: Loss = 0.6581977605819702
Iteration [663]: Loss = 5.178035259246826
Iteration [664]: Loss = 5.165268898010254
Iteration [665]: Loss = 0.6597988605499268
Iteration [666]: Loss = 0.6579973101615906
Iteration [667]: Loss = 0.658130943775177
Iteration [668]: Loss = 0.6581893563270569
Iteration [669]: Loss = 0.6581799387931824
Iteration [670]: Loss = 0.6581095457077026
Iteration [671]: Loss = 0.65798419713974
Iteration [672]: Loss = 0.657809317111969
Iteration [673]: Loss = 0.6575897336006165
Iteration [674]: Loss = 5.180590629577637
Iteration [675]: Loss = 0.6574534773826599
Iteration [676]: Loss = 0.6575033664703369
Iteration [677]: Loss = 5.179683208465576
Iteration [678]: Loss = 0.65782231092453
Iteration [679]: Loss = 0.6580639481544495
Iteration [680]: Loss = 0.6582208275794983
Iteration [681]: Loss = 0.6583013534545898
Iteration [682]: Loss = 5.174909591674805
Iteration [683]: Loss = 0.6586702466011047
Iteration [684]: Loss = 5.171342849731445
Iteration [685]: Loss = 0.6595067977905273
Iteration [686]: Loss = 0.6599655747413635
Iteration [687]: Loss = 0.6603192687034607
Iteration [688]: Loss = 5.161872386932373
Iteration [689]: Loss = 5.158605098724365
Iteration [690]: Loss = 0.6619906425476074
Iteration [691]: Loss = 0.6626918315887451
Iteration [692]: Loss = 0.6632651090621948
Iteration [693]: Loss = 0.6637225151062012
Iteration [694]: Loss = 0.6640756726264954
Iteration [695]: Loss = 0.6643348932266235
Iteration [696]: Loss = 0.6645091772079468
Iteration [697]: Loss = 0.6646068096160889
Iteration [698]: Loss = 0.6646354794502258
Iteration [699]: Loss = 0.6646020412445068
Iteration [700]: Loss = 0.6645125150680542
Iteration [701]: Loss = 0.6643726825714111
Iteration [702]: Loss = 0.6641871929168701
Iteration [703]: Loss = 0.6639609932899475
Iteration [704]: Loss = 0.6636977791786194
Iteration [705]: Loss = 5.145719051361084
Iteration [706]: Loss = 0.6634725332260132
Iteration [707]: Loss = 0.6634778380393982
Iteration [708]: Loss = 5.145592212677002
Iteration [709]: Loss = 5.143975734710693
Iteration [710]: Loss = 5.140665054321289
Iteration [711]: Loss = 5.135866641998291
Iteration [712]: Loss = 5.12976598739624
Iteration [713]: Loss = 0.6674891114234924
Iteration [714]: Loss = 0.6685871481895447
Iteration [715]: Loss = 0.6695035696029663
Iteration [716]: Loss = 0.6702123880386353
Iteration [717]: Loss = 5.103909492492676
Iteration [718]: Loss = 0.6716103553771973
Iteration [719]: Loss = 0.6722896099090576
Iteration [720]: Loss = 0.6728241443634033
Iteration [721]: Loss = 0.6732357740402222
Iteration [722]: Loss = 0.6735599040985107
Iteration [723]: Loss = 0.6738049983978271
Iteration [724]: Loss = 5.08616828918457
Iteration [725]: Loss = 0.6743927001953125
Iteration [726]: Loss = 0.674718976020813
Iteration [727]: Loss = 0.6749662756919861
Iteration [728]: Loss = 0.6751422882080078
Iteration [729]: Loss = 0.6752540469169617
Iteration [730]: Loss = 0.6753078103065491
Iteration [731]: Loss = 0.6753093600273132
Iteration [732]: Loss = 5.079028606414795
Iteration [733]: Loss = 0.675452470779419
Iteration [734]: Loss = 0.67556232213974
Iteration [735]: Loss = 5.077024459838867
Iteration [736]: Loss = 0.6758735179901123
Iteration [737]: Loss = 0.6760615110397339
Iteration [738]: Loss = 0.6761965751647949
Iteration [739]: Loss = 5.073388576507568
Iteration [740]: Loss = 0.6765500903129578
Iteration [741]: Loss = 0.6767557263374329
Iteration [742]: Loss = 9.46298885345459
Iteration [743]: Loss = 0.6774333715438843
Iteration [744]: Loss = 0.6778749823570251
Iteration [745]: Loss = 0.6782398223876953
Iteration [746]: Loss = 0.6785355806350708
Iteration [747]: Loss = 0.6787689328193665
Iteration [748]: Loss = 0.6789461374282837
Iteration [749]: Loss = 0.6790726780891418
Iteration [750]: Loss = 0.6791532635688782
Iteration [751]: Loss = 0.679192841053009
Iteration [752]: Loss = 0.6791951656341553
Iteration [753]: Loss = 0.679163932800293
Iteration [754]: Loss = 0.6791025400161743
Iteration [755]: Loss = 0.6790140867233276
Iteration [756]: Loss = 0.6789008975028992
Iteration [757]: Loss = 5.059708595275879
Iteration [758]: Loss = 0.6788269281387329
Iteration [759]: Loss = 0.6788488030433655
Iteration [760]: Loss = 0.6788353323936462
Iteration [761]: Loss = 0.6787901520729065
Iteration [762]: Loss = 5.059980392456055
Iteration [763]: Loss = 0.6788312196731567
Iteration [764]: Loss = 5.058959484100342
Iteration [765]: Loss = 0.6791452765464783
Iteration [766]: Loss = 0.6793316602706909
Iteration [767]: Loss = 0.6794667840003967
Iteration [768]: Loss = 0.6795554161071777
Iteration [769]: Loss = 0.6796024441719055
Iteration [770]: Loss = 0.67961186170578
Iteration [771]: Loss = 0.6795871257781982
Iteration [772]: Loss = 0.6795321106910706
Iteration [773]: Loss = 0.6794493794441223
Iteration [774]: Loss = 5.056543827056885
Iteration [775]: Loss = 0.6794260740280151
Iteration [776]: Loss = 0.6794688701629639
Iteration [777]: Loss = 0.6794745326042175
Iteration [778]: Loss = 0.6794467568397522
Iteration [779]: Loss = 0.6793888807296753
Iteration [780]: Loss = 5.056752681732178
Iteration [781]: Loss = 0.6794072985649109
Iteration [782]: Loss = 5.055852890014648
Iteration [783]: Loss = 0.6797005534172058
Iteration [784]: Loss = 5.053605079650879
Iteration [785]: Loss = 0.6802137494087219
Iteration [786]: Loss = 0.6804842352867126
Iteration [787]: Loss = 5.049127578735352
Iteration [788]: Loss = 0.6810611486434937
Iteration [789]: Loss = 0.6813584566116333
Iteration [790]: Loss = 0.6815938949584961
Iteration [791]: Loss = 0.6817735433578491
Iteration [792]: Loss = 0.6819027066230774
Iteration [793]: Loss = 0.6819864511489868
Iteration [794]: Loss = 0.6820294857025146
Iteration [795]: Loss = 5.041806697845459
Iteration [796]: Loss = 5.040812969207764
Iteration [797]: Loss = 0.6825567483901978
Iteration [798]: Loss = 0.6828300356864929
Iteration [799]: Loss = 0.6830436587333679
Iteration [800]: Loss = 0.6832038164138794
Iteration [801]: Loss = 0.6833156943321228
Iteration [802]: Loss = 0.6833840012550354
Iteration [803]: Loss = 0.6834129095077515
Iteration [804]: Loss = 0.6834064722061157
Iteration [805]: Loss = 0.6833682060241699
Iteration [806]: Loss = 0.6833011507987976
Iteration [807]: Loss = 0.6832081079483032
Iteration [808]: Loss = 0.6830917596817017
Iteration [809]: Loss = 0.6829543709754944
Iteration [810]: Loss = 0.6827982068061829
Iteration [811]: Loss = 0.682624876499176
Iteration [812]: Loss = 5.039621829986572
Iteration [813]: Loss = 0.6824440956115723
Iteration [814]: Loss = 0.682418704032898
Iteration [815]: Loss = 0.6823633313179016
Iteration [816]: Loss = 0.6822810769081116
Iteration [817]: Loss = 0.6821744441986084
Iteration [818]: Loss = 0.6820459365844727
Iteration [819]: Loss = 0.681897759437561
Iteration [820]: Loss = 0.6817318201065063
Iteration [821]: Loss = 0.6815499663352966
Iteration [822]: Loss = 0.6813536286354065
Iteration [823]: Loss = 0.6811442971229553
Iteration [824]: Loss = 0.680923342704773
Iteration [825]: Loss = 0.6806919574737549
Iteration [826]: Loss = 0.6804509162902832
Iteration [827]: Loss = 0.680201530456543
Iteration [828]: Loss = 0.6799445152282715
Iteration [829]: Loss = 0.6796804666519165
Iteration [830]: Loss = 0.6794103384017944
Iteration [831]: Loss = 0.6791346073150635
Iteration [832]: Loss = 5.059223651885986
Iteration [833]: Loss = 0.6787803769111633
Iteration [834]: Loss = 0.6786817312240601
Iteration [835]: Loss = 0.6785606145858765
Iteration [836]: Loss = 0.6784192323684692
Iteration [837]: Loss = 0.6782594919204712
Iteration [838]: Loss = 0.6780833005905151
Iteration [839]: Loss = 0.6778924465179443
Iteration [840]: Loss = 0.6776880621910095
Iteration [841]: Loss = 0.6774718165397644
Iteration [842]: Loss = 0.6772447824478149
Iteration [843]: Loss = 0.6770079135894775
Iteration [844]: Loss = 0.6767622828483582
Iteration [845]: Loss = 0.6765090227127075
Iteration [846]: Loss = 0.6762484312057495
Iteration [847]: Loss = 5.075061321258545
Iteration [848]: Loss = 0.6759206652641296
Iteration [849]: Loss = 5.07588005065918
Iteration [850]: Loss = 0.6759328246116638
Iteration [851]: Loss = 0.6759902238845825
Iteration [852]: Loss = 0.6760098338127136
Iteration [853]: Loss = 0.6759953498840332
Iteration [854]: Loss = 0.675950288772583
Iteration [855]: Loss = 0.6758776307106018
Iteration [856]: Loss = 0.675780177116394
Iteration [857]: Loss = 0.6756600737571716
Iteration [858]: Loss = 0.6755199432373047
Iteration [859]: Loss = 0.6753615140914917
Iteration [860]: Loss = 0.6751868724822998
Iteration [861]: Loss = 0.6749973893165588
Iteration [862]: Loss = 5.081637859344482
Iteration [863]: Loss = 0.6747905611991882
Iteration [864]: Loss = 0.6747549176216125
Iteration [865]: Loss = 0.674690842628479
Iteration [866]: Loss = 0.6746010780334473
Iteration [867]: Loss = 0.6744883060455322
Iteration [868]: Loss = 0.6743544936180115
Iteration [869]: Loss = 0.6742022633552551
Iteration [870]: Loss = 0.6740328669548035
Iteration [871]: Loss = 0.6738484501838684
Iteration [872]: Loss = 0.6736503839492798
Iteration [873]: Loss = 0.6734398603439331
Iteration [874]: Loss = 0.673218309879303
Iteration [875]: Loss = 0.6729867458343506
Iteration [876]: Loss = 0.6727461814880371
Iteration [877]: Loss = 0.672497570514679
Iteration [878]: Loss = 0.672241747379303
Iteration [879]: Loss = 0.6719792485237122
Iteration [880]: Loss = 0.6717109084129333
Iteration [881]: Loss = 0.6714373230934143
Iteration [882]: Loss = 0.6711589694023132
Iteration [883]: Loss = 0.6708763241767883
Iteration [884]: Loss = 0.6705897450447083
Iteration [885]: Loss = 0.6702997088432312
Iteration [886]: Loss = 0.6700066328048706
Iteration [887]: Loss = 0.6697106957435608
Iteration [888]: Loss = 5.111693382263184
Iteration [889]: Loss = 0.6693241596221924
Iteration [890]: Loss = 0.669213056564331
Iteration [891]: Loss = 0.6690811514854431
Iteration [892]: Loss = 0.6689303517341614
Iteration [893]: Loss = 0.6687630414962769
Iteration [894]: Loss = 0.6685802936553955
Iteration [895]: Loss = 0.6683838367462158
Iteration [896]: Loss = 0.6681751012802124
Iteration [897]: Loss = 0.6679552793502808
Iteration [898]: Loss = 5.12119197845459
Iteration [899]: Loss = 0.667698860168457
Iteration [900]: Loss = 0.6676430106163025
Iteration [901]: Loss = 0.6675609946250916
Iteration [902]: Loss = 0.6674554944038391
Iteration [903]: Loss = 0.6673286557197571
Iteration [904]: Loss = 0.6671828031539917
Iteration [905]: Loss = 0.6670196652412415
Iteration [906]: Loss = 0.6668409705162048
Iteration [907]: Loss = 5.127278804779053
Iteration [908]: Loss = 0.6666547060012817
Iteration [909]: Loss = 5.127389430999756
Iteration [910]: Loss = 0.666783332824707
Iteration [911]: Loss = 0.6668911576271057
Iteration [912]: Loss = 0.666956901550293
Iteration [913]: Loss = 0.6669844388961792
Iteration [914]: Loss = 0.6669777035713196
Iteration [915]: Loss = 0.6669402122497559
Iteration [916]: Loss = 0.6668747067451477
Iteration [917]: Loss = 5.126510143280029
Iteration [918]: Loss = 0.6668809056282043
Iteration [919]: Loss = 0.6669365167617798
Iteration [920]: Loss = 0.6669551730155945
Iteration [921]: Loss = 0.666940450668335
Iteration [922]: Loss = 0.6668956279754639
Iteration [923]: Loss = 0.6668238043785095
Iteration [924]: Loss = 0.6667275428771973
Iteration [925]: Loss = 0.6666093468666077
Iteration [926]: Loss = 0.6664714813232422
Iteration [927]: Loss = 5.129162311553955
Iteration [928]: Loss = 0.6663538813591003
Iteration [929]: Loss = 0.6663568615913391
Iteration [930]: Loss = 0.6663283109664917
Iteration [931]: Loss = 0.6662709712982178
Iteration [932]: Loss = 0.6661880016326904
Iteration [933]: Loss = 0.6660817265510559
Iteration [934]: Loss = 0.6659545302391052
Iteration [935]: Loss = 0.6658085584640503
Iteration [936]: Loss = 5.13295841217041
Iteration [937]: Loss = 0.6656774282455444
Iteration [938]: Loss = 0.66567462682724
Iteration [939]: Loss = 0.6656408309936523
Iteration [940]: Loss = 0.6655790209770203
Iteration [941]: Loss = 0.665492057800293
Iteration [942]: Loss = 0.6653820872306824
Iteration [943]: Loss = 5.13519287109375
Iteration [944]: Loss = 0.665312647819519
Iteration [945]: Loss = 0.6653360724449158
Iteration [946]: Loss = 0.6653258204460144
Iteration [947]: Loss = 0.6652852892875671
Iteration [948]: Loss = 0.6652176380157471
Iteration [949]: Loss = 0.6651252508163452
Iteration [950]: Loss = 0.6650106310844421
Iteration [951]: Loss = 0.6648762226104736
Iteration [952]: Loss = 0.6647237539291382
Iteration [953]: Loss = 0.6645551919937134
Iteration [954]: Loss = 0.664371907711029
Iteration [955]: Loss = 0.6641756296157837
Iteration [956]: Loss = 0.663967490196228
Iteration [957]: Loss = 0.6637486815452576
Iteration [958]: Loss = 0.663520336151123
Iteration [959]: Loss = 0.6632832884788513
Iteration [960]: Loss = 0.6630386114120483
Iteration [961]: Loss = 0.6627868413925171
Iteration [962]: Loss = 0.6625288724899292
Iteration [963]: Loss = 0.6622651219367981
Iteration [964]: Loss = 5.153744697570801
Iteration [965]: Loss = 0.6619344353675842
Iteration [966]: Loss = 0.6618473529815674
Iteration [967]: Loss = 0.6617376804351807
Iteration [968]: Loss = 0.6616077423095703
Iteration [969]: Loss = 5.15681791305542
Iteration [970]: Loss = 5.156558513641357
Iteration [971]: Loss = 0.6617224812507629
Iteration [972]: Loss = 0.661887526512146
Iteration [973]: Loss = 0.6620053052902222
Iteration [974]: Loss = 0.6620801687240601
Iteration [975]: Loss = 0.6621167659759521
Iteration [976]: Loss = 0.6621185541152954
Iteration [977]: Loss = 5.153212547302246
Iteration [978]: Loss = 0.662239670753479
Iteration [979]: Loss = 0.6623443365097046
Iteration [980]: Loss = 0.6624074578285217
Iteration [981]: Loss = 0.662433385848999
Iteration [982]: Loss = 0.6624258160591125
Iteration [983]: Loss = 0.6623879075050354
Iteration [984]: Loss = 0.6623226404190063
Iteration [985]: Loss = 0.6622328162193298
Iteration [986]: Loss = 0.6621209979057312
Iteration [987]: Loss = 0.661989152431488
Iteration [988]: Loss = 0.6618394255638123
Iteration [989]: Loss = 0.6616734862327576
Iteration [990]: Loss = 0.6614928245544434
Iteration [991]: Loss = 0.6612992882728577
Iteration [992]: Loss = 5.158913612365723
Iteration [993]: Loss = 0.661087155342102
Iteration [994]: Loss = 0.6610504388809204
Iteration [995]: Loss = 0.6609862446784973
Iteration [996]: Loss = 9.659180641174316
Iteration [997]: Loss = 0.6611959934234619
Iteration [998]: Loss = 0.6614346504211426
Iteration [999]: Loss = 0.6616194844245911
Iteration [1000]: Loss = 5.155122756958008
Iteration [1001]: Loss = 0.662050187587738
Iteration [1002]: Loss = 0.662285327911377
Iteration [1003]: Loss = 0.6624668836593628
Iteration [1004]: Loss = 0.6626002192497253
Iteration [1005]: Loss = 0.6626901030540466
Iteration [1006]: Loss = 0.6627405881881714
Iteration [1007]: Loss = 0.6627559065818787
Iteration [1008]: Loss = 0.6627392172813416
Iteration [1009]: Loss = 0.6626938581466675
Iteration [1010]: Loss = 0.6626226305961609
Iteration [1011]: Loss = 0.6625280976295471
Iteration [1012]: Loss = 5.151364803314209
Iteration [1013]: Loss = 0.6624820828437805
Iteration [1014]: Loss = 0.662514328956604
Iteration [1015]: Loss = 0.6625131368637085
Iteration [1016]: Loss = 0.6624816656112671
Iteration [1017]: Loss = 0.6624230742454529
Iteration [1018]: Loss = 0.662339985370636
Iteration [1019]: Loss = 0.6622347831726074
Iteration [1020]: Loss = 0.6621096134185791
Iteration [1021]: Loss = 0.6619666218757629
Iteration [1022]: Loss = 0.6618073582649231
Iteration [1023]: Loss = 0.6616337299346924
Iteration [1024]: Loss = 5.156888961791992
Iteration [1025]: Loss = 5.15685510635376
Iteration [1026]: Loss = 5.155837059020996
Iteration [1027]: Loss = 0.6619616150856018
Iteration [1028]: Loss = 0.6622296571731567
Iteration [1029]: Loss = 5.1512017250061035
Iteration [1030]: Loss = 5.149141788482666
Iteration [1031]: Loss = 0.6632951498031616
Iteration [1032]: Loss = 0.6637101173400879
Iteration [1033]: Loss = 0.6640539169311523
Iteration [1034]: Loss = 0.6643336415290833
Iteration [1035]: Loss = 5.139147758483887
Iteration [1036]: Loss = 0.6649246215820312
Iteration [1037]: Loss = 0.6652270555496216
Iteration [1038]: Loss = 0.6654695868492126
Iteration [1039]: Loss = 0.6656579971313477
Iteration [1040]: Loss = 0.6657977104187012
Iteration [1041]: Loss = 0.6658934950828552
Iteration [1042]: Loss = 0.6659496426582336
Iteration [1043]: Loss = 0.6659700274467468
Iteration [1044]: Loss = 0.6659581661224365
Iteration [1045]: Loss = 0.6659175157546997
Iteration [1046]: Loss = 0.6658506989479065
Iteration [1047]: Loss = 0.6657601594924927
Iteration [1048]: Loss = 0.6656486392021179
Iteration [1049]: Loss = 0.6655178666114807
Iteration [1050]: Loss = 0.6653700470924377
Iteration [1051]: Loss = 0.6652066707611084
Iteration [1052]: Loss = 9.607881546020508
Iteration [1053]: Loss = 0.6652382612228394
Iteration [1054]: Loss = 5.134368896484375
Iteration [1055]: Loss = 0.6657061576843262
Iteration [1056]: Loss = 0.6659553050994873
Iteration [1057]: Loss = 0.6661502122879028
Iteration [1058]: Loss = 5.129271984100342
Iteration [1059]: Loss = 0.6665937304496765
Iteration [1060]: Loss = 0.6668323874473572
Iteration [1061]: Loss = 5.125189304351807
Iteration [1062]: Loss = 0.6673502922058105
Iteration [1063]: Loss = 0.6676203012466431
Iteration [1064]: Loss = 0.6678341031074524
Iteration [1065]: Loss = 0.6679971218109131
Iteration [1066]: Loss = 5.1189985275268555
Iteration [1067]: Loss = 0.6683856248855591
Iteration [1068]: Loss = 0.6686003804206848
Iteration [1069]: Loss = 0.6687643527984619
Iteration [1070]: Loss = 0.6688825488090515
Iteration [1071]: Loss = 0.6689594388008118
Iteration [1072]: Loss = 0.6689990162849426
Iteration [1073]: Loss = 0.6690050363540649
Iteration [1074]: Loss = 5.114119529724121
Iteration [1075]: Loss = 5.113307952880859
Iteration [1076]: Loss = 0.6694198846817017
Iteration [1077]: Loss = 0.6696562170982361
Iteration [1078]: Loss = 0.6698393821716309
Iteration [1079]: Loss = 0.6699748635292053
Iteration [1080]: Loss = 0.6700674891471863
Iteration [1081]: Loss = 0.6701213121414185
Iteration [1082]: Loss = 0.6701400876045227
Iteration [1083]: Loss = 0.6701275110244751
Iteration [1084]: Loss = 0.6700864434242249
Iteration [1085]: Loss = 0.6700199842453003
Iteration [1086]: Loss = 0.6699304580688477
Iteration [1087]: Loss = 0.6698200106620789
Iteration [1088]: Loss = 0.6696910858154297
Iteration [1089]: Loss = 0.6695452928543091
Iteration [1090]: Loss = 0.669384241104126
Iteration [1091]: Loss = 0.6692095994949341
Iteration [1092]: Loss = 0.6690227389335632
Iteration [1093]: Loss = 5.114997863769531
Iteration [1094]: Loss = 0.6688137054443359
Iteration [1095]: Loss = 0.6687741875648499
Iteration [1096]: Loss = 0.6687090396881104
Iteration [1097]: Loss = 0.668620765209198
Iteration [1098]: Loss = 0.668511688709259
Iteration [1099]: Loss = 0.668383777141571
Iteration [1100]: Loss = 0.6682389974594116
Iteration [1101]: Loss = 0.6680790185928345
Iteration [1102]: Loss = 0.6679053902626038
Iteration [1103]: Loss = 5.121227264404297
Iteration [1104]: Loss = 5.121228218078613
Iteration [1105]: Loss = 5.120293617248535
Iteration [1106]: Loss = 0.6681988835334778
Iteration [1107]: Loss = 0.6684523224830627
Iteration [1108]: Loss = 0.668651282787323
Iteration [1109]: Loss = 0.6688010692596436
Iteration [1110]: Loss = 0.6689064502716064
Iteration [1111]: Loss = 0.6689720153808594
Iteration [1112]: Loss = 0.669001579284668
Iteration [1113]: Loss = 0.6689985394477844
Iteration [1114]: Loss = 0.6689664721488953
Iteration [1115]: Loss = 0.6689080595970154
Iteration [1116]: Loss = 0.6688259243965149
Iteration [1117]: Loss = 0.6687222719192505
Iteration [1118]: Loss = 0.6685994863510132
Iteration [1119]: Loss = 0.6684592366218567
Iteration [1120]: Loss = 0.6683036684989929
Iteration [1121]: Loss = 0.6681337356567383
Iteration [1122]: Loss = 0.6679512858390808
Iteration [1123]: Loss = 0.6677573323249817
Iteration [1124]: Loss = 0.667553186416626
Iteration [1125]: Loss = 0.6673398017883301
Iteration [1126]: Loss = 0.6671180725097656
Iteration [1127]: Loss = 0.666888952255249
Iteration [1128]: Loss = 0.6666529178619385
Iteration [1129]: Loss = 9.590834617614746
Iteration [1130]: Loss = 0.6665546298027039
Iteration [1131]: Loss = 0.6666550040245056
Iteration [1132]: Loss = 0.666716456413269
Iteration [1133]: Loss = 0.6667426228523254
Iteration [1134]: Loss = 0.6667373180389404
Iteration [1135]: Loss = 0.6667032837867737
Iteration [1136]: Loss = 0.6666436791419983
Iteration [1137]: Loss = 5.127773761749268
Iteration [1138]: Loss = 0.6666507124900818
Iteration [1139]: Loss = 0.6667025685310364
Iteration [1140]: Loss = 0.6667201519012451
Iteration [1141]: Loss = 0.6667069792747498
Iteration [1142]: Loss = 0.6666661500930786
Iteration [1143]: Loss = 0.6666003465652466
Iteration [1144]: Loss = 0.6665117740631104
Iteration [1145]: Loss = 5.128666400909424
Iteration [1146]: Loss = 0.6664696931838989
Iteration [1147]: Loss = 5.128114223480225
Iteration [1148]: Loss = 5.1270318031311035
Iteration [1149]: Loss = 0.6670265197753906
Iteration [1150]: Loss = 5.123599529266357
Iteration [1151]: Loss = 0.6677061319351196
Iteration [1152]: Loss = 0.668043851852417
Iteration [1153]: Loss = 0.6683194637298584
Iteration [1154]: Loss = 0.6685386896133423
Iteration [1155]: Loss = 5.115659713745117
Iteration [1156]: Loss = 0.6690208911895752
Iteration [1157]: Loss = 0.6692744493484497
Iteration [1158]: Loss = 0.6694740056991577
Iteration [1159]: Loss = 0.6696248054504395
Iteration [1160]: Loss = 0.6697316765785217
Iteration [1161]: Loss = 0.6697989702224731
Iteration [1162]: Loss = 0.6698304414749146
Iteration [1163]: Loss = 0.6698298454284668
Iteration [1164]: Loss = 0.6698002815246582
Iteration [1165]: Loss = 0.6697445511817932
Iteration [1166]: Loss = 0.6696653366088867
Iteration [1167]: Loss = 5.110836029052734
Iteration [1168]: Loss = 0.6696375608444214
Iteration [1169]: Loss = 5.110222339630127
Iteration [1170]: Loss = 0.6698691248893738
Iteration [1171]: Loss = 5.108304023742676
Iteration [1172]: Loss = 0.67030930519104
Iteration [1173]: Loss = 0.6705447435379028
Iteration [1174]: Loss = 0.6707279682159424
Iteration [1175]: Loss = 5.103549003601074
Iteration [1176]: Loss = 0.6711475849151611
Iteration [1177]: Loss = 0.6713742017745972
Iteration [1178]: Loss = 0.671549379825592
Iteration [1179]: Loss = 5.098993301391602
Iteration [1180]: Loss = 0.6719551682472229
Iteration [1181]: Loss = 0.6721757054328918
Iteration [1182]: Loss = 0.6723455786705017
Iteration [1183]: Loss = 0.6724693775177002
Iteration [1184]: Loss = 0.6725519895553589
Iteration [1185]: Loss = 5.093861103057861
Iteration [1186]: Loss = 0.6727994084358215
Iteration [1187]: Loss = 0.6729523539543152
Iteration [1188]: Loss = 0.6730611324310303
Iteration [1189]: Loss = 5.090890884399414
Iteration [1190]: Loss = 0.6733531951904297
Iteration [1191]: Loss = 0.6735250949859619
Iteration [1192]: Loss = 0.673650860786438
Iteration [1193]: Loss = 0.6737352013587952
Iteration [1194]: Loss = 0.6737821698188782
Iteration [1195]: Loss = 0.6737954616546631
Iteration [1196]: Loss = 0.6737781763076782
Iteration [1197]: Loss = 0.6737337112426758
Iteration [1198]: Loss = 0.6736646294593811
Iteration [1199]: Loss = 0.6735732555389404
Iteration [1200]: Loss = 0.6734618544578552
Iteration [1201]: Loss = 0.6733325123786926
Iteration [1202]: Loss = 0.6731869578361511
Iteration [1203]: Loss = 0.6730268597602844
Iteration [1204]: Loss = 5.092432975769043
Iteration [1205]: Loss = 0.6728595495223999
Iteration [1206]: Loss = 0.6728362441062927
Iteration [1207]: Loss = 0.6727861762046814
Iteration [1208]: Loss = 0.6727120280265808
Iteration [1209]: Loss = 0.6726161241531372
Iteration [1210]: Loss = 0.6725008487701416
Iteration [1211]: Loss = 0.6723678112030029
Iteration [1212]: Loss = 0.6722190380096436
Iteration [1213]: Loss = 0.6720560193061829
Iteration [1214]: Loss = 5.097865104675293
Iteration [1215]: Loss = 0.6718842387199402
Iteration [1216]: Loss = 0.6718591451644897
Iteration [1217]: Loss = 5.09827184677124
Iteration [1218]: Loss = 0.6719225645065308
Iteration [1219]: Loss = 0.6719973087310791
Iteration [1220]: Loss = 0.6720357537269592
Iteration [1221]: Loss = 0.6720413565635681
Iteration [1222]: Loss = 0.6720174551010132
Iteration [1223]: Loss = 0.6719666719436646
Iteration [1224]: Loss = 5.097797393798828
Iteration [1225]: Loss = 0.6719869375228882
Iteration [1226]: Loss = 0.6720431447029114
Iteration [1227]: Loss = 0.6720649600028992
Iteration [1228]: Loss = 0.6720556616783142
Iteration [1229]: Loss = 0.6720181703567505
Iteration [1230]: Loss = 0.6719555258750916
Iteration [1231]: Loss = 0.6718699336051941
Iteration [1232]: Loss = 0.6717639565467834
Iteration [1233]: Loss = 0.6716394424438477
Iteration [1234]: Loss = 0.6714983582496643
Iteration [1235]: Loss = 5.100871562957764
Iteration [1236]: Loss = 0.6713641285896301
Iteration [1237]: Loss = 0.6713550090789795
Iteration [1238]: Loss = 0.6713177561759949
Iteration [1239]: Loss = 0.6712550520896912
Iteration [1240]: Loss = 0.6711697578430176
Iteration [1241]: Loss = 5.1024298667907715
Iteration [1242]: Loss = 0.6711308360099792
Iteration [1243]: Loss = 0.6711620092391968
Iteration [1244]: Loss = 0.671161413192749
Iteration [1245]: Loss = 0.6711317300796509
Iteration [1246]: Loss = 0.6710760593414307
Iteration [1247]: Loss = 0.6709969639778137
Iteration [1248]: Loss = 0.6708968281745911
Iteration [1249]: Loss = 0.6707774996757507
Iteration [1250]: Loss = 0.6706411242485046
Iteration [1251]: Loss = 0.6704893112182617
Iteration [1252]: Loss = 0.6703237295150757
Iteration [1253]: Loss = 0.6701455116271973
Iteration [1254]: Loss = 0.6699560880661011
Iteration [1255]: Loss = 5.10975980758667
Iteration [1256]: Loss = 0.6697399020195007
Iteration [1257]: Loss = 5.110099792480469
Iteration [1258]: Loss = 0.6698184609413147
Iteration [1259]: Loss = 0.669900119304657
Iteration [1260]: Loss = 0.6699446439743042
Iteration [1261]: Loss = 0.669955849647522
Iteration [1262]: Loss = 5.10874605178833
Iteration [1263]: Loss = 0.6700819134712219
Iteration [1264]: Loss = 0.670183539390564
Iteration [1265]: Loss = 0.6702462434768677
Iteration [1266]: Loss = 5.106856822967529
Iteration [1267]: Loss = 0.6704599857330322
Iteration [1268]: Loss = 0.6705988049507141
Iteration [1269]: Loss = 0.6706950664520264
Iteration [1270]: Loss = 0.6707528829574585
Iteration [1271]: Loss = 0.6707760691642761
Iteration [1272]: Loss = 0.6707680821418762
Iteration [1273]: Loss = 0.670731782913208
Iteration [1274]: Loss = 0.6706703305244446
Iteration [1275]: Loss = 0.6705859899520874
Iteration [1276]: Loss = 5.10569429397583
Iteration [1277]: Loss = 5.105315208435059
Iteration [1278]: Loss = 0.6707707643508911
Iteration [1279]: Loss = 0.6709418296813965
Iteration [1280]: Loss = 0.6710670590400696
Iteration [1281]: Loss = 0.6711511611938477
Iteration [1282]: Loss = 0.6711979508399963
Iteration [1283]: Loss = 0.6712111234664917
Iteration [1284]: Loss = 0.6711941957473755
Iteration [1285]: Loss = 0.6711499094963074
Iteration [1286]: Loss = 0.6710811257362366
Iteration [1287]: Loss = 0.6709903478622437
Iteration [1288]: Loss = 0.670879602432251
Iteration [1289]: Loss = 0.6707509160041809
Iteration [1290]: Loss = 0.6706060171127319
Iteration [1291]: Loss = 5.1058878898620605
Iteration [1292]: Loss = 5.105781555175781
Iteration [1293]: Loss = 0.6706438064575195
Iteration [1294]: Loss = 0.6707756519317627
Iteration [1295]: Loss = 0.6708654165267944
Iteration [1296]: Loss = 0.6709175109863281
Iteration [1297]: Loss = 0.6709354519844055
Iteration [1298]: Loss = 0.6709228754043579
Iteration [1299]: Loss = 5.103445053100586
Iteration [1300]: Loss = 0.6710076332092285
Iteration [1301]: Loss = 0.671091616153717
Iteration [1302]: Loss = 0.6711381673812866
Iteration [1303]: Loss = 0.671151340007782
Iteration [1304]: Loss = 5.102035045623779
Iteration [1305]: Loss = 0.6712802648544312
Iteration [1306]: Loss = 0.6713829040527344
Iteration [1307]: Loss = 0.6714464426040649
Iteration [1308]: Loss = 0.671474814414978
Iteration [1309]: Loss = 9.528826713562012
Iteration [1310]: Loss = 5.098232746124268
Iteration [1311]: Loss = 0.6722800731658936
Iteration [1312]: Loss = 0.6726715564727783
Iteration [1313]: Loss = 0.6729957461357117
Iteration [1314]: Loss = 0.6732594966888428
Iteration [1315]: Loss = 5.08900785446167
Iteration [1316]: Loss = 0.6738141775131226
Iteration [1317]: Loss = 0.6740971803665161
Iteration [1318]: Loss = 9.494182586669922
Iteration [1319]: Loss = 5.08125638961792
Iteration [1320]: Loss = 5.077707767486572
Iteration [1321]: Loss = 0.6762332320213318
Iteration [1322]: Loss = 0.6768630743026733
Iteration [1323]: Loss = 0.6774023771286011
Iteration [1324]: Loss = 0.6778602600097656
Iteration [1325]: Loss = 0.6782448291778564
Iteration [1326]: Loss = 0.6785628795623779
Iteration [1327]: Loss = 0.6788212060928345
Iteration [1328]: Loss = 0.679025411605835
Iteration [1329]: Loss = 0.6791812181472778
Iteration [1330]: Loss = 0.6792930364608765
Iteration [1331]: Loss = 0.6793654561042786
Iteration [1332]: Loss = 0.679402232170105
Iteration [1333]: Loss = 0.6794067621231079
Iteration [1334]: Loss = 0.6793826222419739
Iteration [1335]: Loss = 0.6793322563171387
Iteration [1336]: Loss = 0.6792585849761963
Iteration [1337]: Loss = 0.6791636943817139
Iteration [1338]: Loss = 0.6790497899055481
Iteration [1339]: Loss = 0.6789186596870422
Iteration [1340]: Loss = 0.6787723302841187
Iteration [1341]: Loss = 0.6786119341850281
Iteration [1342]: Loss = 0.6784390807151794
Iteration [1343]: Loss = 0.6782548427581787
Iteration [1344]: Loss = 0.6780606508255005
Iteration [1345]: Loss = 0.6778571605682373
Iteration [1346]: Loss = 0.6776455640792847
Iteration [1347]: Loss = 5.067080497741699
Iteration [1348]: Loss = 0.6773866415023804
Iteration [1349]: Loss = 0.6773223876953125
Iteration [1350]: Loss = 0.6772359609603882
Iteration [1351]: Loss = 5.0687174797058105
Iteration [1352]: Loss = 0.677190899848938
Iteration [1353]: Loss = 0.6772177219390869
Iteration [1354]: Loss = 0.6772133111953735
Iteration [1355]: Loss = 5.0684356689453125
Iteration [1356]: Loss = 0.6773082613945007
Iteration [1357]: Loss = 0.6773945093154907
Iteration [1358]: Loss = 0.6774437427520752
Iteration [1359]: Loss = 0.6774597764015198
Iteration [1360]: Loss = 0.6774457693099976
Iteration [1361]: Loss = 0.6774047613143921
Iteration [1362]: Loss = 0.677339494228363
Iteration [1363]: Loss = 0.6772522926330566
Iteration [1364]: Loss = 0.67714524269104
Iteration [1365]: Loss = 0.6770204305648804
Iteration [1366]: Loss = 0.6768796443939209
Iteration [1367]: Loss = 5.070955753326416
Iteration [1368]: Loss = 0.6767417192459106
Iteration [1369]: Loss = 0.6767290830612183
Iteration [1370]: Loss = 0.6766891479492188
Iteration [1371]: Loss = 5.071505069732666
Iteration [1372]: Loss = 0.6767235994338989
Iteration [1373]: Loss = 0.6767842173576355
Iteration [1374]: Loss = 0.6768104434013367
Iteration [1375]: Loss = 0.6768056154251099
Iteration [1376]: Loss = 0.676772952079773
Iteration [1377]: Loss = 0.6767151355743408
Iteration [1378]: Loss = 0.676634669303894
Iteration [1379]: Loss = 0.6765337586402893
Iteration [1380]: Loss = 0.6764143109321594
Iteration [1381]: Loss = 5.073418617248535
Iteration [1382]: Loss = 5.073226451873779
Iteration [1383]: Loss = 0.6765008568763733
Iteration [1384]: Loss = 0.676641583442688
Iteration [1385]: Loss = 5.0708699226379395
Iteration [1386]: Loss = 0.6769842505455017
Iteration [1387]: Loss = 0.6771759986877441
Iteration [1388]: Loss = 0.6773204207420349
Iteration [1389]: Loss = 0.6774221062660217
Iteration [1390]: Loss = 0.6774854063987732
Iteration [1391]: Loss = 0.6775140166282654
Iteration [1392]: Loss = 0.6775113344192505
Iteration [1393]: Loss = 5.066783428192139
Iteration [1394]: Loss = 9.454540252685547
Iteration [1395]: Loss = 0.6780584454536438
Iteration [1396]: Loss = 0.6784354448318481
Iteration [1397]: Loss = 0.6787469387054443
Iteration [1398]: Loss = 0.6789995431900024
Iteration [1399]: Loss = 0.6791991591453552
Iteration [1400]: Loss = 0.6793507933616638
Iteration [1401]: Loss = 0.6794592142105103
Iteration [1402]: Loss = 0.6795287132263184
Iteration [1403]: Loss = 0.6795631051063538
Iteration [1404]: Loss = 0.6795657873153687
Iteration [1405]: Loss = 5.055455684661865
Iteration [1406]: Loss = 0.6796715259552002
Iteration [1407]: Loss = 0.679761528968811
Iteration [1408]: Loss = 0.6798144578933716
Iteration [1409]: Loss = 0.6798338294029236
Iteration [1410]: Loss = 0.6798233389854431
Iteration [1411]: Loss = 0.6797855496406555
Iteration [1412]: Loss = 0.6797232627868652
Iteration [1413]: Loss = 0.6796389818191528
Iteration [1414]: Loss = 0.6795346736907959
Iteration [1415]: Loss = 0.679412841796875
Iteration [1416]: Loss = 0.6792746782302856
Iteration [1417]: Loss = 0.6791220307350159
Iteration [1418]: Loss = 5.058660507202148
Iteration [1419]: Loss = 0.6789625883102417
Iteration [1420]: Loss = 5.058751583099365
Iteration [1421]: Loss = 0.6790739893913269
Iteration [1422]: Loss = 0.6791665554046631
Iteration [1423]: Loss = 0.6792218685150146
Iteration [1424]: Loss = 0.6792434453964233
Iteration [1425]: Loss = 5.057132244110107
Iteration [1426]: Loss = 0.679381251335144
Iteration [1427]: Loss = 0.6794850826263428
Iteration [1428]: Loss = 0.6795505285263062
Iteration [1429]: Loss = 0.6795810461044312
Iteration [1430]: Loss = 5.055234432220459
Iteration [1431]: Loss = 0.6797342896461487
Iteration [1432]: Loss = 0.6798446178436279
Iteration [1433]: Loss = 0.6799157857894897
Iteration [1434]: Loss = 0.6799516081809998
Iteration [1435]: Loss = 0.6799557209014893
Iteration [1436]: Loss = 5.053311824798584
Iteration [1437]: Loss = 0.6800636649131775
Iteration [1438]: Loss = 0.6801546216011047
Iteration [1439]: Loss = 0.6802082657814026
Iteration [1440]: Loss = 5.051682949066162
Iteration [1441]: Loss = 5.050739288330078
Iteration [1442]: Loss = 0.6807091236114502
Iteration [1443]: Loss = 0.6809589266777039
Iteration [1444]: Loss = 0.681155800819397
Iteration [1445]: Loss = 0.6813048720359802
Iteration [1446]: Loss = 0.6814109086990356
Iteration [1447]: Loss = 0.6814781427383423
Iteration [1448]: Loss = 5.044672012329102
Iteration [1449]: Loss = 0.6816933751106262
Iteration [1450]: Loss = 5.0429277420043945
Iteration [1451]: Loss = 0.682106077671051
Iteration [1452]: Loss = 0.6823267936706543
Iteration [1453]: Loss = 0.6824972033500671
Iteration [1454]: Loss = 0.6826225519180298
Iteration [1455]: Loss = 0.6827071309089661
Iteration [1456]: Loss = 0.6827549338340759
Iteration [1457]: Loss = 0.6827698349952698
Iteration [1458]: Loss = 0.6827548146247864
Iteration [1459]: Loss = 0.682712972164154
Iteration [1460]: Loss = 0.6826469302177429
Iteration [1461]: Loss = 0.682559072971344
Iteration [1462]: Loss = 9.396623611450195
Iteration [1463]: Loss = 5.038246154785156
Iteration [1464]: Loss = 0.683053731918335
Iteration [1465]: Loss = 0.6833544969558716
Iteration [1466]: Loss = 0.6835975050926208
Iteration [1467]: Loss = 5.032266616821289
Iteration [1468]: Loss = 0.684111475944519
Iteration [1469]: Loss = 0.6843746304512024
Iteration [1470]: Loss = 0.6845837235450745
Iteration [1471]: Loss = 0.6847439408302307
Iteration [1472]: Loss = 0.6848602294921875
Iteration [1473]: Loss = 0.6849367618560791
Iteration [1474]: Loss = 0.6849774718284607
Iteration [1475]: Loss = 5.025770664215088
Iteration [1476]: Loss = 0.685145914554596
Iteration [1477]: Loss = 0.6852617263793945
Iteration [1478]: Loss = 0.6853379011154175
Iteration [1479]: Loss = 0.68537837266922
Iteration [1480]: Loss = 0.6853867173194885
Iteration [1481]: Loss = 0.6853659749031067
Iteration [1482]: Loss = 5.023968696594238
Iteration [1483]: Loss = 0.6854290962219238
Iteration [1484]: Loss = 0.6855001449584961
Iteration [1485]: Loss = 0.6855359077453613
Iteration [1486]: Loss = 0.6855400204658508
Iteration [1487]: Loss = 0.6855154037475586
Iteration [1488]: Loss = 0.6854651570320129
Iteration [1489]: Loss = 5.023575782775879
Iteration [1490]: Loss = 0.6854779124259949
Iteration [1491]: Loss = 0.6855273842811584
Iteration [1492]: Loss = 5.022752285003662
Iteration [1493]: Loss = 0.685710608959198
Iteration [1494]: Loss = 0.685832679271698
Iteration [1495]: Loss = 0.6859144568443298
Iteration [1496]: Loss = 0.6859598755836487
Iteration [1497]: Loss = 0.6859726309776306
Iteration [1498]: Loss = 0.6859559416770935
Iteration [1499]: Loss = 0.685912549495697
Iteration [1500]: Loss = 0.6858453750610352
Iteration [1501]: Loss = 0.685756504535675
Iteration [1502]: Loss = 5.022186756134033
Iteration [1503]: Loss = 0.6857036352157593
Iteration [1504]: Loss = 0.6857252717018127
Iteration [1505]: Loss = 0.6857163906097412
Iteration [1506]: Loss = 0.6856803297996521
Iteration [1507]: Loss = 0.6856194734573364
Iteration [1508]: Loss = 0.6855365037918091
Iteration [1509]: Loss = 5.023348808288574
Iteration [1510]: Loss = 0.6854935884475708
Iteration [1511]: Loss = 0.6855193376541138
Iteration [1512]: Loss = 0.6855143904685974
Iteration [1513]: Loss = 0.6854817271232605
Iteration [1514]: Loss = 0.6854239702224731
Iteration [1515]: Loss = 0.685343861579895
Iteration [1516]: Loss = 0.6852434873580933
Iteration [1517]: Loss = 0.6851247549057007
Iteration [1518]: Loss = 0.6849896311759949
Iteration [1519]: Loss = 5.026564121246338
Iteration [1520]: Loss = 0.6848578453063965
Iteration [1521]: Loss = 0.684846043586731
Iteration [1522]: Loss = 0.6848070621490479
Iteration [1523]: Loss = 0.6847438216209412
Iteration [1524]: Loss = 0.6846586465835571
Iteration [1525]: Loss = 0.6845537424087524
Iteration [1526]: Loss = 0.6844308376312256
Iteration [1527]: Loss = 0.6842921376228333
Iteration [1528]: Loss = 5.030364036560059
Iteration [1529]: Loss = 5.030279636383057
Iteration [1530]: Loss = 0.6843207478523254
Iteration [1531]: Loss = 0.6844424605369568
Iteration [1532]: Loss = 5.028275012969971
Iteration [1533]: Loss = 0.6847493648529053
Iteration [1534]: Loss = 0.6849244832992554
Iteration [1535]: Loss = 0.6850539445877075
Iteration [1536]: Loss = 0.6851423382759094
Iteration [1537]: Loss = 0.6851937770843506
Iteration [1538]: Loss = 0.6852118372917175
Iteration [1539]: Loss = 0.6851998567581177
Iteration [1540]: Loss = 0.6851608157157898
Iteration [1541]: Loss = 5.025168418884277
Iteration [1542]: Loss = 5.0246500968933105
Iteration [1543]: Loss = 0.6854314208030701
Iteration [1544]: Loss = 0.6856178641319275
Iteration [1545]: Loss = 0.6857574582099915
Iteration [1546]: Loss = 0.6858551502227783
Iteration [1547]: Loss = 0.6859147548675537
Iteration [1548]: Loss = 0.6859403252601624
Iteration [1549]: Loss = 0.6859349012374878
Iteration [1550]: Loss = 0.6859018206596375
Iteration [1551]: Loss = 0.6858437657356262
Iteration [1552]: Loss = 0.6857630610466003
Iteration [1553]: Loss = 0.6856620907783508
Iteration [1554]: Loss = 0.6855430006980896
Iteration [1555]: Loss = 0.6854073405265808
Iteration [1556]: Loss = 0.6852567791938782
Iteration [1557]: Loss = 0.6850931644439697
Iteration [1558]: Loss = 0.6849172711372375
Iteration [1559]: Loss = 0.6847307682037354
Iteration [1560]: Loss = 0.6845344305038452
Iteration [1561]: Loss = 0.6843293905258179
Iteration [1562]: Loss = 0.6841163635253906
Iteration [1563]: Loss = 0.6838964819908142
Iteration [1564]: Loss = 0.6836700439453125
Iteration [1565]: Loss = 0.6834379434585571
Iteration [1566]: Loss = 5.035460472106934
Iteration [1567]: Loss = 5.0357842445373535
Iteration [1568]: Loss = 0.6832411885261536
Iteration [1569]: Loss = 0.6833028793334961
Iteration [1570]: Loss = 0.6833302974700928
Iteration [1571]: Loss = 0.6833268404006958
Iteration [1572]: Loss = 0.6832953691482544
Iteration [1573]: Loss = 0.6832388639450073
Iteration [1574]: Loss = 0.6831597685813904
Iteration [1575]: Loss = 0.6830601692199707
Iteration [1576]: Loss = 0.6829423904418945
Iteration [1577]: Loss = 5.037598133087158
Iteration [1578]: Loss = 0.6828406453132629
Iteration [1579]: Loss = 0.6828420758247375
Iteration [1580]: Loss = 0.6828151941299438
Iteration [1581]: Loss = 0.6827625632286072
Iteration [1582]: Loss = 0.6826870441436768
Iteration [1583]: Loss = 5.038780212402344
Iteration [1584]: Loss = 0.6826576590538025
Iteration [1585]: Loss = 0.6826900243759155
Iteration [1586]: Loss = 0.6826906800270081
Iteration [1587]: Loss = 0.6826632022857666
Iteration [1588]: Loss = 0.6826101541519165
Iteration [1589]: Loss = 0.6825341582298279
Iteration [1590]: Loss = 0.6824374198913574
Iteration [1591]: Loss = 0.6823221445083618
Iteration [1592]: Loss = 0.6821900606155396
Iteration [1593]: Loss = 0.6820428967475891
Iteration [1594]: Loss = 0.6818820834159851
Iteration [1595]: Loss = 0.6817090511322021
Iteration [1596]: Loss = 0.6815249919891357
Iteration [1597]: Loss = 0.6813310980796814
Iteration [1598]: Loss = 0.6811281442642212
Iteration [1599]: Loss = 0.6809172630310059
Iteration [1600]: Loss = 0.6806990504264832
Iteration [1601]: Loss = 0.6804743409156799
Iteration [1602]: Loss = 0.6802438497543335
Iteration [1603]: Loss = 0.6800081133842468
Iteration [1604]: Loss = 0.6797675490379333
Iteration [1605]: Loss = 0.6795228123664856
Iteration [1606]: Loss = 0.679274320602417
Iteration [1607]: Loss = 0.6790223121643066
Iteration [1608]: Loss = 0.678767204284668
Iteration [1609]: Loss = 0.6785092353820801
Iteration [1610]: Loss = 0.6782488822937012
Iteration [1611]: Loss = 0.6779863834381104
Iteration [1612]: Loss = 0.6777217388153076
Iteration [1613]: Loss = 0.6774554252624512
Iteration [1614]: Loss = 0.677187442779541
Iteration [1615]: Loss = 0.6769179701805115
Iteration [1616]: Loss = 0.6766471862792969
Iteration [1617]: Loss = 0.6763753294944763
Iteration [1618]: Loss = 0.6761023998260498
Iteration [1619]: Loss = 0.6758285760879517
Iteration [1620]: Loss = 0.6755538582801819
Iteration [1621]: Loss = 5.07895565032959
Iteration [1622]: Loss = 0.6751867532730103
Iteration [1623]: Loss = 0.6750763654708862
Iteration [1624]: Loss = 0.6749486327171326
Iteration [1625]: Loss = 5.081575870513916
Iteration [1626]: Loss = 0.674832820892334
Iteration [1627]: Loss = 0.6748292446136475
Iteration [1628]: Loss = 0.6747980117797852
Iteration [1629]: Loss = 0.6747416257858276
Iteration [1630]: Loss = 5.08236837387085
Iteration [1631]: Loss = 0.6747477054595947
Iteration [1632]: Loss = 9.48846435546875
Iteration [1633]: Loss = 0.6751728057861328
Iteration [1634]: Loss = 0.6754844188690186
Iteration [1635]: Loss = 0.6757376194000244
Iteration [1636]: Loss = 0.6759379506111145
Iteration [1637]: Loss = 0.6760905981063843
Iteration [1638]: Loss = 0.6762003898620605
Iteration [1639]: Loss = 0.676271378993988
Iteration [1640]: Loss = 0.6763075590133667
Iteration [1641]: Loss = 0.6763123273849487
Iteration [1642]: Loss = 0.6762887835502625
Iteration [1643]: Loss = 0.6762396693229675
Iteration [1644]: Loss = 0.6761676073074341
Iteration [1645]: Loss = 0.6760748624801636
Iteration [1646]: Loss = 0.6759635210037231
Iteration [1647]: Loss = 5.075870513916016
Iteration [1648]: Loss = 5.075654983520508
Iteration [1649]: Loss = 0.6760625839233398
Iteration [1650]: Loss = 0.6762045621871948
Iteration [1651]: Loss = 0.6763044595718384
Iteration [1652]: Loss = 0.6763666868209839
Iteration [1653]: Loss = 0.6763949990272522
Iteration [1654]: Loss = 0.6763925552368164
Iteration [1655]: Loss = 0.6763625144958496
Iteration [1656]: Loss = 0.6763075590133667
Iteration [1657]: Loss = 5.073685646057129
Iteration [1658]: Loss = 0.6763145923614502
Iteration [1659]: Loss = 0.6763627529144287
Iteration [1660]: Loss = 0.6763782501220703
Iteration [1661]: Loss = 5.072944641113281
Iteration [1662]: Loss = 0.6765053868293762
Iteration [1663]: Loss = 0.676604688167572
Iteration [1664]: Loss = 0.6766661405563354
Iteration [1665]: Loss = 0.6766937971115112
Iteration [1666]: Loss = 0.6766908764839172
Iteration [1667]: Loss = 0.6766602993011475
Iteration [1668]: Loss = 5.071616172790527
Iteration [1669]: Loss = 5.071042060852051
Iteration [1670]: Loss = 0.6769552230834961
Iteration [1671]: Loss = 5.068607807159424
Iteration [1672]: Loss = 0.6774770617485046
Iteration [1673]: Loss = 0.6777442693710327
Iteration [1674]: Loss = 0.6779571175575256
Iteration [1675]: Loss = 5.063254356384277
Iteration [1676]: Loss = 0.6784212589263916
Iteration [1677]: Loss = 0.6786637306213379
Iteration [1678]: Loss = 5.059221267700195
Iteration [1679]: Loss = 0.6791782379150391
Iteration [1680]: Loss = 0.6794421076774597
Iteration [1681]: Loss = 0.6796519160270691
Iteration [1682]: Loss = 0.679813027381897
Iteration [1683]: Loss = 5.053316593170166
Iteration [1684]: Loss = 0.6801881194114685
Iteration [1685]: Loss = 5.050783634185791
Iteration [1686]: Loss = 0.6807286739349365
Iteration [1687]: Loss = 0.6810033917427063
Iteration [1688]: Loss = 0.6812229752540588
Iteration [1689]: Loss = 5.045314788818359
Iteration [1690]: Loss = 0.6816977858543396
Iteration [1691]: Loss = 0.6819443106651306
Iteration [1692]: Loss = 0.6821386218070984
Iteration [1693]: Loss = 0.6822855472564697
Iteration [1694]: Loss = 0.6823898553848267
Iteration [1695]: Loss = 0.682455837726593
Iteration [1696]: Loss = 0.6824873089790344
Iteration [1697]: Loss = 0.682487428188324
Iteration [1698]: Loss = 0.6824595928192139
Iteration [1699]: Loss = 0.6824062466621399
Iteration [1700]: Loss = 0.682330310344696
Iteration [1701]: Loss = 0.6822338104248047
Iteration [1702]: Loss = 0.6821187734603882
Iteration [1703]: Loss = 5.042069911956787
Iteration [1704]: Loss = 0.6820218563079834
Iteration [1705]: Loss = 0.6820250749588013
Iteration [1706]: Loss = 0.6819998025894165
Iteration [1707]: Loss = 0.6819491386413574
Iteration [1708]: Loss = 0.6818754076957703
Iteration [1709]: Loss = 0.6817809343338013
Iteration [1710]: Loss = 0.6816676259040833
Iteration [1711]: Loss = 0.6815376281738281
Iteration [1712]: Loss = 5.045315742492676
Iteration [1713]: Loss = 0.6814152598381042
Iteration [1714]: Loss = 0.6814076900482178
Iteration [1715]: Loss = 0.6813730001449585
Iteration [1716]: Loss = 0.6813134551048279
Iteration [1717]: Loss = 5.0461931228637695
Iteration [1718]: Loss = 0.6813117861747742
Iteration [1719]: Loss = 0.6813554763793945
Iteration [1720]: Loss = 0.6813669800758362
Iteration [1721]: Loss = 0.6813492178916931
Iteration [1722]: Loss = 0.6813051104545593
Iteration [1723]: Loss = 0.6812373399734497
Iteration [1724]: Loss = 0.6811482906341553
Iteration [1725]: Loss = 0.6810399889945984
Iteration [1726]: Loss = 0.6809142231941223
Iteration [1727]: Loss = 0.680773138999939
Iteration [1728]: Loss = 0.6806178092956543
Iteration [1729]: Loss = 0.6804500222206116
Iteration [1730]: Loss = 0.6802706718444824
Iteration [1731]: Loss = 0.680081307888031
Iteration [1732]: Loss = 0.6798826456069946
Iteration [1733]: Loss = 0.6796756982803345
Iteration [1734]: Loss = 0.6794612407684326
Iteration [1735]: Loss = 0.6792401671409607
Iteration [1736]: Loss = 0.6790130734443665
Iteration [1737]: Loss = 5.059628009796143
Iteration [1738]: Loss = 0.67872554063797
Iteration [1739]: Loss = 0.6786482334136963
Iteration [1740]: Loss = 0.6785505414009094
Iteration [1741]: Loss = 0.6784347295761108
Iteration [1742]: Loss = 0.6783021688461304
Iteration [1743]: Loss = 0.6781548261642456
Iteration [1744]: Loss = 0.6779942512512207
Iteration [1745]: Loss = 5.06490421295166
Iteration [1746]: Loss = 0.6778205633163452
Iteration [1747]: Loss = 0.6777918338775635
Iteration [1748]: Loss = 5.065364360809326
Iteration [1749]: Loss = 0.6778433322906494
Iteration [1750]: Loss = 0.677910327911377
Iteration [1751]: Loss = 0.6779427528381348
Iteration [1752]: Loss = 0.6779439449310303
Iteration [1753]: Loss = 0.6779168248176575
Iteration [1754]: Loss = 5.064665794372559
Iteration [1755]: Loss = 0.6779717206954956
Iteration [1756]: Loss = 0.6780399680137634
Iteration [1757]: Loss = 0.678073525428772
Iteration [1758]: Loss = 0.6780757904052734
Iteration [1759]: Loss = 0.6780498027801514
Iteration [1760]: Loss = 0.6779983639717102
Iteration [1761]: Loss = 0.6779240965843201
Iteration [1762]: Loss = 0.6778291463851929
Iteration [1763]: Loss = 0.6777156591415405
Iteration [1764]: Loss = 0.6775853633880615
Iteration [1765]: Loss = 0.6774399280548096
Iteration [1766]: Loss = 0.6772811412811279
Iteration [1767]: Loss = 0.6771100759506226
Iteration [1768]: Loss = 0.6769279837608337
Iteration [1769]: Loss = 0.676736056804657
Iteration [1770]: Loss = 5.072000503540039
Iteration [1771]: Loss = 0.6765094995498657
Iteration [1772]: Loss = 0.6764582395553589
Iteration [1773]: Loss = 0.6763842701911926
Iteration [1774]: Loss = 5.073357582092285
Iteration [1775]: Loss = 5.07297420501709
Iteration [1776]: Loss = 5.071777820587158
Iteration [1777]: Loss = 0.676923394203186
Iteration [1778]: Loss = 5.0682806968688965
Iteration [1779]: Loss = 0.6776189208030701
Iteration [1780]: Loss = 0.6779603362083435
Iteration [1781]: Loss = 0.6782400012016296
Iteration [1782]: Loss = 0.6784641146659851
Iteration [1783]: Loss = 0.6786379814147949
Iteration [1784]: Loss = 5.059704303741455
Iteration [1785]: Loss = 0.6790353655815125
Iteration [1786]: Loss = 0.67924964427948
Iteration [1787]: Loss = 0.6794146299362183
Iteration [1788]: Loss = 0.6795351505279541
Iteration [1789]: Loss = 0.6796157360076904
Iteration [1790]: Loss = 0.6796603798866272
Iteration [1791]: Loss = 5.054730415344238
Iteration [1792]: Loss = 0.679836630821228
Iteration [1793]: Loss = 0.6799566745758057
Iteration [1794]: Loss = 0.6800366044044495
Iteration [1795]: Loss = 0.6800805926322937
Iteration [1796]: Loss = 0.6800923347473145
Iteration [1797]: Loss = 0.6800745725631714
Iteration [1798]: Loss = 0.6800304651260376
Iteration [1799]: Loss = 0.6799626350402832
Iteration [1800]: Loss = 0.679873526096344
Iteration [1801]: Loss = 0.6797652244567871
Iteration [1802]: Loss = 0.679639458656311
Iteration [1803]: Loss = 5.055685997009277
Iteration [1804]: Loss = 0.6795251369476318
Iteration [1805]: Loss = 0.6795215010643005
Iteration [1806]: Loss = 0.6794901490211487
Iteration [1807]: Loss = 0.6794337034225464
Iteration [1808]: Loss = 5.056472301483154
Iteration [1809]: Loss = 5.056016445159912
Iteration [1810]: Loss = 0.6796660423278809
Iteration [1811]: Loss = 0.6798434853553772
Iteration [1812]: Loss = 0.6799754500389099
Iteration [1813]: Loss = 0.6800659894943237
Iteration [1814]: Loss = 0.6801195740699768
Iteration [1815]: Loss = 0.6801397204399109
Iteration [1816]: Loss = 5.052224159240723
Iteration [1817]: Loss = 0.6802743077278137
Iteration [1818]: Loss = 0.6803765892982483
Iteration [1819]: Loss = 0.6804405450820923
Iteration [1820]: Loss = 0.6804699897766113
Iteration [1821]: Loss = 0.6804684400558472
Iteration [1822]: Loss = 0.6804389953613281
Iteration [1823]: Loss = 5.050829887390137
Iteration [1824]: Loss = 0.6804888248443604
Iteration [1825]: Loss = 5.049895286560059
Iteration [1826]: Loss = 0.6807675957679749
Iteration [1827]: Loss = 0.6809312105178833
Iteration [1828]: Loss = 5.04718542098999
Iteration [1829]: Loss = 0.6813106536865234
Iteration [1830]: Loss = 0.6815170049667358
Iteration [1831]: Loss = 0.6816749572753906
Iteration [1832]: Loss = 0.6817889213562012
Iteration [1833]: Loss = 0.6818633675575256
Iteration [1834]: Loss = 0.6819023489952087
Iteration [1835]: Loss = 0.6819092035293579
Iteration [1836]: Loss = 0.6818873882293701
Iteration [1837]: Loss = 5.042876243591309
Iteration [1838]: Loss = 5.042274475097656
Iteration [1839]: Loss = 5.040898323059082
Iteration [1840]: Loss = 0.6825814843177795
Iteration [1841]: Loss = 0.6828952431678772
Iteration [1842]: Loss = 5.03573751449585
Iteration [1843]: Loss = 5.033664703369141
Iteration [1844]: Loss = 0.6840258836746216
Iteration [1845]: Loss = 0.6844435930252075
Iteration [1846]: Loss = 0.6847918033599854
Iteration [1847]: Loss = 0.6850773096084595
Iteration [1848]: Loss = 0.6853063702583313
Iteration [1849]: Loss = 0.6854844093322754
Iteration [1850]: Loss = 0.6856164336204529
Iteration [1851]: Loss = 0.6857072114944458
Iteration [1852]: Loss = 5.021580696105957
Iteration [1853]: Loss = 0.6859610676765442
Iteration [1854]: Loss = 9.353233337402344
Iteration [1855]: Loss = 0.6865783333778381
Iteration [1856]: Loss = 0.6869691014289856
Iteration [1857]: Loss = 0.6872931718826294
Iteration [1858]: Loss = 0.68755704164505
Iteration [1859]: Loss = 0.6877666711807251
Iteration [1860]: Loss = 0.6879273653030396
Iteration [1861]: Loss = 0.6889479160308838
Iteration [1862]: Loss = 0.6890218257904053
Iteration [1863]: Loss = 0.6890573501586914
Iteration [1864]: Loss = 0.6890580058097839
Iteration [1865]: Loss = 0.6890276670455933
Iteration [1866]: Loss = 0.6889691352844238
Iteration [1867]: Loss = 0.6888852715492249
Iteration [1868]: Loss = 0.6887785792350769
Iteration [1869]: Loss = 0.6886515617370605
Iteration [1870]: Loss = 0.6885058879852295
Iteration [1871]: Loss = 0.6883436441421509
Iteration [1872]: Loss = 5.008611679077148
Iteration [1873]: Loss = 0.6881744265556335
Iteration [1874]: Loss = 0.6881504654884338
Iteration [1875]: Loss = 0.6880979537963867
Iteration [1876]: Loss = 0.6880195140838623
Iteration [1877]: Loss = 0.6870337128639221
Iteration [1878]: Loss = 5.015367031097412
Iteration [1879]: Loss = 0.6878518462181091
Iteration [1880]: Loss = 0.6878718137741089
Iteration [1881]: Loss = 0.6878587603569031
Iteration [1882]: Loss = 5.010496139526367
Iteration [1883]: Loss = 0.6879440546035767
Iteration [1884]: Loss = 5.009354114532471
Iteration [1885]: Loss = 0.6882702112197876
Iteration [1886]: Loss = 0.6884570121765137
Iteration [1887]: Loss = 0.6885943412780762
Iteration [1888]: Loss = 0.6886870861053467
Iteration [1889]: Loss = 0.688739538192749
Iteration [1890]: Loss = 0.6887557506561279
Iteration [1891]: Loss = 5.005533695220947
Iteration [1892]: Loss = 0.6888906359672546
Iteration [1893]: Loss = 0.6889960765838623
Iteration [1894]: Loss = 0.6890599131584167
Iteration [1895]: Loss = 0.6890863180160522
Iteration [1896]: Loss = 0.689079225063324
Iteration [1897]: Loss = 5.003911018371582
Iteration [1898]: Loss = 0.6891741752624512
Iteration [1899]: Loss = 0.6892622709274292
Iteration [1900]: Loss = 0.6893108487129211
Iteration [1901]: Loss = 5.002401351928711
Iteration [1902]: Loss = 0.6895003914833069
Iteration [1903]: Loss = 5.0007643699646
Iteration [1904]: Loss = 0.6899092793464661
Iteration [1905]: Loss = 0.6901310682296753
Iteration [1906]: Loss = 0.6903000473976135
Iteration [1907]: Loss = 0.6904210448265076
Iteration [1908]: Loss = 4.99610710144043
Iteration [1909]: Loss = 0.690734326839447
Iteration [1910]: Loss = 0.6909152269363403
Iteration [1911]: Loss = 0.6910472512245178
Iteration [1912]: Loss = 4.992709636688232
Iteration [1913]: Loss = 0.6913724541664124
Iteration [1914]: Loss = 0.6915455460548401
Iteration [1915]: Loss = 0.6916729807853699
Iteration [1916]: Loss = 0.6917593479156494
Iteration [1917]: Loss = 0.6918086409568787
Iteration [1918]: Loss = 0.6918246746063232
Iteration [1919]: Loss = 0.691810667514801
Iteration [1920]: Loss = 0.6917694807052612
Iteration [1921]: Loss = 0.6917039155960083
Iteration [1922]: Loss = 0.6916164755821228
Iteration [1923]: Loss = 0.6915092468261719
Iteration [1924]: Loss = 0.6913841962814331
Iteration [1925]: Loss = 0.691243052482605
Iteration [1926]: Loss = 0.6910874247550964
Iteration [1927]: Loss = 0.690919041633606
Iteration [1928]: Loss = 4.994826316833496
Iteration [1929]: Loss = 0.6907289028167725
Iteration [1930]: Loss = 0.6906915307044983
Iteration [1931]: Loss = 0.6906294822692871
Iteration [1932]: Loss = 4.995861530303955
Iteration [1933]: Loss = 4.995454788208008
Iteration [1934]: Loss = 0.6908408999443054
Iteration [1935]: Loss = 0.6910104155540466
Iteration [1936]: Loss = 0.6911345720291138
Iteration [1937]: Loss = 4.992265701293945
Iteration [1938]: Loss = 4.991058349609375
Iteration [1939]: Loss = 0.6917990446090698
Iteration [1940]: Loss = 0.6920900344848633
Iteration [1941]: Loss = 0.6923236846923828
Iteration [1942]: Loss = 0.6925057172775269
Iteration [1943]: Loss = 0.6926411390304565
Iteration [1944]: Loss = 0.6927347183227539
Iteration [1945]: Loss = 0.6927904486656189
Iteration [1946]: Loss = 0.6928121447563171
Iteration [1947]: Loss = 0.6928030848503113
Iteration [1948]: Loss = 0.6927663683891296
Iteration [1949]: Loss = 4.984347343444824
Iteration [1950]: Loss = 4.983835220336914
Iteration [1951]: Loss = 0.6930387020111084
Iteration [1952]: Loss = 4.98158597946167
Iteration [1953]: Loss = 4.979899883270264
Iteration [1954]: Loss = 0.6939780712127686
Iteration [1955]: Loss = 0.6943426132202148
Iteration [1956]: Loss = 0.6946424841880798
Iteration [1957]: Loss = 0.6948840022087097
Iteration [1958]: Loss = 0.6950730681419373
Iteration [1959]: Loss = 0.6952148675918579
Iteration [1960]: Loss = 0.6953137516975403
Iteration [1961]: Loss = 0.6953743696212769
Iteration [1962]: Loss = 0.6954002976417542
Iteration [1963]: Loss = 0.6953948736190796
Iteration [1964]: Loss = 0.6953613758087158
Iteration [1965]: Loss = 0.6953025460243225
Iteration [1966]: Loss = 0.6952208280563354
Iteration [1967]: Loss = 0.6951186060905457
Iteration [1968]: Loss = 0.6949979662895203
Iteration [1969]: Loss = 0.6948605179786682
Iteration [1970]: Loss = 0.6947081089019775
Iteration [1971]: Loss = 0.6945421695709229
Iteration [1972]: Loss = 0.694364070892334
Iteration [1973]: Loss = 0.6941751837730408
Iteration [1974]: Loss = 0.6939764022827148
Iteration [1975]: Loss = 0.6937686800956726
Iteration [1976]: Loss = 0.6935529708862305
Iteration [1977]: Loss = 0.6933301687240601
Iteration [1978]: Loss = 0.6931009292602539
Iteration [1979]: Loss = 0.6928659677505493
Iteration [1980]: Loss = 0.6926257014274597
Iteration [1981]: Loss = 0.6923808455467224
Iteration [1982]: Loss = 4.987397193908691
Iteration [1983]: Loss = 0.6920603513717651
Iteration [1984]: Loss = 4.988271713256836
Iteration [1985]: Loss = 0.6920359134674072
Iteration [1986]: Loss = 4.987730026245117
Iteration [1987]: Loss = 0.6922506093978882
Iteration [1988]: Loss = 0.6923856139183044
Iteration [1989]: Loss = 0.6924786567687988
Iteration [1990]: Loss = 0.6925337910652161
Iteration [1991]: Loss = 0.6925548911094666
Iteration [1992]: Loss = 0.6925452351570129
Iteration [1993]: Loss = 0.6925081014633179
Iteration [1994]: Loss = 0.6924459934234619
Iteration [1995]: Loss = 0.6923612952232361
Iteration [1996]: Loss = 4.98673152923584
Iteration [1997]: Loss = 0.6923147439956665
Iteration [1998]: Loss = 13.574213027954102
Iteration [1999]: Loss = 0.692857027053833
Iteration [2000]: Loss = 0.6932966709136963
Iteration [2001]: Loss = 0.6936650276184082
Iteration [2002]: Loss = 0.6939690113067627
Iteration [2003]: Loss = 0.6942148208618164
Iteration [2004]: Loss = 0.6944082379341125
Iteration [2005]: Loss = 0.6945547461509705
Iteration [2006]: Loss = 0.6946584582328796
Iteration [2007]: Loss = 0.694723904132843
Iteration [2008]: Loss = 0.694754958152771
Iteration [2009]: Loss = 0.6947547197341919
Iteration [2010]: Loss = 0.6947264075279236
Iteration [2011]: Loss = 0.6946729421615601
Iteration [2012]: Loss = 0.6945967674255371
Iteration [2013]: Loss = 0.6945000290870667
Iteration [2014]: Loss = 0.6943849921226501
Iteration [2015]: Loss = 9.258001327514648
Iteration [2016]: Loss = 4.975043296813965
Iteration [2017]: Loss = 0.6947885155677795
Iteration [2018]: Loss = 0.6950586438179016
Iteration [2019]: Loss = 0.6952739953994751
Iteration [2020]: Loss = 0.6954402923583984
Iteration [2021]: Loss = 0.6955621838569641
Iteration [2022]: Loss = 0.6956441402435303
Iteration [2023]: Loss = 4.968526363372803
Iteration [2024]: Loss = 0.6958782076835632
Iteration [2025]: Loss = 0.6960198283195496
Iteration [2026]: Loss = 0.6961195468902588
Iteration [2027]: Loss = 0.6961814761161804
Iteration [2028]: Loss = 4.965786457061768
Iteration [2029]: Loss = 0.6963812112808228
Iteration [2030]: Loss = 0.6965081095695496
Iteration [2031]: Loss = 0.6965945959091187
Iteration [2032]: Loss = 0.6966444253921509
Iteration [2033]: Loss = 0.6966612935066223
Iteration [2034]: Loss = 0.6966486573219299
Iteration [2035]: Loss = 0.6966092586517334
Iteration [2036]: Loss = 0.6965457797050476
Iteration [2037]: Loss = 0.6964607238769531
Iteration [2038]: Loss = 4.965012550354004
Iteration [2039]: Loss = 0.6964094042778015
Iteration [2040]: Loss = 4.964625358581543
Iteration [2041]: Loss = 0.6965945959091187
Iteration [2042]: Loss = 0.6967154145240784
Iteration [2043]: Loss = 0.696796178817749
Iteration [2044]: Loss = 4.962456703186035
Iteration [2045]: Loss = 0.6970282793045044
Iteration [2046]: Loss = 9.22429084777832
Iteration [2047]: Loss = 0.6976128220558167
Iteration [2048]: Loss = 0.6979849338531494
Iteration [2049]: Loss = 0.6982924938201904
Iteration [2050]: Loss = 0.6985418796539307
Iteration [2051]: Loss = 4.952486038208008
Iteration [2052]: Loss = 0.69906085729599
Iteration [2053]: Loss = 0.6993233561515808
Iteration [2054]: Loss = 0.6995320916175842
Iteration [2055]: Loss = 0.6996921896934509
Iteration [2056]: Loss = 0.6998084187507629
Iteration [2057]: Loss = 0.6998852491378784
Iteration [2058]: Loss = 4.946266174316406
Iteration [2059]: Loss = 0.7001093626022339
Iteration [2060]: Loss = 0.7002460956573486
Iteration [2061]: Loss = 0.7003411650657654
Iteration [2062]: Loss = 0.7003990411758423
Iteration [2063]: Loss = 0.7004230618476868
Iteration [2064]: Loss = 4.9437031745910645
Iteration [2065]: Loss = 0.7005569338798523
Iteration [2066]: Loss = 0.7006553411483765
Iteration [2067]: Loss = 0.7007158398628235
Iteration [2068]: Loss = 0.7007424235343933
Iteration [2069]: Loss = 0.7007383108139038
Iteration [2070]: Loss = 0.7007066011428833
Iteration [2071]: Loss = 0.7006500363349915
Iteration [2072]: Loss = 0.7005711197853088
Iteration [2073]: Loss = 4.943415641784668
Iteration [2074]: Loss = 0.7005288600921631
Iteration [2075]: Loss = 0.7005522847175598
Iteration [2076]: Loss = 0.7005453109741211
Iteration [2077]: Loss = 0.70051109790802
Iteration [2078]: Loss = 0.7004522085189819
Iteration [2079]: Loss = 0.7003712058067322
Iteration [2080]: Loss = 0.7002701163291931
Iteration [2081]: Loss = 0.7001510262489319
Iteration [2082]: Loss = 0.7000157237052917
Iteration [2083]: Loss = 0.6998659372329712
Iteration [2084]: Loss = 0.6997030973434448
Iteration [2085]: Loss = 4.9483489990234375
Iteration [2086]: Loss = 0.6995179653167725
Iteration [2087]: Loss = 0.6994805335998535
Iteration [2088]: Loss = 0.699418842792511
Iteration [2089]: Loss = 0.6993352770805359
Iteration [2090]: Loss = 0.6992321014404297
Iteration [2091]: Loss = 0.6991111040115356
Iteration [2092]: Loss = 0.6989741325378418
Iteration [2093]: Loss = 0.6988227367401123
Iteration [2094]: Loss = 4.952905654907227
Iteration [2095]: Loss = 0.6974796652793884
Iteration [2096]: Loss = 0.6974510550498962
Iteration [2097]: Loss = 0.6973971724510193
Iteration [2098]: Loss = 0.6973209381103516
Iteration [2099]: Loss = 0.6972241997718811
Iteration [2100]: Loss = 0.6971093416213989
Iteration [2101]: Loss = 0.6969776749610901
Iteration [2102]: Loss = 0.6968313455581665
Iteration [2103]: Loss = 0.6966716051101685
Iteration [2104]: Loss = 0.6964999437332153
Iteration [2105]: Loss = 0.6963173151016235
Iteration [2106]: Loss = 4.966231346130371
Iteration [2107]: Loss = 0.6960994601249695
Iteration [2108]: Loss = 0.6960485577583313
Iteration [2109]: Loss = 0.6959747672080994
Iteration [2110]: Loss = 0.6958804726600647
Iteration [2111]: Loss = 0.6957676410675049
Iteration [2112]: Loss = 0.6956380605697632
Iteration [2113]: Loss = 0.6954934597015381
Iteration [2114]: Loss = 0.6953353881835938
Iteration [2115]: Loss = 0.6951651573181152
Iteration [2116]: Loss = 0.694983959197998
Iteration [2117]: Loss = 0.6947929263114929
Iteration [2118]: Loss = 4.974327564239502
Iteration [2119]: Loss = 0.6945610642433167
Iteration [2120]: Loss = 0.6945043206214905
Iteration [2121]: Loss = 4.975214958190918
Iteration [2122]: Loss = 0.6945019364356995
Iteration [2123]: Loss = 0.6945430040359497
Iteration [2124]: Loss = 4.974544048309326
Iteration [2125]: Loss = 4.973721027374268
Iteration [2126]: Loss = 4.972204208374023
Iteration [2127]: Loss = 0.6953984498977661
Iteration [2128]: Loss = 4.968289852142334
Iteration [2129]: Loss = 4.965920448303223
Iteration [2130]: Loss = 0.6967337131500244
Iteration [2131]: Loss = 0.6972013711929321
Iteration [2132]: Loss = 0.6975947618484497
Iteration [2133]: Loss = 0.6979214549064636
Iteration [2134]: Loss = 4.9553751945495605
Iteration [2135]: Loss = 0.6985734105110168
Iteration [2136]: Loss = 0.6988929510116577
Iteration [2137]: Loss = 0.6991528272628784
Iteration [2138]: Loss = 0.6993589997291565
Iteration [2139]: Loss = 0.6995165348052979
Iteration [2140]: Loss = 0.6996303796768188
Iteration [2141]: Loss = 0.6997048854827881
Iteration [2142]: Loss = 0.6997437477111816
Iteration [2143]: Loss = 0.6997508406639099
Iteration [2144]: Loss = 0.6997289061546326
Iteration [2145]: Loss = 0.6996809840202332
Iteration [2146]: Loss = 0.6996098756790161
Iteration [2147]: Loss = 0.6995177268981934
Iteration [2148]: Loss = 0.6994065046310425
Iteration [2149]: Loss = 0.6992781758308411
Iteration [2150]: Loss = 0.6991345882415771
Iteration [2151]: Loss = 0.6989771127700806
Iteration [2152]: Loss = 0.6988071203231812
Iteration [2153]: Loss = 0.6986259818077087
Iteration [2154]: Loss = 0.6984348297119141
Iteration [2155]: Loss = 0.698234498500824
Iteration [2156]: Loss = 0.6980261206626892
Iteration [2157]: Loss = 0.6978102922439575
Iteration [2158]: Loss = 0.6975879073143005
Iteration [2159]: Loss = 0.6973596215248108
Iteration [2160]: Loss = 0.6971259713172913
Iteration [2161]: Loss = 0.6968874335289001
Iteration [2162]: Loss = 0.69664466381073
Iteration [2163]: Loss = 0.6963981986045837
Iteration [2164]: Loss = 0.6961479783058167
Iteration [2165]: Loss = 0.6958947777748108
Iteration [2166]: Loss = 0.6956387758255005
Iteration [2167]: Loss = 0.6953802108764648
Iteration [2168]: Loss = 0.6951194405555725
Iteration [2169]: Loss = 0.6948565244674683
Iteration [2170]: Loss = 0.6945919990539551
Iteration [2171]: Loss = 0.6943258047103882
Iteration [2172]: Loss = 0.6940580010414124
Iteration [2173]: Loss = 4.978588104248047
Iteration [2174]: Loss = 0.6936958432197571
Iteration [2175]: Loss = 0.6935839653015137
Iteration [2176]: Loss = 0.6934552788734436
Iteration [2177]: Loss = 4.981123447418213
Iteration [2178]: Loss = 0.6933304071426392
Iteration [2179]: Loss = 4.9810791015625
Iteration [2180]: Loss = 0.6934581995010376
Iteration [2181]: Loss = 0.6935548186302185
Iteration [2182]: Loss = 0.69361412525177
Iteration [2183]: Loss = 0.6936395168304443
Iteration [2184]: Loss = 4.979409217834473
Iteration [2185]: Loss = 0.6937777400016785
Iteration [2186]: Loss = 0.6938790082931519
Iteration [2187]: Loss = 0.6939422488212585
Iteration [2188]: Loss = 0.6939713954925537
Iteration [2189]: Loss = 0.6939694881439209
Iteration [2190]: Loss = 0.693939745426178
Iteration [2191]: Loss = 0.6938851475715637
Iteration [2192]: Loss = 0.69380784034729
Iteration [2193]: Loss = 0.6937102675437927
Iteration [2194]: Loss = 0.6935944557189941
Iteration [2195]: Loss = 4.980323314666748
Iteration [2196]: Loss = 0.6934916377067566
Iteration [2197]: Loss = 0.693490207195282
Iteration [2198]: Loss = 0.693461000919342
Iteration [2199]: Loss = 0.693406879901886
Iteration [2200]: Loss = 0.6933298110961914
Iteration [2201]: Loss = 0.6932326555252075
Iteration [2202]: Loss = 0.6931171417236328
Iteration [2203]: Loss = 0.6929850578308105
Iteration [2204]: Loss = 4.983637809753418
Iteration [2205]: Loss = 0.6928547620773315
Iteration [2206]: Loss = 0.6928419470787048
Iteration [2207]: Loss = 0.692802369594574
Iteration [2208]: Loss = 0.6927386522293091
Iteration [2209]: Loss = 0.6926532983779907
Iteration [2210]: Loss = 4.985178470611572
Iteration [2211]: Loss = 4.984887599945068
Iteration [2212]: Loss = 4.983838081359863
Iteration [2213]: Loss = 0.69312584400177
Iteration [2214]: Loss = 0.6933910846710205
Iteration [2215]: Loss = 0.6936020851135254
Iteration [2216]: Loss = 0.6937641501426697
Iteration [2217]: Loss = 0.6938822865486145
Iteration [2218]: Loss = 0.6939605474472046
Iteration [2219]: Loss = 0.6940028667449951
Iteration [2220]: Loss = 0.6940129995346069
Iteration [2221]: Loss = 0.6939942240715027
Iteration [2222]: Loss = 0.6939491629600525
Iteration [2223]: Loss = 0.6938806176185608
Iteration [2224]: Loss = 0.69379061460495
Iteration [2225]: Loss = 0.6936815977096558
Iteration [2226]: Loss = 0.6935554146766663
Iteration [2227]: Loss = 0.6934137940406799
Iteration [2228]: Loss = 0.6932580471038818
Iteration [2229]: Loss = 0.6930899620056152
Iteration [2230]: Loss = 4.983253479003906
Iteration [2231]: Loss = 0.692898154258728
Iteration [2232]: Loss = 0.6928590536117554
Iteration [2233]: Loss = 0.6927958130836487
Iteration [2234]: Loss = 4.984314441680908
Iteration [2235]: Loss = 0.6927832961082458
Iteration [2236]: Loss = 0.6928207278251648
Iteration [2237]: Loss = 0.6928262114524841
Iteration [2238]: Loss = 0.6928032040596008
Iteration [2239]: Loss = 0.6927545070648193
Iteration [2240]: Loss = 0.6926823854446411
Iteration [2241]: Loss = 0.692589521408081
Iteration [2242]: Loss = 0.6924779415130615
Iteration [2243]: Loss = 0.6923493146896362
Iteration [2244]: Loss = 0.6922053098678589
Iteration [2245]: Loss = 0.6920478343963623
Iteration [2246]: Loss = 0.6918779015541077
Iteration [2247]: Loss = 4.989713668823242
Iteration [2248]: Loss = 0.6916835904121399
Iteration [2249]: Loss = 0.6916435360908508
Iteration [2250]: Loss = 0.6915794610977173
Iteration [2251]: Loss = 0.691493809223175
Iteration [2252]: Loss = 0.691388726234436
Iteration [2253]: Loss = 0.6912659406661987
Iteration [2254]: Loss = 0.691127359867096
Iteration [2255]: Loss = 0.6909745931625366
Iteration [2256]: Loss = 0.690808892250061
Iteration [2257]: Loss = 0.6906318664550781
Iteration [2258]: Loss = 0.6904442310333252
Iteration [2259]: Loss = 0.6902474164962769
Iteration [2260]: Loss = 0.6900421380996704
Iteration [2261]: Loss = 0.6898293495178223
Iteration [2262]: Loss = 0.6896096467971802
Iteration [2263]: Loss = 0.689383864402771
Iteration [2264]: Loss = 0.689152717590332
Iteration [2265]: Loss = 0.6889165043830872
Iteration [2266]: Loss = 0.6886759996414185
Iteration [2267]: Loss = 0.6884312629699707
Iteration [2268]: Loss = 0.6881831288337708
Iteration [2269]: Loss = 0.6879316568374634
Iteration [2270]: Loss = 0.6876773238182068
Iteration [2271]: Loss = 0.6874204277992249
Iteration [2272]: Loss = 0.6871611475944519
Iteration [2273]: Loss = 0.6868998408317566
Iteration [2274]: Loss = 0.6866365671157837
Iteration [2275]: Loss = 0.6863717436790466
Iteration [2276]: Loss = 0.6861053109169006
Iteration [2277]: Loss = 0.68583744764328
Iteration [2278]: Loss = 0.6855683922767639
Iteration [2279]: Loss = 0.6852984428405762
Iteration [2280]: Loss = 5.025548458099365
Iteration [2281]: Loss = 0.6849349141120911
Iteration [2282]: Loss = 0.6848238110542297
Iteration [2283]: Loss = 0.6846959590911865
Iteration [2284]: Loss = 0.6845530271530151
Iteration [2285]: Loss = 5.028966903686523
Iteration [2286]: Loss = 0.6844064593315125
Iteration [2287]: Loss = 0.6843879222869873
Iteration [2288]: Loss = 0.6843433380126953
Iteration [2289]: Loss = 0.6842752695083618
Iteration [2290]: Loss = 0.6841862201690674
Iteration [2291]: Loss = 0.6840780377388
Iteration [2292]: Loss = 5.031373023986816
Iteration [2293]: Loss = 0.6839914321899414
Iteration [2294]: Loss = 0.6839982271194458
Iteration [2295]: Loss = 0.6839767098426819
Iteration [2296]: Loss = 0.6839293837547302
Iteration [2297]: Loss = 0.6838589310646057
Iteration [2298]: Loss = 9.38099193572998
Iteration [2299]: Loss = 0.6840128898620605
Iteration [2300]: Loss = 0.6842062473297119
Iteration [2301]: Loss = 0.6843528747558594
Iteration [2302]: Loss = 0.6844571828842163
Iteration [2303]: Loss = 5.0282769203186035
Iteration [2304]: Loss = 0.6847326755523682
Iteration [2305]: Loss = 5.026272296905518
Iteration [2306]: Loss = 5.024682521820068
Iteration [2307]: Loss = 0.6855998635292053
Iteration [2308]: Loss = 0.6859440207481384
Iteration [2309]: Loss = 5.01906156539917
Iteration [2310]: Loss = 0.6866292357444763
Iteration [2311]: Loss = 0.6869643926620483
Iteration [2312]: Loss = 0.6872386932373047
Iteration [2313]: Loss = 0.6874580979347229
Iteration [2314]: Loss = 0.6876278519630432
Iteration [2315]: Loss = 0.6877532005310059
Iteration [2316]: Loss = 0.6878382563591003
Iteration [2317]: Loss = 0.6878870725631714
Iteration [2318]: Loss = 0.6879033446311951
Iteration [2319]: Loss = 0.6878901124000549
Iteration [2320]: Loss = 0.6878504753112793
Iteration [2321]: Loss = 0.6877869367599487
Iteration [2322]: Loss = 0.687701940536499
Iteration [2323]: Loss = 0.6875975728034973
Iteration [2324]: Loss = 0.6874759197235107
Iteration [2325]: Loss = 0.6873385310173035
Iteration [2326]: Loss = 5.013882637023926
Iteration [2327]: Loss = 0.6872003674507141
Iteration [2328]: Loss = 0.687184751033783
Iteration [2329]: Loss = 0.6871429085731506
Iteration [2330]: Loss = 0.687077522277832
Iteration [2331]: Loss = 0.6869906783103943
Iteration [2332]: Loss = 0.6868846416473389
Iteration [2333]: Loss = 0.6867614984512329
Iteration [2334]: Loss = 0.6866227388381958
Iteration [2335]: Loss = 0.686470091342926
Iteration [2336]: Loss = 0.6863046884536743
Iteration [2337]: Loss = 0.6861281394958496
Iteration [2338]: Loss = 0.6859413981437683
Iteration [2339]: Loss = 0.685745358467102
Iteration [2340]: Loss = 0.6855412125587463
Iteration [2341]: Loss = 0.6853294372558594
Iteration [2342]: Loss = 0.6851110458374023
Iteration [2343]: Loss = 0.6848866939544678
Iteration [2344]: Loss = 0.6846568584442139
Iteration [2345]: Loss = 5.0288262367248535
Iteration [2346]: Loss = 5.029153823852539
Iteration [2347]: Loss = 0.6844578385353088
Iteration [2348]: Loss = 5.028315544128418
Iteration [2349]: Loss = 0.6847192049026489
Iteration [2350]: Loss = 5.0263776779174805
Iteration [2351]: Loss = 0.6851627230644226
Iteration [2352]: Loss = 0.6853950619697571
Iteration [2353]: Loss = 0.6855767965316772
Iteration [2354]: Loss = 0.6857125759124756
Iteration [2355]: Loss = 0.6858071088790894
Iteration [2356]: Loss = 0.6858646273612976
Iteration [2357]: Loss = 0.6858885288238525
Iteration [2358]: Loss = 0.6858824491500854
Iteration [2359]: Loss = 0.685849130153656
Iteration [2360]: Loss = 0.6857912540435791
Iteration [2361]: Loss = 0.6857113242149353
Iteration [2362]: Loss = 0.6856115460395813
Iteration [2363]: Loss = 5.023022174835205
Iteration [2364]: Loss = 0.6855384707450867
Iteration [2365]: Loss = 0.6855506896972656
Iteration [2366]: Loss = 0.6855341196060181
Iteration [2367]: Loss = 0.6854913234710693
Iteration [2368]: Loss = 0.6854249238967896
Iteration [2369]: Loss = 0.6853373050689697
Iteration [2370]: Loss = 0.6852306723594666
Iteration [2371]: Loss = 0.6851068735122681
Iteration [2372]: Loss = 5.025871276855469
Iteration [2373]: Loss = 0.6849927306175232
Iteration [2374]: Loss = 0.6849877238273621
Iteration [2375]: Loss = 5.025937080383301
Iteration [2376]: Loss = 0.6850765347480774
Iteration [2377]: Loss = 0.685157835483551
Iteration [2378]: Loss = 0.6852033734321594
Iteration [2379]: Loss = 0.68521648645401
Iteration [2380]: Loss = 0.685200572013855
Iteration [2381]: Loss = 0.6851584315299988
Iteration [2382]: Loss = 0.6850926876068115
Iteration [2383]: Loss = 0.6850056648254395
Iteration [2384]: Loss = 0.6848993301391602
Iteration [2385]: Loss = 0.6847759485244751
Iteration [2386]: Loss = 0.6846369504928589
Iteration [2387]: Loss = 5.028491973876953
Iteration [2388]: Loss = 9.372342109680176
Iteration [2389]: Loss = 0.6848342418670654
Iteration [2390]: Loss = 0.6851102113723755
Iteration [2391]: Loss = 0.6853312849998474
Iteration [2392]: Loss = 0.6855029463768005
Iteration [2393]: Loss = 0.6856298446655273
Iteration [2394]: Loss = 0.6857165098190308
Iteration [2395]: Loss = 0.6857669949531555
Iteration [2396]: Loss = 0.6857848763465881
Iteration [2397]: Loss = 0.6857733130455017
Iteration [2398]: Loss = 0.6857352256774902
Iteration [2399]: Loss = 0.6856732964515686
Iteration [2400]: Loss = 0.6855898499488831
Iteration [2401]: Loss = 0.6854870915412903
Iteration [2402]: Loss = 0.6853669285774231
Iteration [2403]: Loss = 0.6852309107780457
Iteration [2404]: Loss = 0.685080885887146
Iteration [2405]: Loss = 0.684918224811554
Iteration [2406]: Loss = 0.6847440600395203
Iteration [2407]: Loss = 0.6845594644546509
Iteration [2408]: Loss = 0.6843656301498413
Iteration [2409]: Loss = 0.6841635704040527
Iteration [2410]: Loss = 0.6839539408683777
Iteration [2411]: Loss = 0.683737576007843
Iteration [2412]: Loss = 5.033751487731934
Iteration [2413]: Loss = 0.6834655404090881
Iteration [2414]: Loss = 5.034414768218994
Iteration [2415]: Loss = 0.6834777593612671
Iteration [2416]: Loss = 5.033688545227051
Iteration [2417]: Loss = 0.6837201118469238
Iteration [2418]: Loss = 0.6838666796684265
Iteration [2419]: Loss = 0.683971107006073
Iteration [2420]: Loss = 0.6840375661849976
Iteration [2421]: Loss = 0.6840699315071106
Iteration [2422]: Loss = 0.6840713024139404
Iteration [2423]: Loss = 0.6840450167655945
Iteration [2424]: Loss = 0.6839936375617981
Iteration [2425]: Loss = 0.6839197278022766
Iteration [2426]: Loss = 0.6838254928588867
Iteration [2427]: Loss = 0.6837131381034851
Iteration [2428]: Loss = 0.6835842132568359
Iteration [2429]: Loss = 0.6834405064582825
Iteration [2430]: Loss = 0.6832833290100098
Iteration [2431]: Loss = 0.6831142902374268
Iteration [2432]: Loss = 9.390884399414062
Iteration [2433]: Loss = 0.6830993890762329
Iteration [2434]: Loss = 0.683220624923706
Iteration [2435]: Loss = 5.034908294677734
Iteration [2436]: Loss = 0.683524489402771
Iteration [2437]: Loss = 0.6836971044540405
Iteration [2438]: Loss = 0.6838252544403076
Iteration [2439]: Loss = 0.6839131116867065
Iteration [2440]: Loss = 5.031308174133301
Iteration [2441]: Loss = 5.030248641967773
Iteration [2442]: Loss = 0.6844837665557861
Iteration [2443]: Loss = 0.6847478747367859
Iteration [2444]: Loss = 0.6849584579467773
Iteration [2445]: Loss = 0.6851205825805664
Iteration [2446]: Loss = 0.685239315032959
Iteration [2447]: Loss = 0.6853185296058655
Iteration [2448]: Loss = 0.6853625178337097
Iteration [2449]: Loss = 5.023667335510254
Iteration [2450]: Loss = 0.685533881187439
Iteration [2451]: Loss = 0.6856499910354614
Iteration [2452]: Loss = 5.021761417388916
Iteration [2453]: Loss = 0.6859446167945862
Iteration [2454]: Loss = 0.6861131191253662
Iteration [2455]: Loss = 0.6862372756004333
Iteration [2456]: Loss = 0.6863217353820801
Iteration [2457]: Loss = 0.6863700747489929
Iteration [2458]: Loss = 0.6863861680030823
Iteration [2459]: Loss = 0.6863731145858765
Iteration [2460]: Loss = 0.6863336563110352
Iteration [2461]: Loss = 5.018825054168701
Iteration [2462]: Loss = 5.0183281898498535
Iteration [2463]: Loss = 0.6865935921669006
Iteration [2464]: Loss = 5.016107082366943
Iteration [2465]: Loss = 0.6870844960212708
Iteration [2466]: Loss = 0.6873365044593811
Iteration [2467]: Loss = 0.6875360608100891
Iteration [2468]: Loss = 0.6876880526542664
Iteration [2469]: Loss = 0.6877975463867188
Iteration [2470]: Loss = 0.6878683567047119
Iteration [2471]: Loss = 0.6879046559333801
Iteration [2472]: Loss = 0.6879096031188965
Iteration [2473]: Loss = 0.6878864765167236
Iteration [2474]: Loss = 0.6878380179405212
Iteration [2475]: Loss = 0.6877666711807251
Iteration [2476]: Loss = 0.6876747608184814
Iteration [2477]: Loss = 0.6875643134117126
Iteration [2478]: Loss = 0.6874372363090515
Iteration [2479]: Loss = 0.6872952580451965
Iteration [2480]: Loss = 0.687139630317688
Iteration [2481]: Loss = 0.6869719624519348
Iteration [2482]: Loss = 0.6867931485176086
Iteration [2483]: Loss = 0.6866047382354736
Iteration [2484]: Loss = 0.6864072680473328
Iteration [2485]: Loss = 0.6862018704414368
Iteration [2486]: Loss = 5.020344257354736
Iteration [2487]: Loss = 0.6859475374221802
Iteration [2488]: Loss = 0.6858823299407959
Iteration [2489]: Loss = 0.6857960224151611
Iteration [2490]: Loss = 0.6856908202171326
Iteration [2491]: Loss = 5.02262020111084
Iteration [2492]: Loss = 0.6856074333190918
Iteration [2493]: Loss = 0.6856150031089783
Iteration [2494]: Loss = 0.6855944395065308
Iteration [2495]: Loss = 0.6855481863021851
Iteration [2496]: Loss = 5.0231032371521
Iteration [2497]: Loss = 5.022633075714111
Iteration [2498]: Loss = 0.6857926845550537
Iteration [2499]: Loss = 0.6859694719314575
Iteration [2500]: Loss = 0.6861011981964111
Iteration [2501]: Loss = 0.6861921548843384
Iteration [2502]: Loss = 5.018954753875732
Iteration [2503]: Loss = 0.6864441633224487
Iteration [2504]: Loss = 0.6865944266319275
Iteration [2505]: Loss = 5.016495227813721
Iteration [2506]: Loss = 0.6869478225708008
Iteration [2507]: Loss = 0.6871413588523865
Iteration [2508]: Loss = 0.6872882843017578
Iteration [2509]: Loss = 0.6873925924301147
Iteration [2510]: Loss = 0.6874590516090393
Iteration [2511]: Loss = 0.6874911785125732
Iteration [2512]: Loss = 0.6874924898147583
Iteration [2513]: Loss = 5.012380123138428
Iteration [2514]: Loss = 9.335824966430664
Iteration [2515]: Loss = 0.6880238056182861
Iteration [2516]: Loss = 0.6883863210678101
Iteration [2517]: Loss = 0.6886856555938721
Iteration [2518]: Loss = 0.6889278292655945
Iteration [2519]: Loss = 5.003499984741211
Iteration [2520]: Loss = 0.6894368529319763
Iteration [2521]: Loss = 0.6896961331367493
Iteration [2522]: Loss = 4.999300479888916
Iteration [2523]: Loss = 0.6902345418930054
Iteration [2524]: Loss = 4.996068000793457
Iteration [2525]: Loss = 0.6908974051475525
Iteration [2526]: Loss = 0.6912223696708679
Iteration [2527]: Loss = 0.6914873719215393
Iteration [2528]: Loss = 0.6916986107826233
Iteration [2529]: Loss = 0.6918611526489258
Iteration [2530]: Loss = 0.6919798851013184
Iteration [2531]: Loss = 0.6920591592788696
Iteration [2532]: Loss = 0.69210284948349
Iteration [2533]: Loss = 0.692114531993866
Iteration [2534]: Loss = 0.6920974254608154
Iteration [2535]: Loss = 0.6920541524887085
Iteration [2536]: Loss = 0.6919875144958496
Iteration [2537]: Loss = 4.9886322021484375
Iteration [2538]: Loss = 0.6919683814048767
Iteration [2539]: Loss = 0.6920025944709778
Iteration [2540]: Loss = 0.6920056343078613
Iteration [2541]: Loss = 0.6919806003570557
Iteration [2542]: Loss = 0.69193035364151
Iteration [2543]: Loss = 0.6918574571609497
Iteration [2544]: Loss = 4.989355564117432
Iteration [2545]: Loss = 0.6918275356292725
Iteration [2546]: Loss = 0.6918572187423706
Iteration [2547]: Loss = 0.6918561458587646
Iteration [2548]: Loss = 0.6918275356292725
Iteration [2549]: Loss = 0.6917738914489746
Iteration [2550]: Loss = 0.691697895526886
Iteration [2551]: Loss = 0.6916017532348633
Iteration [2552]: Loss = 0.6914873719215393
Iteration [2553]: Loss = 0.6913567185401917
Iteration [2554]: Loss = 0.6912113428115845
Iteration [2555]: Loss = 0.6910526156425476
Iteration [2556]: Loss = 0.6908820271492004
Iteration [2557]: Loss = 0.6907007098197937
Iteration [2558]: Loss = 0.690509557723999
Iteration [2559]: Loss = 0.690310001373291
Iteration [2560]: Loss = 0.6901024580001831
Iteration [2561]: Loss = 0.6898877620697021
Iteration [2562]: Loss = 0.6896669268608093
Iteration [2563]: Loss = 0.6894401907920837
Iteration [2564]: Loss = 0.6892085075378418
Iteration [2565]: Loss = 0.6889722943305969
Iteration [2566]: Loss = 0.6887317895889282
Iteration [2567]: Loss = 0.6884876489639282
Iteration [2568]: Loss = 0.6882401704788208
Iteration [2569]: Loss = 0.6879896521568298
Iteration [2570]: Loss = 0.687736451625824
Iteration [2571]: Loss = 0.6874808073043823
Iteration [2572]: Loss = 0.6872228980064392
Iteration [2573]: Loss = 0.6869632601737976
Iteration [2574]: Loss = 0.6867017149925232
Iteration [2575]: Loss = 0.6864387392997742
Iteration [2576]: Loss = 0.6861742734909058
Iteration [2577]: Loss = 0.6859086155891418
Iteration [2578]: Loss = 0.6856416463851929
Iteration [2579]: Loss = 0.6853739023208618
Iteration [2580]: Loss = 0.6851051449775696
Iteration [2581]: Loss = 5.026586055755615
Iteration [2582]: Loss = 0.6847429275512695
Iteration [2583]: Loss = 0.6846320033073425
Iteration [2584]: Loss = 0.6845044493675232
Iteration [2585]: Loss = 0.6843621134757996
Iteration [2586]: Loss = 0.6842063665390015
Iteration [2587]: Loss = 5.03090763092041
Iteration [2588]: Loss = 0.6840372085571289
Iteration [2589]: Loss = 0.6840087175369263
Iteration [2590]: Loss = 5.031360626220703
Iteration [2591]: Loss = 0.6840564608573914
Iteration [2592]: Loss = 0.6841202974319458
Iteration [2593]: Loss = 0.6841500997543335
Iteration [2594]: Loss = 0.6841495037078857
Iteration [2595]: Loss = 0.6841211915016174
Iteration [2596]: Loss = 0.6840683221817017
Iteration [2597]: Loss = 0.6839931607246399
Iteration [2598]: Loss = 0.683897852897644
Iteration [2599]: Loss = 0.683784544467926
Iteration [2600]: Loss = 0.6836548447608948
Iteration [2601]: Loss = 5.03377628326416
Iteration [2602]: Loss = 0.6835305690765381
Iteration [2603]: Loss = 0.683521032333374
Iteration [2604]: Loss = 0.6834848523139954
Iteration [2605]: Loss = 0.6834247708320618
Iteration [2606]: Loss = 0.6833430528640747
Iteration [2607]: Loss = 5.035236835479736
Iteration [2608]: Loss = 0.683300793170929
Iteration [2609]: Loss = 0.683326244354248
Iteration [2610]: Loss = 0.6833215951919556
Iteration [2611]: Loss = 0.6832898259162903
Iteration [2612]: Loss = 0.6832337975502014
Iteration [2613]: Loss = 0.6831555962562561
Iteration [2614]: Loss = 0.6830577850341797
Iteration [2615]: Loss = 0.6829419732093811
Iteration [2616]: Loss = 5.037585258483887
Iteration [2617]: Loss = 0.6828417181968689
Iteration [2618]: Loss = 0.6828425526618958
Iteration [2619]: Loss = 0.682815670967102
Iteration [2620]: Loss = 0.6827639937400818
Iteration [2621]: Loss = 0.6826899647712708
Iteration [2622]: Loss = 0.6825955510139465
Iteration [2623]: Loss = 0.6824830770492554
Iteration [2624]: Loss = 0.6823543310165405
Iteration [2625]: Loss = 0.6822105646133423
Iteration [2626]: Loss = 0.6820537447929382
Iteration [2627]: Loss = 0.6818850636482239
Iteration [2628]: Loss = 5.043607234954834
Iteration [2629]: Loss = 5.043667316436768
Iteration [2630]: Loss = 5.042902946472168
Iteration [2631]: Loss = 0.682110071182251
Iteration [2632]: Loss = 0.6823307275772095
Iteration [2633]: Loss = 5.039264678955078
Iteration [2634]: Loss = 0.6828052997589111
Iteration [2635]: Loss = 0.6830511093139648
Iteration [2636]: Loss = 0.6832448840141296
Iteration [2637]: Loss = 0.6833921074867249
Iteration [2638]: Loss = 0.6834969520568848
Iteration [2639]: Loss = 0.6835638284683228
Iteration [2640]: Loss = 0.6835964918136597
Iteration [2641]: Loss = 0.6835981607437134
Iteration [2642]: Loss = 0.6835722923278809
Iteration [2643]: Loss = 0.6835210919380188
Iteration [2644]: Loss = 0.6834476590156555
Iteration [2645]: Loss = 9.385904312133789
Iteration [2646]: Loss = 0.6835945248603821
Iteration [2647]: Loss = 5.032290458679199
Iteration [2648]: Loss = 5.030560493469238
Iteration [2649]: Loss = 0.6845369935035706
Iteration [2650]: Loss = 0.6849008798599243
Iteration [2651]: Loss = 0.6852013468742371
Iteration [2652]: Loss = 0.685444712638855
Iteration [2653]: Loss = 5.022251605987549
Iteration [2654]: Loss = 0.6859566569328308
Iteration [2655]: Loss = 0.6862176060676575
Iteration [2656]: Loss = 0.6864253282546997
Iteration [2657]: Loss = 0.6865849494934082
Iteration [2658]: Loss = 5.016500949859619
Iteration [2659]: Loss = 0.6869536638259888
Iteration [2660]: Loss = 0.6871535778045654
Iteration [2661]: Loss = 0.6873060464859009
Iteration [2662]: Loss = 0.6874158978462219
Iteration [2663]: Loss = 0.6874871850013733
Iteration [2664]: Loss = 0.6875240206718445
Iteration [2665]: Loss = 0.6875293254852295
Iteration [2666]: Loss = 0.6875068545341492
Iteration [2667]: Loss = 0.6874588131904602
Iteration [2668]: Loss = 0.6873880624771118
Iteration [2669]: Loss = 0.6872966885566711
Iteration [2670]: Loss = 0.6871868371963501
Iteration [2671]: Loss = 5.014564037322998
Iteration [2672]: Loss = 0.6870952844619751
Iteration [2673]: Loss = 0.6870989799499512
Iteration [2674]: Loss = 5.014485836029053
Iteration [2675]: Loss = 0.6872015595436096
Iteration [2676]: Loss = 5.013336658477783
Iteration [2677]: Loss = 0.6875140070915222
Iteration [2678]: Loss = 5.011174201965332
Iteration [2679]: Loss = 0.687995970249176
Iteration [2680]: Loss = 0.6882439255714417
Iteration [2681]: Loss = 0.6884399056434631
Iteration [2682]: Loss = 0.6885887980461121
Iteration [2683]: Loss = 0.6886953115463257
Iteration [2684]: Loss = 0.6887634992599487
Iteration [2685]: Loss = 5.005223274230957
Iteration [2686]: Loss = 0.6889755725860596
Iteration [2687]: Loss = 0.6891087889671326
Iteration [2688]: Loss = 0.6892009973526001
Iteration [2689]: Loss = 0.6892563700675964
Iteration [2690]: Loss = 0.6892786622047424
Iteration [2691]: Loss = 0.6892709732055664
Iteration [2692]: Loss = 0.6892363429069519
Iteration [2693]: Loss = 0.6891774535179138
Iteration [2694]: Loss = 0.6890966892242432
Iteration [2695]: Loss = 0.6889963150024414
Iteration [2696]: Loss = 0.6888781189918518
Iteration [2697]: Loss = 5.005507469177246
Iteration [2698]: Loss = 5.00535774230957
Iteration [2699]: Loss = 0.6889457106590271
Iteration [2700]: Loss = 5.00373649597168
Iteration [2701]: Loss = 0.6893379092216492
Iteration [2702]: Loss = 0.6895477771759033
Iteration [2703]: Loss = 0.6897088885307312
Iteration [2704]: Loss = 4.999706268310547
Iteration [2705]: Loss = 0.6900800466537476
Iteration [2706]: Loss = 4.997274398803711
Iteration [2707]: Loss = 4.995520114898682
Iteration [2708]: Loss = 0.6910514235496521
Iteration [2709]: Loss = 0.6914222836494446
Iteration [2710]: Loss = 0.6917287707328796
Iteration [2711]: Loss = 0.6919770240783691
Iteration [2712]: Loss = 0.6921730041503906
Iteration [2713]: Loss = 0.6923215985298157
Iteration [2714]: Loss = 0.6924276947975159
Iteration [2715]: Loss = 0.6924954056739807
Iteration [2716]: Loss = 0.692528486251831
Iteration [2717]: Loss = 4.985273838043213
Iteration [2718]: Loss = 0.6926802396774292
Iteration [2719]: Loss = 0.6927871108055115
Iteration [2720]: Loss = 0.6928555965423584
Iteration [2721]: Loss = 0.6928894519805908
Iteration [2722]: Loss = 0.6928920745849609
Iteration [2723]: Loss = 0.6928664445877075
Iteration [2724]: Loss = 0.6928154826164246
Iteration [2725]: Loss = 0.692741870880127
Iteration [2726]: Loss = 0.6926475763320923
Iteration [2727]: Loss = 0.6925347447395325
Iteration [2728]: Loss = 0.6924053430557251
Iteration [2729]: Loss = 0.6922607421875
Iteration [2730]: Loss = 0.69210284948349
Iteration [2731]: Loss = 0.691932737827301
Iteration [2732]: Loss = 0.6917516589164734
Iteration [2733]: Loss = 0.691560685634613
Iteration [2734]: Loss = 0.6913610100746155
Iteration [2735]: Loss = 0.6911532878875732
Iteration [2736]: Loss = 0.690938413143158
Iteration [2737]: Loss = 0.6907171010971069
Iteration [2738]: Loss = 0.6904898881912231
Iteration [2739]: Loss = 0.6902574896812439
Iteration [2740]: Loss = 0.6900205016136169
Iteration [2741]: Loss = 0.6897793412208557
Iteration [2742]: Loss = 0.6895343661308289
Iteration [2743]: Loss = 0.6892858147621155
Iteration [2744]: Loss = 0.6890344619750977
Iteration [2745]: Loss = 5.005314350128174
Iteration [2746]: Loss = 0.6887010931968689
Iteration [2747]: Loss = 0.688602089881897
Iteration [2748]: Loss = 0.6884850859642029
Iteration [2749]: Loss = 5.0076141357421875
Iteration [2750]: Loss = 0.688381552696228
Iteration [2751]: Loss = 0.6883803606033325
Iteration [2752]: Loss = 5.00761604309082
Iteration [2753]: Loss = 0.6884745359420776
Iteration [2754]: Loss = 5.006509304046631
Iteration [2755]: Loss = 5.005310535430908
Iteration [2756]: Loss = 0.6891301274299622
Iteration [2757]: Loss = 0.6894168853759766
Iteration [2758]: Loss = 0.6896475553512573
Iteration [2759]: Loss = 0.6898273825645447
Iteration [2760]: Loss = 4.998981952667236
Iteration [2761]: Loss = 0.6902307868003845
Iteration [2762]: Loss = 0.6904453039169312
Iteration [2763]: Loss = 0.6906107664108276
Iteration [2764]: Loss = 0.690731942653656
Iteration [2765]: Loss = 0.690813422203064
Iteration [2766]: Loss = 4.994185924530029
Iteration [2767]: Loss = 0.6910479068756104
Iteration [2768]: Loss = 0.6911904811859131
Iteration [2769]: Loss = 0.6912911534309387
Iteration [2770]: Loss = 0.6913538575172424
Iteration [2771]: Loss = 0.6913824081420898
Iteration [2772]: Loss = 0.6913802027702332
Iteration [2773]: Loss = 0.6913502812385559
Iteration [2774]: Loss = 0.6912955641746521
Iteration [2775]: Loss = 4.992265701293945
Iteration [2776]: Loss = 0.6912976503372192
Iteration [2777]: Loss = 0.6913410425186157
Iteration [2778]: Loss = 0.6913524270057678
Iteration [2779]: Loss = 0.6913346648216248
Iteration [2780]: Loss = 4.991878986358643
Iteration [2781]: Loss = 0.6914001107215881
Iteration [2782]: Loss = 0.6914705634117126
Iteration [2783]: Loss = 0.6915061473846436
Iteration [2784]: Loss = 4.990707874298096
Iteration [2785]: Loss = 0.6916627287864685
Iteration [2786]: Loss = 0.6917719841003418
Iteration [2787]: Loss = 0.6918426156044006
Iteration [2788]: Loss = 0.6918781399726868
Iteration [2789]: Loss = 0.6918821334838867
Iteration [2790]: Loss = 0.6918579339981079
Iteration [2791]: Loss = 9.286434173583984
Iteration [2792]: Loss = 0.6920862197875977
Iteration [2793]: Loss = 0.6923090219497681
Iteration [2794]: Loss = 0.692482054233551
Iteration [2795]: Loss = 0.6926100850105286
Iteration [2796]: Loss = 0.6926975846290588
Iteration [2797]: Loss = 0.6927485466003418
Iteration [2798]: Loss = 0.6927667260169983
Iteration [2799]: Loss = 0.6927552223205566
Iteration [2800]: Loss = 0.6927171349525452
Iteration [2801]: Loss = 0.6926549673080444
Iteration [2802]: Loss = 0.6925711631774902
Iteration [2803]: Loss = 0.6924678087234497
Iteration [2804]: Loss = 0.6923468112945557
Iteration [2805]: Loss = 0.6922101974487305
Iteration [2806]: Loss = 0.6920593976974487
Iteration [2807]: Loss = 4.988653659820557
Iteration [2808]: Loss = 4.988648414611816
Iteration [2809]: Loss = 0.6920454502105713
Iteration [2810]: Loss = 0.6921517252922058
Iteration [2811]: Loss = 0.6922195553779602
Iteration [2812]: Loss = 4.986752033233643
Iteration [2813]: Loss = 0.6924305558204651
Iteration [2814]: Loss = 0.6925628781318665
Iteration [2815]: Loss = 0.6926541328430176
Iteration [2816]: Loss = 4.98432731628418
Iteration [2817]: Loss = 4.983282089233398
Iteration [2818]: Loss = 0.6932291984558105
Iteration [2819]: Loss = 0.6934934258460999
Iteration [2820]: Loss = 0.6937035322189331
Iteration [2821]: Loss = 4.978186130523682
Iteration [2822]: Loss = 0.6941574215888977
Iteration [2823]: Loss = 4.9753875732421875
Iteration [2824]: Loss = 0.6947518587112427
Iteration [2825]: Loss = 0.6950473785400391
Iteration [2826]: Loss = 0.6952855587005615
Iteration [2827]: Loss = 0.6954723000526428
Iteration [2828]: Loss = 0.6956126093864441
Iteration [2829]: Loss = 4.968416213989258
Iteration [2830]: Loss = 0.6959466934204102
Iteration [2831]: Loss = 0.6961310505867004
Iteration [2832]: Loss = 0.696269154548645
Iteration [2833]: Loss = 0.6963655352592468
Iteration [2834]: Loss = 0.6964243650436401
Iteration [2835]: Loss = 0.6964492201805115
Iteration [2836]: Loss = 0.6964436173439026
Iteration [2837]: Loss = 4.964725494384766
Iteration [2838]: Loss = 0.6965283155441284
Iteration [2839]: Loss = 0.6966063976287842
Iteration [2840]: Loss = 0.6966487765312195
Iteration [2841]: Loss = 0.6966587901115417
Iteration [2842]: Loss = 0.6966397762298584
Iteration [2843]: Loss = 0.6965947151184082
Iteration [2844]: Loss = 0.6965258121490479
Iteration [2845]: Loss = 0.6964358687400818
Iteration [2846]: Loss = 0.6963267922401428
Iteration [2847]: Loss = 4.965832710266113
Iteration [2848]: Loss = 0.696234941482544
Iteration [2849]: Loss = 0.6962379217147827
Iteration [2850]: Loss = 0.6962124705314636
Iteration [2851]: Loss = 0.6961615085601807
Iteration [2852]: Loss = 0.6960874795913696
Iteration [2853]: Loss = 0.6959929466247559
Iteration [2854]: Loss = 0.6958796381950378
Iteration [2855]: Loss = 0.6957495808601379
Iteration [2856]: Loss = 0.6956043839454651
Iteration [2857]: Loss = 4.969818115234375
Iteration [2858]: Loss = 0.695451021194458
Iteration [2859]: Loss = 0.6954278945922852
Iteration [2860]: Loss = 0.6953791379928589
Iteration [2861]: Loss = 0.6953069567680359
Iteration [2862]: Loss = 0.6952141523361206
Iteration [2863]: Loss = 0.695102334022522
Iteration [2864]: Loss = 0.6949737071990967
Iteration [2865]: Loss = 0.6948298215866089
Iteration [2866]: Loss = 0.6946720480918884
Iteration [2867]: Loss = 0.6945021748542786
Iteration [2868]: Loss = 0.6943211555480957
Iteration [2869]: Loss = 0.6941299438476562
Iteration [2870]: Loss = 0.6939299702644348
Iteration [2871]: Loss = 0.6937217712402344
Iteration [2872]: Loss = 4.980088233947754
Iteration [2873]: Loss = 0.6934614777565002
Iteration [2874]: Loss = 0.6933930516242981
Iteration [2875]: Loss = 0.6933033466339111
Iteration [2876]: Loss = 0.6931947469711304
Iteration [2877]: Loss = 4.982412338256836
Iteration [2878]: Loss = 0.6931042671203613
Iteration [2879]: Loss = 0.693108320236206
Iteration [2880]: Loss = 0.6930840015411377
Iteration [2881]: Loss = 0.6930340528488159
Iteration [2882]: Loss = 4.98298454284668
Iteration [2883]: Loss = 0.6930440664291382
Iteration [2884]: Loss = 0.6930909156799316
Iteration [2885]: Loss = 0.6931049823760986
Iteration [2886]: Loss = 0.6930897235870361
Iteration [2887]: Loss = 4.982522010803223
Iteration [2888]: Loss = 0.6931589841842651
Iteration [2889]: Loss = 0.6932309865951538
Iteration [2890]: Loss = 4.981354713439941
Iteration [2891]: Loss = 0.6934494376182556
Iteration [2892]: Loss = 0.6935849189758301
Iteration [2893]: Loss = 0.6936788558959961
Iteration [2894]: Loss = 0.693735659122467
Iteration [2895]: Loss = 0.6937585473060608
Iteration [2896]: Loss = 0.6937512755393982
Iteration [2897]: Loss = 0.6937166452407837
Iteration [2898]: Loss = 0.693657398223877
Iteration [2899]: Loss = 0.6935759782791138
Iteration [2900]: Loss = 4.9802565574646
Iteration [2901]: Loss = 0.6935321688652039
Iteration [2902]: Loss = 0.693556010723114
Iteration [2903]: Loss = 0.6935495138168335
Iteration [2904]: Loss = 4.980038642883301
Iteration [2905]: Loss = 0.6936337947845459
Iteration [2906]: Loss = 4.9789958000183105
Iteration [2907]: Loss = 0.693930983543396
Iteration [2908]: Loss = 0.6941001415252686
Iteration [2909]: Loss = 0.6942243576049805
Iteration [2910]: Loss = 0.6943081021308899
Iteration [2911]: Loss = 0.6943556070327759
Iteration [2912]: Loss = 0.6943703293800354
Iteration [2913]: Loss = 4.975586414337158
Iteration [2914]: Loss = 0.694490373134613
Iteration [2915]: Loss = 0.6945840716362
Iteration [2916]: Loss = 0.6946403384208679
Iteration [2917]: Loss = 9.253253936767578
Iteration [2918]: Loss = 0.6950050592422485
Iteration [2919]: Loss = 4.9706645011901855
Iteration [2920]: Loss = 4.968555927276611
Iteration [2921]: Loss = 0.6961899995803833
Iteration [2922]: Loss = 0.6966175436973572
Iteration [2923]: Loss = 0.6969748139381409
Iteration [2924]: Loss = 0.6972686648368835
Iteration [2925]: Loss = 0.697505533695221
Iteration [2926]: Loss = 0.6976907849311829
Iteration [2927]: Loss = 0.6978296041488647
Iteration [2928]: Loss = 0.6979265809059143
Iteration [2929]: Loss = 0.6979860067367554
Iteration [2930]: Loss = 0.6980112791061401
Iteration [2931]: Loss = 0.6980059146881104
Iteration [2932]: Loss = 0.6979730725288391
Iteration [2933]: Loss = 0.6979154348373413
Iteration [2934]: Loss = 0.6978354454040527
Iteration [2935]: Loss = 0.6977351903915405
Iteration [2936]: Loss = 0.6976169943809509
Iteration [2937]: Loss = 0.6974822878837585
Iteration [2938]: Loss = 0.6973331570625305
Iteration [2939]: Loss = 0.697170615196228
Iteration [2940]: Loss = 0.6969960927963257
Iteration [2941]: Loss = 0.6968109607696533
Iteration [2942]: Loss = 0.6966162323951721
Iteration [2943]: Loss = 0.6964127421379089
Iteration [2944]: Loss = 0.6962015628814697
Iteration [2945]: Loss = 0.695983350276947
Iteration [2946]: Loss = 0.6957587599754333
Iteration [2947]: Loss = 0.695528507232666
Iteration [2948]: Loss = 0.695293128490448
Iteration [2949]: Loss = 0.695053219795227
Iteration [2950]: Loss = 0.6948092579841614
Iteration [2951]: Loss = 0.6945615410804749
Iteration [2952]: Loss = 0.6943104863166809
Iteration [2953]: Loss = 0.6940564513206482
Iteration [2954]: Loss = 0.6937998533248901
Iteration [2955]: Loss = 0.693540632724762
Iteration [2956]: Loss = 0.6932793855667114
Iteration [2957]: Loss = 0.6930161714553833
Iteration [2958]: Loss = 0.6927512884140015
Iteration [2959]: Loss = 0.6924847960472107
Iteration [2960]: Loss = 0.6922169923782349
Iteration [2961]: Loss = 0.6919478178024292
Iteration [2962]: Loss = 0.6916776895523071
Iteration [2963]: Loss = 0.6914064884185791
Iteration [2964]: Loss = 4.992713928222656
Iteration [2965]: Loss = 0.6910390853881836
Iteration [2966]: Loss = 0.6909252405166626
Iteration [2967]: Loss = 0.6907948851585388
Iteration [2968]: Loss = 0.690649688243866
Iteration [2969]: Loss = 0.6904910802841187
Iteration [2970]: Loss = 0.6903202533721924
Iteration [2971]: Loss = 0.6901386380195618
Iteration [2972]: Loss = 0.6899471879005432
Iteration [2973]: Loss = 0.6897468566894531
Iteration [2974]: Loss = 0.6895387768745422
Iteration [2975]: Loss = 0.6893234252929688
Iteration [2976]: Loss = 0.6891016960144043
Iteration [2977]: Loss = 0.6888742446899414
Iteration [2978]: Loss = 0.6886416673660278
Iteration [2979]: Loss = 0.6884042024612427
Iteration [2980]: Loss = 0.6881626844406128
Iteration [2981]: Loss = 0.6879174709320068
Iteration [2982]: Loss = 0.6876688599586487
Iteration [2983]: Loss = 0.6874170899391174
Iteration [2984]: Loss = 0.6871626973152161
Iteration [2985]: Loss = 0.6869057416915894
Iteration [2986]: Loss = 0.6866467595100403
Iteration [2987]: Loss = 0.6863856911659241
Iteration [2988]: Loss = 0.6861228942871094
Iteration [2989]: Loss = 0.685858428478241
Iteration [2990]: Loss = 0.6855926513671875
Iteration [2991]: Loss = 0.6853256225585938
Iteration [2992]: Loss = 0.6850572824478149
Iteration [2993]: Loss = 0.6847879886627197
Iteration [2994]: Loss = 0.6845179200172424
Iteration [2995]: Loss = 0.6842469573020935
Iteration [2996]: Loss = 0.683975338935852
Iteration [2997]: Loss = 0.6837029457092285
Iteration [2998]: Loss = 0.6834300756454468
Iteration [2999]: Loss = 0.6831565499305725
Iteration [3000]: Loss = 0.6828827261924744
Iteration [3001]: Loss = 0.6826084852218628
Iteration [3002]: Loss = 0.682333767414093
Iteration [3003]: Loss = 0.6820588111877441
Iteration [3004]: Loss = 0.6817836761474609
Iteration [3005]: Loss = 0.6815083026885986
Iteration [3006]: Loss = 5.046189785003662
Iteration [3007]: Loss = 0.6811361908912659
Iteration [3008]: Loss = 0.6810218095779419
Iteration [3009]: Loss = 5.048056125640869
Iteration [3010]: Loss = 0.6809245944023132
Iteration [3011]: Loss = 5.047858715057373
Iteration [3012]: Loss = 5.047022342681885
Iteration [3013]: Loss = 0.6813682317733765
Iteration [3014]: Loss = 0.681600034236908
Iteration [3015]: Loss = 0.6817811727523804
Iteration [3016]: Loss = 0.6819167137145996
Iteration [3017]: Loss = 0.6820111274719238
Iteration [3018]: Loss = 0.6820685863494873
Iteration [3019]: Loss = 5.041494369506836
Iteration [3020]: Loss = 0.6822648048400879
Iteration [3021]: Loss = 0.6823921799659729
Iteration [3022]: Loss = 5.039388179779053
Iteration [3023]: Loss = 0.682707667350769
Iteration [3024]: Loss = 0.6828859448432922
Iteration [3025]: Loss = 0.683018684387207
Iteration [3026]: Loss = 0.6831107139587402
Iteration [3027]: Loss = 5.035650730133057
Iteration [3028]: Loss = 0.6833657026290894
Iteration [3029]: Loss = 0.6835180521011353
Iteration [3030]: Loss = 5.033140182495117
Iteration [3031]: Loss = 0.6838759183883667
Iteration [3032]: Loss = 0.6840721368789673
Iteration [3033]: Loss = 0.6842209696769714
Iteration [3034]: Loss = 0.6843274831771851
Iteration [3035]: Loss = 5.028971195220947
Iteration [3036]: Loss = 0.6846069693565369
Iteration [3037]: Loss = 0.6847693920135498
Iteration [3038]: Loss = 0.6848882436752319
Iteration [3039]: Loss = 0.6849672794342041
Iteration [3040]: Loss = 0.6850107908248901
Iteration [3041]: Loss = 0.6850221753120422
Iteration [3042]: Loss = 5.025670528411865
Iteration [3043]: Loss = 0.6851389408111572
Iteration [3044]: Loss = 0.6852323412895203
Iteration [3045]: Loss = 0.685288667678833
Iteration [3046]: Loss = 0.6853114366531372
Iteration [3047]: Loss = 0.6853042244911194
Iteration [3048]: Loss = 0.6852700710296631
Iteration [3049]: Loss = 0.6852113008499146
Iteration [3050]: Loss = 0.6851306557655334
Iteration [3051]: Loss = 0.6850301027297974
Iteration [3052]: Loss = 0.6849117279052734
Iteration [3053]: Loss = 0.6847773790359497
Iteration [3054]: Loss = 0.6846284866333008
Iteration [3055]: Loss = 5.0285844802856445
Iteration [3056]: Loss = 0.6844722032546997
Iteration [3057]: Loss = 0.6844491958618164
Iteration [3058]: Loss = 0.6844006776809692
Iteration [3059]: Loss = 0.6843291521072388
Iteration [3060]: Loss = 0.684237003326416
Iteration [3061]: Loss = 0.6841263175010681
Iteration [3062]: Loss = 0.683998703956604
Iteration [3063]: Loss = 0.6838560104370117
Iteration [3064]: Loss = 5.032748699188232
Iteration [3065]: Loss = 0.6837100982666016
Iteration [3066]: Loss = 0.6836917996406555
Iteration [3067]: Loss = 5.033031463623047
Iteration [3068]: Loss = 5.032429218292236
Iteration [3069]: Loss = 0.6840084791183472
Iteration [3070]: Loss = 0.6842060685157776
Iteration [3071]: Loss = 0.6843560934066772
Iteration [3072]: Loss = 0.6844635605812073
Iteration [3073]: Loss = 0.6845325231552124
Iteration [3074]: Loss = 0.6845667362213135
Iteration [3075]: Loss = 0.684569776058197
Iteration [3076]: Loss = 0.6845446825027466
Iteration [3077]: Loss = 5.028435707092285
Iteration [3078]: Loss = 0.6845996379852295
Iteration [3079]: Loss = 0.684666633605957
Iteration [3080]: Loss = 0.6846991777420044
Iteration [3081]: Loss = 0.6847007870674133
Iteration [3082]: Loss = 0.6846743226051331
Iteration [3083]: Loss = 5.027740955352783
Iteration [3084]: Loss = 0.6847267150878906
Iteration [3085]: Loss = 0.6847927570343018
Iteration [3086]: Loss = 0.684824526309967
Iteration [3087]: Loss = 0.6848251223564148
Iteration [3088]: Loss = 0.6847977042198181
Iteration [3089]: Loss = 0.6847453117370605
Iteration [3090]: Loss = 0.6846702098846436
Iteration [3091]: Loss = 0.6845747232437134
Iteration [3092]: Loss = 0.6844609379768372
Iteration [3093]: Loss = 0.6843305230140686
Iteration [3094]: Loss = 0.684185266494751
Iteration [3095]: Loss = 0.6840265393257141
Iteration [3096]: Loss = 0.6838558912277222
Iteration [3097]: Loss = 0.6836743354797363
Iteration [3098]: Loss = 5.033925533294678
Iteration [3099]: Loss = 0.683462381362915
Iteration [3100]: Loss = 0.683415949344635
Iteration [3101]: Loss = 0.6833465099334717
Iteration [3102]: Loss = 0.6832558512687683
Iteration [3103]: Loss = 0.683146595954895
Iteration [3104]: Loss = 0.683020293712616
Iteration [3105]: Loss = 0.6828786134719849
Iteration [3106]: Loss = 0.682723343372345
Iteration [3107]: Loss = 0.682555615901947
Iteration [3108]: Loss = 0.6823768615722656
Iteration [3109]: Loss = 0.6821879744529724
Iteration [3110]: Loss = 5.042054176330566
Iteration [3111]: Loss = 0.681964099407196
Iteration [3112]: Loss = 0.6819128394126892
Iteration [3113]: Loss = 0.6818387508392334
Iteration [3114]: Loss = 0.681744396686554
Iteration [3115]: Loss = 0.6816315650939941
Iteration [3116]: Loss = 0.6815020442008972
Iteration [3117]: Loss = 0.6813578009605408
Iteration [3118]: Loss = 0.6811999678611755
Iteration [3119]: Loss = 0.6810300946235657
Iteration [3120]: Loss = 0.6808492541313171
Iteration [3121]: Loss = 5.049327850341797
Iteration [3122]: Loss = 0.6806396245956421
Iteration [3123]: Loss = 0.6805944442749023
Iteration [3124]: Loss = 0.6805261969566345
Iteration [3125]: Loss = 0.6804368495941162
Iteration [3126]: Loss = 0.6803286671638489
Iteration [3127]: Loss = 0.680203378200531
Iteration [3128]: Loss = 0.6800627112388611
Iteration [3129]: Loss = 0.6799083352088928
Iteration [3130]: Loss = 0.679741621017456
Iteration [3131]: Loss = 0.6795636415481567
Iteration [3132]: Loss = 0.6793756484985352
Iteration [3133]: Loss = 0.6791785955429077
Iteration [3134]: Loss = 0.6789733171463013
Iteration [3135]: Loss = 0.6787608861923218
Iteration [3136]: Loss = 0.6785416603088379
Iteration [3137]: Loss = 5.062178611755371
Iteration [3138]: Loss = 0.6782671809196472
Iteration [3139]: Loss = 0.6781949400901794
Iteration [3140]: Loss = 0.6781019568443298
Iteration [3141]: Loss = 0.6779906153678894
Iteration [3142]: Loss = 0.6778626441955566
Iteration [3143]: Loss = 5.065464496612549
Iteration [3144]: Loss = 0.6777438521385193
Iteration [3145]: Loss = 0.6777378916740417
Iteration [3146]: Loss = 0.677704930305481
Iteration [3147]: Loss = 0.6776474118232727
Iteration [3148]: Loss = 0.6775680184364319
Iteration [3149]: Loss = 0.6774686574935913
Iteration [3150]: Loss = 0.6773513555526733
Iteration [3151]: Loss = 0.6772181987762451
Iteration [3152]: Loss = 0.6770704388618469
Iteration [3153]: Loss = 0.6769096851348877
Iteration [3154]: Loss = 0.6767371296882629
Iteration [3155]: Loss = 0.6765541434288025
Iteration [3156]: Loss = 0.676361620426178
Iteration [3157]: Loss = 0.6761605739593506
Iteration [3158]: Loss = 0.6759516596794128
Iteration [3159]: Loss = 0.6757360696792603
Iteration [3160]: Loss = 0.6755141019821167
Iteration [3161]: Loss = 5.078909397125244
Iteration [3162]: Loss = 0.6752356290817261
Iteration [3163]: Loss = 5.079599857330322
Iteration [3164]: Loss = 0.6752493977546692
Iteration [3165]: Loss = 0.6753003597259521
Iteration [3166]: Loss = 0.6753183603286743
Iteration [3167]: Loss = 0.6753071546554565
Iteration [3168]: Loss = 0.6752691864967346
Iteration [3169]: Loss = 0.6752073168754578
Iteration [3170]: Loss = 0.6751239895820618
Iteration [3171]: Loss = 0.675021231174469
Iteration [3172]: Loss = 0.6749009490013123
Iteration [3173]: Loss = 0.6747649908065796
Iteration [3174]: Loss = 0.6746147274971008
Iteration [3175]: Loss = 0.6744518280029297
Iteration [3176]: Loss = 0.6742775440216064
Iteration [3177]: Loss = 0.6740928292274475
Iteration [3178]: Loss = 0.6738988757133484
Iteration [3179]: Loss = 0.6736963987350464
Iteration [3180]: Loss = 0.6734864711761475
Iteration [3181]: Loss = 0.6732698082923889
Iteration [3182]: Loss = 0.6730470061302185
Iteration [3183]: Loss = 0.6728187799453735
Iteration [3184]: Loss = 5.093926906585693
Iteration [3185]: Loss = 0.672530472278595
Iteration [3186]: Loss = 0.6724531054496765
Iteration [3187]: Loss = 5.095208168029785
Iteration [3188]: Loss = 5.094836235046387
Iteration [3189]: Loss = 0.6726361513137817
Iteration [3190]: Loss = 0.6728009581565857
Iteration [3191]: Loss = 0.6729218363761902
Iteration [3192]: Loss = 0.6730029582977295
Iteration [3193]: Loss = 5.091346263885498
Iteration [3194]: Loss = 0.6732429265975952
Iteration [3195]: Loss = 5.089442729949951
Iteration [3196]: Loss = 5.087850570678711
Iteration [3197]: Loss = 0.6740862131118774
Iteration [3198]: Loss = 9.492918968200684
Iteration [3199]: Loss = 0.6750615835189819
Iteration [3200]: Loss = 0.6756053566932678
Iteration [3201]: Loss = 5.074584484100342
Iteration [3202]: Loss = 0.6766344308853149
Iteration [3203]: Loss = 0.6771175861358643
Iteration [3204]: Loss = 0.6775254607200623
Iteration [3205]: Loss = 0.6778655052185059
Iteration [3206]: Loss = 0.6781442165374756
Iteration [3207]: Loss = 0.6783677935600281
Iteration [3208]: Loss = 0.6785416603088379
Iteration [3209]: Loss = 0.6786705851554871
Iteration [3210]: Loss = 0.6787590980529785
Iteration [3211]: Loss = 0.6788113713264465
Iteration [3212]: Loss = 0.6788308024406433
Iteration [3213]: Loss = 0.6788206100463867
Iteration [3214]: Loss = 0.6787840127944946
Iteration [3215]: Loss = 0.6787232756614685
Iteration [3216]: Loss = 0.6786409020423889
Iteration [3217]: Loss = 5.060953617095947
Iteration [3218]: Loss = 0.6785995960235596
Iteration [3219]: Loss = 0.678626298904419
Iteration [3220]: Loss = 0.6786226630210876
Iteration [3221]: Loss = 0.6785918474197388
Iteration [3222]: Loss = 0.6785365343093872
Iteration [3223]: Loss = 5.061395168304443
Iteration [3224]: Loss = 5.060944080352783
Iteration [3225]: Loss = 0.6787661910057068
Iteration [3226]: Loss = 0.6789413094520569
Iteration [3227]: Loss = 0.6790715456008911
Iteration [3228]: Loss = 0.6791611313819885
Iteration [3229]: Loss = 0.6792141199111938
Iteration [3230]: Loss = 0.6792343258857727
Iteration [3231]: Loss = 0.6792248487472534
Iteration [3232]: Loss = 0.6791887283325195
Iteration [3233]: Loss = 0.6791285276412964
Iteration [3234]: Loss = 0.679046630859375
Iteration [3235]: Loss = 5.058722496032715
Iteration [3236]: Loss = 0.6790059208869934
Iteration [3237]: Loss = 0.6790329217910767
Iteration [3238]: Loss = 0.6790294647216797
Iteration [3239]: Loss = 0.6789988875389099
Iteration [3240]: Loss = 0.6789435148239136
Iteration [3241]: Loss = 0.6788660883903503
Iteration [3242]: Loss = 0.6787687540054321
Iteration [3243]: Loss = 0.678653359413147
Iteration [3244]: Loss = 0.6785218119621277
Iteration [3245]: Loss = 0.6783757209777832
Iteration [3246]: Loss = 0.6782165169715881
Iteration [3247]: Loss = 0.6780455112457275
Iteration [3248]: Loss = 0.6778639554977417
Iteration [3249]: Loss = 0.6776727437973022
Iteration [3250]: Loss = 0.6774729490280151
Iteration [3251]: Loss = 0.6772654056549072
Iteration [3252]: Loss = 0.6770510077476501
Iteration [3253]: Loss = 0.6768301725387573
Iteration [3254]: Loss = 0.6766038537025452
Iteration [3255]: Loss = 5.072900295257568
Iteration [3256]: Loss = 0.676317036151886
Iteration [3257]: Loss = 0.6762397289276123
Iteration [3258]: Loss = 0.6761424541473389
Iteration [3259]: Loss = 0.676027238368988
Iteration [3260]: Loss = 0.6758959889411926
Iteration [3261]: Loss = 0.6757500767707825
Iteration [3262]: Loss = 5.0772223472595215
Iteration [3263]: Loss = 0.675601065158844
Iteration [3264]: Loss = 0.6755824089050293
Iteration [3265]: Loss = 5.077516078948975
Iteration [3266]: Loss = 0.6756507158279419
Iteration [3267]: Loss = 0.6757245063781738
Iteration [3268]: Loss = 0.6757635474205017
Iteration [3269]: Loss = 0.6757711172103882
Iteration [3270]: Loss = 0.6757502555847168
Iteration [3271]: Loss = 0.6757038235664368
Iteration [3272]: Loss = 0.6756345629692078
Iteration [3273]: Loss = 0.6755445003509521
Iteration [3274]: Loss = 0.6754356622695923
Iteration [3275]: Loss = 0.6753103137016296
Iteration [3276]: Loss = 0.6751695871353149
Iteration [3277]: Loss = 5.080413341522217
Iteration [3278]: Loss = 0.6750297546386719
Iteration [3279]: Loss = 0.6750152707099915
Iteration [3280]: Loss = 5.0806403160095215
Iteration [3281]: Loss = 0.6750906109809875
Iteration [3282]: Loss = 0.6751675605773926
Iteration [3283]: Loss = 0.6752093434333801
Iteration [3284]: Loss = 0.6752192378044128
Iteration [3285]: Loss = 0.6752007603645325
Iteration [3286]: Loss = 5.079631328582764
Iteration [3287]: Loss = 0.6752692461013794
Iteration [3288]: Loss = 0.67534339427948
Iteration [3289]: Loss = 0.6753825545310974
Iteration [3290]: Loss = 0.6753902435302734
Iteration [3291]: Loss = 0.6753694415092468
Iteration [3292]: Loss = 0.6753231287002563
Iteration [3293]: Loss = 0.6752538084983826
Iteration [3294]: Loss = 0.6751638054847717
Iteration [3295]: Loss = 0.6750551462173462
Iteration [3296]: Loss = 5.080888271331787
Iteration [3297]: Loss = 0.6749700307846069
Iteration [3298]: Loss = 0.6749786734580994
Iteration [3299]: Loss = 5.0807271003723145
Iteration [3300]: Loss = 0.6750938892364502
Iteration [3301]: Loss = 0.675187885761261
Iteration [3302]: Loss = 0.6752450466156006
Iteration [3303]: Loss = 0.6752687096595764
Iteration [3304]: Loss = 0.6752626299858093
Iteration [3305]: Loss = 5.079226970672607
Iteration [3306]: Loss = 0.6753522753715515
Iteration [3307]: Loss = 0.6754354238510132
Iteration [3308]: Loss = 5.077823638916016
Iteration [3309]: Loss = 0.6756777167320251
Iteration [3310]: Loss = 0.675825834274292
Iteration [3311]: Loss = 0.6759315133094788
Iteration [3312]: Loss = 0.6759991645812988
Iteration [3313]: Loss = 0.6760324239730835
Iteration [3314]: Loss = 5.074767112731934
Iteration [3315]: Loss = 0.6761894822120667
Iteration [3316]: Loss = 0.676301121711731
Iteration [3317]: Loss = 0.676374077796936
Iteration [3318]: Loss = 0.676412045955658
Iteration [3319]: Loss = 0.6764187216758728
Iteration [3320]: Loss = 5.072764873504639
Iteration [3321]: Loss = 0.676530122756958
Iteration [3322]: Loss = 0.6766222715377808
Iteration [3323]: Loss = 0.6766777038574219
Iteration [3324]: Loss = 0.6766999959945679
Iteration [3325]: Loss = 0.6766922473907471
Iteration [3326]: Loss = 0.6766576766967773
Iteration [3327]: Loss = 0.6765987873077393
Iteration [3328]: Loss = 0.6765181422233582
Iteration [3329]: Loss = 5.0726494789123535
Iteration [3330]: Loss = 0.6764804720878601
Iteration [3331]: Loss = 0.6765092611312866
Iteration [3332]: Loss = 0.6765075922012329
Iteration [3333]: Loss = 0.6764782667160034
Iteration [3334]: Loss = 0.6764242649078369
Iteration [3335]: Loss = 0.6763479113578796
Iteration [3336]: Loss = 0.6762514114379883
Iteration [3337]: Loss = 0.6761369109153748
Iteration [3338]: Loss = 5.074925899505615
Iteration [3339]: Loss = 0.6760415434837341
Iteration [3340]: Loss = 0.6760457754135132
Iteration [3341]: Loss = 0.6760219931602478
Iteration [3342]: Loss = 0.6759729385375977
Iteration [3343]: Loss = 0.675900936126709
Iteration [3344]: Loss = 0.6758084297180176
Iteration [3345]: Loss = 0.6756975054740906
Iteration [3346]: Loss = 0.6755698919296265
Iteration [3347]: Loss = 0.6754273176193237
Iteration [3348]: Loss = 0.675271213054657
Iteration [3349]: Loss = 0.6751030087471008
Iteration [3350]: Loss = 0.674923837184906
Iteration [3351]: Loss = 5.081969738006592
Iteration [3352]: Loss = 9.489399909973145
Iteration [3353]: Loss = 0.6750348806381226
Iteration [3354]: Loss = 5.078878879547119
Iteration [3355]: Loss = 0.6756747961044312
Iteration [3356]: Loss = 0.6759921312332153
Iteration [3357]: Loss = 0.6762504577636719
Iteration [3358]: Loss = 0.6764558553695679
Iteration [3359]: Loss = 0.6766133308410645
Iteration [3360]: Loss = 0.6767276525497437
Iteration [3361]: Loss = 0.6768031716346741
Iteration [3362]: Loss = 5.070296764373779
Iteration [3363]: Loss = 5.0692596435546875
Iteration [3364]: Loss = 0.6773515343666077
Iteration [3365]: Loss = 0.6776123642921448
Iteration [3366]: Loss = 0.6778198480606079
Iteration [3367]: Loss = 0.6779791116714478
Iteration [3368]: Loss = 9.448700904846191
Iteration [3369]: Loss = 0.6785247921943665
Iteration [3370]: Loss = 0.6788848638534546
Iteration [3371]: Loss = 0.6791818737983704
Iteration [3372]: Loss = 0.6794219613075256
Iteration [3373]: Loss = 0.6796109080314636
Iteration [3374]: Loss = 0.679753839969635
Iteration [3375]: Loss = 0.6798551082611084
Iteration [3376]: Loss = 0.6799188256263733
Iteration [3377]: Loss = 0.6799488663673401
Iteration [3378]: Loss = 5.053216457366943
Iteration [3379]: Loss = 0.680098295211792
Iteration [3380]: Loss = 0.6802055239677429
Iteration [3381]: Loss = 0.6802747845649719
Iteration [3382]: Loss = 0.6803098320960999
Iteration [3383]: Loss = 0.6803138256072998
Iteration [3384]: Loss = 5.051345348358154
Iteration [3385]: Loss = 5.050641059875488
Iteration [3386]: Loss = 0.6806838512420654
Iteration [3387]: Loss = 0.6808955073356628
Iteration [3388]: Loss = 5.047140121459961
Iteration [3389]: Loss = 5.045522212982178
Iteration [3390]: Loss = 0.6817700862884521
Iteration [3391]: Loss = 0.6821169257164001
Iteration [3392]: Loss = 0.6824019551277161
Iteration [3393]: Loss = 0.682631254196167
Iteration [3394]: Loss = 5.037585258483887
Iteration [3395]: Loss = 0.6831204295158386
Iteration [3396]: Loss = 0.6833721995353699
Iteration [3397]: Loss = 0.6835715770721436
Iteration [3398]: Loss = 0.683723509311676
Iteration [3399]: Loss = 0.6838329434394836
Iteration [3400]: Loss = 5.031639575958252
Iteration [3401]: Loss = 0.6841170191764832
Iteration [3402]: Loss = 0.6842812895774841
Iteration [3403]: Loss = 0.68440181016922
Iteration [3404]: Loss = 0.6844826936721802
Iteration [3405]: Loss = 0.6845279335975647
Iteration [3406]: Loss = 5.028181076049805
Iteration [3407]: Loss = 0.6847023367881775
Iteration [3408]: Loss = 0.6848198175430298
Iteration [3409]: Loss = 0.6848981976509094
Iteration [3410]: Loss = 0.6849409937858582
Iteration [3411]: Loss = 0.6849521398544312
Iteration [3412]: Loss = 0.6849341988563538
Iteration [3413]: Loss = 0.6848907470703125
Iteration [3414]: Loss = 5.026649475097656
Iteration [3415]: Loss = 0.684913158416748
Iteration [3416]: Loss = 5.025879383087158
Iteration [3417]: Loss = 0.6851629614830017
Iteration [3418]: Loss = 0.6853125691413879
Iteration [3419]: Loss = 0.6854197382926941
Iteration [3420]: Loss = 0.6854885816574097
Iteration [3421]: Loss = 0.6855229735374451
Iteration [3422]: Loss = 5.0228471755981445
Iteration [3423]: Loss = 0.6856784224510193
Iteration [3424]: Loss = 0.6857879757881165
Iteration [3425]: Loss = 0.6858589053153992
Iteration [3426]: Loss = 0.6858951449394226
Iteration [3427]: Loss = 0.6859002113342285
Iteration [3428]: Loss = 5.020951747894287
Iteration [3429]: Loss = 0.6860054135322571
Iteration [3430]: Loss = 0.6860933899879456
Iteration [3431]: Loss = 0.6861449480056763
Iteration [3432]: Loss = 0.6861637830734253
Iteration [3433]: Loss = 0.686152994632721
Iteration [3434]: Loss = 0.686115562915802
Iteration [3435]: Loss = 0.6860541701316833
Iteration [3436]: Loss = 5.020442485809326
Iteration [3437]: Loss = 0.6860460042953491
Iteration [3438]: Loss = 0.6860858798027039
Iteration [3439]: Loss = 0.6860939860343933
Iteration [3440]: Loss = 0.6860735416412354
Iteration [3441]: Loss = 0.686027467250824
Iteration [3442]: Loss = 0.6859583258628845
Iteration [3443]: Loss = 0.6858682632446289
Iteration [3444]: Loss = 0.6857593059539795
Iteration [3445]: Loss = 0.6856335997581482
Iteration [3446]: Loss = 0.6854926943778992
Iteration [3447]: Loss = 0.685338020324707
Iteration [3448]: Loss = 5.024769306182861
Iteration [3449]: Loss = 0.6851710081100464
Iteration [3450]: Loss = 0.6851431727409363
Iteration [3451]: Loss = 0.6850906014442444
Iteration [3452]: Loss = 0.6850154399871826
Iteration [3453]: Loss = 0.6849200129508972
Iteration [3454]: Loss = 0.6848063468933105
Iteration [3455]: Loss = 0.6846764087677002
Iteration [3456]: Loss = 0.6845316290855408
Iteration [3457]: Loss = 0.6843734979629517
Iteration [3458]: Loss = 0.6842034459114075
Iteration [3459]: Loss = 0.6840226650238037
Iteration [3460]: Loss = 0.6838322281837463
Iteration [3461]: Loss = 0.6836329698562622
Iteration [3462]: Loss = 0.6834259033203125
Iteration [3463]: Loss = 0.6832117438316345
Iteration [3464]: Loss = 0.6829911470413208
Iteration [3465]: Loss = 0.6827651262283325
Iteration [3466]: Loss = 0.6825336813926697
Iteration [3467]: Loss = 0.6822977662086487
Iteration [3468]: Loss = 0.6820576786994934
Iteration [3469]: Loss = 0.6818138957023621
Iteration [3470]: Loss = 0.6815667152404785
Iteration [3471]: Loss = 0.681316614151001
Iteration [3472]: Loss = 0.6810636520385742
Iteration [3473]: Loss = 0.6808083653450012
Iteration [3474]: Loss = 0.6805509924888611
Iteration [3475]: Loss = 5.051337718963623
Iteration [3476]: Loss = 0.6802096366882324
Iteration [3477]: Loss = 0.6801084280014038
Iteration [3478]: Loss = 0.6799896359443665
Iteration [3479]: Loss = 0.679855227470398
Iteration [3480]: Loss = 0.679706335067749
Iteration [3481]: Loss = 0.6795448660850525
Iteration [3482]: Loss = 0.6793718338012695
Iteration [3483]: Loss = 0.6791884899139404
Iteration [3484]: Loss = 0.6789957284927368
Iteration [3485]: Loss = 5.059549331665039
Iteration [3486]: Loss = 0.6787654757499695
Iteration [3487]: Loss = 5.060004711151123
Iteration [3488]: Loss = 0.6788145303726196
Iteration [3489]: Loss = 0.6788798570632935
Iteration [3490]: Loss = 0.6789109110832214
Iteration [3491]: Loss = 0.6789113879203796
Iteration [3492]: Loss = 0.6788842678070068
Iteration [3493]: Loss = 0.6788321733474731
Iteration [3494]: Loss = 0.6787577271461487
Iteration [3495]: Loss = 0.6786630153656006
Iteration [3496]: Loss = 0.6785503029823303
Iteration [3497]: Loss = 0.6784212589263916
Iteration [3498]: Loss = 0.6782774329185486
Iteration [3499]: Loss = 0.6781203150749207
Iteration [3500]: Loss = 5.064189434051514
Iteration [3501]: Loss = 0.6779512166976929
Iteration [3502]: Loss = 0.6779234409332275
Iteration [3503]: Loss = 0.6778711080551147
Iteration [3504]: Loss = 0.6777961850166321
Iteration [3505]: Loss = 5.065566539764404
Iteration [3506]: Loss = 0.6777676939964294
Iteration [3507]: Loss = 0.6777998805046082
Iteration [3508]: Loss = 0.6778014302253723
Iteration [3509]: Loss = 0.6777750849723816
Iteration [3510]: Loss = 5.065441608428955
Iteration [3511]: Loss = 0.6778295040130615
Iteration [3512]: Loss = 0.677897036075592
Iteration [3513]: Loss = 5.064304351806641
Iteration [3514]: Loss = 0.6781116724014282
Iteration [3515]: Loss = 5.062558650970459
Iteration [3516]: Loss = 0.6785205602645874
Iteration [3517]: Loss = 0.678739070892334
Iteration [3518]: Loss = 0.6789082288742065
Iteration [3519]: Loss = 0.6790331602096558
Iteration [3520]: Loss = 0.6791180372238159
Iteration [3521]: Loss = 0.6791667938232422
Iteration [3522]: Loss = 0.6791832447052002
Iteration [3523]: Loss = 5.057485103607178
Iteration [3524]: Loss = 5.056718349456787
Iteration [3525]: Loss = 0.6795867085456848
Iteration [3526]: Loss = 0.6798081994056702
Iteration [3527]: Loss = 0.6799802780151367
Iteration [3528]: Loss = 0.6801074743270874
Iteration [3529]: Loss = 0.6801944971084595
Iteration [3530]: Loss = 5.051590919494629
Iteration [3531]: Loss = 0.6804417967796326
Iteration [3532]: Loss = 0.6805911660194397
Iteration [3533]: Loss = 5.049111843109131
Iteration [3534]: Loss = 0.6809450387954712
Iteration [3535]: Loss = 0.6811399459838867
Iteration [3536]: Loss = 0.6812877655029297
Iteration [3537]: Loss = 0.6813931465148926
Iteration [3538]: Loss = 5.044945240020752
Iteration [3539]: Loss = 0.6816717386245728
Iteration [3540]: Loss = 0.6818343997001648
Iteration [3541]: Loss = 0.6819530129432678
Iteration [3542]: Loss = 0.6820323467254639
Iteration [3543]: Loss = 0.6820761561393738
Iteration [3544]: Loss = 0.6820876598358154
Iteration [3545]: Loss = 0.6820704936981201
Iteration [3546]: Loss = 5.041851997375488
Iteration [3547]: Loss = 5.041240215301514
Iteration [3548]: Loss = 0.6823906898498535
Iteration [3549]: Loss = 0.6825892925262451
Iteration [3550]: Loss = 0.6827406287193298
Iteration [3551]: Loss = 0.6828492283821106
Iteration [3552]: Loss = 0.6829193234443665
Iteration [3553]: Loss = 0.6829544901847839
Iteration [3554]: Loss = 0.6829586029052734
Iteration [3555]: Loss = 0.6829344034194946
Iteration [3556]: Loss = 5.037178993225098
Iteration [3557]: Loss = 0.6829913854598999
Iteration [3558]: Loss = 0.6830593943595886
Iteration [3559]: Loss = 0.6830929517745972
Iteration [3560]: Loss = 0.6830953359603882
Iteration [3561]: Loss = 5.036172389984131
Iteration [3562]: Loss = 5.035477638244629
Iteration [3563]: Loss = 0.6834630370140076
Iteration [3564]: Loss = 0.6836743950843811
Iteration [3565]: Loss = 0.6838369965553284
Iteration [3566]: Loss = 0.6839556694030762
Iteration [3567]: Loss = 5.030928611755371
Iteration [3568]: Loss = 0.684256374835968
Iteration [3569]: Loss = 5.028793811798096
Iteration [3570]: Loss = 0.6847329139709473
Iteration [3571]: Loss = 5.025805950164795
Iteration [3572]: Loss = 0.6853513121604919
Iteration [3573]: Loss = 0.6856583952903748
Iteration [3574]: Loss = 0.6859074234962463
Iteration [3575]: Loss = 5.019726753234863
Iteration [3576]: Loss = 5.017963886260986
Iteration [3577]: Loss = 5.015573978424072
Iteration [3578]: Loss = 0.6874209642410278
Iteration [3579]: Loss = 0.6878867149353027
Iteration [3580]: Loss = 0.6882784962654114
Iteration [3581]: Loss = 0.6886035799980164
Iteration [3582]: Loss = 0.6888684034347534
Iteration [3583]: Loss = 0.6890789866447449
Iteration [3584]: Loss = 0.6892408132553101
Iteration [3585]: Loss = 0.6893584728240967
Iteration [3586]: Loss = 0.6894364953041077
Iteration [3587]: Loss = 0.6894786357879639
Iteration [3588]: Loss = 0.6894886493682861
Iteration [3589]: Loss = 0.6894697546958923
Iteration [3590]: Loss = 0.6894243955612183
Iteration [3591]: Loss = 0.689355731010437
Iteration [3592]: Loss = 0.6892658472061157
Iteration [3593]: Loss = 0.689156711101532
Iteration [3594]: Loss = 5.003971576690674
Iteration [3595]: Loss = 0.6890674829483032
Iteration [3596]: Loss = 0.6890724897384644
Iteration [3597]: Loss = 0.6890490651130676
Iteration [3598]: Loss = 0.6890000700950623
Iteration [3599]: Loss = 5.004522323608398
Iteration [3600]: Loss = 0.6890130639076233
Iteration [3601]: Loss = 0.6890618801116943
Iteration [3602]: Loss = 0.6890777945518494
Iteration [3603]: Loss = 0.6890641450881958
Iteration [3604]: Loss = 5.004008769989014
Iteration [3605]: Loss = 0.6891376376152039
Iteration [3606]: Loss = 0.6892120838165283
Iteration [3607]: Loss = 0.689251184463501
Iteration [3608]: Loss = 5.002748966217041
Iteration [3609]: Loss = 0.6894149780273438
Iteration [3610]: Loss = 0.6895279288291931
Iteration [3611]: Loss = 0.6896015405654907
Iteration [3612]: Loss = 0.6896397471427917
Iteration [3613]: Loss = 5.00067138671875
Iteration [3614]: Loss = 9.309869766235352
Iteration [3615]: Loss = 0.6902655363082886
Iteration [3616]: Loss = 4.995272636413574
Iteration [3617]: Loss = 0.6911537647247314
Iteration [3618]: Loss = 0.6915752291679382
Iteration [3619]: Loss = 0.691926896572113
Iteration [3620]: Loss = 0.6922159194946289
Iteration [3621]: Loss = 4.985711574554443
Iteration [3622]: Loss = 0.6928054690361023
Iteration [3623]: Loss = 4.982250213623047
Iteration [3624]: Loss = 0.693511426448822
Iteration [3625]: Loss = 4.9782395362854
Iteration [3626]: Loss = 0.6943114399909973
Iteration [3627]: Loss = 4.973787307739258
Iteration [3628]: Loss = 0.695187509059906
Iteration [3629]: Loss = 0.6956031918525696
Iteration [3630]: Loss = 0.6959496736526489
Iteration [3631]: Loss = 0.6962337493896484
Iteration [3632]: Loss = 4.964456081390381
Iteration [3633]: Loss = 0.6968141198158264
Iteration [3634]: Loss = 0.6971035599708557
Iteration [3635]: Loss = 0.6973361372947693
Iteration [3636]: Loss = 0.6975175142288208
Iteration [3637]: Loss = 0.6976526975631714
Iteration [3638]: Loss = 4.9576945304870605
Iteration [3639]: Loss = 0.6979780793190002
Iteration [3640]: Loss = 0.6981589794158936
Iteration [3641]: Loss = 0.6982935667037964
Iteration [3642]: Loss = 0.6983864307403564
Iteration [3643]: Loss = 0.6984419226646423
Iteration [3644]: Loss = 0.6984636187553406
Iteration [3645]: Loss = 0.6984548568725586
Iteration [3646]: Loss = 0.6984186768531799
Iteration [3647]: Loss = 0.6983576416969299
Iteration [3648]: Loss = 0.6982744932174683
Iteration [3649]: Loss = 0.6981714367866516
Iteration [3650]: Loss = 0.6980502605438232
Iteration [3651]: Loss = 0.6979128122329712
Iteration [3652]: Loss = 0.697760820388794
Iteration [3653]: Loss = 0.6975957155227661
Iteration [3654]: Loss = 0.697418749332428
Iteration [3655]: Loss = 0.6972310543060303
Iteration [3656]: Loss = 0.6970338225364685
Iteration [3657]: Loss = 0.6968280076980591
Iteration [3658]: Loss = 0.6966144442558289
Iteration [3659]: Loss = 0.6963938474655151
Iteration [3660]: Loss = 0.6961669921875
Iteration [3661]: Loss = 0.6959345936775208
Iteration [3662]: Loss = 0.6956970691680908
Iteration [3663]: Loss = 0.695455014705658
Iteration [3664]: Loss = 4.9710693359375
Iteration [3665]: Loss = 0.6951369643211365
Iteration [3666]: Loss = 0.6950439214706421
Iteration [3667]: Loss = 0.6949320435523987
Iteration [3668]: Loss = 0.6948030591011047
Iteration [3669]: Loss = 0.6946586966514587
Iteration [3670]: Loss = 0.6945005059242249
Iteration [3671]: Loss = 4.975720405578613
Iteration [3672]: Loss = 0.6943260431289673
Iteration [3673]: Loss = 0.6942941546440125
Iteration [3674]: Loss = 4.976211071014404
Iteration [3675]: Loss = 4.975693225860596
Iteration [3676]: Loss = 0.6945720314979553
Iteration [3677]: Loss = 0.6947572231292725
Iteration [3678]: Loss = 0.69489586353302
Iteration [3679]: Loss = 0.6949924826622009
Iteration [3680]: Loss = 0.6950513124465942
Iteration [3681]: Loss = 0.6950761079788208
Iteration [3682]: Loss = 0.6950703263282776
Iteration [3683]: Loss = 0.6950368881225586
Iteration [3684]: Loss = 0.6949784755706787
Iteration [3685]: Loss = 0.6948976516723633
Iteration [3686]: Loss = 0.6947967410087585
Iteration [3687]: Loss = 0.6946775913238525
Iteration [3688]: Loss = 4.974596977233887
Iteration [3689]: Loss = 0.6945696473121643
Iteration [3690]: Loss = 0.6945661902427673
Iteration [3691]: Loss = 0.6945348978042603
Iteration [3692]: Loss = 0.6944785714149475
Iteration [3693]: Loss = 0.6943995356559753
Iteration [3694]: Loss = 0.6943002343177795
Iteration [3695]: Loss = 0.6941825747489929
Iteration [3696]: Loss = 0.6940484642982483
Iteration [3697]: Loss = 0.6938994526863098
Iteration [3698]: Loss = 0.6937370896339417
Iteration [3699]: Loss = 0.6935626268386841
Iteration [3700]: Loss = 0.6933773756027222
Iteration [3701]: Loss = 0.6931825876235962
Iteration [3702]: Loss = 0.6929788589477539
Iteration [3703]: Loss = 0.6927672028541565
Iteration [3704]: Loss = 0.6925485730171204
Iteration [3705]: Loss = 4.986375331878662
Iteration [3706]: Loss = 4.9866533279418945
Iteration [3707]: Loss = 0.6923736929893494
Iteration [3708]: Loss = 4.985766410827637
Iteration [3709]: Loss = 0.6926450729370117
Iteration [3710]: Loss = 0.6928035616874695
Iteration [3711]: Loss = 0.6929181218147278
Iteration [3712]: Loss = 4.982814311981201
Iteration [3713]: Loss = 0.6932097673416138
Iteration [3714]: Loss = 0.6933767795562744
Iteration [3715]: Loss = 0.6934991478919983
Iteration [3716]: Loss = 4.979691505432129
Iteration [3717]: Loss = 4.978508949279785
Iteration [3718]: Loss = 4.976657390594482
Iteration [3719]: Loss = 0.6946158409118652
Iteration [3720]: Loss = 0.6950045228004456
Iteration [3721]: Loss = 0.695326566696167
Iteration [3722]: Loss = 0.6955883502960205
Iteration [3723]: Loss = 0.6957960724830627
Iteration [3724]: Loss = 0.6959546804428101
Iteration [3725]: Loss = 0.6960694789886475
Iteration [3726]: Loss = 0.6961444020271301
Iteration [3727]: Loss = 0.6961836218833923
Iteration [3728]: Loss = 0.6961907148361206
Iteration [3729]: Loss = 0.6961686611175537
Iteration [3730]: Loss = 0.6961205005645752
Iteration [3731]: Loss = 0.6960487961769104
Iteration [3732]: Loss = 0.6959558725357056
Iteration [3733]: Loss = 0.6958438754081726
Iteration [3734]: Loss = 0.6957146525382996
Iteration [3735]: Loss = 0.6955700516700745
Iteration [3736]: Loss = 0.6954113841056824
Iteration [3737]: Loss = 0.695240318775177
Iteration [3738]: Loss = 4.97186803817749
Iteration [3739]: Loss = 0.6950438022613525
Iteration [3740]: Loss = 4.972159385681152
Iteration [3741]: Loss = 0.6951152086257935
Iteration [3742]: Loss = 4.97117805480957
Iteration [3743]: Loss = 0.6954032778739929
Iteration [3744]: Loss = 0.6955685019493103
Iteration [3745]: Loss = 0.6956890821456909
Iteration [3746]: Loss = 0.6957693099975586
Iteration [3747]: Loss = 0.6958132982254028
Iteration [3748]: Loss = 0.6958245038986206
Iteration [3749]: Loss = 4.967912673950195
Iteration [3750]: Loss = 0.6959393620491028
Iteration [3751]: Loss = 0.696030855178833
Iteration [3752]: Loss = 0.6960848569869995
Iteration [3753]: Loss = 0.6961051821708679
Iteration [3754]: Loss = 4.9663896560668945
Iteration [3755]: Loss = 0.6962354183197021
Iteration [3756]: Loss = 4.965131759643555
Iteration [3757]: Loss = 0.696570634841919
Iteration [3758]: Loss = 4.962904930114746
Iteration [3759]: Loss = 0.6970714926719666
Iteration [3760]: Loss = 0.6973273754119873
Iteration [3761]: Loss = 0.6975296139717102
Iteration [3762]: Loss = 0.6976832151412964
Iteration [3763]: Loss = 0.697793185710907
Iteration [3764]: Loss = 0.6978638172149658
Iteration [3765]: Loss = 0.6978990435600281
Iteration [3766]: Loss = 4.956874847412109
Iteration [3767]: Loss = 0.698054313659668
Iteration [3768]: Loss = 0.698162853717804
Iteration [3769]: Loss = 0.698232114315033
Iteration [3770]: Loss = 0.6982659697532654
Iteration [3771]: Loss = 0.6982680559158325
Iteration [3772]: Loss = 0.6982414126396179
Iteration [3773]: Loss = 0.6981889605522156
Iteration [3774]: Loss = 0.6981132626533508
Iteration [3775]: Loss = 0.6980165839195251
Iteration [3776]: Loss = 0.6979009509086609
Iteration [3777]: Loss = 0.69776850938797
Iteration [3778]: Loss = 0.6976206302642822
Iteration [3779]: Loss = 0.6974589824676514
Iteration [3780]: Loss = 0.697284996509552
Iteration [3781]: Loss = 0.6970998644828796
Iteration [3782]: Loss = 0.6969047784805298
Iteration [3783]: Loss = 0.6967005729675293
Iteration [3784]: Loss = 0.6964883804321289
Iteration [3785]: Loss = 0.6962687969207764
Iteration [3786]: Loss = 0.696042537689209
Iteration [3787]: Loss = 9.239970207214355
Iteration [3788]: Loss = 0.6959296464920044
Iteration [3789]: Loss = 4.96684455871582
Iteration [3790]: Loss = 0.6962281465530396
Iteration [3791]: Loss = 0.6954796314239502
Iteration [3792]: Loss = 0.6956036686897278
Iteration [3793]: Loss = 0.6956871747970581
Iteration [3794]: Loss = 0.6957342624664307
Iteration [3795]: Loss = 0.695748507976532
Iteration [3796]: Loss = 0.6957330703735352
Iteration [3797]: Loss = 0.6956909894943237
Iteration [3798]: Loss = 4.968871116638184
Iteration [3799]: Loss = 0.6957142949104309
Iteration [3800]: Loss = 0.6957665681838989
Iteration [3801]: Loss = 0.6957855224609375
Iteration [3802]: Loss = 0.6957743167877197
Iteration [3803]: Loss = 4.9682841300964355
Iteration [3804]: Loss = 0.6958503127098083
Iteration [3805]: Loss = 0.6959250569343567
Iteration [3806]: Loss = 0.6959641575813293
Iteration [3807]: Loss = 4.967042922973633
Iteration [3808]: Loss = 4.966226100921631
Iteration [3809]: Loss = 0.6964136958122253
Iteration [3810]: Loss = 0.6966446042060852
Iteration [3811]: Loss = 0.6968244314193726
Iteration [3812]: Loss = 4.961840629577637
Iteration [3813]: Loss = 0.6972265243530273
Iteration [3814]: Loss = 0.6974401473999023
Iteration [3815]: Loss = 0.6976044178009033
Iteration [3816]: Loss = 0.697723925113678
Iteration [3817]: Loss = 0.6978033781051636
Iteration [3818]: Loss = 0.6978464722633362
Iteration [3819]: Loss = 9.216368675231934
Iteration [3820]: Loss = 0.6981889605522156
Iteration [3821]: Loss = 0.6984598636627197
Iteration [3822]: Loss = 0.6986758708953857
Iteration [3823]: Loss = 0.6988421678543091
Iteration [3824]: Loss = 0.6989638209342957
Iteration [3825]: Loss = 0.6990451216697693
Iteration [3826]: Loss = 0.6990902423858643
Iteration [3827]: Loss = 0.6991026997566223
Iteration [3828]: Loss = 0.6990856528282166
Iteration [3829]: Loss = 0.6990421414375305
Iteration [3830]: Loss = 0.6989746689796448
Iteration [3831]: Loss = 4.951713562011719
Iteration [3832]: Loss = 0.6989535093307495
Iteration [3833]: Loss = 0.6989863514900208
Iteration [3834]: Loss = 4.951179504394531
Iteration [3835]: Loss = 0.69913649559021
Iteration [3836]: Loss = 0.6992422938346863
Iteration [3837]: Loss = 0.6993094682693481
Iteration [3838]: Loss = 0.6993415951728821
Iteration [3839]: Loss = 0.6993423104286194
Iteration [3840]: Loss = 4.949466705322266
Iteration [3841]: Loss = 0.6994375586509705
Iteration [3842]: Loss = 0.6995199918746948
Iteration [3843]: Loss = 4.948151588439941
Iteration [3844]: Loss = 0.6997546553611755
Iteration [3845]: Loss = 4.9464216232299805
Iteration [3846]: Loss = 0.7001714706420898
Iteration [3847]: Loss = 0.7003907561302185
Iteration [3848]: Loss = 0.7005600929260254
Iteration [3849]: Loss = 0.700684130191803
Iteration [3850]: Loss = 0.7007677555084229
Iteration [3851]: Loss = 0.7008147239685059
Iteration [3852]: Loss = 0.7008286714553833
Iteration [3853]: Loss = 0.700812816619873
Iteration [3854]: Loss = 0.7007702589035034
Iteration [3855]: Loss = 0.7007037401199341
Iteration [3856]: Loss = 0.7006153464317322
Iteration [3857]: Loss = 0.7005073428153992
Iteration [3858]: Loss = 0.700381875038147
Iteration [3859]: Loss = 0.7002405524253845
Iteration [3860]: Loss = 0.700084924697876
Iteration [3861]: Loss = 0.6999164819717407
Iteration [3862]: Loss = 0.6997364163398743
Iteration [3863]: Loss = 9.196965217590332
Iteration [3864]: Loss = 4.9474592208862305
Iteration [3865]: Loss = 0.6999816298484802
Iteration [3866]: Loss = 0.7002087235450745
Iteration [3867]: Loss = 0.7003852128982544
Iteration [3868]: Loss = 0.7005161046981812
Iteration [3869]: Loss = 0.7006058692932129
Iteration [3870]: Loss = 0.7006584405899048
Iteration [3871]: Loss = 4.942341327667236
Iteration [3872]: Loss = 4.9414849281311035
Iteration [3873]: Loss = 0.7011356353759766
Iteration [3874]: Loss = 0.7013722658157349
Iteration [3875]: Loss = 0.7015572786331177
Iteration [3876]: Loss = 0.7016956210136414
Iteration [3877]: Loss = 0.7017920613288879
Iteration [3878]: Loss = 0.7018507719039917
Iteration [3879]: Loss = 0.7018753886222839
Iteration [3880]: Loss = 0.7018692493438721
Iteration [3881]: Loss = 4.936307430267334
Iteration [3882]: Loss = 0.7019519805908203
Iteration [3883]: Loss = 0.7020286321640015
Iteration [3884]: Loss = 4.935092926025391
Iteration [3885]: Loss = 0.7022477984428406
Iteration [3886]: Loss = 0.7023815512657166
Iteration [3887]: Loss = 0.7024744749069214
Iteration [3888]: Loss = 0.7025305032730103
Iteration [3889]: Loss = 0.7025532722473145
Iteration [3890]: Loss = 0.7025461792945862
Iteration [3891]: Loss = 0.7025120854377747
Iteration [3892]: Loss = 0.7024537324905396
Iteration [3893]: Loss = 0.7023735046386719
Iteration [3894]: Loss = 0.7022736668586731
Iteration [3895]: Loss = 4.934638977050781
Iteration [3896]: Loss = 0.7021939754486084
Iteration [3897]: Loss = 0.7022006511688232
Iteration [3898]: Loss = 0.702178955078125
Iteration [3899]: Loss = 0.7021318078041077
Iteration [3900]: Loss = 0.7020617127418518
Iteration [3901]: Loss = 0.7019708752632141
Iteration [3902]: Loss = 0.7018613219261169
Iteration [3903]: Loss = 0.7017351388931274
Iteration [3904]: Loss = 0.7015939354896545
Iteration [3905]: Loss = 0.7014389038085938
Iteration [3906]: Loss = 0.7012717723846436
Iteration [3907]: Loss = 0.7010936737060547
Iteration [3908]: Loss = 0.7009056806564331
Iteration [3909]: Loss = 0.7007086277008057
Iteration [3910]: Loss = 4.943248748779297
Iteration [3911]: Loss = 0.7004638910293579
Iteration [3912]: Loss = 4.943789005279541
Iteration [3913]: Loss = 4.94333553314209
Iteration [3914]: Loss = 0.7007091045379639
Iteration [3915]: Loss = 0.7008813619613647
Iteration [3916]: Loss = 0.7010088562965393
Iteration [3917]: Loss = 0.70109623670578
Iteration [3918]: Loss = 0.7011471390724182
Iteration [3919]: Loss = 0.7011654376983643
Iteration [3920]: Loss = 0.7011541128158569
Iteration [3921]: Loss = 4.940053462982178
Iteration [3922]: Loss = 0.7012263536453247
Iteration [3923]: Loss = 4.9391069412231445
Iteration [3924]: Loss = 0.7015057802200317
Iteration [3925]: Loss = 4.937191009521484
Iteration [3926]: Loss = 0.7019527554512024
Iteration [3927]: Loss = 4.934494495391846
Iteration [3928]: Loss = 0.7025349736213684
Iteration [3929]: Loss = 0.7028235793113708
Iteration [3930]: Loss = 4.929962635040283
Iteration [3931]: Loss = 4.928134918212891
Iteration [3932]: Loss = 0.7038680911064148
Iteration [3933]: Loss = 0.704254686832428
Iteration [3934]: Loss = 0.70457524061203
Iteration [3935]: Loss = 0.704836368560791
Iteration [3936]: Loss = 0.7050437331199646
Iteration [3937]: Loss = 0.705202579498291
Iteration [3938]: Loss = 0.7053180932998657
Iteration [3939]: Loss = 0.7053940892219543
Iteration [3940]: Loss = 0.7054346203804016
Iteration [3941]: Loss = 0.7054433226585388
Iteration [3942]: Loss = 0.7054232954978943
Iteration [3943]: Loss = 0.7053773403167725
Iteration [3944]: Loss = 0.7053079605102539
Iteration [3945]: Loss = 0.7052176594734192
Iteration [3946]: Loss = 0.7051085829734802
Iteration [3947]: Loss = 0.7049823999404907
Iteration [3948]: Loss = 0.7048408389091492
Iteration [3949]: Loss = 0.7046855092048645
Iteration [3950]: Loss = 0.7045178413391113
Iteration [3951]: Loss = 0.7043389678001404
Iteration [3952]: Loss = 0.7041500806808472
Iteration [3953]: Loss = 0.7039521932601929
Iteration [3954]: Loss = 0.7037460207939148
Iteration [3955]: Loss = 0.7035325765609741
Iteration [3956]: Loss = 4.928630828857422
Iteration [3957]: Loss = 0.7032594084739685
Iteration [3958]: Loss = 0.703183650970459
Iteration [3959]: Loss = 4.929798126220703
Iteration [3960]: Loss = 0.7031455039978027
Iteration [3961]: Loss = 4.929371356964111
Iteration [3962]: Loss = 0.7033357620239258
Iteration [3963]: Loss = 0.7034574151039124
Iteration [3964]: Loss = 4.927456378936768
Iteration [3965]: Loss = 0.7037565112113953
Iteration [3966]: Loss = 4.925459384918213
Iteration [3967]: Loss = 0.7042192816734314
Iteration [3968]: Loss = 4.922703266143799
Iteration [3969]: Loss = 0.7048141360282898
Iteration [3970]: Loss = 0.7051082253456116
Iteration [3971]: Loss = 0.7053452134132385
Iteration [3972]: Loss = 0.7055308222770691
Iteration [3973]: Loss = 0.7056699991226196
Iteration [3974]: Loss = 0.7057675123214722
Iteration [3975]: Loss = 0.7058273553848267
Iteration [3976]: Loss = 0.7058534026145935
Iteration [3977]: Loss = 4.915513515472412
Iteration [3978]: Loss = 0.7059884667396545
Iteration [3979]: Loss = 0.7060865163803101
Iteration [3980]: Loss = 0.706146776676178
Iteration [3981]: Loss = 0.7061730027198792
Iteration [3982]: Loss = 0.7061687707901001
Iteration [3983]: Loss = 0.7061368823051453
Iteration [3984]: Loss = 0.7060802578926086
Iteration [3985]: Loss = 0.7060011625289917
Iteration [3986]: Loss = 0.7059019207954407
Iteration [3987]: Loss = 4.915844917297363
Iteration [3988]: Loss = 4.915644645690918
Iteration [3989]: Loss = 0.7060023546218872
Iteration [3990]: Loss = 0.7061354517936707
Iteration [3991]: Loss = 0.7062273621559143
Iteration [3992]: Loss = 0.7062821984291077
Iteration [3993]: Loss = 0.706303596496582
Iteration [3994]: Loss = 0.7062947750091553
Iteration [3995]: Loss = 0.7062588930130005
Iteration [3996]: Loss = 0.7061983942985535
Iteration [3997]: Loss = 0.7061160206794739
Iteration [3998]: Loss = 0.7060137391090393
Iteration [3999]: Loss = 0.7058936953544617
Iteration [4000]: Loss = 0.7057574987411499
Iteration [4001]: Loss = 0.7056068778038025
Iteration [4002]: Loss = 0.7054433226585388
Iteration [4003]: Loss = 0.7052679061889648
Iteration [4004]: Loss = 0.7050819396972656
Iteration [4005]: Loss = 0.7048866748809814
Iteration [4006]: Loss = 0.7046827077865601
Iteration [4007]: Loss = 0.704471230506897
Iteration [4008]: Loss = 0.7042527794837952
Iteration [4009]: Loss = 0.7040281295776367
Iteration [4010]: Loss = 0.7037978172302246
Iteration [4011]: Loss = 4.927333831787109
Iteration [4012]: Loss = 0.7034961581230164
Iteration [4013]: Loss = 0.7034084796905518
Iteration [4014]: Loss = 0.7033015489578247
Iteration [4015]: Loss = 0.703177273273468
Iteration [4016]: Loss = 0.7030375003814697
Iteration [4017]: Loss = 0.702883780002594
Iteration [4018]: Loss = 4.931720733642578
Iteration [4019]: Loss = 0.7027127146720886
Iteration [4020]: Loss = 0.7026807069778442
Iteration [4021]: Loss = 0.7026240229606628
Iteration [4022]: Loss = 0.7025449872016907
Iteration [4023]: Loss = 0.702445924282074
Iteration [4024]: Loss = 0.7023287415504456
Iteration [4025]: Loss = 0.7021954655647278
Iteration [4026]: Loss = 0.7020474076271057
Iteration [4027]: Loss = 0.7018863558769226
Iteration [4028]: Loss = 0.7017132043838501
Iteration [4029]: Loss = 0.7015296220779419
Iteration [4030]: Loss = 4.938906669616699
Iteration [4031]: Loss = 0.7013079524040222
Iteration [4032]: Loss = 4.939332485198975
Iteration [4033]: Loss = 0.7013516426086426
Iteration [4034]: Loss = 0.7014111876487732
Iteration [4035]: Loss = 0.7014369368553162
Iteration [4036]: Loss = 0.7014322280883789
Iteration [4037]: Loss = 4.938573837280273
Iteration [4038]: Loss = 0.7015163898468018
Iteration [4039]: Loss = 0.7015931010246277
Iteration [4040]: Loss = 0.7016344666481018
Iteration [4041]: Loss = 4.937304973602295
Iteration [4042]: Loss = 0.7017970085144043
Iteration [4043]: Loss = 0.7019072771072388
Iteration [4044]: Loss = 0.7019786834716797
Iteration [4045]: Loss = 0.7020150423049927
Iteration [4046]: Loss = 0.7020198106765747
Iteration [4047]: Loss = 0.7019962072372437
Iteration [4048]: Loss = 0.7019470930099487
Iteration [4049]: Loss = 0.7018747925758362
Iteration [4050]: Loss = 0.7017818689346313
Iteration [4051]: Loss = 0.7016702890396118
Iteration [4052]: Loss = 0.7015417218208313
Iteration [4053]: Loss = 0.7013982534408569
Iteration [4054]: Loss = 0.7012408971786499
Iteration [4055]: Loss = 0.7010714411735535
Iteration [4056]: Loss = 0.7008908987045288
Iteration [4057]: Loss = 0.7007003426551819
Iteration [4058]: Loss = 0.700501024723053
Iteration [4059]: Loss = 0.7002935409545898
Iteration [4060]: Loss = 0.7000789642333984
Iteration [4061]: Loss = 0.6998578906059265
Iteration [4062]: Loss = 0.699630856513977
Iteration [4063]: Loss = 0.6993986964225769
Iteration [4064]: Loss = 0.69916170835495
Iteration [4065]: Loss = 0.6989204287528992
Iteration [4066]: Loss = 0.6986755132675171
Iteration [4067]: Loss = 0.6984270215034485
Iteration [4068]: Loss = 0.6981756687164307
Iteration [4069]: Loss = 0.6979213356971741
Iteration [4070]: Loss = 0.6976646780967712
Iteration [4071]: Loss = 4.959484577178955
Iteration [4072]: Loss = 0.697319507598877
Iteration [4073]: Loss = 0.6972140073776245
Iteration [4074]: Loss = 0.6970911026000977
Iteration [4075]: Loss = 0.6969528794288635
Iteration [4076]: Loss = 0.6968004703521729
Iteration [4077]: Loss = 4.963539123535156
Iteration [4078]: Loss = 0.6966335773468018
Iteration [4079]: Loss = 0.6966040134429932
Iteration [4080]: Loss = 0.6965497136116028
Iteration [4081]: Loss = 0.6964730620384216
Iteration [4082]: Loss = 0.6963761448860168
Iteration [4083]: Loss = 0.6962612271308899
Iteration [4084]: Loss = 0.6961299777030945
Iteration [4085]: Loss = 0.6959839463233948
Iteration [4086]: Loss = 0.6958247423171997
Iteration [4087]: Loss = 0.6956536173820496
Iteration [4088]: Loss = 0.6954718232154846
Iteration [4089]: Loss = 0.6952804327011108
Iteration [4090]: Loss = 0.6950802206993103
Iteration [4091]: Loss = 0.6948724389076233
Iteration [4092]: Loss = 0.6946575045585632
Iteration [4093]: Loss = 0.6944361925125122
Iteration [4094]: Loss = 0.6942092776298523
Iteration [4095]: Loss = 0.6939773559570312
Iteration [4096]: Loss = 0.6937407851219177
Iteration [4097]: Loss = 0.6935001015663147
Iteration [4098]: Loss = 0.6932557821273804
Iteration [4099]: Loss = 4.982735633850098
Iteration [4100]: Loss = 0.692932665348053
Iteration [4101]: Loss = 0.6928371787071228
Iteration [4102]: Loss = 0.6927233338356018
Iteration [4103]: Loss = 0.6925933361053467
Iteration [4104]: Loss = 0.6924484968185425
Iteration [4105]: Loss = 0.6922904253005981
Iteration [4106]: Loss = 0.6921206712722778
Iteration [4107]: Loss = 0.6919400095939636
Iteration [4108]: Loss = 0.691749632358551
Iteration [4109]: Loss = 0.6915507316589355
Iteration [4110]: Loss = 0.6913439035415649
Iteration [4111]: Loss = 0.6911301612854004
Iteration [4112]: Loss = 0.6909099817276001
Iteration [4113]: Loss = 4.9951171875
Iteration [4114]: Loss = 0.6906290054321289
Iteration [4115]: Loss = 0.6905515789985657
Iteration [4116]: Loss = 0.6904541850090027
Iteration [4117]: Loss = 0.6903390288352966
Iteration [4118]: Loss = 0.6902077794075012
Iteration [4119]: Loss = 0.6900618672370911
Iteration [4120]: Loss = 0.6899029016494751
Iteration [4121]: Loss = 0.6897322535514832
Iteration [4122]: Loss = 0.6895511150360107
Iteration [4123]: Loss = 0.6893602609634399
Iteration [4124]: Loss = 0.689160943031311
Iteration [4125]: Loss = 0.6889539361000061
Iteration [4126]: Loss = 0.6887399554252625
Iteration [4127]: Loss = 0.6885196566581726
Iteration [4128]: Loss = 0.6882938742637634
Iteration [4129]: Loss = 0.6880629658699036
Iteration [4130]: Loss = 0.6878277063369751
Iteration [4131]: Loss = 0.6875882148742676
Iteration [4132]: Loss = 0.6873451471328735
Iteration [4133]: Loss = 0.6870986819267273
Iteration [4134]: Loss = 0.6868492960929871
Iteration [4135]: Loss = 0.6865973472595215
Iteration [4136]: Loss = 0.6863429546356201
Iteration [4137]: Loss = 0.6860863566398621
Iteration [4138]: Loss = 5.021215915679932
Iteration [4139]: Loss = 0.6857444047927856
Iteration [4140]: Loss = 0.6856415867805481
Iteration [4141]: Loss = 0.6855217218399048
Iteration [4142]: Loss = 0.6853862404823303
Iteration [4143]: Loss = 5.024413585662842
Iteration [4144]: Loss = 0.6852509379386902
Iteration [4145]: Loss = 0.6852362751960754
Iteration [4146]: Loss = 0.685195803642273
Iteration [4147]: Loss = 0.6851317286491394
Iteration [4148]: Loss = 0.6850466132164001
Iteration [4149]: Loss = 5.026006698608398
Iteration [4150]: Loss = 0.68499755859375
Iteration [4151]: Loss = 0.6850196719169617
Iteration [4152]: Loss = 0.6850119829177856
Iteration [4153]: Loss = 5.025816440582275
Iteration [4154]: Loss = 0.6850951910018921
Iteration [4155]: Loss = 0.685173749923706
Iteration [4156]: Loss = 5.024521350860596
Iteration [4157]: Loss = 0.6854039430618286
Iteration [4158]: Loss = 0.6855450868606567
Iteration [4159]: Loss = 0.6856446266174316
Iteration [4160]: Loss = 0.6857069134712219
Iteration [4161]: Loss = 0.6857353448867798
Iteration [4162]: Loss = 0.6857336759567261
Iteration [4163]: Loss = 0.6857045292854309
Iteration [4164]: Loss = 0.6856509447097778
Iteration [4165]: Loss = 0.6855751872062683
Iteration [4166]: Loss = 0.6854794025421143
Iteration [4167]: Loss = 0.6853657364845276
Iteration [4168]: Loss = 0.6852359175682068
Iteration [4169]: Loss = 0.685091495513916
Iteration [4170]: Loss = 0.6849340200424194
Iteration [4171]: Loss = 0.6847647428512573
Iteration [4172]: Loss = 0.6845847368240356
Iteration [4173]: Loss = 5.028972625732422
Iteration [4174]: Loss = 0.6843739748001099
Iteration [4175]: Loss = 0.684327244758606
Iteration [4176]: Loss = 0.6842579245567322
Iteration [4177]: Loss = 0.6841678023338318
Iteration [4178]: Loss = 0.6840593814849854
Iteration [4179]: Loss = 5.031474590301514
Iteration [4180]: Loss = 0.6839706897735596
Iteration [4181]: Loss = 0.6839759945869446
Iteration [4182]: Loss = 0.6839535236358643
Iteration [4183]: Loss = 0.6839057803153992
Iteration [4184]: Loss = 0.6838352680206299
Iteration [4185]: Loss = 0.6837441921234131
Iteration [4186]: Loss = 0.683634877204895
Iteration [4187]: Loss = 0.6835090517997742
Iteration [4188]: Loss = 0.6833682656288147
Iteration [4189]: Loss = 5.035387992858887
Iteration [4190]: Loss = 0.6832245588302612
Iteration [4191]: Loss = 0.6832067370414734
Iteration [4192]: Loss = 0.6831631064414978
Iteration [4193]: Loss = 0.6830963492393494
Iteration [4194]: Loss = 0.6830089688301086
Iteration [4195]: Loss = 0.6829028129577637
Iteration [4196]: Loss = 0.6827796697616577
Iteration [4197]: Loss = 0.6826415061950684
Iteration [4198]: Loss = 0.6824895739555359
Iteration [4199]: Loss = 0.6823253631591797
Iteration [4200]: Loss = 0.6821500062942505
Iteration [4201]: Loss = 0.6819648146629333
Iteration [4202]: Loss = 5.043251991271973
Iteration [4203]: Loss = 0.681745707988739
Iteration [4204]: Loss = 0.681695818901062
Iteration [4205]: Loss = 0.6816234588623047
Iteration [4206]: Loss = 0.6815310120582581
Iteration [4207]: Loss = 0.6814203262329102
Iteration [4208]: Loss = 0.6812931299209595
Iteration [4209]: Loss = 0.6811514496803284
Iteration [4210]: Loss = 5.047481060028076
Iteration [4211]: Loss = 5.047424793243408
Iteration [4212]: Loss = 0.6811652183532715
Iteration [4213]: Loss = 0.6812807321548462
Iteration [4214]: Loss = 0.6813573241233826
Iteration [4215]: Loss = 5.045280933380127
Iteration [4216]: Loss = 5.044261455535889
Iteration [4217]: Loss = 0.6819023489952087
Iteration [4218]: Loss = 0.6821600794792175
Iteration [4219]: Loss = 5.040010452270508
Iteration [4220]: Loss = 0.6826978921890259
Iteration [4221]: Loss = 5.036713600158691
Iteration [4222]: Loss = 0.6833639144897461
Iteration [4223]: Loss = 0.6836909055709839
Iteration [4224]: Loss = 0.6839580535888672
Iteration [4225]: Loss = 0.6841713190078735
Iteration [4226]: Loss = 0.6843358874320984
Iteration [4227]: Loss = 0.6844567060470581
Iteration [4228]: Loss = 0.6845380663871765
Iteration [4229]: Loss = 5.027951240539551
Iteration [4230]: Loss = 0.6847735643386841
Iteration [4231]: Loss = 0.6849170327186584
Iteration [4232]: Loss = 0.6850187182426453
Iteration [4233]: Loss = 0.6850829124450684
Iteration [4234]: Loss = 0.6851130723953247
Iteration [4235]: Loss = 0.685112714767456
Iteration [4236]: Loss = 5.025235652923584
Iteration [4237]: Loss = 0.6852086782455444
Iteration [4238]: Loss = 0.685292661190033
Iteration [4239]: Loss = 0.6853408813476562
Iteration [4240]: Loss = 0.6853564977645874
Iteration [4241]: Loss = 0.6853431463241577
Iteration [4242]: Loss = 0.6853036880493164
Iteration [4243]: Loss = 0.6852405071258545
Iteration [4244]: Loss = 0.6851561069488525
Iteration [4245]: Loss = 0.6850523948669434
Iteration [4246]: Loss = 0.6849316954612732
Iteration [4247]: Loss = 0.6847952604293823
Iteration [4248]: Loss = 0.6846450567245483
Iteration [4249]: Loss = 0.6844820976257324
Iteration [4250]: Loss = 0.6843077540397644
Iteration [4251]: Loss = 0.6841234564781189
Iteration [4252]: Loss = 0.6839298605918884
Iteration [4253]: Loss = 0.6837280988693237
Iteration [4254]: Loss = 0.6835187673568726
Iteration [4255]: Loss = 0.6833028793334961
Iteration [4256]: Loss = 0.6830809116363525
Iteration [4257]: Loss = 5.037348747253418
Iteration [4258]: Loss = 0.6827991008758545
Iteration [4259]: Loss = 5.038062572479248
Iteration [4260]: Loss = 5.037623405456543
Iteration [4261]: Loss = 0.6830248832702637
Iteration [4262]: Loss = 0.683197021484375
Iteration [4263]: Loss = 5.034787654876709
Iteration [4264]: Loss = 0.6835881471633911
Iteration [4265]: Loss = 0.6837981343269348
Iteration [4266]: Loss = 0.6839597821235657
Iteration [4267]: Loss = 0.684077799320221
Iteration [4268]: Loss = 5.030266761779785
Iteration [4269]: Loss = 0.6843765377998352
Iteration [4270]: Loss = 0.6845470070838928
Iteration [4271]: Loss = 0.6846729516983032
Iteration [4272]: Loss = 0.6847589612007141
Iteration [4273]: Loss = 0.6848086714744568
Iteration [4274]: Loss = 0.6848260760307312
Iteration [4275]: Loss = 0.6848141551017761
Iteration [4276]: Loss = 0.6847759485244751
Iteration [4277]: Loss = 0.6847138404846191
Iteration [4278]: Loss = 0.6846303939819336
Iteration [4279]: Loss = 0.684527575969696
Iteration [4280]: Loss = 5.028905868530273
Iteration [4281]: Loss = 0.6844490170478821
Iteration [4282]: Loss = 0.68445885181427
Iteration [4283]: Loss = 5.028729438781738
Iteration [4284]: Loss = 0.6845723390579224
Iteration [4285]: Loss = 5.027515888214111
Iteration [4286]: Loss = 0.6848952174186707
Iteration [4287]: Loss = 0.6850759387016296
Iteration [4288]: Loss = 0.685211181640625
Iteration [4289]: Loss = 0.6853054165840149
Iteration [4290]: Loss = 5.0237321853637695
Iteration [4291]: Loss = 0.6855629682540894
Iteration [4292]: Loss = 0.6857157945632935
Iteration [4293]: Loss = 0.6858260631561279
Iteration [4294]: Loss = 0.6858976483345032
Iteration [4295]: Loss = 0.6859344840049744
Iteration [4296]: Loss = 0.6859399676322937
Iteration [4297]: Loss = 0.6859174966812134
Iteration [4298]: Loss = 0.6858693957328796
Iteration [4299]: Loss = 0.6857985258102417
Iteration [4300]: Loss = 0.6857072114944458
Iteration [4301]: Loss = 0.68559730052948
Iteration [4302]: Loss = 0.685470700263977
Iteration [4303]: Loss = 0.6853289604187012
Iteration [4304]: Loss = 0.6851739287376404
Iteration [4305]: Loss = 0.6850065588951111
Iteration [4306]: Loss = 0.6848282217979431
Iteration [4307]: Loss = 0.6846401691436768
Iteration [4308]: Loss = 0.6844431161880493
Iteration [4309]: Loss = 0.6842381954193115
Iteration [4310]: Loss = 0.6840261220932007
Iteration [4311]: Loss = 5.032163143157959
Iteration [4312]: Loss = 5.032416343688965
Iteration [4313]: Loss = 5.03183126449585
Iteration [4314]: Loss = 5.030496120452881
Iteration [4315]: Loss = 0.6844841241836548
Iteration [4316]: Loss = 0.6847898960113525
Iteration [4317]: Loss = 0.6850374937057495
Iteration [4318]: Loss = 0.6852332353591919
Iteration [4319]: Loss = 0.6853818297386169
Iteration [4320]: Loss = 0.6854879856109619
Iteration [4321]: Loss = 0.6855561137199402
Iteration [4322]: Loss = 0.6855898499488831
Iteration [4323]: Loss = 0.685592532157898
Iteration [4324]: Loss = 0.6855673789978027
Iteration [4325]: Loss = 0.6855170726776123
Iteration [4326]: Loss = 0.6854441165924072
Iteration [4327]: Loss = 5.023796081542969
Iteration [4328]: Loss = 0.6854162812232971
Iteration [4329]: Loss = 0.685447633266449
Iteration [4330]: Loss = 0.6854482293128967
Iteration [4331]: Loss = 0.6854211688041687
Iteration [4332]: Loss = 0.6853691339492798
Iteration [4333]: Loss = 0.6852947473526001
Iteration [4334]: Loss = 0.6851999759674072
Iteration [4335]: Loss = 0.6850870847702026
Iteration [4336]: Loss = 0.68495774269104
Iteration [4337]: Loss = 0.6848135590553284
Iteration [4338]: Loss = 0.6846562027931213
Iteration [4339]: Loss = 5.028475761413574
Iteration [4340]: Loss = 0.6844843626022339
Iteration [4341]: Loss = 0.6844546794891357
Iteration [4342]: Loss = 0.684400200843811
Iteration [4343]: Loss = 0.6843236088752747
Iteration [4344]: Loss = 9.375545501708984
Iteration [4345]: Loss = 0.684464693069458
Iteration [4346]: Loss = 0.6846515536308289
Iteration [4347]: Loss = 5.026819705963135
Iteration [4348]: Loss = 0.6906028985977173
Iteration [4349]: Loss = 0.6852824687957764
Iteration [4350]: Loss = 0.6854493618011475
Iteration [4351]: Loss = 0.6855721473693848
Iteration [4352]: Loss = 0.6856552362442017
Iteration [4353]: Loss = 0.6857026815414429
Iteration [4354]: Loss = 0.6857179403305054
Iteration [4355]: Loss = 0.6857041716575623
Iteration [4356]: Loss = 0.6856644749641418
Iteration [4357]: Loss = 0.6856010556221008
Iteration [4358]: Loss = 0.6855165958404541
Iteration [4359]: Loss = 0.6854130029678345
Iteration [4360]: Loss = 0.6852921843528748
Iteration [4361]: Loss = 0.685155987739563
Iteration [4362]: Loss = 0.6850059032440186
Iteration [4363]: Loss = 5.026544570922852
Iteration [4364]: Loss = 0.6848459243774414
Iteration [4365]: Loss = 0.6848207712173462
Iteration [4366]: Loss = 0.6847706437110901
Iteration [4367]: Loss = 0.6846981048583984
Iteration [4368]: Loss = 0.6846053004264832
Iteration [4369]: Loss = 0.6844942569732666
Iteration [4370]: Loss = 0.6843668818473816
Iteration [4371]: Loss = 0.6842247247695923
Iteration [4372]: Loss = 0.6840692162513733
Iteration [4373]: Loss = 0.6839017868041992
Iteration [4374]: Loss = 5.032618999481201
Iteration [4375]: Loss = 5.032679080963135
Iteration [4376]: Loss = 0.6838510036468506
Iteration [4377]: Loss = 0.6839486360549927
Iteration [4378]: Loss = 0.6840089559555054
Iteration [4379]: Loss = 0.6840358972549438
Iteration [4380]: Loss = 0.6840327978134155
Iteration [4381]: Loss = 0.6840024590492249
Iteration [4382]: Loss = 0.6839476823806763
Iteration [4383]: Loss = 0.6838709712028503
Iteration [4384]: Loss = 0.6837745308876038
Iteration [4385]: Loss = 0.6836600303649902
Iteration [4386]: Loss = 0.6835296154022217
Iteration [4387]: Loss = 5.034460067749023
Iteration [4388]: Loss = 9.3853120803833
Iteration [4389]: Loss = 0.6837422847747803
Iteration [4390]: Loss = 0.6840200424194336
Iteration [4391]: Loss = 0.6842432618141174
Iteration [4392]: Loss = 0.6844168901443481
Iteration [4393]: Loss = 0.6845462918281555
Iteration [4394]: Loss = 0.68463534116745
Iteration [4395]: Loss = 0.6846883893013
Iteration [4396]: Loss = 0.6847089529037476
Iteration [4397]: Loss = 0.6847000122070312
Iteration [4398]: Loss = 0.684664785861969
Iteration [4399]: Loss = 0.6846056580543518
Iteration [4400]: Loss = 0.6845251321792603
Iteration [4401]: Loss = 5.028809070587158
Iteration [4402]: Loss = 0.684483528137207
Iteration [4403]: Loss = 0.6845086812973022
Iteration [4404]: Loss = 0.6845040321350098
Iteration [4405]: Loss = 0.6844726800918579
Iteration [4406]: Loss = 0.6844168901443481
Iteration [4407]: Loss = 0.6843396425247192
Iteration [4408]: Loss = 0.6842425465583801
Iteration [4409]: Loss = 9.37671947479248
Iteration [4410]: Loss = 0.6843460202217102
Iteration [4411]: Loss = 0.6845154166221619
Iteration [4412]: Loss = 0.6846410036087036
Iteration [4413]: Loss = 5.027175426483154
Iteration [4414]: Loss = 0.684950590133667
Iteration [4415]: Loss = 0.6851249933242798
Iteration [4416]: Loss = 0.6852551102638245
Iteration [4417]: Loss = 0.6853449940681458
Iteration [4418]: Loss = 0.6853989362716675
Iteration [4419]: Loss = 0.6854202151298523
Iteration [4420]: Loss = 5.023462772369385
Iteration [4421]: Loss = 9.35986614227295
Iteration [4422]: Loss = 0.6859930157661438
Iteration [4423]: Loss = 0.6863635778427124
Iteration [4424]: Loss = 0.6866704225540161
Iteration [4425]: Loss = 0.6869199275970459
Iteration [4426]: Loss = 0.6871175169944763
Iteration [4427]: Loss = 0.6872686743736267
Iteration [4428]: Loss = 0.6873777508735657
Iteration [4429]: Loss = 0.6874489784240723
Iteration [4430]: Loss = 0.6874859929084778
Iteration [4431]: Loss = 0.6874923706054688
Iteration [4432]: Loss = 0.6874710321426392
Iteration [4433]: Loss = 5.012601375579834
Iteration [4434]: Loss = 0.6875286102294922
Iteration [4435]: Loss = 5.011684894561768
Iteration [4436]: Loss = 5.010581016540527
Iteration [4437]: Loss = 0.6881293654441833
Iteration [4438]: Loss = 0.6883987784385681
Iteration [4439]: Loss = 0.6886146664619446
Iteration [4440]: Loss = 0.6887819170951843
Iteration [4441]: Loss = 0.6889054179191589
Iteration [4442]: Loss = 0.6889896988868713
Iteration [4443]: Loss = 0.6890385150909424
Iteration [4444]: Loss = 0.6890552043914795
Iteration [4445]: Loss = 0.6890431642532349
Iteration [4446]: Loss = 5.0041069984436035
Iteration [4447]: Loss = 0.6891164183616638
Iteration [4448]: Loss = 0.6891893744468689
Iteration [4449]: Loss = 0.6892279982566833
Iteration [4450]: Loss = 0.6892356872558594
Iteration [4451]: Loss = 5.002980709075928
Iteration [4452]: Loss = 0.6893424987792969
Iteration [4453]: Loss = 0.6894298791885376
Iteration [4454]: Loss = 5.001554489135742
Iteration [4455]: Loss = 0.6896727681159973
Iteration [4456]: Loss = 0.6898179054260254
Iteration [4457]: Loss = 0.6899217367172241
Iteration [4458]: Loss = 4.998841285705566
Iteration [4459]: Loss = 0.690192461013794
Iteration [4460]: Loss = 0.6903496980667114
Iteration [4461]: Loss = 4.99629545211792
Iteration [4462]: Loss = 4.994971752166748
Iteration [4463]: Loss = 0.6903457641601562
Iteration [4464]: Loss = 4.9953083992004395
Iteration [4465]: Loss = 0.6910653710365295
Iteration [4466]: Loss = 0.6914137601852417
Iteration [4467]: Loss = 0.6917003989219666
Iteration [4468]: Loss = 0.691931426525116
Iteration [4469]: Loss = 0.692112386226654
Iteration [4470]: Loss = 0.6922480463981628
Iteration [4471]: Loss = 4.986271381378174
Iteration [4472]: Loss = 4.985047817230225
Iteration [4473]: Loss = 0.6929241418838501
Iteration [4474]: Loss = 0.6932133436203003
Iteration [4475]: Loss = 0.6934465765953064
Iteration [4476]: Loss = 0.6936293840408325
Iteration [4477]: Loss = 0.6937666535377502
Iteration [4478]: Loss = 0.693863034248352
Iteration [4479]: Loss = 0.6939225792884827
Iteration [4480]: Loss = 0.6939486861228943
Iteration [4481]: Loss = 0.6939449906349182
Iteration [4482]: Loss = 0.6939143538475037
Iteration [4483]: Loss = 0.693859338760376
Iteration [4484]: Loss = 0.693782389163971
Iteration [4485]: Loss = 0.69368577003479
Iteration [4486]: Loss = 0.6935715675354004
Iteration [4487]: Loss = 0.6934412121772766
Iteration [4488]: Loss = 0.6932964324951172
Iteration [4489]: Loss = 0.693138837814331
Iteration [4490]: Loss = 0.6929696202278137
Iteration [4491]: Loss = 0.6927897930145264
Iteration [4492]: Loss = 0.6926007270812988
Iteration [4493]: Loss = 0.6924029588699341
Iteration [4494]: Loss = 4.9870452880859375
Iteration [4495]: Loss = 0.6921586990356445
Iteration [4496]: Loss = 0.6920962333679199
Iteration [4497]: Loss = 0.6920127272605896
Iteration [4498]: Loss = 0.6919102072715759
Iteration [4499]: Loss = 0.6917904615402222
Iteration [4500]: Loss = 0.6916555166244507
Iteration [4501]: Loss = 0.6915066242218018
Iteration [4502]: Loss = 0.6913453340530396
Iteration [4503]: Loss = 0.6911727786064148
Iteration [4504]: Loss = 0.6909900307655334
Iteration [4505]: Loss = 0.6907982230186462
Iteration [4506]: Loss = 0.6905983090400696
Iteration [4507]: Loss = 0.690390944480896
Iteration [4508]: Loss = 0.6901769042015076
Iteration [4509]: Loss = 0.6899570226669312
Iteration [4510]: Loss = 0.689731776714325
Iteration [4511]: Loss = 0.6895018219947815
Iteration [4512]: Loss = 0.6892674565315247
Iteration [4513]: Loss = 0.6890291571617126
Iteration [4514]: Loss = 0.6887874603271484
Iteration [4515]: Loss = 0.6885425448417664
Iteration [4516]: Loss = 0.6882949471473694
Iteration [4517]: Loss = 0.6880446672439575
Iteration [4518]: Loss = 0.6877922415733337
Iteration [4519]: Loss = 0.687537670135498
Iteration [4520]: Loss = 5.013373851776123
Iteration [4521]: Loss = 0.6871976256370544
Iteration [4522]: Loss = 0.687095046043396
Iteration [4523]: Loss = 0.6869754195213318
Iteration [4524]: Loss = 0.6868406534194946
Iteration [4525]: Loss = 0.6866919994354248
Iteration [4526]: Loss = 0.6865310668945312
Iteration [4527]: Loss = 0.6863589882850647
Iteration [4528]: Loss = 0.6861770153045654
Iteration [4529]: Loss = 0.685985803604126
Iteration [4530]: Loss = 0.6857866048812866
Iteration [4531]: Loss = 0.6855800151824951
Iteration [4532]: Loss = 5.023708820343018
Iteration [4533]: Loss = 0.6853222846984863
Iteration [4534]: Loss = 0.6852550506591797
Iteration [4535]: Loss = 0.6851673126220703
Iteration [4536]: Loss = 0.6850610971450806
Iteration [4537]: Loss = 5.026029109954834
Iteration [4538]: Loss = 0.6849749684333801
Iteration [4539]: Loss = 0.6849807500839233
Iteration [4540]: Loss = 5.025918006896973
Iteration [4541]: Loss = 0.6850858330726624
Iteration [4542]: Loss = 0.685172975063324
Iteration [4543]: Loss = 0.6852244138717651
Iteration [4544]: Loss = 9.363510131835938
Iteration [4545]: Loss = 0.6855778694152832
Iteration [4546]: Loss = 0.68585205078125
Iteration [4547]: Loss = 0.6860721707344055
Iteration [4548]: Loss = 0.6862435340881348
Iteration [4549]: Loss = 5.018284320831299
Iteration [4550]: Loss = 0.686630368232727
Iteration [4551]: Loss = 0.6868371963500977
Iteration [4552]: Loss = 0.6869966387748718
Iteration [4553]: Loss = 0.6871131658554077
Iteration [4554]: Loss = 0.6871910095214844
Iteration [4555]: Loss = 0.6872344017028809
Iteration [4556]: Loss = 5.01356315612793
Iteration [4557]: Loss = 0.687402069568634
Iteration [4558]: Loss = 0.6875155568122864
Iteration [4559]: Loss = 0.6875907778739929
Iteration [4560]: Loss = 0.687631368637085
Iteration [4561]: Loss = 0.6876409649848938
Iteration [4562]: Loss = 0.6876224875450134
Iteration [4563]: Loss = 5.011772155761719
Iteration [4564]: Loss = 0.6876850724220276
Iteration [4565]: Loss = 0.6877534985542297
Iteration [4566]: Loss = 0.6877882480621338
Iteration [4567]: Loss = 0.6877924799919128
Iteration [4568]: Loss = 0.6877691745758057
Iteration [4569]: Loss = 0.6877210140228271
Iteration [4570]: Loss = 0.6876506805419922
Iteration [4571]: Loss = 0.6875603199005127
Iteration [4572]: Loss = 0.6874517798423767
Iteration [4573]: Loss = 0.6873269081115723
Iteration [4574]: Loss = 5.013879299163818
Iteration [4575]: Loss = 5.013769149780273
Iteration [4576]: Loss = 0.6873718500137329
Iteration [4577]: Loss = 0.6874923706054688
Iteration [4578]: Loss = 0.6875737905502319
Iteration [4579]: Loss = 5.011549949645996
Iteration [4580]: Loss = 0.6878070831298828
Iteration [4581]: Loss = 0.6879485249519348
Iteration [4582]: Loss = 0.688048779964447
Iteration [4583]: Loss = 0.6881119608879089
Iteration [4584]: Loss = 0.6881418228149414
Iteration [4585]: Loss = 0.6881415843963623
Iteration [4586]: Loss = 0.6881140470504761
Iteration [4587]: Loss = 0.6880623698234558
Iteration [4588]: Loss = 0.6879886984825134
Iteration [4589]: Loss = 0.6878952980041504
Iteration [4590]: Loss = 0.6877838969230652
Iteration [4591]: Loss = 0.6876565217971802
Iteration [4592]: Loss = 0.6875148415565491
Iteration [4593]: Loss = 0.6873599886894226
Iteration [4594]: Loss = 0.6871936321258545
Iteration [4595]: Loss = 0.6870166063308716
Iteration [4596]: Loss = 5.015805721282959
Iteration [4597]: Loss = 0.6868086457252502
Iteration [4598]: Loss = 0.6867623329162598
Iteration [4599]: Loss = 0.6866933107376099
Iteration [4600]: Loss = 0.6866042613983154
Iteration [4601]: Loss = 0.6864969730377197
Iteration [4602]: Loss = 5.018270969390869
Iteration [4603]: Loss = 0.6864081621170044
Iteration [4604]: Loss = 0.6864123344421387
Iteration [4605]: Loss = 0.6863892674446106
Iteration [4606]: Loss = 0.6863413453102112
Iteration [4607]: Loss = 0.686271071434021
Iteration [4608]: Loss = 0.6861807107925415
Iteration [4609]: Loss = 0.6860722899436951
Iteration [4610]: Loss = 0.6859475374221802
Iteration [4611]: Loss = 0.6858080625534058
Iteration [4612]: Loss = 0.6856555938720703
Iteration [4613]: Loss = 0.6854910850524902
Iteration [4614]: Loss = 5.023986339569092
Iteration [4615]: Loss = 0.6853048205375671
Iteration [4616]: Loss = 5.024245262145996
Iteration [4617]: Loss = 0.6853809952735901
Iteration [4618]: Loss = 0.6854556798934937
Iteration [4619]: Loss = 0.685495913028717
Iteration [4620]: Loss = 0.6855052709579468
Iteration [4621]: Loss = 0.6854864358901978
Iteration [4622]: Loss = 0.685442328453064
Iteration [4623]: Loss = 0.6853756308555603
Iteration [4624]: Loss = 0.6852884292602539
Iteration [4625]: Loss = 0.6851829290390015
Iteration [4626]: Loss = 0.6850607991218567
Iteration [4627]: Loss = 0.6849237680435181
Iteration [4628]: Loss = 0.684773325920105
Iteration [4629]: Loss = 0.6846106648445129
Iteration [4630]: Loss = 0.6844372749328613
Iteration [4631]: Loss = 0.6842539310455322
Iteration [4632]: Loss = 0.6840620040893555
Iteration [4633]: Loss = 5.031867027282715
Iteration [4634]: Loss = 0.6838291883468628
Iteration [4635]: Loss = 0.6837726831436157
Iteration [4636]: Loss = 0.68369460105896
Iteration [4637]: Loss = 0.6835973858833313
Iteration [4638]: Loss = 0.6834827661514282
Iteration [4639]: Loss = 0.683352530002594
Iteration [4640]: Loss = 5.0354204177856445
Iteration [4641]: Loss = 0.6832255125045776
Iteration [4642]: Loss = 0.6832138895988464
Iteration [4643]: Loss = 5.035591125488281
Iteration [4644]: Loss = 0.6832898259162903
Iteration [4645]: Loss = 0.6833646297454834
Iteration [4646]: Loss = 0.6834051012992859
Iteration [4647]: Loss = 0.6834145784378052
Iteration [4648]: Loss = 0.6833959221839905
Iteration [4649]: Loss = 0.6833520531654358
Iteration [4650]: Loss = 0.6832855939865112
Iteration [4651]: Loss = 0.6831986904144287
Iteration [4652]: Loss = 0.6830933690071106
Iteration [4653]: Loss = 0.6829715371131897
Iteration [4654]: Loss = 0.6828346848487854
Iteration [4655]: Loss = 0.6826844811439514
Iteration [4656]: Loss = 0.6825221180915833
Iteration [4657]: Loss = 0.6823490262031555
Iteration [4658]: Loss = 0.6821660399436951
Iteration [4659]: Loss = 0.6819742321968079
Iteration [4660]: Loss = 0.6817744374275208
Iteration [4661]: Loss = 0.6815676689147949
Iteration [4662]: Loss = 0.681354284286499
Iteration [4663]: Loss = 0.681135356426239
Iteration [4664]: Loss = 0.6809111833572388
Iteration [4665]: Loss = 0.6806823015213013
Iteration [4666]: Loss = 0.6804491877555847
Iteration [4667]: Loss = 5.0517706871032715
Iteration [4668]: Loss = 0.6801475286483765
Iteration [4669]: Loss = 0.6800620555877686
Iteration [4670]: Loss = 0.6799582839012146
Iteration [4671]: Loss = 5.053824424743652
Iteration [4672]: Loss = 0.6798771619796753
Iteration [4673]: Loss = 0.6798856258392334
Iteration [4674]: Loss = 0.679866373538971
Iteration [4675]: Loss = 0.6798220872879028
Iteration [4676]: Loss = 0.6797552108764648
Iteration [4677]: Loss = 0.6796680092811584
Iteration [4678]: Loss = 0.679562509059906
Iteration [4679]: Loss = 0.6794404983520508
Iteration [4680]: Loss = 0.6793037056922913
Iteration [4681]: Loss = 0.6791535019874573
Iteration [4682]: Loss = 5.058468341827393
Iteration [4683]: Loss = 0.678993821144104
Iteration [4684]: Loss = 0.6789689064025879
Iteration [4685]: Loss = 0.6789196133613586
Iteration [4686]: Loss = 0.678848385810852
Iteration [4687]: Loss = 0.6787570118904114
Iteration [4688]: Loss = 0.6786479949951172
Iteration [4689]: Loss = 0.6785227656364441
Iteration [4690]: Loss = 0.6783829927444458
Iteration [4691]: Loss = 0.6782302260398865
Iteration [4692]: Loss = 0.6780657768249512
Iteration [4693]: Loss = 5.064523220062256
Iteration [4694]: Loss = 0.6778817772865295
Iteration [4695]: Loss = 0.6778467297554016
Iteration [4696]: Loss = 0.6777884364128113
Iteration [4697]: Loss = 0.6777088046073914
Iteration [4698]: Loss = 0.6776102781295776
Iteration [4699]: Loss = 0.6774945259094238
Iteration [4700]: Loss = 0.677363395690918
Iteration [4701]: Loss = 5.068228244781494
Iteration [4702]: Loss = 0.6772366166114807
Iteration [4703]: Loss = 0.6772259473800659
Iteration [4704]: Loss = 0.6771895885467529
Iteration [4705]: Loss = 5.0687174797058105
Iteration [4706]: Loss = 0.6772245168685913
Iteration [4707]: Loss = 5.067872524261475
Iteration [4708]: Loss = 0.6774833798408508
Iteration [4709]: Loss = 0.677636981010437
Iteration [4710]: Loss = 0.6777486205101013
Iteration [4711]: Loss = 0.6778221130371094
Iteration [4712]: Loss = 5.064684867858887
Iteration [4713]: Loss = 0.6780445575714111
Iteration [4714]: Loss = 5.0629143714904785
Iteration [4715]: Loss = 0.6784548163414001
Iteration [4716]: Loss = 0.678672730922699
Iteration [4717]: Loss = 0.6788422465324402
Iteration [4718]: Loss = 0.6789678335189819
Iteration [4719]: Loss = 0.6790541410446167
Iteration [4720]: Loss = 0.679104745388031
Iteration [4721]: Loss = 0.6791234016418457
Iteration [4722]: Loss = 0.6791132092475891
Iteration [4723]: Loss = 5.057998180389404
Iteration [4724]: Loss = 0.6791924834251404
Iteration [4725]: Loss = 0.679269552230835
Iteration [4726]: Loss = 0.6793119311332703
Iteration [4727]: Loss = 0.6793231964111328
Iteration [4728]: Loss = 0.6793060898780823
Iteration [4729]: Loss = 0.6792638301849365
Iteration [4730]: Loss = 0.6791988015174866
Iteration [4731]: Loss = 0.6791130900382996
Iteration [4732]: Loss = 0.6790090203285217
Iteration [4733]: Loss = 5.059034824371338
Iteration [4734]: Loss = 5.058816432952881
Iteration [4735]: Loss = 0.6791117191314697
Iteration [4736]: Loss = 0.6792502403259277
Iteration [4737]: Loss = 0.6793478727340698
Iteration [4738]: Loss = 0.6794089078903198
Iteration [4739]: Loss = 0.6794368028640747
Iteration [4740]: Loss = 0.6794350147247314
Iteration [4741]: Loss = 0.6794061660766602
Iteration [4742]: Loss = 0.6793532967567444
Iteration [4743]: Loss = 0.679278552532196
Iteration [4744]: Loss = 0.6791843771934509
Iteration [4745]: Loss = 0.6790724396705627
Iteration [4746]: Loss = 0.6789445877075195
Iteration [4747]: Loss = 0.678802490234375
Iteration [4748]: Loss = 5.060358047485352
Iteration [4749]: Loss = 0.6786566376686096
Iteration [4750]: Loss = 0.6786379814147949
Iteration [4751]: Loss = 0.6785941123962402
Iteration [4752]: Loss = 0.6785276532173157
Iteration [4753]: Loss = 5.061495304107666
Iteration [4754]: Loss = 5.061108589172363
Iteration [4755]: Loss = 0.6787223815917969
Iteration [4756]: Loss = 0.6788855791091919
Iteration [4757]: Loss = 5.058390140533447
Iteration [4758]: Loss = 0.6792616844177246
Iteration [4759]: Loss = 0.6794650554656982
Iteration [4760]: Loss = 0.6796213388442993
Iteration [4761]: Loss = 0.679735004901886
Iteration [4762]: Loss = 5.05397367477417
Iteration [4763]: Loss = 0.680026113986969
Iteration [4764]: Loss = 0.6801931858062744
Iteration [4765]: Loss = 0.6803167462348938
Iteration [4766]: Loss = 0.6804009675979614
Iteration [4767]: Loss = 0.6804496645927429
Iteration [4768]: Loss = 0.6804665923118591
Iteration [4769]: Loss = 0.6804546117782593
Iteration [4770]: Loss = 5.050651550292969
Iteration [4771]: Loss = 0.6805307865142822
Iteration [4772]: Loss = 0.6806063652038574
Iteration [4773]: Loss = 0.6806473731994629
Iteration [4774]: Loss = 0.6806572675704956
Iteration [4775]: Loss = 0.6806391477584839
Iteration [4776]: Loss = 0.6805955171585083
Iteration [4777]: Loss = 0.6805291771888733
Iteration [4778]: Loss = 0.6804424524307251
Iteration [4779]: Loss = 0.680337131023407
Iteration [4780]: Loss = 0.6802151799201965
Iteration [4781]: Loss = 0.6800783276557922
Iteration [4782]: Loss = 0.6799279451370239
Iteration [4783]: Loss = 0.6797654032707214
Iteration [4784]: Loss = 0.6795920133590698
Iteration [4785]: Loss = 0.6794087886810303
Iteration [4786]: Loss = 0.6792166233062744
Iteration [4787]: Loss = 5.058329105377197
Iteration [4788]: Loss = 5.058500289916992
Iteration [4789]: Loss = 0.6791062951087952
Iteration [4790]: Loss = 0.6791878342628479
Iteration [4791]: Loss = 0.6792342066764832
Iteration [4792]: Loss = 5.057054042816162
Iteration [4793]: Loss = 0.6794105172157288
Iteration [4794]: Loss = 0.6795288920402527
Iteration [4795]: Loss = 0.6796084046363831
Iteration [4796]: Loss = 0.679652988910675
Iteration [4797]: Loss = 0.6796660423278809
Iteration [4798]: Loss = 0.6796507239341736
Iteration [4799]: Loss = 0.6796097755432129
Iteration [4800]: Loss = 0.6795459389686584
Iteration [4801]: Loss = 0.6794611215591431
Iteration [4802]: Loss = 5.056455612182617
Iteration [4803]: Loss = 0.6794134378433228
Iteration [4804]: Loss = 0.6794365644454956
Iteration [4805]: Loss = 0.6794303059577942
Iteration [4806]: Loss = 0.679397463798523
Iteration [4807]: Loss = 0.6793408393859863
Iteration [4808]: Loss = 0.6792628169059753
Iteration [4809]: Loss = 0.6791654825210571
Iteration [4810]: Loss = 0.6790505051612854
Iteration [4811]: Loss = 0.6789200305938721
Iteration [4812]: Loss = 0.6787753105163574
Iteration [4813]: Loss = 0.6786180734634399
Iteration [4814]: Loss = 0.678449273109436
Iteration [4815]: Loss = 5.062433242797852
Iteration [4816]: Loss = 0.6782583594322205
Iteration [4817]: Loss = 0.6789785623550415
Iteration [4818]: Loss = 0.6789175868034363
Iteration [4819]: Loss = 5.059325218200684
Iteration [4820]: Loss = 0.6789104342460632
Iteration [4821]: Loss = 0.6789509057998657
Iteration [4822]: Loss = 0.6789602637290955
Iteration [4823]: Loss = 0.678941547870636
Iteration [4824]: Loss = 0.6788976788520813
Iteration [4825]: Loss = 0.6788309216499329
Iteration [4826]: Loss = 0.6787436008453369
Iteration [4827]: Loss = 0.6786379814147949
Iteration [4828]: Loss = 0.6785156726837158
Iteration [4829]: Loss = 0.6783784031867981
Iteration [4830]: Loss = 0.6782276630401611
Iteration [4831]: Loss = 0.6780647039413452
Iteration [4832]: Loss = 0.6778908371925354
Iteration [4833]: Loss = 0.6777071952819824
Iteration [4834]: Loss = 0.6775147914886475
Iteration [4835]: Loss = 0.6773144006729126
Iteration [4836]: Loss = 0.6771069169044495
Iteration [4837]: Loss = 0.6768927574157715
Iteration [4838]: Loss = 0.6766730546951294
Iteration [4839]: Loss = 0.6764480471611023
Iteration [4840]: Loss = 0.6762183308601379
Iteration [4841]: Loss = 0.6759844422340393
Iteration [4842]: Loss = 0.6757469177246094
Iteration [4843]: Loss = 0.6755056977272034
Iteration [4844]: Loss = 0.6752616167068481
Iteration [4845]: Loss = 0.6750147938728333
Iteration [4846]: Loss = 0.6747652888298035
Iteration [4847]: Loss = 0.6745138168334961
Iteration [4848]: Loss = 0.6742603182792664
Iteration [4849]: Loss = 0.6740050315856934
Iteration [4850]: Loss = 0.6737479567527771
Iteration [4851]: Loss = 0.6734896302223206
Iteration [4852]: Loss = 0.6732301115989685
Iteration [4853]: Loss = 0.6729692220687866
Iteration [4854]: Loss = 0.6727074384689331
Iteration [4855]: Loss = 0.6724447011947632
Iteration [4856]: Loss = 5.096183776855469
Iteration [4857]: Loss = 0.6720952391624451
Iteration [4858]: Loss = 0.6719908118247986
Iteration [4859]: Loss = 0.6718699336051941
Iteration [4860]: Loss = 5.098681449890137
Iteration [4861]: Loss = 0.6717626452445984
Iteration [4862]: Loss = 5.098527908325195
Iteration [4863]: Loss = 5.097694396972656
Iteration [4864]: Loss = 5.0961079597473145
Iteration [4865]: Loss = 0.6725999116897583
Iteration [4866]: Loss = 0.67293781042099
Iteration [4867]: Loss = 0.673215389251709
Iteration [4868]: Loss = 0.6734384298324585
Iteration [4869]: Loss = 0.6736123561859131
Iteration [4870]: Loss = 0.6737419962882996
Iteration [4871]: Loss = 0.6738318204879761
Iteration [4872]: Loss = 5.086687088012695
Iteration [4873]: Loss = 0.674083948135376
Iteration [4874]: Loss = 0.6742354035377502
Iteration [4875]: Loss = 0.6743448376655579
Iteration [4876]: Loss = 0.6744164228439331
Iteration [4877]: Loss = 0.674453854560852
Iteration [4878]: Loss = 0.6744604110717773
Iteration [4879]: Loss = 0.6744393110275269
Iteration [4880]: Loss = 0.6743932962417603
Iteration [4881]: Loss = 0.6743248105049133
Iteration [4882]: Loss = 0.6742361187934875
Iteration [4883]: Loss = 0.674129068851471
Iteration [4884]: Loss = 5.086019039154053
Iteration [4885]: Loss = 0.6740450859069824
Iteration [4886]: Loss = 0.6740536093711853
Iteration [4887]: Loss = 0.6740339994430542
Iteration [4888]: Loss = 0.6739895343780518
Iteration [4889]: Loss = 0.6739223003387451
Iteration [4890]: Loss = 0.6738347411155701
Iteration [4891]: Loss = 0.673728883266449
Iteration [4892]: Loss = 0.6736065149307251
Iteration [4893]: Loss = 5.089004039764404
Iteration [4894]: Loss = 5.088852405548096
Iteration [4895]: Loss = 0.6736707091331482
Iteration [4896]: Loss = 0.6738008260726929
Iteration [4897]: Loss = 0.6738908886909485
Iteration [4898]: Loss = 0.6739449501037598
Iteration [4899]: Loss = 0.6739667654037476
Iteration [4900]: Loss = 0.6739591956138611
Iteration [4901]: Loss = 0.6739253401756287
Iteration [4902]: Loss = 0.6738678216934204
Iteration [4903]: Loss = 5.087223529815674
Iteration [4904]: Loss = 0.6738684773445129
Iteration [4905]: Loss = 0.6739130020141602
Iteration [4906]: Loss = 0.673926055431366
Iteration [4907]: Loss = 0.6739106178283691
Iteration [4908]: Loss = 0.673869788646698
Iteration [4909]: Loss = 0.6738059520721436
Iteration [4910]: Loss = 0.6737213730812073
Iteration [4911]: Loss = 0.6736180782318115
Iteration [4912]: Loss = 5.088841915130615
Iteration [4913]: Loss = 0.6735408306121826
Iteration [4914]: Loss = 0.6735520362854004
Iteration [4915]: Loss = 0.6735352277755737
Iteration [4916]: Loss = 0.6734930276870728
Iteration [4917]: Loss = 0.673427939414978
Iteration [4918]: Loss = 0.6733422875404358
Iteration [4919]: Loss = 0.6732381582260132
Iteration [4920]: Loss = 0.6731172204017639
Iteration [4921]: Loss = 0.672981321811676
Iteration [4922]: Loss = 0.6728318333625793
Iteration [4923]: Loss = 0.6726702451705933
Iteration [4924]: Loss = 0.6724976897239685
Iteration [4925]: Loss = 0.6723151206970215
Iteration [4926]: Loss = 0.6721238493919373
Iteration [4927]: Loss = 5.097616195678711
Iteration [4928]: Loss = 0.6718964576721191
Iteration [4929]: Loss = 0.6718443036079407
Iteration [4930]: Loss = 0.6717702746391296
Iteration [4931]: Loss = 0.6716764569282532
Iteration [4932]: Loss = 0.671565055847168
Iteration [4933]: Loss = 5.100337982177734
Iteration [4934]: Loss = 0.671474277973175
Iteration [4935]: Loss = 0.6714801788330078
Iteration [4936]: Loss = 0.6714585423469543
Iteration [4937]: Loss = 0.6714118719100952
Iteration [4938]: Loss = 0.6713430285453796
Iteration [4939]: Loss = 0.6712539196014404
Iteration [4940]: Loss = 5.101966381072998
Iteration [4941]: Loss = 0.6712012887001038
Iteration [4942]: Loss = 0.6712236404418945
Iteration [4943]: Loss = 0.6712166666984558
Iteration [4944]: Loss = 0.6711833477020264
Iteration [4945]: Loss = 0.6711263656616211
Iteration [4946]: Loss = 0.6710479259490967
Iteration [4947]: Loss = 0.6709504127502441
Iteration [4948]: Loss = 0.670835554599762
Iteration [4949]: Loss = 0.6707050800323486
Iteration [4950]: Loss = 0.6705605983734131
Iteration [4951]: Loss = 0.6704034805297852
Iteration [4952]: Loss = 0.6702349185943604
Iteration [4953]: Loss = 0.670056164264679
Iteration [4954]: Loss = 0.6698682308197021
Iteration [4955]: Loss = 0.6696719527244568
Iteration [4956]: Loss = 0.6694682836532593
Iteration [4957]: Loss = 5.11256217956543
Iteration [4958]: Loss = 0.6692206263542175
Iteration [4959]: Loss = 0.6691600680351257
Iteration [4960]: Loss = 0.6690785884857178
Iteration [4961]: Loss = 0.668978214263916
Iteration [4962]: Loss = 0.6688608527183533
Iteration [4963]: Loss = 0.6687282919883728
Iteration [4964]: Loss = 0.6685817837715149
Iteration [4965]: Loss = 0.6684229969978333
Iteration [4966]: Loss = 0.6682530045509338
Iteration [4967]: Loss = 0.6680729389190674
Iteration [4968]: Loss = 0.6678838729858398
Iteration [4969]: Loss = 0.6676867008209229
Iteration [4970]: Loss = 5.1225666999816895
Iteration [4971]: Loss = 0.6674505472183228
Iteration [4972]: Loss = 0.6673952341079712
Iteration [4973]: Loss = 0.6673185229301453
Iteration [4974]: Loss = 5.124032974243164
Iteration [4975]: Loss = 0.6672881245613098
Iteration [4976]: Loss = 0.6673203110694885
Iteration [4977]: Loss = 0.6673225164413452
Iteration [4978]: Loss = 5.123610019683838
Iteration [4979]: Loss = 0.6674267053604126
Iteration [4980]: Loss = 5.122373580932617
Iteration [4981]: Loss = 5.121064186096191
Iteration [4982]: Loss = 0.6681079268455505
Iteration [4983]: Loss = 0.6684049963951111
Iteration [4984]: Loss = 0.6686457395553589
Iteration [4985]: Loss = 0.6688356399536133
Iteration [4986]: Loss = 5.114125728607178
Iteration [4987]: Loss = 0.6692603230476379
Iteration [4988]: Loss = 0.6694860458374023
Iteration [4989]: Loss = 0.6696624159812927
Iteration [4990]: Loss = 0.6697945594787598
Iteration [4991]: Loss = 0.6698862314224243
Iteration [4992]: Loss = 0.6699419617652893
Iteration [4993]: Loss = 0.6699653267860413
Iteration [4994]: Loss = 0.6699590682983398
Iteration [4995]: Loss = 0.669926643371582
Iteration [4996]: Loss = 0.6698704361915588
Iteration [4997]: Loss = 0.6697927117347717
Iteration [4998]: Loss = 0.6696957349777222
Iteration [4999]: Loss = 0.669581413269043
Iteration [5000]: Loss = 5.111473560333252
Iteration [5001]: Loss = 5.111278057098389
Iteration [5002]: Loss = 0.6696688532829285
Iteration [5003]: Loss = 0.6698063015937805
Iteration [5004]: Loss = 0.6699031591415405
Iteration [5005]: Loss = 5.108598232269287
Iteration [5006]: Loss = 0.6701686382293701
Iteration [5007]: Loss = 0.6703265309333801
Iteration [5008]: Loss = 0.6704416275024414
Iteration [5009]: Loss = 0.6705183982849121
Iteration [5010]: Loss = 0.6705605983734131
Iteration [5011]: Loss = 0.6705713868141174
Iteration [5012]: Loss = 0.6705541014671326
Iteration [5013]: Loss = 0.6705116033554077
Iteration [5014]: Loss = 0.6704462170600891
Iteration [5015]: Loss = 0.6703603267669678
Iteration [5016]: Loss = 0.6702560186386108
Iteration [5017]: Loss = 0.6701350212097168
Iteration [5018]: Loss = 0.6699989438056946
Iteration [5019]: Loss = 0.6698494553565979
Iteration [5020]: Loss = 5.110146522521973
Iteration [5021]: Loss = 0.6696942448616028
Iteration [5022]: Loss = 0.6696730852127075
Iteration [5023]: Loss = 0.6696270108222961
Iteration [5024]: Loss = 0.669558584690094
Iteration [5025]: Loss = 0.6694698333740234
Iteration [5026]: Loss = 0.6693629026412964
Iteration [5027]: Loss = 0.6692396402359009
Iteration [5028]: Loss = 0.6691015958786011
Iteration [5029]: Loss = 0.6689503192901611
Iteration [5030]: Loss = 0.6687869429588318
Iteration [5031]: Loss = 0.6686130166053772
Iteration [5032]: Loss = 0.6684291958808899
Iteration [5033]: Loss = 0.6682369112968445
Iteration [5034]: Loss = 0.6680365204811096
Iteration [5035]: Loss = 0.6678292751312256
Iteration [5036]: Loss = 0.6676157116889954
Iteration [5037]: Loss = 0.6673963665962219
Iteration [5038]: Loss = 5.124319076538086
Iteration [5039]: Loss = 0.667122483253479
Iteration [5040]: Loss = 0.667051374912262
Iteration [5041]: Loss = 0.6669602394104004
Iteration [5042]: Loss = 0.6668511033058167
Iteration [5043]: Loss = 0.6667259335517883
Iteration [5044]: Loss = 0.6665863394737244
Iteration [5045]: Loss = 0.6664336323738098
Iteration [5046]: Loss = 0.6662691235542297
Iteration [5047]: Loss = 0.6660940051078796
Iteration [5048]: Loss = 5.131462574005127
Iteration [5049]: Loss = 0.6658962965011597
Iteration [5050]: Loss = 0.6658576726913452
Iteration [5051]: Loss = 0.6657958626747131
Iteration [5052]: Loss = 0.6657131910324097
Iteration [5053]: Loss = 0.6656118035316467
Iteration [5054]: Loss = 0.6654936075210571
Iteration [5055]: Loss = 0.665360152721405
Iteration [5056]: Loss = 0.6652131676673889
Iteration [5057]: Loss = 0.6650538444519043
Iteration [5058]: Loss = 0.6648833155632019
Iteration [5059]: Loss = 0.6647030115127563
Iteration [5060]: Loss = 0.6645136475563049
Iteration [5061]: Loss = 0.6643161177635193
Iteration [5062]: Loss = 0.6641114354133606
Iteration [5063]: Loss = 0.6639002561569214
Iteration [5064]: Loss = 0.6636830568313599
Iteration [5065]: Loss = 0.6634606719017029
Iteration [5066]: Loss = 0.6632335186004639
Iteration [5067]: Loss = 0.6630021333694458
Iteration [5068]: Loss = 0.6627667546272278
Iteration [5069]: Loss = 0.6625280380249023
Iteration [5070]: Loss = 0.6622861623764038
Iteration [5071]: Loss = 5.153485298156738
Iteration [5072]: Loss = 0.6619755625724792
Iteration [5073]: Loss = 0.661889374256134
Iteration [5074]: Loss = 0.6617848873138428
Iteration [5075]: Loss = 0.6616639494895935
Iteration [5076]: Loss = 0.6615281105041504
Iteration [5077]: Loss = 0.6613789200782776
Iteration [5078]: Loss = 0.6612177491188049
Iteration [5079]: Loss = 0.6610458493232727
Iteration [5080]: Loss = 0.660863995552063
Iteration [5081]: Loss = 5.161324501037598
Iteration [5082]: Loss = 0.6606565713882446
Iteration [5083]: Loss = 0.6606142520904541
Iteration [5084]: Loss = 0.660549521446228
Iteration [5085]: Loss = 0.660464346408844
Iteration [5086]: Loss = 0.6603607535362244
Iteration [5087]: Loss = 5.1638102531433105
Iteration [5088]: Loss = 5.16354513168335
Iteration [5089]: Loss = 0.6604818105697632
Iteration [5090]: Loss = 0.6606306433677673
Iteration [5091]: Loss = 5.160954475402832
Iteration [5092]: Loss = 0.6609876155853271
Iteration [5093]: Loss = 0.6611857414245605
Iteration [5094]: Loss = 0.6613373756408691
Iteration [5095]: Loss = 0.6614471673965454
Iteration [5096]: Loss = 0.6615192890167236
Iteration [5097]: Loss = 0.6615573167800903
Iteration [5098]: Loss = 0.6615646481513977
Iteration [5099]: Loss = 0.6615444421768188
Iteration [5100]: Loss = 5.156588554382324
Iteration [5101]: Loss = 5.155941486358643
Iteration [5102]: Loss = 0.6618671417236328
Iteration [5103]: Loss = 5.153324604034424
Iteration [5104]: Loss = 0.6624046564102173
Iteration [5105]: Loss = 0.6626792550086975
Iteration [5106]: Loss = 0.6628999710083008
Iteration [5107]: Loss = 0.663071870803833
Iteration [5108]: Loss = 0.6632000207901001
Iteration [5109]: Loss = 9.629439353942871
Iteration [5110]: Loss = 0.6636959314346313
Iteration [5111]: Loss = 0.6640365123748779
Iteration [5112]: Loss = 0.6643167734146118
Iteration [5113]: Loss = 0.6645423769950867
Iteration [5114]: Loss = 0.6647190451622009
Iteration [5115]: Loss = 0.6648513674736023
Iteration [5116]: Loss = 0.664944052696228
Iteration [5117]: Loss = 0.6650007367134094
Iteration [5118]: Loss = 0.6650250554084778
Iteration [5119]: Loss = 0.665020227432251
Iteration [5120]: Loss = 0.664989173412323
Iteration [5121]: Loss = 0.664934515953064
Iteration [5122]: Loss = 0.6648586392402649
Iteration [5123]: Loss = 0.6647634506225586
Iteration [5124]: Loss = 0.6646509766578674
Iteration [5125]: Loss = 0.6645231246948242
Iteration [5126]: Loss = 5.140140056610107
Iteration [5127]: Loss = 5.1400017738342285
Iteration [5128]: Loss = 0.6645788550376892
Iteration [5129]: Loss = 0.6647084355354309
Iteration [5130]: Loss = 5.137768745422363
Iteration [5131]: Loss = 0.665030300617218
Iteration [5132]: Loss = 0.6652126908302307
Iteration [5133]: Loss = 0.6653501987457275
Iteration [5134]: Loss = 0.6654473543167114
Iteration [5135]: Loss = 0.6655081510543823
Iteration [5136]: Loss = 5.133579730987549
Iteration [5137]: Loss = 0.6657125353813171
Iteration [5138]: Loss = 0.665844738483429
Iteration [5139]: Loss = 0.6659370064735413
Iteration [5140]: Loss = 0.6659934520721436
Iteration [5141]: Loss = 0.6660174131393433
Iteration [5142]: Loss = 0.6660124063491821
Iteration [5143]: Loss = 0.665981113910675
Iteration [5144]: Loss = 0.6659261584281921
Iteration [5145]: Loss = 0.6658498048782349
Iteration [5146]: Loss = 0.6657543778419495
Iteration [5147]: Loss = 0.665641725063324
Iteration [5148]: Loss = 0.6655135154724121
Iteration [5149]: Loss = 0.6653713583946228
Iteration [5150]: Loss = 0.6652164459228516
Iteration [5151]: Loss = 0.665050208568573
Iteration [5152]: Loss = 0.6648738980293274
Iteration [5153]: Loss = 0.6646883487701416
Iteration [5154]: Loss = 0.664494514465332
Iteration [5155]: Loss = 0.6642932295799255
Iteration [5156]: Loss = 0.6640852689743042
Iteration [5157]: Loss = 0.6638713479042053
Iteration [5158]: Loss = 0.6636519432067871
Iteration [5159]: Loss = 0.6634275913238525
Iteration [5160]: Loss = 0.6631988883018494
Iteration [5161]: Loss = 5.1482014656066895
Iteration [5162]: Loss = 0.662909984588623
Iteration [5163]: Loss = 0.6628323793411255
Iteration [5164]: Loss = 0.6627358794212341
Iteration [5165]: Loss = 0.662622332572937
Iteration [5166]: Loss = 5.15090274810791
Iteration [5167]: Loss = 0.6625298857688904
Iteration [5168]: Loss = 5.15065860748291
Iteration [5169]: Loss = 0.6626937985420227
Iteration [5170]: Loss = 0.6628091335296631
Iteration [5171]: Loss = 0.6628862619400024
Iteration [5172]: Loss = 0.662929117679596
Iteration [5173]: Loss = 0.6629410982131958
Iteration [5174]: Loss = 0.6629249453544617
Iteration [5175]: Loss = 0.6628838777542114
Iteration [5176]: Loss = 0.6628202199935913
Iteration [5177]: Loss = 0.6627361178398132
Iteration [5178]: Loss = 0.6626337170600891
Iteration [5179]: Loss = 0.6625148057937622
Iteration [5180]: Loss = 0.6623809337615967
Iteration [5181]: Loss = 0.6622339487075806
Iteration [5182]: Loss = 0.6620745658874512
Iteration [5183]: Loss = 0.661904513835907
Iteration [5184]: Loss = 5.155299663543701
Iteration [5185]: Loss = 0.6617158651351929
Iteration [5186]: Loss = 0.6616813540458679
Iteration [5187]: Loss = 0.6616235375404358
Iteration [5188]: Loss = 0.6615447998046875
Iteration [5189]: Loss = 5.156888961791992
Iteration [5190]: Loss = 0.6615120768547058
Iteration [5191]: Loss = 0.6615439057350159
Iteration [5192]: Loss = 5.156323432922363
Iteration [5193]: Loss = 0.6616999506950378
Iteration [5194]: Loss = 0.6618121266365051
Iteration [5195]: Loss = 0.66188645362854
Iteration [5196]: Loss = 0.6619267463684082
Iteration [5197]: Loss = 0.6619364619255066
Iteration [5198]: Loss = 0.6619185209274292
Iteration [5199]: Loss = 0.6618756055831909
Iteration [5200]: Loss = 0.6618101596832275
Iteration [5201]: Loss = 0.6617246866226196
Iteration [5202]: Loss = 0.6616209745407104
Iteration [5203]: Loss = 0.6615010499954224
Iteration [5204]: Loss = 0.6613662242889404
Iteration [5205]: Loss = 0.6612181663513184
Iteration [5206]: Loss = 0.6610581278800964
Iteration [5207]: Loss = 0.6608873605728149
Iteration [5208]: Loss = 0.6607068777084351
Iteration [5209]: Loss = 0.6605177521705627
Iteration [5210]: Loss = 0.6603207588195801
Iteration [5211]: Loss = 0.6601166725158691
Iteration [5212]: Loss = 0.659906268119812
Iteration [5213]: Loss = 0.6596902012825012
Iteration [5214]: Loss = 0.659468948841095
Iteration [5215]: Loss = 5.169548034667969
Iteration [5216]: Loss = 0.6591936349868774
Iteration [5217]: Loss = 0.65912264585495
Iteration [5218]: Loss = 5.170764923095703
Iteration [5219]: Loss = 0.6591037511825562
Iteration [5220]: Loss = 0.6591417789459229
Iteration [5221]: Loss = 5.170086860656738
Iteration [5222]: Loss = 0.6593093276023865
Iteration [5223]: Loss = 0.659426748752594
Iteration [5224]: Loss = 5.16803503036499
Iteration [5225]: Loss = 0.659729540348053
Iteration [5226]: Loss = 0.6599045395851135
Iteration [5227]: Loss = 0.6600354909896851
Iteration [5228]: Loss = 0.6601269245147705
Iteration [5229]: Loss = 0.6601824760437012
Iteration [5230]: Loss = 0.6602058410644531
Iteration [5231]: Loss = 0.6602004766464233
Iteration [5232]: Loss = 0.6601687669754028
Iteration [5233]: Loss = 0.6601136326789856
Iteration [5234]: Loss = 5.16497802734375
Iteration [5235]: Loss = 0.6601218581199646
Iteration [5236]: Loss = 0.6601711511611938
Iteration [5237]: Loss = 0.6601889729499817
Iteration [5238]: Loss = 5.164167881011963
Iteration [5239]: Loss = 0.6603216528892517
Iteration [5240]: Loss = 0.660423994064331
Iteration [5241]: Loss = 0.6604896187782288
Iteration [5242]: Loss = 0.6605220437049866
Iteration [5243]: Loss = 5.162179470062256
Iteration [5244]: Loss = 0.6606794595718384
Iteration [5245]: Loss = 0.6607924699783325
Iteration [5246]: Loss = 0.6608675122261047
Iteration [5247]: Loss = 0.6609084010124207
Iteration [5248]: Loss = 0.660918653011322
Iteration [5249]: Loss = 5.160018444061279
Iteration [5250]: Loss = 0.6610381603240967
Iteration [5251]: Loss = 0.6611347198486328
Iteration [5252]: Loss = 0.6611951589584351
Iteration [5253]: Loss = 0.6612229347229004
Iteration [5254]: Loss = 5.1581830978393555
Iteration [5255]: Loss = 0.6613721251487732
Iteration [5256]: Loss = 0.6614816188812256
Iteration [5257]: Loss = 0.6615533232688904
Iteration [5258]: Loss = 0.6615912914276123
Iteration [5259]: Loss = 5.15601921081543
Iteration [5260]: Loss = 9.648459434509277
Iteration [5261]: Loss = 5.152425765991211
Iteration [5262]: Loss = 0.6627984642982483
Iteration [5263]: Loss = 0.6632870435714722
Iteration [5264]: Loss = 0.6637007594108582
Iteration [5265]: Loss = 0.664047122001648
Iteration [5266]: Loss = 0.6643326282501221
Iteration [5267]: Loss = 0.6645633578300476
Iteration [5268]: Loss = 0.6647447347640991
Iteration [5269]: Loss = 0.6648813486099243
Iteration [5270]: Loss = 0.6649781465530396
Iteration [5271]: Loss = 0.6650385856628418
Iteration [5272]: Loss = 0.6650665402412415
Iteration [5273]: Loss = 0.6650651097297668
Iteration [5274]: Loss = 0.6650373339653015
Iteration [5275]: Loss = 5.136703968048096
Iteration [5276]: Loss = 0.6650898456573486
Iteration [5277]: Loss = 0.6651572585105896
Iteration [5278]: Loss = 9.605880737304688
Iteration [5279]: Loss = 5.1335248947143555
Iteration [5280]: Loss = 0.6660128235816956
Iteration [5281]: Loss = 0.6664072871208191
Iteration [5282]: Loss = 5.126781940460205
Iteration [5283]: Loss = 0.6671804189682007
Iteration [5284]: Loss = 0.6675541996955872
Iteration [5285]: Loss = 0.6678645610809326
Iteration [5286]: Loss = 0.6681177616119385
Iteration [5287]: Loss = 0.6683193445205688
Iteration [5288]: Loss = 0.6684746742248535
Iteration [5289]: Loss = 5.116330623626709
Iteration [5290]: Loss = 0.6688382625579834
Iteration [5291]: Loss = 0.669037401676178
Iteration [5292]: Loss = 0.6691901087760925
Iteration [5293]: Loss = 0.6693012714385986
Iteration [5294]: Loss = 0.6693750023841858
Iteration [5295]: Loss = 5.1116790771484375
Iteration [5296]: Loss = 5.1106438636779785
Iteration [5297]: Loss = 0.6699128746986389
Iteration [5298]: Loss = 0.6701690554618835
Iteration [5299]: Loss = 0.6703733205795288
Iteration [5300]: Loss = 0.6705308556556702
Iteration [5301]: Loss = 0.6706462502479553
Iteration [5302]: Loss = 0.670723557472229
Iteration [5303]: Loss = 0.6707667112350464
Iteration [5304]: Loss = 5.104024410247803
Iteration [5305]: Loss = 5.1031317710876465
Iteration [5306]: Loss = 0.6712296009063721
Iteration [5307]: Loss = 5.100183010101318
Iteration [5308]: Loss = 0.671825110912323
Iteration [5309]: Loss = 0.6721224784851074
Iteration [5310]: Loss = 0.6723639965057373
Iteration [5311]: Loss = 0.6725549101829529
Iteration [5312]: Loss = 0.6727004051208496
Iteration [5313]: Loss = 0.6728047132492065
Iteration [5314]: Loss = 0.6728721261024475
Iteration [5315]: Loss = 0.6729063391685486
Iteration [5316]: Loss = 0.6729105114936829
Iteration [5317]: Loss = 0.6728875637054443
Iteration [5318]: Loss = 0.6728402972221375
Iteration [5319]: Loss = 0.6727713346481323
Iteration [5320]: Loss = 0.6726822853088379
Iteration [5321]: Loss = 0.6725757122039795
Iteration [5322]: Loss = 0.672452986240387
Iteration [5323]: Loss = 0.6723159551620483
Iteration [5324]: Loss = 0.6721659302711487
Iteration [5325]: Loss = 0.672004222869873
Iteration [5326]: Loss = 0.6718319654464722
Iteration [5327]: Loss = 0.6716502904891968
Iteration [5328]: Loss = 0.6714600920677185
Iteration [5329]: Loss = 0.6712621450424194
Iteration [5330]: Loss = 5.102465629577637
Iteration [5331]: Loss = 0.6710225343704224
Iteration [5332]: Loss = 0.6709643602371216
Iteration [5333]: Loss = 0.6708853244781494
Iteration [5334]: Loss = 0.6707876324653625
Iteration [5335]: Loss = 0.6706731915473938
Iteration [5336]: Loss = 0.670543372631073
Iteration [5337]: Loss = 0.6704000234603882
Iteration [5338]: Loss = 5.107022285461426
Iteration [5339]: Loss = 0.6702534556388855
Iteration [5340]: Loss = 0.6702351570129395
Iteration [5341]: Loss = 0.6701919436454773
Iteration [5342]: Loss = 0.6701266169548035
Iteration [5343]: Loss = 0.670041024684906
Iteration [5344]: Loss = 0.6699375510215759
Iteration [5345]: Loss = 0.6698178052902222
Iteration [5346]: Loss = 0.6696835160255432
Iteration [5347]: Loss = 0.6695358753204346
Iteration [5348]: Loss = 0.6693764925003052
Iteration [5349]: Loss = 0.6692062020301819
Iteration [5350]: Loss = 0.6690264940261841
Iteration [5351]: Loss = 0.6688380837440491
Iteration [5352]: Loss = 0.668641984462738
Iteration [5353]: Loss = 0.668438732624054
Iteration [5354]: Loss = 0.6682292222976685
Iteration [5355]: Loss = 0.6680140495300293
Iteration [5356]: Loss = 0.6677938103675842
Iteration [5357]: Loss = 5.122076511383057
Iteration [5358]: Loss = 5.122372150421143
Iteration [5359]: Loss = 0.6676192283630371
Iteration [5360]: Loss = 0.6676849722862244
Iteration [5361]: Loss = 0.667717695236206
Iteration [5362]: Loss = 0.6677207350730896
Iteration [5363]: Loss = 0.6676968932151794
Iteration [5364]: Loss = 0.6676489114761353
Iteration [5365]: Loss = 0.667579174041748
Iteration [5366]: Loss = 0.6674898862838745
Iteration [5367]: Loss = 0.6673829555511475
Iteration [5368]: Loss = 0.6672601103782654
Iteration [5369]: Loss = 5.124594211578369
Iteration [5370]: Loss = 0.667149543762207
Iteration [5371]: Loss = 0.6671469211578369
Iteration [5372]: Loss = 5.124622344970703
Iteration [5373]: Loss = 0.6672416925430298
Iteration [5374]: Loss = 0.6673264503479004
Iteration [5375]: Loss = 0.6673762798309326
Iteration [5376]: Loss = 0.667394757270813
Iteration [5377]: Loss = 0.6673848628997803
Iteration [5378]: Loss = 0.6673493981361389
Iteration [5379]: Loss = 0.6672909259796143
Iteration [5380]: Loss = 0.6672117114067078
Iteration [5381]: Loss = 0.6671139001846313
Iteration [5382]: Loss = 0.6669994592666626
Iteration [5383]: Loss = 0.666869580745697
Iteration [5384]: Loss = 0.6667264103889465
Iteration [5385]: Loss = 0.666570782661438
Iteration [5386]: Loss = 0.666404128074646
Iteration [5387]: Loss = 0.6662277579307556
Iteration [5388]: Loss = 5.130710601806641
Iteration [5389]: Loss = 0.6660257577896118
Iteration [5390]: Loss = 0.6659845113754272
Iteration [5391]: Loss = 0.6659207344055176
Iteration [5392]: Loss = 0.6658368706703186
Iteration [5393]: Loss = 5.132452487945557
Iteration [5394]: Loss = 0.6657931804656982
Iteration [5395]: Loss = 0.6658192873001099
Iteration [5396]: Loss = 0.6658163666725159
Iteration [5397]: Loss = 5.132155418395996
Iteration [5398]: Loss = 0.6659107804298401
Iteration [5399]: Loss = 5.130974292755127
Iteration [5400]: Loss = 5.12969446182251
Iteration [5401]: Loss = 0.6665736436843872
Iteration [5402]: Loss = 0.6668645143508911
Iteration [5403]: Loss = 0.6671000123023987
Iteration [5404]: Loss = 0.667285680770874
Iteration [5405]: Loss = 0.6674264073371887
Iteration [5406]: Loss = 0.6675266027450562
Iteration [5407]: Loss = 0.667590320110321
Iteration [5408]: Loss = 0.6676212549209595
Iteration [5409]: Loss = 0.6676225066184998
Iteration [5410]: Loss = 0.6675971746444702
Iteration [5411]: Loss = 0.6675478219985962
Iteration [5412]: Loss = 5.1225972175598145
Iteration [5413]: Loss = 0.6675624847412109
Iteration [5414]: Loss = 0.6676132678985596
Iteration [5415]: Loss = 0.6676324605941772
Iteration [5416]: Loss = 0.6676232218742371
Iteration [5417]: Loss = 0.6675882339477539
Iteration [5418]: Loss = 0.6675302386283875
Iteration [5419]: Loss = 0.6674513816833496
Iteration [5420]: Loss = 0.6673539876937866
Iteration [5421]: Loss = 0.6672396659851074
Iteration [5422]: Loss = 0.6671102046966553
Iteration [5423]: Loss = 0.66696697473526
Iteration [5424]: Loss = 0.666811466217041
Iteration [5425]: Loss = 0.6666449904441833
Iteration [5426]: Loss = 0.6664683818817139
Iteration [5427]: Loss = 5.12934684753418
Iteration [5428]: Loss = 0.6662665605545044
Iteration [5429]: Loss = 0.6662253141403198
Iteration [5430]: Loss = 0.6661615967750549
Iteration [5431]: Loss = 0.6660776734352112
Iteration [5432]: Loss = 0.6659756302833557
Iteration [5433]: Loss = 0.665857195854187
Iteration [5434]: Loss = 0.665723979473114
Iteration [5435]: Loss = 0.6655774712562561
Iteration [5436]: Loss = 0.6654191017150879
Iteration [5437]: Loss = 0.6652499437332153
Iteration [5438]: Loss = 0.6650712490081787
Iteration [5439]: Loss = 5.137284278869629
Iteration [5440]: Loss = 0.6648657321929932
Iteration [5441]: Loss = 0.6648232340812683
Iteration [5442]: Loss = 0.6647582650184631
Iteration [5443]: Loss = 9.612283706665039
Iteration [5444]: Loss = 0.6649218201637268
Iteration [5445]: Loss = 0.6651194095611572
Iteration [5446]: Loss = 0.6652711033821106
Iteration [5447]: Loss = 0.6653813719749451
Iteration [5448]: Loss = 5.134042263031006
Iteration [5449]: Loss = 0.6656690239906311
Iteration [5450]: Loss = 0.665835976600647
Iteration [5451]: Loss = 0.6659599542617798
Iteration [5452]: Loss = 0.6660453081130981
Iteration [5453]: Loss = 0.6660957336425781
Iteration [5454]: Loss = 5.130297660827637
Iteration [5455]: Loss = 0.6662810444831848
Iteration [5456]: Loss = 5.128660202026367
Iteration [5457]: Loss = 0.6666637063026428
Iteration [5458]: Loss = 0.6668708920478821
Iteration [5459]: Loss = 0.6670312881469727
Iteration [5460]: Loss = 0.6671493649482727
Iteration [5461]: Loss = 0.667229413986206
Iteration [5462]: Loss = 0.6672751307487488
Iteration [5463]: Loss = 0.6672898530960083
Iteration [5464]: Loss = 5.123725414276123
Iteration [5465]: Loss = 0.6674137115478516
Iteration [5466]: Loss = 0.6675107479095459
Iteration [5467]: Loss = 0.6675716638565063
Iteration [5468]: Loss = 0.6676002740859985
Iteration [5469]: Loss = 0.667599618434906
Iteration [5470]: Loss = 0.6675724983215332
Iteration [5471]: Loss = 5.122342586517334
Iteration [5472]: Loss = 0.6676249504089355
Iteration [5473]: Loss = 0.6676914691925049
Iteration [5474]: Loss = 0.6677250266075134
Iteration [5475]: Loss = 0.667728841304779
Iteration [5476]: Loss = 0.6677058935165405
Iteration [5477]: Loss = 0.6676586866378784
Iteration [5478]: Loss = 5.121957778930664
Iteration [5479]: Loss = 0.6676769256591797
Iteration [5480]: Loss = 0.667728841304779
Iteration [5481]: Loss = 5.121058940887451
Iteration [5482]: Loss = 0.6679161787033081
Iteration [5483]: Loss = 5.119417667388916
Iteration [5484]: Loss = 0.6682999134063721
Iteration [5485]: Loss = 0.66850745677948
Iteration [5486]: Loss = 0.6686682105064392
Iteration [5487]: Loss = 0.6687864065170288
Iteration [5488]: Loss = 0.6688663959503174
Iteration [5489]: Loss = 0.6689121723175049
Iteration [5490]: Loss = 0.6689268350601196
Iteration [5491]: Loss = 0.6689135432243347
Iteration [5492]: Loss = 0.6688752174377441
Iteration [5493]: Loss = 0.6688141226768494
Iteration [5494]: Loss = 0.6687328219413757
Iteration [5495]: Loss = 0.6686331033706665
Iteration [5496]: Loss = 0.6685167551040649
Iteration [5497]: Loss = 0.6683855056762695
Iteration [5498]: Loss = 0.668241024017334
Iteration [5499]: Loss = 0.6680843830108643
Iteration [5500]: Loss = 0.6679168939590454
Iteration [5501]: Loss = 0.6677396297454834
Iteration [5502]: Loss = 0.6675534844398499
Iteration [5503]: Loss = 0.6673595309257507
Iteration [5504]: Loss = 0.6671584844589233
Iteration [5505]: Loss = 0.6669510006904602
Iteration [5506]: Loss = 0.6667377948760986
Iteration [5507]: Loss = 0.666519284248352
Iteration [5508]: Loss = 0.6662961840629578
Iteration [5509]: Loss = 0.6660690307617188
Iteration [5510]: Loss = 0.6658380031585693
Iteration [5511]: Loss = 0.6656035780906677
Iteration [5512]: Loss = 0.6653660535812378
Iteration [5513]: Loss = 5.135908603668213
Iteration [5514]: Loss = 0.6650599241256714
Iteration [5515]: Loss = 5.136767864227295
Iteration [5516]: Loss = 9.629192352294922
Iteration [5517]: Loss = 0.6637102961540222
Iteration [5518]: Loss = 5.142053604125977
Iteration [5519]: Loss = 0.6644943356513977
Iteration [5520]: Loss = 0.6648616790771484
Iteration [5521]: Loss = 0.6651663780212402
Iteration [5522]: Loss = 0.6654150485992432
Iteration [5523]: Loss = 0.6656128168106079
Iteration [5524]: Loss = 0.6657649278640747
Iteration [5525]: Loss = 5.13165283203125
Iteration [5526]: Loss = 0.6661229729652405
Iteration [5527]: Loss = 0.6663196682929993
Iteration [5528]: Loss = 0.666470468044281
Iteration [5529]: Loss = 0.666580319404602
Iteration [5530]: Loss = 0.6666531562805176
Iteration [5531]: Loss = 5.127028942108154
Iteration [5532]: Loss = 0.6668755412101746
Iteration [5533]: Loss = 0.6670141816139221
Iteration [5534]: Loss = 5.124652862548828
Iteration [5535]: Loss = 0.6673489212989807
Iteration [5536]: Loss = 0.667535662651062
Iteration [5537]: Loss = 0.6676774621009827
Iteration [5538]: Loss = 0.6677789688110352
Iteration [5539]: Loss = 0.6678442358970642
Iteration [5540]: Loss = 0.6678768992424011
Iteration [5541]: Loss = 0.6678799986839294
Iteration [5542]: Loss = 0.6678566932678223
Iteration [5543]: Loss = 0.6678093671798706
Iteration [5544]: Loss = 0.6677406430244446
Iteration [5545]: Loss = 5.1216044425964355
Iteration [5546]: Loss = 0.6677210330963135
Iteration [5547]: Loss = 0.6677566170692444
Iteration [5548]: Loss = 0.6677623987197876
Iteration [5549]: Loss = 0.6677414774894714
Iteration [5550]: Loss = 0.6676962375640869
Iteration [5551]: Loss = 0.6676293611526489
Iteration [5552]: Loss = 0.6675429344177246
Iteration [5553]: Loss = 0.6674388647079468
Iteration [5554]: Loss = 0.6673189401626587
Iteration [5555]: Loss = 0.6671848297119141
Iteration [5556]: Loss = 0.6670377254486084
Iteration [5557]: Loss = 0.666878879070282
Iteration [5558]: Loss = 0.666709840297699
Iteration [5559]: Loss = 0.6665313839912415
Iteration [5560]: Loss = 0.6663445234298706
Iteration [5561]: Loss = 0.6661499738693237
Iteration [5562]: Loss = 0.665948748588562
Iteration [5563]: Loss = 0.6657412052154541
Iteration [5564]: Loss = 0.6655281782150269
Iteration [5565]: Loss = 0.6653101444244385
Iteration [5566]: Loss = 0.6650876402854919
Iteration [5567]: Loss = 0.6648612022399902
Iteration [5568]: Loss = 0.6646310687065125
Iteration [5569]: Loss = 0.6643977165222168
Iteration [5570]: Loss = 0.6641614437103271
Iteration [5571]: Loss = 0.6639226078987122
Iteration [5572]: Loss = 0.6636813282966614
Iteration [5573]: Loss = 0.6634378433227539
Iteration [5574]: Loss = 0.663192629814148
Iteration [5575]: Loss = 0.662945568561554
Iteration [5576]: Loss = 0.6626971960067749
Iteration [5577]: Loss = 0.6624472737312317
Iteration [5578]: Loss = 5.152601718902588
Iteration [5579]: Loss = 0.6621201038360596
Iteration [5580]: Loss = 0.6620253324508667
Iteration [5581]: Loss = 0.6619141101837158
Iteration [5582]: Loss = 0.6617876291275024
Iteration [5583]: Loss = 0.6616477966308594
Iteration [5584]: Loss = 0.6614957451820374
Iteration [5585]: Loss = 0.6613327264785767
Iteration [5586]: Loss = 0.6611597537994385
Iteration [5587]: Loss = 0.6609780788421631
Iteration [5588]: Loss = 0.6607882380485535
Iteration [5589]: Loss = 0.6605912446975708
Iteration [5590]: Loss = 5.162964820861816
Iteration [5591]: Loss = 0.6603547930717468
Iteration [5592]: Loss = 0.6602990627288818
Iteration [5593]: Loss = 0.6602228879928589
Iteration [5594]: Loss = 0.6601280570030212
Iteration [5595]: Loss = 0.6600167155265808
Iteration [5596]: Loss = 0.6598902940750122
Iteration [5597]: Loss = 0.6597503423690796
Iteration [5598]: Loss = 0.6595982909202576
Iteration [5599]: Loss = 0.6594353318214417
Iteration [5600]: Loss = 0.659262478351593
Iteration [5601]: Loss = 0.6590808033943176
Iteration [5602]: Loss = 0.6588910818099976
Iteration [5603]: Loss = 0.658694326877594
Iteration [5604]: Loss = 0.6584910154342651
Iteration [5605]: Loss = 0.6582819223403931
Iteration [5606]: Loss = 0.6580675840377808
Iteration [5607]: Loss = 0.6578484773635864
Iteration [5608]: Loss = 0.6576251983642578
Iteration [5609]: Loss = 0.6573982238769531
Iteration [5610]: Loss = 0.6571676731109619
Iteration [5611]: Loss = 0.6569342613220215
Iteration [5612]: Loss = 0.6566977500915527
Iteration [5613]: Loss = 0.6564590930938721
Iteration [5614]: Loss = 0.6562179327011108
Iteration [5615]: Loss = 0.6559749841690063
Iteration [5616]: Loss = 0.655730128288269
Iteration [5617]: Loss = 0.655483603477478
Iteration [5618]: Loss = 0.6552356481552124
Iteration [5619]: Loss = 0.6549865007400513
Iteration [5620]: Loss = 0.6547360420227051
Iteration [5621]: Loss = 0.6544846296310425
Iteration [5622]: Loss = 0.6542322635650635
Iteration [5623]: Loss = 5.200057029724121
Iteration [5624]: Loss = 0.6539032459259033
Iteration [5625]: Loss = 0.6538089513778687
Iteration [5626]: Loss = 0.653698205947876
Iteration [5627]: Loss = 0.6535724401473999
Iteration [5628]: Loss = 5.203242301940918
Iteration [5629]: Loss = 0.6534596681594849
Iteration [5630]: Loss = 0.653457522392273
Iteration [5631]: Loss = 0.6534296870231628
Iteration [5632]: Loss = 0.6533786058425903
Iteration [5633]: Loss = 0.6533067226409912
Iteration [5634]: Loss = 0.6532159447669983
Iteration [5635]: Loss = 0.6531082391738892
Iteration [5636]: Loss = 0.6529853343963623
Iteration [5637]: Loss = 0.6528487205505371
Iteration [5638]: Loss = 0.6526998281478882
Iteration [5639]: Loss = 0.6525396108627319
Iteration [5640]: Loss = 0.652369499206543
Iteration [5641]: Loss = 0.6521903276443481
Iteration [5642]: Loss = 0.6520030498504639
Iteration [5643]: Loss = 5.212750434875488
Iteration [5644]: Loss = 0.6501005291938782
Iteration [5645]: Loss = 0.6498507857322693
Iteration [5646]: Loss = 5.2268147468566895
Iteration [5647]: Loss = 0.6498774290084839
Iteration [5648]: Loss = 5.222342491149902
Iteration [5649]: Loss = 0.6505658626556396
Iteration [5650]: Loss = 0.6507105827331543
Iteration [5651]: Loss = 0.6508169770240784
Iteration [5652]: Loss = 5.218147277832031
Iteration [5653]: Loss = 0.6510934829711914
Iteration [5654]: Loss = 5.21600341796875
Iteration [5655]: Loss = 0.6515376567840576
Iteration [5656]: Loss = 0.6517692804336548
Iteration [5657]: Loss = 0.6519542336463928
Iteration [5658]: Loss = 0.6520967483520508
Iteration [5659]: Loss = 0.6522012948989868
Iteration [5660]: Loss = 0.6522716283798218
Iteration [5661]: Loss = 0.6523109078407288
Iteration [5662]: Loss = 5.209738254547119
Iteration [5663]: Loss = 0.6524724960327148
Iteration [5664]: Loss = 0.6525837182998657
Iteration [5665]: Loss = 0.6535698175430298
Iteration [5666]: Loss = 0.6536145210266113
Iteration [5667]: Loss = 0.6536307334899902
Iteration [5668]: Loss = 0.65362149477005
Iteration [5669]: Loss = 0.6535890698432922
Iteration [5670]: Loss = 0.6535359025001526
Iteration [5671]: Loss = 5.203062534332275
Iteration [5672]: Loss = 0.6535393595695496
Iteration [5673]: Loss = 0.653583288192749
Iteration [5674]: Loss = 0.6535986661911011
Iteration [5675]: Loss = 0.6535886526107788
Iteration [5676]: Loss = 0.6535555720329285
Iteration [5677]: Loss = 5.202840805053711
Iteration [5678]: Loss = 5.202305793762207
Iteration [5679]: Loss = 0.6538152694702148
Iteration [5680]: Loss = 0.6539910435676575
Iteration [5681]: Loss = 5.199203014373779
Iteration [5682]: Loss = 0.6543853878974915
Iteration [5683]: Loss = 0.6545955538749695
Iteration [5684]: Loss = 0.6547609567642212
Iteration [5685]: Loss = 0.6548859477043152
Iteration [5686]: Loss = 0.6549745798110962
Iteration [5687]: Loss = 0.6550303101539612
Iteration [5688]: Loss = 0.6550565958023071
Iteration [5689]: Loss = 0.6550561189651489
Iteration [5690]: Loss = 0.6550317406654358
Iteration [5691]: Loss = 0.654985785484314
Iteration [5692]: Loss = 0.6549203395843506
Iteration [5693]: Loss = 0.6548373699188232
Iteration [5694]: Loss = 5.195630073547363
Iteration [5695]: Loss = 0.6538786292076111
Iteration [5696]: Loss = 5.200514793395996
Iteration [5697]: Loss = 0.6546152830123901
Iteration [5698]: Loss = 0.654733419418335
Iteration [5699]: Loss = 5.1951799392700195
Iteration [5700]: Loss = 0.6550291776657104
Iteration [5701]: Loss = 0.655197262763977
Iteration [5702]: Loss = 0.6553247570991516
Iteration [5703]: Loss = 0.655415415763855
Iteration [5704]: Loss = 5.191357135772705
Iteration [5705]: Loss = 0.6556641459465027
Iteration [5706]: Loss = 0.65581214427948
Iteration [5707]: Loss = 0.655921459197998
Iteration [5708]: Loss = 0.6559959650039673
Iteration [5709]: Loss = 0.6560389995574951
Iteration [5710]: Loss = 0.6560536623001099
Iteration [5711]: Loss = 0.6560430526733398
Iteration [5712]: Loss = 9.720479011535645
Iteration [5713]: Loss = 0.6562786102294922
Iteration [5714]: Loss = 0.6564972996711731
Iteration [5715]: Loss = 0.6566704511642456
Iteration [5716]: Loss = 0.6568026542663574
Iteration [5717]: Loss = 0.6568978428840637
Iteration [5718]: Loss = 0.6569598317146301
Iteration [5719]: Loss = 0.6569916009902954
Iteration [5720]: Loss = 0.656996488571167
Iteration [5721]: Loss = 0.6569770574569702
Iteration [5722]: Loss = 0.6569357514381409
Iteration [5723]: Loss = 0.6568746566772461
Iteration [5724]: Loss = 0.6567956209182739
Iteration [5725]: Loss = 5.184234142303467
Iteration [5726]: Loss = 0.656753659248352
Iteration [5727]: Loss = 0.6567772626876831
Iteration [5728]: Loss = 5.183804988861084
Iteration [5729]: Loss = 0.6569104194641113
Iteration [5730]: Loss = 0.6570088267326355
Iteration [5731]: Loss = 0.657073438167572
Iteration [5732]: Loss = 0.6571078896522522
Iteration [5733]: Loss = 0.6571150422096252
Iteration [5734]: Loss = 5.1819353103637695
Iteration [5735]: Loss = 5.1812286376953125
Iteration [5736]: Loss = 0.6574670076370239
Iteration [5737]: Loss = 0.657666027545929
Iteration [5738]: Loss = 0.6578214168548584
Iteration [5739]: Loss = 5.177078723907471
Iteration [5740]: Loss = 0.6581791043281555
Iteration [5741]: Loss = 0.6583729386329651
Iteration [5742]: Loss = 0.6585237979888916
Iteration [5743]: Loss = 5.173048973083496
Iteration [5744]: Loss = 0.658873438835144
Iteration [5745]: Loss = 0.6590638160705566
Iteration [5746]: Loss = 0.6592113971710205
Iteration [5747]: Loss = 5.169103622436523
Iteration [5748]: Loss = 5.167749404907227
Iteration [5749]: Loss = 0.6599036455154419
Iteration [5750]: Loss = 0.6601933836936951
Iteration [5751]: Loss = 0.6604304909706116
Iteration [5752]: Loss = 0.6606200933456421
Iteration [5753]: Loss = 0.6607669591903687
Iteration [5754]: Loss = 0.6608754396438599
Iteration [5755]: Loss = 0.660949170589447
Iteration [5756]: Loss = 5.159500598907471
Iteration [5757]: Loss = 0.6611665487289429
Iteration [5758]: Loss = 0.6613003015518188
Iteration [5759]: Loss = 0.6613969206809998
Iteration [5760]: Loss = 5.156816005706787
Iteration [5761]: Loss = 0.6616532802581787
Iteration [5762]: Loss = 0.6618036031723022
Iteration [5763]: Loss = 0.6619150638580322
Iteration [5764]: Loss = 0.6619912981987
Iteration [5765]: Loss = 0.6620361804962158
Iteration [5766]: Loss = 0.6620525121688843
Iteration [5767]: Loss = 0.6620433330535889
Iteration [5768]: Loss = 5.153659820556641
Iteration [5769]: Loss = 0.6621189713478088
Iteration [5770]: Loss = 5.152623653411865
Iteration [5771]: Loss = 5.1514668464660645
Iteration [5772]: Loss = 0.6627131104469299
Iteration [5773]: Loss = 0.6629760265350342
Iteration [5774]: Loss = 0.6631889343261719
Iteration [5775]: Loss = 0.6633566617965698
Iteration [5776]: Loss = 0.6634836792945862
Iteration [5777]: Loss = 5.144735336303711
Iteration [5778]: Loss = 0.663791835308075
Iteration [5779]: Loss = 0.663964033126831
Iteration [5780]: Loss = 5.141768455505371
Iteration [5781]: Loss = 0.6643489599227905
Iteration [5782]: Loss = 0.6645537614822388
Iteration [5783]: Loss = 0.6647142171859741
Iteration [5784]: Loss = 0.6648346781730652
Iteration [5785]: Loss = 0.6649191975593567
Iteration [5786]: Loss = 0.6649711728096008
Iteration [5787]: Loss = 0.6649940013885498
Iteration [5788]: Loss = 0.664990246295929
Iteration [5789]: Loss = 0.6649630069732666
Iteration [5790]: Loss = 0.6649143695831299
Iteration [5791]: Loss = 0.6648465394973755
Iteration [5792]: Loss = 0.6647613644599915
Iteration [5793]: Loss = 0.6646603345870972
Iteration [5794]: Loss = 0.6645455360412598
Iteration [5795]: Loss = 0.6644179821014404
Iteration [5796]: Loss = 0.664279043674469
Iteration [5797]: Loss = 0.6641299724578857
Iteration [5798]: Loss = 0.663971483707428
Iteration [5799]: Loss = 0.663804829120636
Iteration [5800]: Loss = 5.144413471221924
Iteration [5801]: Loss = 0.6636113524436951
Iteration [5802]: Loss = 0.6635698080062866
Iteration [5803]: Loss = 0.6635083556175232
Iteration [5804]: Loss = 0.6634290218353271
Iteration [5805]: Loss = 0.6633335947990417
Iteration [5806]: Loss = 0.6632235050201416
Iteration [5807]: Loss = 0.6631003022193909
Iteration [5808]: Loss = 0.6629652976989746
Iteration [5809]: Loss = 0.6628196835517883
Iteration [5810]: Loss = 0.6626644134521484
Iteration [5811]: Loss = 0.66250079870224
Iteration [5812]: Loss = 0.6623291373252869
Iteration [5813]: Loss = 5.152862071990967
Iteration [5814]: Loss = 0.6621279120445251
Iteration [5815]: Loss = 0.6620832085609436
Iteration [5816]: Loss = 0.6620190143585205
Iteration [5817]: Loss = 0.6619371771812439
Iteration [5818]: Loss = 5.154642581939697
Iteration [5819]: Loss = 0.6618890166282654
Iteration [5820]: Loss = 0.6619095802307129
Iteration [5821]: Loss = 0.6619042158126831
Iteration [5822]: Loss = 0.6618751883506775
Iteration [5823]: Loss = 0.6618251204490662
Iteration [5824]: Loss = 0.6617560386657715
Iteration [5825]: Loss = 0.6616696715354919
Iteration [5826]: Loss = 0.6615679264068604
Iteration [5827]: Loss = 0.6614521741867065
Iteration [5828]: Loss = 0.6613240242004395
Iteration [5829]: Loss = 5.1583943367004395
Iteration [5830]: Loss = 0.6611968278884888
Iteration [5831]: Loss = 0.6611840128898621
Iteration [5832]: Loss = 0.6611483693122864
Iteration [5833]: Loss = 0.661092221736908
Iteration [5834]: Loss = 0.6610175967216492
Iteration [5835]: Loss = 0.6609264612197876
Iteration [5836]: Loss = 0.6608203649520874
Iteration [5837]: Loss = 0.6607007384300232
Iteration [5838]: Loss = 5.161924362182617
Iteration [5839]: Loss = 0.6605885028839111
Iteration [5840]: Loss = 0.6605820059776306
Iteration [5841]: Loss = 5.162021636962891
Iteration [5842]: Loss = 0.6606630086898804
Iteration [5843]: Loss = 0.6607388257980347
Iteration [5844]: Loss = 0.660783052444458
Iteration [5845]: Loss = 0.6607989072799683
Iteration [5846]: Loss = 0.6607891321182251
Iteration [5847]: Loss = 0.6607562899589539
Iteration [5848]: Loss = 0.6607027649879456
Iteration [5849]: Loss = 0.660630464553833
Iteration [5850]: Loss = 0.6605411767959595
Iteration [5851]: Loss = 0.6604369282722473
Iteration [5852]: Loss = 0.6603187918663025
Iteration [5853]: Loss = 0.660188615322113
Iteration [5854]: Loss = 0.6600472927093506
Iteration [5855]: Loss = 5.165791034698486
Iteration [5856]: Loss = 0.659898042678833
Iteration [5857]: Loss = 0.6598761081695557
Iteration [5858]: Loss = 0.659832239151001
Iteration [5859]: Loss = 0.6597687005996704
Iteration [5860]: Loss = 0.659687340259552
Iteration [5861]: Loss = 0.6595901250839233
Iteration [5862]: Loss = 0.6594785451889038
Iteration [5863]: Loss = 0.659354031085968
Iteration [5864]: Loss = 0.6592180132865906
Iteration [5865]: Loss = 0.6590713262557983
Iteration [5866]: Loss = 0.6589152812957764
Iteration [5867]: Loss = 0.6587507724761963
Iteration [5868]: Loss = 0.6585785746574402
Iteration [5869]: Loss = 0.6583995223045349
Iteration [5870]: Loss = 0.6582142114639282
Iteration [5871]: Loss = 0.658023476600647
Iteration [5872]: Loss = 5.177713394165039
Iteration [5873]: Loss = 0.6577904224395752
Iteration [5874]: Loss = 0.6577330231666565
Iteration [5875]: Loss = 0.657657265663147
Iteration [5876]: Loss = 0.6575651168823242
Iteration [5877]: Loss = 0.6574580669403076
Iteration [5878]: Loss = 5.180546760559082
Iteration [5879]: Loss = 0.6573683619499207
Iteration [5880]: Loss = 5.180348873138428
Iteration [5881]: Loss = 0.6575133800506592
Iteration [5882]: Loss = 5.178930282592773
Iteration [5883]: Loss = 0.6578481793403625
Iteration [5884]: Loss = 0.6580325961112976
Iteration [5885]: Loss = 0.6581746339797974
Iteration [5886]: Loss = 0.6582785844802856
Iteration [5887]: Loss = 5.174706935882568
Iteration [5888]: Loss = 0.658548891544342
Iteration [5889]: Loss = 5.1726460456848145
Iteration [5890]: Loss = 0.6589841842651367
Iteration [5891]: Loss = 0.659211277961731
Iteration [5892]: Loss = 0.6593918204307556
Iteration [5893]: Loss = 0.6595303416252136
Iteration [5894]: Loss = 0.6596311926841736
Iteration [5895]: Loss = 0.6596978902816772
Iteration [5896]: Loss = 0.6597340703010559
Iteration [5897]: Loss = 0.6597424745559692
Iteration [5898]: Loss = 5.166767597198486
Iteration [5899]: Loss = 0.6598494052886963
Iteration [5900]: Loss = 0.6599364280700684
Iteration [5901]: Loss = 0.659990668296814
Iteration [5902]: Loss = 0.6600154042243958
Iteration [5903]: Loss = 0.6600137948989868
Iteration [5904]: Loss = 0.659988284111023
Iteration [5905]: Loss = 0.6599411368370056
Iteration [5906]: Loss = 0.6598747968673706
Iteration [5907]: Loss = 0.6597908735275269
Iteration [5908]: Loss = 0.6596912145614624
Iteration [5909]: Loss = 0.6595774292945862
Iteration [5910]: Loss = 0.659450888633728
Iteration [5911]: Loss = 0.6593129634857178
Iteration [5912]: Loss = 0.659164547920227
Iteration [5913]: Loss = 0.6590070724487305
Iteration [5914]: Loss = 5.1718645095825195
Iteration [5915]: Loss = 0.6588305234909058
Iteration [5916]: Loss = 0.658797025680542
Iteration [5917]: Loss = 0.6587429046630859
Iteration [5918]: Loss = 0.6586700677871704
Iteration [5919]: Loss = 5.173367500305176
Iteration [5920]: Loss = 0.6586383581161499
Iteration [5921]: Loss = 0.6579614877700806
Iteration [5922]: Loss = 0.6579628586769104
Iteration [5923]: Loss = 0.6579399704933167
Iteration [5924]: Loss = 0.6578955054283142
Iteration [5925]: Loss = 0.6578314304351807
Iteration [5926]: Loss = 0.6577497124671936
Iteration [5927]: Loss = 0.6576521396636963
Iteration [5928]: Loss = 0.6575403213500977
Iteration [5929]: Loss = 0.6574155688285828
Iteration [5930]: Loss = 0.6572791934013367
Iteration [5931]: Loss = 0.6571323871612549
Iteration [5932]: Loss = 0.6569762825965881
Iteration [5933]: Loss = 0.6568117141723633
Iteration [5934]: Loss = 0.656639575958252
Iteration [5935]: Loss = 0.6564604640007019
Iteration [5936]: Loss = 0.6562752723693848
Iteration [5937]: Loss = 0.6560845375061035
Iteration [5938]: Loss = 0.6558889150619507
Iteration [5939]: Loss = 0.6556887030601501
Iteration [5940]: Loss = 0.6554843783378601
Iteration [5941]: Loss = 0.6552764773368835
Iteration [5942]: Loss = 0.6550652980804443
Iteration [5943]: Loss = 0.6548512578010559
Iteration [5944]: Loss = 0.6546344757080078
Iteration [5945]: Loss = 0.6544153094291687
Iteration [5946]: Loss = 0.6541941165924072
Iteration [5947]: Loss = 0.6539709568023682
Iteration [5948]: Loss = 5.201416015625
Iteration [5949]: Loss = 5.201779365539551
Iteration [5950]: Loss = 0.6537675261497498
Iteration [5951]: Loss = 0.6538189053535461
Iteration [5952]: Loss = 0.6538412570953369
Iteration [5953]: Loss = 0.6538374423980713
Iteration [5954]: Loss = 0.6538100242614746
Iteration [5955]: Loss = 5.201326370239258
Iteration [5956]: Loss = 0.6538573503494263
Iteration [5957]: Loss = 0.6539196372032166
Iteration [5958]: Loss = 5.2002153396606445
Iteration [5959]: Loss = 0.6541200280189514
Iteration [5960]: Loss = 0.654247522354126
Iteration [5961]: Loss = 0.6543384194374084
Iteration [5962]: Loss = 0.6543964147567749
Iteration [5963]: Loss = 0.654424786567688
Iteration [5964]: Loss = 0.6544262170791626
Iteration [5965]: Loss = 5.197581768035889
Iteration [5966]: Loss = 5.1968889236450195
Iteration [5967]: Loss = 0.6547683477401733
Iteration [5968]: Loss = 0.6549657583236694
Iteration [5969]: Loss = 0.6551197171211243
Iteration [5970]: Loss = 0.6552343368530273
Iteration [5971]: Loss = 5.19228458404541
Iteration [5972]: Loss = 0.6555238962173462
Iteration [5973]: Loss = 0.6556891202926636
Iteration [5974]: Loss = 0.6558141708374023
Iteration [5975]: Loss = 5.1888628005981445
Iteration [5976]: Loss = 0.6561209559440613
Iteration [5977]: Loss = 0.6562936305999756
Iteration [5978]: Loss = 0.6564250588417053
Iteration [5979]: Loss = 0.6565196514129639
Iteration [5980]: Loss = 0.6565807461738586
Iteration [5981]: Loss = 0.6566118597984314
Iteration [5982]: Loss = 0.6566158533096313
Iteration [5983]: Loss = 0.6565954685211182
Iteration [5984]: Loss = 0.6565530896186829
Iteration [5985]: Loss = 0.6564909219741821
Iteration [5986]: Loss = 0.6564110517501831
Iteration [5987]: Loss = 0.6563149094581604
Iteration [5988]: Loss = 0.6562044620513916
Iteration [5989]: Loss = 0.6560809016227722
Iteration [5990]: Loss = 0.6559456586837769
Iteration [5991]: Loss = 0.6558000445365906
Iteration [5992]: Loss = 0.6556447148323059
Iteration [5993]: Loss = 0.6554809808731079
Iteration [5994]: Loss = 0.6553094983100891
Iteration [5995]: Loss = 0.6551311016082764
Iteration [5996]: Loss = 0.6549463868141174
Iteration [5997]: Loss = 0.6547561883926392
Iteration [5998]: Loss = 0.6545608639717102
Iteration [5999]: Loss = 5.197829246520996
Iteration [6000]: Loss = 0.6543213129043579
Iteration [6001]: Loss = 9.74255657196045
Iteration [6002]: Loss = 0.6545082926750183
Iteration [6003]: Loss = 0.6547067761421204
Iteration [6004]: Loss = 0.6548616290092468
Iteration [6005]: Loss = 0.6549774408340454
Iteration [6006]: Loss = 5.193771839141846
Iteration [6007]: Loss = 0.6552683115005493
Iteration [6008]: Loss = 0.6554338932037354
Iteration [6009]: Loss = 0.6555593609809875
Iteration [6010]: Loss = 0.6556484699249268
Iteration [6011]: Loss = 0.6557047963142395
Iteration [6012]: Loss = 5.189853668212891
Iteration [6013]: Loss = 0.6558941602706909
Iteration [6014]: Loss = 0.6560165882110596
Iteration [6015]: Loss = 0.6561028957366943
Iteration [6016]: Loss = 0.6561568975448608
Iteration [6017]: Loss = 0.6561817526817322
Iteration [6018]: Loss = 5.187252044677734
Iteration [6019]: Loss = 0.6563166975975037
Iteration [6020]: Loss = 0.6564159393310547
Iteration [6021]: Loss = 0.6564815044403076
Iteration [6022]: Loss = 0.6565166711807251
Iteration [6023]: Loss = 0.6565245389938354
Iteration [6024]: Loss = 5.1853532791137695
Iteration [6025]: Loss = 0.6566305160522461
Iteration [6026]: Loss = 0.6567173004150391
Iteration [6027]: Loss = 0.6567716002464294
Iteration [6028]: Loss = 0.6567966938018799
Iteration [6029]: Loss = 5.183685779571533
Iteration [6030]: Loss = 0.6569321751594543
Iteration [6031]: Loss = 5.182318687438965
Iteration [6032]: Loss = 0.657258152961731
Iteration [6033]: Loss = 5.179962635040283
Iteration [6034]: Loss = 0.6577379703521729
Iteration [6035]: Loss = 0.6579838991165161
Iteration [6036]: Loss = 0.6581815481185913
Iteration [6037]: Loss = 0.6583356857299805
Iteration [6038]: Loss = 5.1741156578063965
Iteration [6039]: Loss = 5.172728538513184
Iteration [6040]: Loss = 0.6590443849563599
Iteration [6041]: Loss = 0.6593385338783264
Iteration [6042]: Loss = 0.6595798134803772
Iteration [6043]: Loss = 0.6597732305526733
Iteration [6044]: Loss = 0.6599236130714417
Iteration [6045]: Loss = 0.6600350141525269
Iteration [6046]: Loss = 0.660111665725708
Iteration [6047]: Loss = 0.6601566076278687
Iteration [6048]: Loss = 0.660173237323761
Iteration [6049]: Loss = 0.6601642966270447
Iteration [6050]: Loss = 0.6601322889328003
Iteration [6051]: Loss = 0.6600796580314636
Iteration [6052]: Loss = 5.165146827697754
Iteration [6053]: Loss = 0.6600812673568726
Iteration [6054]: Loss = 0.6601232290267944
Iteration [6055]: Loss = 0.6601371169090271
Iteration [6056]: Loss = 0.660125732421875
Iteration [6057]: Loss = 5.16466760635376
Iteration [6058]: Loss = 0.6601980924606323
Iteration [6059]: Loss = 5.163640975952148
Iteration [6060]: Loss = 0.6604717969894409
Iteration [6061]: Loss = 5.161575794219971
Iteration [6062]: Loss = 0.6609082818031311
Iteration [6063]: Loss = 0.6611352562904358
Iteration [6064]: Loss = 0.66131591796875
Iteration [6065]: Loss = 5.156846046447754
Iteration [6066]: Loss = 0.6617158651351929
Iteration [6067]: Loss = 0.6619274020195007
Iteration [6068]: Loss = 0.6620939373970032
Iteration [6069]: Loss = 0.6622200012207031
Iteration [6070]: Loss = 0.6623095870018005
Iteration [6071]: Loss = 0.6623662114143372
Iteration [6072]: Loss = 0.66239333152771
Iteration [6073]: Loss = 0.6623936891555786
Iteration [6074]: Loss = 0.662369966506958
Iteration [6075]: Loss = 0.6623246669769287
Iteration [6076]: Loss = 0.6622599363327026
Iteration [6077]: Loss = 0.6621775031089783
Iteration [6078]: Loss = 0.6620792746543884
Iteration [6079]: Loss = 0.6619669198989868
Iteration [6080]: Loss = 0.6618417501449585
Iteration [6081]: Loss = 0.661704957485199
Iteration [6082]: Loss = 0.6615577936172485
Iteration [6083]: Loss = 0.6614013314247131
Iteration [6084]: Loss = 5.158096790313721
Iteration [6085]: Loss = 0.6612256765365601
Iteration [6086]: Loss = 0.6611921191215515
Iteration [6087]: Loss = 0.6611378192901611
Iteration [6088]: Loss = 0.6610651016235352
Iteration [6089]: Loss = 0.660975456237793
Iteration [6090]: Loss = 0.6608709096908569
Iteration [6091]: Loss = 5.16087007522583
Iteration [6092]: Loss = 0.6607839465141296
Iteration [6093]: Loss = 0.6607881188392639
Iteration [6094]: Loss = 0.6607679128646851
Iteration [6095]: Loss = 0.6607258915901184
Iteration [6096]: Loss = 0.6606637835502625
Iteration [6097]: Loss = 0.660584032535553
Iteration [6098]: Loss = 0.6604882478713989
Iteration [6099]: Loss = 5.163021087646484
Iteration [6100]: Loss = 0.6604164838790894
Iteration [6101]: Loss = 9.66504955291748
Iteration [6102]: Loss = 5.160986423492432
Iteration [6103]: Loss = 0.6611425280570984
Iteration [6104]: Loss = 5.156654357910156
Iteration [6105]: Loss = 0.6619340777397156
Iteration [6106]: Loss = 0.6623122692108154
Iteration [6107]: Loss = 0.6626293063163757
Iteration [6108]: Loss = 5.148632049560547
Iteration [6109]: Loss = 0.6632615327835083
Iteration [6110]: Loss = 0.6635715961456299
Iteration [6111]: Loss = 0.6638270020484924
Iteration [6112]: Loss = 0.6640333533287048
Iteration [6113]: Loss = 0.6641952395439148
Iteration [6114]: Loss = 0.66431725025177
Iteration [6115]: Loss = 0.6644032001495361
Iteration [6116]: Loss = 0.6644567251205444
Iteration [6117]: Loss = 0.6644810438156128
Iteration [6118]: Loss = 0.6644790768623352
Iteration [6119]: Loss = 0.6644532680511475
Iteration [6120]: Loss = 0.6644062995910645
Iteration [6121]: Loss = 5.140374660491943
Iteration [6122]: Loss = 0.6644161343574524
Iteration [6123]: Loss = 0.6644610166549683
Iteration [6124]: Loss = 0.6644773483276367
Iteration [6125]: Loss = 0.6644683480262756
Iteration [6126]: Loss = 0.6644361615180969
Iteration [6127]: Loss = 0.6643832325935364
Iteration [6128]: Loss = 0.6643117666244507
Iteration [6129]: Loss = 5.141037940979004
Iteration [6130]: Loss = 0.6642798781394958
Iteration [6131]: Loss = 5.140561580657959
Iteration [6132]: Loss = 0.6644669771194458
Iteration [6133]: Loss = 0.6645873785018921
Iteration [6134]: Loss = 0.6646717190742493
Iteration [6135]: Loss = 0.6647237539291382
Iteration [6136]: Loss = 0.6647467017173767
Iteration [6137]: Loss = 0.6647434830665588
Iteration [6138]: Loss = 0.6647166013717651
Iteration [6139]: Loss = 0.6646684408187866
Iteration [6140]: Loss = 0.6646011471748352
Iteration [6141]: Loss = 0.6645165681838989
Iteration [6142]: Loss = 0.6644165515899658
Iteration [6143]: Loss = 0.6643025279045105
Iteration [6144]: Loss = 0.664175808429718
Iteration [6145]: Loss = 0.6640379428863525
Iteration [6146]: Loss = 5.142937660217285
Iteration [6147]: Loss = 0.6638928651809692
Iteration [6148]: Loss = 0.6638717651367188
Iteration [6149]: Loss = 0.6638288497924805
Iteration [6150]: Loss = 0.6637662053108215
Iteration [6151]: Loss = 0.6636859178543091
Iteration [6152]: Loss = 0.663589596748352
Iteration [6153]: Loss = 0.6634789705276489
Iteration [6154]: Loss = 0.6633553504943848
Iteration [6155]: Loss = 0.6632202863693237
Iteration [6156]: Loss = 0.6630745530128479
Iteration [6157]: Loss = 5.148468971252441
Iteration [6158]: Loss = 0.6629167199134827
Iteration [6159]: Loss = 0.6628901958465576
Iteration [6160]: Loss = 0.6628425717353821
Iteration [6161]: Loss = 0.6627756953239441
Iteration [6162]: Loss = 0.6626914739608765
Iteration [6163]: Loss = 0.6625916957855225
Iteration [6164]: Loss = 0.6624780297279358
Iteration [6165]: Loss = 0.6623517274856567
Iteration [6166]: Loss = 0.6622140407562256
Iteration [6167]: Loss = 0.6620660424232483
Iteration [6168]: Loss = 0.6619091033935547
Iteration [6169]: Loss = 0.661743700504303
Iteration [6170]: Loss = 0.6615709662437439
Iteration [6171]: Loss = 0.6613913774490356
Iteration [6172]: Loss = 0.6612058281898499
Iteration [6173]: Loss = 5.159365653991699
Iteration [6174]: Loss = 0.6609804630279541
Iteration [6175]: Loss = 5.159879207611084
Iteration [6176]: Loss = 0.6610130071640015
Iteration [6177]: Loss = 0.6610677242279053
Iteration [6178]: Loss = 0.6610933542251587
Iteration [6179]: Loss = 0.6610924005508423
Iteration [6180]: Loss = 0.6610677242279053
Iteration [6181]: Loss = 0.6610215902328491
Iteration [6182]: Loss = 0.6609561443328857
Iteration [6183]: Loss = 0.660873293876648
Iteration [6184]: Loss = 0.6607748866081238
Iteration [6185]: Loss = 0.6606621742248535
Iteration [6186]: Loss = 0.6605368852615356
Iteration [6187]: Loss = 5.162893772125244
Iteration [6188]: Loss = 0.6604145765304565
Iteration [6189]: Loss = 0.6604035496711731
Iteration [6190]: Loss = 0.6603696942329407
Iteration [6191]: Loss = 5.163381099700928
Iteration [6192]: Loss = 0.6604036092758179
Iteration [6193]: Loss = 0.6604592204093933
Iteration [6194]: Loss = 0.6604852676391602
Iteration [6195]: Loss = 0.6604849100112915
Iteration [6196]: Loss = 0.6604607105255127
Iteration [6197]: Loss = 5.162808895111084
Iteration [6198]: Loss = 0.6605109572410583
Iteration [6199]: Loss = 0.6605734825134277
Iteration [6200]: Loss = 0.6606058478355408
Iteration [6201]: Loss = 0.6606112718582153
Iteration [6202]: Loss = 0.6605920791625977
Iteration [6203]: Loss = 0.6605509519577026
Iteration [6204]: Loss = 5.162377834320068
Iteration [6205]: Loss = 0.660572350025177
Iteration [6206]: Loss = 0.6606224775314331
Iteration [6207]: Loss = 0.6606438159942627
Iteration [6208]: Loss = 0.6606391072273254
Iteration [6209]: Loss = 0.6606110334396362
Iteration [6210]: Loss = 5.161966323852539
Iteration [6211]: Loss = 0.6606544256210327
Iteration [6212]: Loss = 0.6607142090797424
Iteration [6213]: Loss = 0.6607440114021301
Iteration [6214]: Loss = 0.6607468724250793
Iteration [6215]: Loss = 0.6607256531715393
Iteration [6216]: Loss = 5.1612725257873535
Iteration [6217]: Loss = 0.6607809066772461
Iteration [6218]: Loss = 0.6608455181121826
Iteration [6219]: Loss = 5.160141468048096
Iteration [6220]: Loss = 0.6610475182533264
Iteration [6221]: Loss = 0.6611745953559875
Iteration [6222]: Loss = 0.6612651944160461
Iteration [6223]: Loss = 5.1576008796691895
Iteration [6224]: Loss = 0.6615113615989685
Iteration [6225]: Loss = 0.6616572141647339
Iteration [6226]: Loss = 0.6617647409439087
Iteration [6227]: Loss = 0.6618375778198242
Iteration [6228]: Loss = 0.6618791818618774
Iteration [6229]: Loss = 0.661892831325531
Iteration [6230]: Loss = 0.6618810296058655
Iteration [6231]: Loss = 0.6618465781211853
Iteration [6232]: Loss = 0.6617915630340576
Iteration [6233]: Loss = 0.66171795129776
Iteration [6234]: Loss = 0.6616278886795044
Iteration [6235]: Loss = 0.6615227460861206
Iteration [6236]: Loss = 0.6614039540290833
Iteration [6237]: Loss = 0.6612731218338013
Iteration [6238]: Loss = 0.6611313819885254
Iteration [6239]: Loss = 0.6609798073768616
Iteration [6240]: Loss = 0.6608193516731262
Iteration [6241]: Loss = 0.6606507301330566
Iteration [6242]: Loss = 0.6604751348495483
Iteration [6243]: Loss = 0.6602931618690491
Iteration [6244]: Loss = 0.6601051092147827
Iteration [6245]: Loss = 0.6599120497703552
Iteration [6246]: Loss = 0.6597141623497009
Iteration [6247]: Loss = 0.6595120429992676
Iteration [6248]: Loss = 0.6593061089515686
Iteration [6249]: Loss = 0.659096896648407
Iteration [6250]: Loss = 0.6588843464851379
Iteration [6251]: Loss = 0.6586692333221436
Iteration [6252]: Loss = 0.6584516167640686
Iteration [6253]: Loss = 0.6582317352294922
Iteration [6254]: Loss = 0.6580097675323486
Iteration [6255]: Loss = 0.6577861905097961
Iteration [6256]: Loss = 0.6575607061386108
Iteration [6257]: Loss = 0.6573339700698853
Iteration [6258]: Loss = 0.6571059823036194
Iteration [6259]: Loss = 0.6568766236305237
Iteration [6260]: Loss = 0.6566462516784668
Iteration [6261]: Loss = 5.1858906745910645
Iteration [6262]: Loss = 0.6563459038734436
Iteration [6263]: Loss = 0.6562598943710327
Iteration [6264]: Loss = 0.6561583876609802
Iteration [6265]: Loss = 5.188048839569092
Iteration [6266]: Loss = 5.187845230102539
Iteration [6267]: Loss = 0.6562474370002747
Iteration [6268]: Loss = 0.6563761234283447
Iteration [6269]: Loss = 0.6564682722091675
Iteration [6270]: Loss = 0.6565273404121399
Iteration [6271]: Loss = 0.6565566658973694
Iteration [6272]: Loss = 0.6565592885017395
Iteration [6273]: Loss = 0.6565375924110413
Iteration [6274]: Loss = 0.6564942598342896
Iteration [6275]: Loss = 0.6564314961433411
Iteration [6276]: Loss = 0.6563509702682495
Iteration [6277]: Loss = 0.6562545299530029
Iteration [6278]: Loss = 0.6561439037322998
Iteration [6279]: Loss = 0.6560204029083252
Iteration [6280]: Loss = 0.6558852791786194
Iteration [6281]: Loss = 5.189809322357178
Iteration [6282]: Loss = 0.6557475328445435
Iteration [6283]: Loss = 5.18986177444458
Iteration [6284]: Loss = 0.6558540463447571
Iteration [6285]: Loss = 0.6559411287307739
Iteration [6286]: Loss = 5.188323497772217
Iteration [6287]: Loss = 0.6561828255653381
Iteration [6288]: Loss = 0.6563275456428528
Iteration [6289]: Loss = 0.6564339995384216
Iteration [6290]: Loss = 0.6565061211585999
Iteration [6291]: Loss = 0.6565470695495605
Iteration [6292]: Loss = 0.6565600633621216
Iteration [6293]: Loss = 0.6565479636192322
Iteration [6294]: Loss = 5.185320854187012
Iteration [6295]: Loss = 0.6566202044487
Iteration [6296]: Loss = 0.6566926836967468
Iteration [6297]: Loss = 5.184042453765869
Iteration [6298]: Loss = 0.6569090485572815
Iteration [6299]: Loss = 0.6570429801940918
Iteration [6300]: Loss = 0.6571397185325623
Iteration [6301]: Loss = 0.6572028398513794
Iteration [6302]: Loss = 0.6572359800338745
Iteration [6303]: Loss = 0.657241702079773
Iteration [6304]: Loss = 0.6572231650352478
Iteration [6305]: Loss = 0.6571823954582214
Iteration [6306]: Loss = 0.6571218967437744
Iteration [6307]: Loss = 0.65704345703125
Iteration [6308]: Loss = 0.6569489240646362
Iteration [6309]: Loss = 0.6568397283554077
Iteration [6310]: Loss = 0.6567175984382629
Iteration [6311]: Loss = 0.6565837860107422
Iteration [6312]: Loss = 0.6564393043518066
Iteration [6313]: Loss = 0.656285285949707
Iteration [6314]: Loss = 0.6561225652694702
Iteration [6315]: Loss = 0.6559523344039917
Iteration [6316]: Loss = 0.6557750701904297
Iteration [6317]: Loss = 5.190669536590576
Iteration [6318]: Loss = 5.190821647644043
Iteration [6319]: Loss = 0.6556807160377502
Iteration [6320]: Loss = 0.6557605266571045
Iteration [6321]: Loss = 0.6558085083961487
Iteration [6322]: Loss = 0.6558278799057007
Iteration [6323]: Loss = 14.25636100769043
Iteration [6324]: Loss = 0.6562665104866028
Iteration [6325]: Loss = 0.6566439867019653
Iteration [6326]: Loss = 0.6569608449935913
Iteration [6327]: Loss = 5.181210994720459
Iteration [6328]: Loss = 0.6575928926467896
Iteration [6329]: Loss = 9.696653366088867
Iteration [6330]: Loss = 0.6584684252738953
Iteration [6331]: Loss = 0.6589546799659729
Iteration [6332]: Loss = 0.6593695878982544
Iteration [6333]: Loss = 0.659720242023468
Iteration [6334]: Loss = 0.6600128412246704
Iteration [6335]: Loss = 0.6602532863616943
Iteration [6336]: Loss = 0.6604464650154114
Iteration [6337]: Loss = 0.6605972647666931
Iteration [6338]: Loss = 5.161116600036621
Iteration [6339]: Loss = 0.6609441637992859
Iteration [6340]: Loss = 0.6611320376396179
Iteration [6341]: Loss = 0.6612778306007385
Iteration [6342]: Loss = 0.6613860130310059
Iteration [6343]: Loss = 0.6614599227905273
Iteration [6344]: Loss = 0.6615033149719238
Iteration [6345]: Loss = 0.6615190505981445
Iteration [6346]: Loss = 0.6615097522735596
Iteration [6347]: Loss = 0.6614781618118286
Iteration [6348]: Loss = 0.6614261865615845
Iteration [6349]: Loss = 0.6613561511039734
Iteration [6350]: Loss = 0.6612697243690491
Iteration [6351]: Loss = 0.6611684560775757
Iteration [6352]: Loss = 5.159142017364502
Iteration [6353]: Loss = 0.6610848903656006
Iteration [6354]: Loss = 0.6610894799232483
Iteration [6355]: Loss = 0.6610701084136963
Iteration [6356]: Loss = 0.6610294580459595
Iteration [6357]: Loss = 0.6609694361686707
Iteration [6358]: Loss = 0.6608918905258179
Iteration [6359]: Loss = 0.6607989072799683
Iteration [6360]: Loss = 0.6606917977333069
Iteration [6361]: Loss = 0.6605718731880188
Iteration [6362]: Loss = 0.6604405641555786
Iteration [6363]: Loss = 0.6602989435195923
Iteration [6364]: Loss = 0.6601481437683105
Iteration [6365]: Loss = 0.6599889397621155
Iteration [6366]: Loss = 0.6598221659660339
Iteration [6367]: Loss = 0.6596488356590271
Iteration [6368]: Loss = 0.6594692468643188
Iteration [6369]: Loss = 0.659284234046936
Iteration [6370]: Loss = 0.6590943336486816
Iteration [6371]: Loss = 0.6589000225067139
Iteration [6372]: Loss = 0.6587016582489014
Iteration [6373]: Loss = 0.6584997773170471
Iteration [6374]: Loss = 0.6582946181297302
Iteration [6375]: Loss = 0.6580865979194641
Iteration [6376]: Loss = 0.6578760743141174
Iteration [6377]: Loss = 0.6576629877090454
Iteration [6378]: Loss = 0.6574478149414062
Iteration [6379]: Loss = 5.181164264678955
Iteration [6380]: Loss = 5.181510925292969
Iteration [6381]: Loss = 0.65725177526474
Iteration [6382]: Loss = 0.6573013067245483
Iteration [6383]: Loss = 0.6573225855827332
Iteration [6384]: Loss = 5.180658340454102
Iteration [6385]: Loss = 0.6574492454528809
Iteration [6386]: Loss = 0.6575437784194946
Iteration [6387]: Loss = 0.6576055288314819
Iteration [6388]: Loss = 0.6576380133628845
Iteration [6389]: Loss = 0.6576437950134277
Iteration [6390]: Loss = 0.6576257944107056
Iteration [6391]: Loss = 0.6575861573219299
Iteration [6392]: Loss = 0.6575272083282471
Iteration [6393]: Loss = 5.179892063140869
Iteration [6394]: Loss = 5.17950963973999
Iteration [6395]: Loss = 0.657710611820221
Iteration [6396]: Loss = 0.6578617691993713
Iteration [6397]: Loss = 0.6579746603965759
Iteration [6398]: Loss = 0.6580529808998108
Iteration [6399]: Loss = 0.6581003069877625
Iteration [6400]: Loss = 0.6581195592880249
Iteration [6401]: Loss = 0.6581134796142578
Iteration [6402]: Loss = 0.6580847501754761
Iteration [6403]: Loss = 0.6580354571342468
Iteration [6404]: Loss = 5.176903247833252
Iteration [6405]: Loss = 0.6580416560173035
Iteration [6406]: Loss = 0.6580847501754761
Iteration [6407]: Loss = 0.6581003069877625
Iteration [6408]: Loss = 0.6580908894538879
Iteration [6409]: Loss = 0.6580592393875122
Iteration [6410]: Loss = 5.176676273345947
Iteration [6411]: Loss = 0.6580951809883118
Iteration [6412]: Loss = 0.6581510305404663
Iteration [6413]: Loss = 0.6581780314445496
Iteration [6414]: Loss = 0.658178985118866
Iteration [6415]: Loss = 0.6581563949584961
Iteration [6416]: Loss = 0.6581128239631653
Iteration [6417]: Loss = 5.176428318023682
Iteration [6418]: Loss = 0.658128559589386
Iteration [6419]: Loss = 0.6581758856773376
Iteration [6420]: Loss = 0.6581951379776001
Iteration [6421]: Loss = 0.658189058303833
Iteration [6422]: Loss = 0.6581602096557617
Iteration [6423]: Loss = 0.6581109166145325
Iteration [6424]: Loss = 0.6580431461334229
Iteration [6425]: Loss = 0.6579586267471313
Iteration [6426]: Loss = 0.6578593850135803
Iteration [6427]: Loss = 0.657746434211731
Iteration [6428]: Loss = 0.6576213836669922
Iteration [6429]: Loss = 9.701898574829102
Iteration [6430]: Loss = 0.6576551198959351
Iteration [6431]: Loss = 0.6577848196029663
Iteration [6432]: Loss = 0.6578783392906189
Iteration [6433]: Loss = 0.6579395532608032
Iteration [6434]: Loss = 0.6579714417457581
Iteration [6435]: Loss = 0.6579768657684326
Iteration [6436]: Loss = 0.6579586267471313
Iteration [6437]: Loss = 0.6579189300537109
Iteration [6438]: Loss = 0.6578599810600281
Iteration [6439]: Loss = 0.6577836275100708
Iteration [6440]: Loss = 0.6576916575431824
Iteration [6441]: Loss = 0.657585620880127
Iteration [6442]: Loss = 0.6574669480323792
Iteration [6443]: Loss = 0.6573367714881897
Iteration [6444]: Loss = 0.6571963429450989
Iteration [6445]: Loss = 0.6570467352867126
Iteration [6446]: Loss = 0.6568887829780579
Iteration [6447]: Loss = 0.6567233800888062
Iteration [6448]: Loss = 0.65655118227005
Iteration [6449]: Loss = 0.6563729047775269
Iteration [6450]: Loss = 0.6561890840530396
Iteration [6451]: Loss = 0.6560004353523254
Iteration [6452]: Loss = 0.6558072566986084
Iteration [6453]: Loss = 0.6556103229522705
Iteration [6454]: Loss = 0.6554096341133118
Iteration [6455]: Loss = 0.6552057266235352
Iteration [6456]: Loss = 0.6549990177154541
Iteration [6457]: Loss = 0.6547895669937134
Iteration [6458]: Loss = 0.654577910900116
Iteration [6459]: Loss = 0.6543641090393066
Iteration [6460]: Loss = 5.199069023132324
Iteration [6461]: Loss = 0.6540899872779846
Iteration [6462]: Loss = 0.6540141105651855
Iteration [6463]: Loss = 0.6539224982261658
Iteration [6464]: Loss = 0.6538169980049133
Iteration [6465]: Loss = 0.653698742389679
Iteration [6466]: Loss = 0.6535689830780029
Iteration [6467]: Loss = 5.203266620635986
Iteration [6468]: Loss = 0.6534386277198792
Iteration [6469]: Loss = 0.6534242033958435
Iteration [6470]: Loss = 0.6533879041671753
Iteration [6471]: Loss = 0.653331995010376
Iteration [6472]: Loss = 5.204263210296631
Iteration [6473]: Loss = 0.6533277630805969
Iteration [6474]: Loss = 0.6533669233322144
Iteration [6475]: Loss = 0.6533790230751038
Iteration [6476]: Loss = 0.65336674451828
Iteration [6477]: Loss = 0.6533324122428894
Iteration [6478]: Loss = 0.6532784700393677
Iteration [6479]: Loss = 0.6532066464424133
Iteration [6480]: Loss = 0.653118908405304
Iteration [6481]: Loss = 0.6530164480209351
Iteration [6482]: Loss = 5.206351280212402
Iteration [6483]: Loss = 5.206164836883545
Iteration [6484]: Loss = 5.205208778381348
Iteration [6485]: Loss = 0.6533787250518799
Iteration [6486]: Loss = 0.653609573841095
Iteration [6487]: Loss = 5.201134204864502
Iteration [6488]: Loss = 5.1993818283081055
Iteration [6489]: Loss = 0.6544994115829468
Iteration [6490]: Loss = 0.6548406481742859
Iteration [6491]: Loss = 0.6551249027252197
Iteration [6492]: Loss = 5.192028045654297
Iteration [6493]: Loss = 0.6557014584541321
Iteration [6494]: Loss = 9.72075080871582
Iteration [6495]: Loss = 5.185217380523682
Iteration [6496]: Loss = 0.6571520566940308
Iteration [6497]: Loss = 0.6576886177062988
Iteration [6498]: Loss = 0.6581491231918335
Iteration [6499]: Loss = 0.6585409641265869
Iteration [6500]: Loss = 0.6588708162307739
Iteration [6501]: Loss = 0.6591449975967407
Iteration [6502]: Loss = 0.6593687534332275
Iteration [6503]: Loss = 0.6595472097396851
Iteration [6504]: Loss = 5.167006015777588
Iteration [6505]: Loss = 0.6599411964416504
Iteration [6506]: Loss = 0.6601489782333374
Iteration [6507]: Loss = 0.6603129506111145
Iteration [6508]: Loss = 5.1626787185668945
Iteration [6509]: Loss = 0.6606822609901428
Iteration [6510]: Loss = 0.660879373550415
Iteration [6511]: Loss = 0.6610338091850281
Iteration [6512]: Loss = 0.6611496210098267
Iteration [6513]: Loss = 0.6612308025360107
Iteration [6514]: Loss = 0.6612806916236877
Iteration [6515]: Loss = 5.157717704772949
Iteration [6516]: Loss = 5.1568450927734375
Iteration [6517]: Loss = 5.155303955078125
Iteration [6518]: Loss = 0.6620981693267822
Iteration [6519]: Loss = 0.6624119877815247
Iteration [6520]: Loss = 0.6626716256141663
Iteration [6521]: Loss = 0.662882387638092
Iteration [6522]: Loss = 5.147731304168701
Iteration [6523]: Loss = 0.6633305549621582
Iteration [6524]: Loss = 0.663561224937439
Iteration [6525]: Loss = 0.6637457013130188
Iteration [6526]: Loss = 0.6638885736465454
Iteration [6527]: Loss = 0.6639940738677979
Iteration [6528]: Loss = 0.6640657782554626
Iteration [6529]: Loss = 0.6641069650650024
Iteration [6530]: Loss = 0.6641208529472351
Iteration [6531]: Loss = 0.6641099452972412
Iteration [6532]: Loss = 0.6640768647193909
Iteration [6533]: Loss = 5.142173767089844
Iteration [6534]: Loss = 0.6641086339950562
Iteration [6535]: Loss = 0.6641616225242615
Iteration [6536]: Loss = 0.6641860604286194
Iteration [6537]: Loss = 0.6641849875450134
Iteration [6538]: Loss = 0.664160430431366
Iteration [6539]: Loss = 0.6641150712966919
Iteration [6540]: Loss = 0.664050817489624
Iteration [6541]: Loss = 5.142481803894043
Iteration [6542]: Loss = 0.6640294790267944
Iteration [6543]: Loss = 0.6640599966049194
Iteration [6544]: Loss = 0.6640642881393433
Iteration [6545]: Loss = 0.6640445590019226
Iteration [6546]: Loss = 5.142288684844971
Iteration [6547]: Loss = 0.6640994548797607
Iteration [6548]: Loss = 0.6641623973846436
Iteration [6549]: Loss = 0.6641958951950073
Iteration [6550]: Loss = 0.6642024517059326
Iteration [6551]: Loss = 0.6641852259635925
Iteration [6552]: Loss = 0.664146363735199
Iteration [6553]: Loss = 0.6640878915786743
Iteration [6554]: Loss = 0.6640119552612305
Iteration [6555]: Loss = 0.6639202237129211
Iteration [6556]: Loss = 0.6638142466545105
Iteration [6557]: Loss = 0.6636954545974731
Iteration [6558]: Loss = 0.6635651588439941
Iteration [6559]: Loss = 0.6634243726730347
Iteration [6560]: Loss = 9.629613876342773
Iteration [6561]: Loss = 0.6634275913238525
Iteration [6562]: Loss = 0.6635425686836243
Iteration [6563]: Loss = 0.6636229753494263
Iteration [6564]: Loss = 0.6636722087860107
Iteration [6565]: Loss = 0.6636931896209717
Iteration [6566]: Loss = 0.6636890172958374
Iteration [6567]: Loss = 0.6636620759963989
Iteration [6568]: Loss = 0.6636144518852234
Iteration [6569]: Loss = 0.663548469543457
Iteration [6570]: Loss = 0.6634659767150879
Iteration [6571]: Loss = 5.145909309387207
Iteration [6572]: Loss = 0.663412868976593
Iteration [6573]: Loss = 5.145558834075928
Iteration [6574]: Loss = 5.144720077514648
Iteration [6575]: Loss = 0.663840651512146
Iteration [6576]: Loss = 0.6640552878379822
Iteration [6577]: Loss = 0.6642253398895264
Iteration [6578]: Loss = 0.6643553376197815
Iteration [6579]: Loss = 0.6644492149353027
Iteration [6580]: Loss = 5.139404773712158
Iteration [6581]: Loss = 5.138341903686523
Iteration [6582]: Loss = 0.6649968028068542
Iteration [6583]: Loss = 5.135240077972412
Iteration [6584]: Loss = 0.6663831472396851
Iteration [6585]: Loss = 0.6666773557662964
Iteration [6586]: Loss = 0.6669192910194397
Iteration [6587]: Loss = 5.1246466636657715
Iteration [6588]: Loss = 0.6674199104309082
Iteration [6589]: Loss = 0.667672336101532
Iteration [6590]: Loss = 0.6678764224052429
Iteration [6591]: Loss = 0.6680369973182678
Iteration [6592]: Loss = 0.6681581139564514
Iteration [6593]: Loss = 0.6682440042495728
Iteration [6594]: Loss = 0.6682978868484497
Iteration [6595]: Loss = 0.6683230400085449
Iteration [6596]: Loss = 5.117826461791992
Iteration [6597]: Loss = 0.6684533357620239
Iteration [6598]: Loss = 0.6685477495193481
Iteration [6599]: Loss = 0.6686094403266907
Iteration [6600]: Loss = 0.6686416864395142
Iteration [6601]: Loss = 0.668647289276123
Iteration [6602]: Loss = 0.6686288714408875
Iteration [6603]: Loss = 5.1163249015808105
Iteration [6604]: Loss = 0.6686846613883972
Iteration [6605]: Loss = 0.6687475442886353
Iteration [6606]: Loss = 0.6687805652618408
Iteration [6607]: Loss = 0.6687870621681213
Iteration [6608]: Loss = 0.6687694191932678
Iteration [6609]: Loss = 0.6687300801277161
Iteration [6610]: Loss = 0.6686713099479675
Iteration [6611]: Loss = 5.116291522979736
Iteration [6612]: Loss = 0.6686581373214722
Iteration [6613]: Loss = 0.6686915159225464
Iteration [6614]: Loss = 0.6686981320381165
Iteration [6615]: Loss = 5.115808963775635
Iteration [6616]: Loss = 0.6687966585159302
Iteration [6617]: Loss = 0.6688777208328247
Iteration [6618]: Loss = 5.114421367645264
Iteration [6619]: Loss = 0.6691033840179443
Iteration [6620]: Loss = 0.6692385673522949
Iteration [6621]: Loss = 5.112117767333984
Iteration [6622]: Loss = 0.6695564985275269
Iteration [6623]: Loss = 0.6697310209274292
Iteration [6624]: Loss = 0.6698647141456604
Iteration [6625]: Loss = 0.66996169090271
Iteration [6626]: Loss = 0.6700254678726196
Iteration [6627]: Loss = 0.6700595021247864
Iteration [6628]: Loss = 0.6700667142868042
Iteration [6629]: Loss = 9.546178817749023
Iteration [6630]: Loss = 0.670318603515625
Iteration [6631]: Loss = 0.6705376505851746
Iteration [6632]: Loss = 0.6707114577293396
Iteration [6633]: Loss = 0.6708446741104126
Iteration [6634]: Loss = 0.6709413528442383
Iteration [6635]: Loss = 0.6710050702095032
Iteration [6636]: Loss = 0.6710391640663147
Iteration [6637]: Loss = 0.6710464954376221
Iteration [6638]: Loss = 5.102621555328369
Iteration [6639]: Loss = 0.6711452603340149
Iteration [6640]: Loss = 0.6712258458137512
Iteration [6641]: Loss = 0.6712750792503357
Iteration [6642]: Loss = 5.10113000869751
Iteration [6643]: Loss = 0.6714455485343933
Iteration [6644]: Loss = 5.099672317504883
Iteration [6645]: Loss = 0.6717872619628906
Iteration [6646]: Loss = 0.6719713807106018
Iteration [6647]: Loss = 0.6721137762069702
Iteration [6648]: Loss = 0.6722186803817749
Iteration [6649]: Loss = 0.6722898483276367
Iteration [6650]: Loss = 0.6723303198814392
Iteration [6651]: Loss = 0.6723433136940002
Iteration [6652]: Loss = 0.672331690788269
Iteration [6653]: Loss = 5.0955328941345215
Iteration [6654]: Loss = 0.6723979711532593
Iteration [6655]: Loss = 0.6724646091461182
Iteration [6656]: Loss = 0.6725013256072998
Iteration [6657]: Loss = 0.6725109815597534
Iteration [6658]: Loss = 0.6724960803985596
Iteration [6659]: Loss = 0.6724592447280884
Iteration [6660]: Loss = 0.6724026203155518
Iteration [6661]: Loss = 5.095363140106201
Iteration [6662]: Loss = 5.095006465911865
Iteration [6663]: Loss = 0.6725800633430481
Iteration [6664]: Loss = 0.672726035118103
Iteration [6665]: Loss = 0.6728339195251465
Iteration [6666]: Loss = 5.092130661010742
Iteration [6667]: Loss = 0.6731044054031372
Iteration [6668]: Loss = 0.6732582449913025
Iteration [6669]: Loss = 0.6733733415603638
Iteration [6670]: Loss = 0.6734534502029419
Iteration [6671]: Loss = 0.6735020875930786
Iteration [6672]: Loss = 0.673522412776947
Iteration [6673]: Loss = 0.6735170483589172
Iteration [6674]: Loss = 0.6734889149665833
Iteration [6675]: Loss = 0.6734398603439331
Iteration [6676]: Loss = 0.6733721494674683
Iteration [6677]: Loss = 0.6732877492904663
Iteration [6678]: Loss = 0.6731881499290466
Iteration [6679]: Loss = 0.6730750203132629
Iteration [6680]: Loss = 0.672949492931366
Iteration [6681]: Loss = 5.092658996582031
Iteration [6682]: Loss = 0.6728214621543884
Iteration [6683]: Loss = 0.6728056073188782
Iteration [6684]: Loss = 0.672767698764801
Iteration [6685]: Loss = 0.672710120677948
Iteration [6686]: Loss = 0.6726346015930176
Iteration [6687]: Loss = 0.6725432276725769
Iteration [6688]: Loss = 0.6724373698234558
Iteration [6689]: Loss = 0.6723185181617737
Iteration [6690]: Loss = 0.6721880435943604
Iteration [6691]: Loss = 0.6720467805862427
Iteration [6692]: Loss = 0.6718962788581848
Iteration [6693]: Loss = 0.6717371940612793
Iteration [6694]: Loss = 0.6715704202651978
Iteration [6695]: Loss = 0.671396791934967
Iteration [6696]: Loss = 0.6712169051170349
Iteration [6697]: Loss = 5.102611064910889
Iteration [6698]: Loss = 0.6709964275360107
Iteration [6699]: Loss = 0.6709413528442383
Iteration [6700]: Loss = 0.6708683371543884
Iteration [6701]: Loss = 0.6707789897918701
Iteration [6702]: Loss = 0.6706752181053162
Iteration [6703]: Loss = 0.6705581545829773
Iteration [6704]: Loss = 0.6704292297363281
Iteration [6705]: Loss = 0.6702895760536194
Iteration [6706]: Loss = 0.6701403856277466
Iteration [6707]: Loss = 0.6699826121330261
Iteration [6708]: Loss = 0.6698172092437744
Iteration [6709]: Loss = 0.6696444153785706
Iteration [6710]: Loss = 0.6694656014442444
Iteration [6711]: Loss = 0.6692811250686646
Iteration [6712]: Loss = 0.6690915822982788
Iteration [6713]: Loss = 0.6688973903656006
Iteration [6714]: Loss = 0.6686990261077881
Iteration [6715]: Loss = 0.6684969663619995
Iteration [6716]: Loss = 0.6682917475700378
Iteration [6717]: Loss = 0.6680832505226135
Iteration [6718]: Loss = 0.6678722500801086
Iteration [6719]: Loss = 5.121569633483887
Iteration [6720]: Loss = 0.6675993800163269
Iteration [6721]: Loss = 0.6675224304199219
Iteration [6722]: Loss = 0.6674296855926514
Iteration [6723]: Loss = 0.6673227548599243
Iteration [6724]: Loss = 5.124142646789551
Iteration [6725]: Loss = 0.6672278046607971
Iteration [6726]: Loss = 0.6672266721725464
Iteration [6727]: Loss = 5.124148368835449
Iteration [6728]: Loss = 0.6673122048377991
Iteration [6729]: Loss = 0.6673880219459534
Iteration [6730]: Loss = 0.667432963848114
Iteration [6731]: Loss = 0.6674498915672302
Iteration [6732]: Loss = 0.6674416065216064
Iteration [6733]: Loss = 0.6674108505249023
Iteration [6734]: Loss = 0.6673595309257507
Iteration [6735]: Loss = 0.6672900915145874
Iteration [6736]: Loss = 0.667203962802887
Iteration [6737]: Loss = 0.6671029329299927
Iteration [6738]: Loss = 0.6669886112213135
Iteration [6739]: Loss = 0.6668621301651001
Iteration [6740]: Loss = 0.6667248010635376
Iteration [6741]: Loss = 0.6665777564048767
Iteration [6742]: Loss = 0.6664218902587891
Iteration [6743]: Loss = 0.6662581562995911
Iteration [6744]: Loss = 5.130455493927002
Iteration [6745]: Loss = 0.6660663485527039
Iteration [6746]: Loss = 0.6660242080688477
Iteration [6747]: Loss = 0.665962815284729
Iteration [6748]: Loss = 0.6658840179443359
Iteration [6749]: Loss = 0.6657897233963013
Iteration [6750]: Loss = 0.6656813621520996
Iteration [6751]: Loss = 5.13344144821167
Iteration [6752]: Loss = 0.66558438539505
Iteration [6753]: Loss = 0.6655826568603516
Iteration [6754]: Loss = 0.6655575633049011
Iteration [6755]: Loss = 0.6655117869377136
Iteration [6756]: Loss = 0.6654468774795532
Iteration [6757]: Loss = 0.6653650999069214
Iteration [6758]: Loss = 0.6652680039405823
Iteration [6759]: Loss = 0.6651572585105896
Iteration [6760]: Loss = 0.6650339365005493
Iteration [6761]: Loss = 5.13719367980957
Iteration [6762]: Loss = 0.6649117469787598
Iteration [6763]: Loss = 5.137194633483887
Iteration [6764]: Loss = 0.6650210618972778
Iteration [6765]: Loss = 0.665107250213623
Iteration [6766]: Loss = 5.135705947875977
Iteration [6767]: Loss = 0.6653426885604858
Iteration [6768]: Loss = 5.133882999420166
Iteration [6769]: Loss = 0.6657408475875854
Iteration [6770]: Loss = 0.6659500598907471
Iteration [6771]: Loss = 0.6661149263381958
Iteration [6772]: Loss = 0.6662400960922241
Iteration [6773]: Loss = 0.6663293838500977
Iteration [6774]: Loss = 0.6663863062858582
Iteration [6775]: Loss = 0.6664141416549683
Iteration [6776]: Loss = 0.6664157509803772
Iteration [6777]: Loss = 0.6663935780525208
Iteration [6778]: Loss = 5.128965854644775
Iteration [6779]: Loss = 0.666443943977356
Iteration [6780]: Loss = 0.666504979133606
Iteration [6781]: Loss = 0.6665363907814026
Iteration [6782]: Loss = 0.6665412187576294
Iteration [6783]: Loss = 0.6665221452713013
Iteration [6784]: Loss = 5.128223419189453
Iteration [6785]: Loss = 5.127679824829102
Iteration [6786]: Loss = 0.6667962670326233
Iteration [6787]: Loss = 0.6669701933860779
Iteration [6788]: Loss = 0.667103111743927
Iteration [6789]: Loss = 0.6671993732452393
Iteration [6790]: Loss = 0.6672624349594116
Iteration [6791]: Loss = 0.6672958731651306
Iteration [6792]: Loss = 0.6673024892807007
Iteration [6793]: Loss = 0.6672848463058472
Iteration [6794]: Loss = 0.6672453880310059
Iteration [6795]: Loss = 0.6671863794326782
Iteration [6796]: Loss = 0.6671096086502075
Iteration [6797]: Loss = 0.6670170426368713
Iteration [6798]: Loss = 5.125798225402832
Iteration [6799]: Loss = 0.6669469475746155
Iteration [6800]: Loss = 0.6669567227363586
Iteration [6801]: Loss = 0.6669418215751648
Iteration [6802]: Loss = 0.6669050455093384
Iteration [6803]: Loss = 0.6668482422828674
Iteration [6804]: Loss = 0.6667735576629639
Iteration [6805]: Loss = 0.666682779788971
Iteration [6806]: Loss = 0.6665775179862976
Iteration [6807]: Loss = 0.6664592623710632
Iteration [6808]: Loss = 5.129085540771484
Iteration [6809]: Loss = 0.6663454174995422
Iteration [6810]: Loss = 0.6663365364074707
Iteration [6811]: Loss = 0.6663050055503845
Iteration [6812]: Loss = 0.6662532091140747
Iteration [6813]: Loss = 0.666182816028595
Iteration [6814]: Loss = 5.130405902862549
Iteration [6815]: Loss = 0.6661511659622192
Iteration [6816]: Loss = 5.129945755004883
Iteration [6817]: Loss = 0.666333794593811
Iteration [6818]: Loss = 0.6664511561393738
Iteration [6819]: Loss = 0.666533350944519
Iteration [6820]: Loss = 5.127643585205078
Iteration [6821]: Loss = 0.666762113571167
Iteration [6822]: Loss = 0.6668990254402161
Iteration [6823]: Loss = 5.125296592712402
Iteration [6824]: Loss = 0.6672214865684509
Iteration [6825]: Loss = 0.6673983335494995
Iteration [6826]: Loss = 0.6675340533256531
Iteration [6827]: Loss = 0.6676328182220459
Iteration [6828]: Loss = 0.6676980257034302
Iteration [6829]: Loss = 0.6677332520484924
Iteration [6830]: Loss = 5.121102809906006
Iteration [6831]: Loss = 0.6678816676139832
Iteration [6832]: Loss = 0.6679843068122864
Iteration [6833]: Loss = 0.6680530905723572
Iteration [6834]: Loss = 0.6680915355682373
Iteration [6835]: Loss = 0.6681025624275208
Iteration [6836]: Loss = 0.6680889129638672
Iteration [6837]: Loss = 5.1193461418151855
Iteration [6838]: Loss = 5.11877965927124
Iteration [6839]: Loss = 0.6683765649795532
Iteration [6840]: Loss = 5.116522789001465
Iteration [6841]: Loss = 0.6688457727432251
Iteration [6842]: Loss = 0.6690852046012878
Iteration [6843]: Loss = 0.6692771315574646
Iteration [6844]: Loss = 0.6694265007972717
Iteration [6845]: Loss = 0.6695372462272644
Iteration [6846]: Loss = 0.6696134209632874
Iteration [6847]: Loss = 0.6696584224700928
Iteration [6848]: Loss = 0.6696751713752747
Iteration [6849]: Loss = 0.6696666479110718
Iteration [6850]: Loss = 0.6696351170539856
Iteration [6851]: Loss = 0.6695832014083862
Iteration [6852]: Loss = 5.1111297607421875
Iteration [6853]: Loss = 0.6695823073387146
Iteration [6854]: Loss = 0.6696212291717529
Iteration [6855]: Loss = 0.6696326732635498
Iteration [6856]: Loss = 0.6696193814277649
Iteration [6857]: Loss = 0.6695835590362549
Iteration [6858]: Loss = 0.6695276498794556
Iteration [6859]: Loss = 0.6694536805152893
Iteration [6860]: Loss = 0.6693631410598755
Iteration [6861]: Loss = 0.6692580580711365
Iteration [6862]: Loss = 5.113225936889648
Iteration [6863]: Loss = 0.6691665649414062
Iteration [6864]: Loss = 0.6691671013832092
Iteration [6865]: Loss = 5.113202095031738
Iteration [6866]: Loss = 0.6699532866477966
Iteration [6867]: Loss = 0.670030415058136
Iteration [6868]: Loss = 0.6700761914253235
Iteration [6869]: Loss = 0.6700936555862427
Iteration [6870]: Loss = 0.6700855493545532
Iteration [6871]: Loss = 5.108087539672852
Iteration [6872]: Loss = 0.6701597571372986
Iteration [6873]: Loss = 0.6702307462692261
Iteration [6874]: Loss = 0.6702710390090942
Iteration [6875]: Loss = 0.6702834963798523
Iteration [6876]: Loss = 5.106873035430908
Iteration [6877]: Loss = 0.670392632484436
Iteration [6878]: Loss = 0.6704786419868469
Iteration [6879]: Loss = 5.105407238006592
Iteration [6880]: Loss = 0.6707134246826172
Iteration [6881]: Loss = 0.6708527207374573
Iteration [6882]: Loss = 0.6709545254707336
Iteration [6883]: Loss = 0.6710224151611328
Iteration [6884]: Loss = 0.6710597276687622
Iteration [6885]: Loss = 0.6710695028305054
Iteration [6886]: Loss = 0.6710543632507324
Iteration [6887]: Loss = 0.6710171699523926
Iteration [6888]: Loss = 0.6709596514701843
Iteration [6889]: Loss = 0.6708841323852539
Iteration [6890]: Loss = 0.6707923412322998
Iteration [6891]: Loss = 0.6706856489181519
Iteration [6892]: Loss = 0.6705659031867981
Iteration [6893]: Loss = 9.541478157043457
Iteration [6894]: Loss = 0.6706051826477051
Iteration [6895]: Loss = 0.6707352995872498
Iteration [6896]: Loss = 5.1037445068359375
Iteration [6897]: Loss = 0.6710452437400818
Iteration [6898]: Loss = 5.10157585144043
Iteration [6899]: Loss = 0.6715021729469299
Iteration [6900]: Loss = 0.671735942363739
Iteration [6901]: Loss = 0.6719228625297546
Iteration [6902]: Loss = 0.6720675230026245
Iteration [6903]: Loss = 0.6721742153167725
Iteration [6904]: Loss = 0.6722464561462402
Iteration [6905]: Loss = 0.6722878217697144
Iteration [6906]: Loss = 0.6723014712333679
Iteration [6907]: Loss = 0.6722899675369263
Iteration [6908]: Loss = 0.6722558736801147
Iteration [6909]: Loss = 0.6722014546394348
Iteration [6910]: Loss = 0.6721287965774536
Iteration [6911]: Loss = 0.6720395088195801
Iteration [6912]: Loss = 5.097556114196777
Iteration [6913]: Loss = 0.671974241733551
Iteration [6914]: Loss = 0.6719856858253479
Iteration [6915]: Loss = 0.6719721555709839
Iteration [6916]: Loss = 0.6719361543655396
Iteration [6917]: Loss = 0.6718801259994507
Iteration [6918]: Loss = 0.6718057990074158
Iteration [6919]: Loss = 0.6717153191566467
Iteration [6920]: Loss = 0.6716098785400391
Iteration [6921]: Loss = 0.6714913845062256
Iteration [6922]: Loss = 0.6713609099388123
Iteration [6923]: Loss = 0.6712195873260498
Iteration [6924]: Loss = 0.6710687279701233
Iteration [6925]: Loss = 0.67090904712677
Iteration [6926]: Loss = 0.6707416772842407
Iteration [6927]: Loss = 5.1052117347717285
Iteration [6928]: Loss = 0.6705433130264282
Iteration [6929]: Loss = 0.6704981327056885
Iteration [6930]: Loss = 0.670433759689331
Iteration [6931]: Loss = 5.106417655944824
Iteration [6932]: Loss = 0.6704114675521851
Iteration [6933]: Loss = 9.541393280029297
Iteration [6934]: Loss = 0.6707540154457092
Iteration [6935]: Loss = 0.671012282371521
Iteration [6936]: Loss = 0.6712213754653931
Iteration [6937]: Loss = 0.671386182308197
Iteration [6938]: Loss = 0.671511173248291
Iteration [6939]: Loss = 0.6716000437736511
Iteration [6940]: Loss = 0.6716565489768982
Iteration [6941]: Loss = 0.6716839075088501
Iteration [6942]: Loss = 0.6716849207878113
Iteration [6943]: Loss = 0.6716621518135071
Iteration [6944]: Loss = 0.6716180443763733
Iteration [6945]: Loss = 0.6715547442436218
Iteration [6946]: Loss = 0.6714741587638855
Iteration [6947]: Loss = 0.671377956867218
Iteration [6948]: Loss = 5.10128927230835
Iteration [6949]: Loss = 5.101105690002441
Iteration [6950]: Loss = 0.6714618802070618
Iteration [6951]: Loss = 5.099523067474365
Iteration [6952]: Loss = 0.6718245148658752
Iteration [6953]: Loss = 0.6720178723335266
Iteration [6954]: Loss = 0.6721686124801636
Iteration [6955]: Loss = 5.095627784729004
Iteration [6956]: Loss = 0.6725127696990967
Iteration [6957]: Loss = 5.093297958374023
Iteration [6958]: Loss = 0.6729965806007385
Iteration [6959]: Loss = 0.6732413172721863
Iteration [6960]: Loss = 0.6734384298324585
Iteration [6961]: Loss = 0.6735921502113342
Iteration [6962]: Loss = 0.6737070083618164
Iteration [6963]: Loss = 0.6737866997718811
Iteration [6964]: Loss = 0.6738347411155701
Iteration [6965]: Loss = 0.673854410648346
Iteration [6966]: Loss = 0.6738483905792236
Iteration [6967]: Loss = 0.6738192439079285
Iteration [6968]: Loss = 0.6737692356109619
Iteration [6969]: Loss = 0.6737005710601807
Iteration [6970]: Loss = 0.6736149191856384
Iteration [6971]: Loss = 0.6735141277313232
Iteration [6972]: Loss = 0.6733995676040649
Iteration [6973]: Loss = 0.6732727289199829
Iteration [6974]: Loss = 0.6731348633766174
Iteration [6975]: Loss = 0.6729869246482849
Iteration [6976]: Loss = 0.6728299856185913
Iteration [6977]: Loss = 0.6726650595664978
Iteration [6978]: Loss = 0.6724928617477417
Iteration [6979]: Loss = 5.095442295074463
Iteration [6980]: Loss = 0.6722855567932129
Iteration [6981]: Loss = 0.6722363829612732
Iteration [6982]: Loss = 0.6721683740615845
Iteration [6983]: Loss = 5.096729278564453
Iteration [6984]: Loss = 0.6721392869949341
Iteration [6985]: Loss = 0.6721658706665039
Iteration [6986]: Loss = 5.096267223358154
Iteration [6987]: Loss = 5.095529079437256
Iteration [6988]: Loss = 0.6725489497184753
Iteration [6989]: Loss = 0.6727509498596191
Iteration [6990]: Loss = 0.6729093790054321
Iteration [6991]: Loss = 0.6730281710624695
Iteration [6992]: Loss = 0.673111617565155
Iteration [6993]: Loss = 0.6731630563735962
Iteration [6994]: Loss = 5.090582847595215
Iteration [6995]: Loss = 0.6733376383781433
Iteration [6996]: Loss = 0.6734510064125061
Iteration [6997]: Loss = 0.6735293865203857
Iteration [6998]: Loss = 5.088408946990967
Iteration [6999]: Loss = 0.6737500429153442
Iteration [7000]: Loss = 0.6738828420639038
Iteration [7001]: Loss = 0.6739788055419922
Iteration [7002]: Loss = 9.497600555419922
Iteration [7003]: Loss = 0.6743819713592529
Iteration [7004]: Loss = 5.08235502243042
Iteration [7005]: Loss = 0.6750504374504089
Iteration [7006]: Loss = 0.6753738522529602
Iteration [7007]: Loss = 0.6756415367126465
Iteration [7008]: Loss = 0.6758590936660767
Iteration [7009]: Loss = 0.6760313510894775
Iteration [7010]: Loss = 0.676162838935852
Iteration [7011]: Loss = 0.6762574911117554
Iteration [7012]: Loss = 0.6763191223144531
Iteration [7013]: Loss = 5.073018550872803
Iteration [7014]: Loss = 0.6765103936195374
Iteration [7015]: Loss = 0.6766300797462463
Iteration [7016]: Loss = 0.6767143607139587
Iteration [7017]: Loss = 0.6767663955688477
Iteration [7018]: Loss = 0.6767897605895996
Iteration [7019]: Loss = 0.6767868399620056
Iteration [7020]: Loss = 0.6767605543136597
Iteration [7021]: Loss = 0.6767131090164185
Iteration [7022]: Loss = 5.071384906768799
Iteration [7023]: Loss = 0.6767178773880005
Iteration [7024]: Loss = 0.6767582893371582
Iteration [7025]: Loss = 5.070697784423828
Iteration [7026]: Loss = 0.6769133806228638
Iteration [7027]: Loss = 5.0693359375
Iteration [7028]: Loss = 0.6772422194480896
Iteration [7029]: Loss = 0.6774209141731262
Iteration [7030]: Loss = 5.066357135772705
Iteration [7031]: Loss = 0.6778116822242737
Iteration [7032]: Loss = 0.6780165433883667
Iteration [7033]: Loss = 0.6781773567199707
Iteration [7034]: Loss = 0.6782984137535095
Iteration [7035]: Loss = 0.678383469581604
Iteration [7036]: Loss = 0.678436279296875
Iteration [7037]: Loss = 0.6784602403640747
Iteration [7038]: Loss = 0.6784577369689941
Iteration [7039]: Loss = 0.6784316897392273
Iteration [7040]: Loss = 0.67838454246521
Iteration [7041]: Loss = 0.6783181428909302
Iteration [7042]: Loss = 0.6782344579696655
Iteration [7043]: Loss = 0.6781352758407593
Iteration [7044]: Loss = 0.6780222654342651
Iteration [7045]: Loss = 0.6778965592384338
Iteration [7046]: Loss = 0.6777594089508057
Iteration [7047]: Loss = 0.6776121258735657
Iteration [7048]: Loss = 0.6774557828903198
Iteration [7049]: Loss = 0.6772910952568054
Iteration [7050]: Loss = 0.6771190166473389
Iteration [7051]: Loss = 5.069763660430908
Iteration [7052]: Loss = 0.6769111752510071
Iteration [7053]: Loss = 0.676861047744751
Iteration [7054]: Loss = 0.6767921447753906
Iteration [7055]: Loss = 0.6767063140869141
Iteration [7056]: Loss = 0.6766051650047302
Iteration [7057]: Loss = 0.676490306854248
Iteration [7058]: Loss = 0.6763630509376526
Iteration [7059]: Loss = 0.6762246489524841
Iteration [7060]: Loss = 0.6760764122009277
Iteration [7061]: Loss = 0.6759188175201416
Iteration [7062]: Loss = 0.6757532358169556
Iteration [7063]: Loss = 0.6755803823471069
Iteration [7064]: Loss = 5.07827615737915
Iteration [7065]: Loss = 0.6753714680671692
Iteration [7066]: Loss = 0.6753212213516235
Iteration [7067]: Loss = 0.6752521991729736
Iteration [7068]: Loss = 0.6751662492752075
Iteration [7069]: Loss = 0.6750649809837341
Iteration [7070]: Loss = 0.6749500632286072
Iteration [7071]: Loss = 0.6748228073120117
Iteration [7072]: Loss = 0.6746843457221985
Iteration [7073]: Loss = 0.6745361089706421
Iteration [7074]: Loss = 0.6743786334991455
Iteration [7075]: Loss = 0.6742131114006042
Iteration [7076]: Loss = 0.6740403175354004
Iteration [7077]: Loss = 0.673861026763916
Iteration [7078]: Loss = 5.08785343170166
Iteration [7079]: Loss = 0.6736416816711426
Iteration [7080]: Loss = 0.6735870838165283
Iteration [7081]: Loss = 0.6735141277313232
Iteration [7082]: Loss = 0.6734247207641602
Iteration [7083]: Loss = 0.6733205318450928
Iteration [7084]: Loss = 0.6732028126716614
Iteration [7085]: Loss = 0.6730731725692749
Iteration [7086]: Loss = 5.091991901397705
Iteration [7087]: Loss = 5.091958045959473
Iteration [7088]: Loss = 0.6730760931968689
Iteration [7089]: Loss = 0.673176109790802
Iteration [7090]: Loss = 0.673242449760437
Iteration [7091]: Loss = 0.6732785701751709
Iteration [7092]: Loss = 0.6732872128486633
Iteration [7093]: Loss = 0.6732712984085083
Iteration [7094]: Loss = 0.673233151435852
Iteration [7095]: Loss = 0.6731750965118408
Iteration [7096]: Loss = 0.6730990409851074
Iteration [7097]: Loss = 0.6730066537857056
Iteration [7098]: Loss = 0.6728997826576233
Iteration [7099]: Loss = 0.6727797985076904
Iteration [7100]: Loss = 0.672648012638092
Iteration [7101]: Loss = 0.6725056171417236
Iteration [7102]: Loss = 0.6723536252975464
Iteration [7103]: Loss = 0.6721929907798767
Iteration [7104]: Loss = 0.6720244884490967
Iteration [7105]: Loss = 0.6718490719795227
Iteration [7106]: Loss = 0.6716675162315369
Iteration [7107]: Loss = 0.6714801788330078
Iteration [7108]: Loss = 0.6712878346443176
Iteration [7109]: Loss = 0.6710907220840454
Iteration [7110]: Loss = 5.103405475616455
Iteration [7111]: Loss = 5.103672027587891
Iteration [7112]: Loss = 0.6709318161010742
Iteration [7113]: Loss = 5.102849960327148
Iteration [7114]: Loss = 0.6711726784706116
Iteration [7115]: Loss = 0.6713144183158875
Iteration [7116]: Loss = 0.671418309211731
Iteration [7117]: Loss = 0.6714884638786316
Iteration [7118]: Loss = 0.6715276837348938
Iteration [7119]: Loss = 0.671539306640625
Iteration [7120]: Loss = 0.6715259552001953
Iteration [7121]: Loss = 0.6714901924133301
Iteration [7122]: Loss = 0.6714343428611755
Iteration [7123]: Loss = 0.6713602542877197
Iteration [7124]: Loss = 0.6712697744369507
Iteration [7125]: Loss = 0.6711645126342773
Iteration [7126]: Loss = 5.102530002593994
Iteration [7127]: Loss = 5.102381706237793
Iteration [7128]: Loss = 0.6712287664413452
Iteration [7129]: Loss = 0.6713457107543945
Iteration [7130]: Loss = 0.6714274883270264
Iteration [7131]: Loss = 0.6714773178100586
Iteration [7132]: Loss = 0.6714982986450195
Iteration [7133]: Loss = 0.6714935898780823
Iteration [7134]: Loss = 0.6714655160903931
Iteration [7135]: Loss = 0.6714164614677429
Iteration [7136]: Loss = 0.671348512172699
Iteration [7137]: Loss = 0.6712635159492493
Iteration [7138]: Loss = 0.6711632609367371
Iteration [7139]: Loss = 0.6710492372512817
Iteration [7140]: Loss = 0.6709226369857788
Iteration [7141]: Loss = 0.6707849502563477
Iteration [7142]: Loss = 0.6706373691558838
Iteration [7143]: Loss = 0.670480489730835
Iteration [7144]: Loss = 0.6703156232833862
Iteration [7145]: Loss = 0.6701433062553406
Iteration [7146]: Loss = 0.6699643731117249
Iteration [7147]: Loss = 9.549479484558105
Iteration [7148]: Loss = 0.6699029207229614
Iteration [7149]: Loss = 0.6699904203414917
Iteration [7150]: Loss = 0.6700455546379089
Iteration [7151]: Loss = 0.6700717210769653
Iteration [7152]: Loss = 0.6700716018676758
Iteration [7153]: Loss = 5.108123779296875
Iteration [7154]: Loss = 0.670158863067627
Iteration [7155]: Loss = 0.670235276222229
Iteration [7156]: Loss = 0.6702803373336792
Iteration [7157]: Loss = 0.670297384262085
Iteration [7158]: Loss = 5.106770992279053
Iteration [7159]: Loss = 0.6704139113426208
Iteration [7160]: Loss = 0.6709600687026978
Iteration [7161]: Loss = 0.671016275882721
Iteration [7162]: Loss = 0.6710432171821594
Iteration [7163]: Loss = 0.671043872833252
Iteration [7164]: Loss = 0.6710206866264343
Iteration [7165]: Loss = 0.6709763407707214
Iteration [7166]: Loss = 0.6709126234054565
Iteration [7167]: Loss = 0.670831561088562
Iteration [7168]: Loss = 5.104271411895752
Iteration [7169]: Loss = 0.6707805395126343
Iteration [7170]: Loss = 0.6707980036735535
Iteration [7171]: Loss = 5.1039628982543945
Iteration [7172]: Loss = 0.6709150671958923
Iteration [7173]: Loss = 0.6710041165351868
Iteration [7174]: Loss = 0.6710605621337891
Iteration [7175]: Loss = 5.102295875549316
Iteration [7176]: Loss = 0.6712444424629211
Iteration [7177]: Loss = 0.6713618636131287
Iteration [7178]: Loss = 0.6714439392089844
Iteration [7179]: Loss = 5.100021839141846
Iteration [7180]: Loss = 0.6716715097427368
Iteration [7181]: Loss = 5.098271369934082
Iteration [7182]: Loss = 0.672061562538147
Iteration [7183]: Loss = 0.6722667813301086
Iteration [7184]: Loss = 0.6724279522895813
Iteration [7185]: Loss = 0.6725495457649231
Iteration [7186]: Loss = 0.6726351976394653
Iteration [7187]: Loss = 0.6726886034011841
Iteration [7188]: Loss = 0.672713041305542
Iteration [7189]: Loss = 5.093225479125977
Iteration [7190]: Loss = 0.6728418469429016
Iteration [7191]: Loss = 0.6729357242584229
Iteration [7192]: Loss = 5.091637134552002
Iteration [7193]: Loss = 0.6731829643249512
Iteration [7194]: Loss = 0.6733272671699524
Iteration [7195]: Loss = 0.6734336018562317
Iteration [7196]: Loss = 0.6735056042671204
Iteration [7197]: Loss = 0.673546552658081
Iteration [7198]: Loss = 0.6735597252845764
Iteration [7199]: Loss = 5.088566303253174
Iteration [7200]: Loss = 0.6736690998077393
Iteration [7201]: Loss = 0.6737547516822815
Iteration [7202]: Loss = 5.087118148803711
Iteration [7203]: Loss = 0.6739878058433533
Iteration [7204]: Loss = 5.085350036621094
Iteration [7205]: Loss = 5.083928108215332
Iteration [7206]: Loss = 0.6747437119483948
Iteration [7207]: Loss = 0.6750456690788269
Iteration [7208]: Loss = 5.078868389129639
Iteration [7209]: Loss = 0.67564857006073
Iteration [7210]: Loss = 0.6759443879127502
Iteration [7211]: Loss = 0.6761868596076965
Iteration [7212]: Loss = 0.676381528377533
Iteration [7213]: Loss = 0.676533043384552
Iteration [7214]: Loss = 9.46613597869873
Iteration [7215]: Loss = 0.6770303845405579
Iteration [7216]: Loss = 0.6773533821105957
Iteration [7217]: Loss = 0.677620530128479
Iteration [7218]: Loss = 0.677837610244751
Iteration [7219]: Loss = 5.063869476318359
Iteration [7220]: Loss = 5.062302112579346
Iteration [7221]: Loss = 0.6786803603172302
Iteration [7222]: Loss = 0.6790048480033875
Iteration [7223]: Loss = 0.6792730689048767
Iteration [7224]: Loss = 0.6794910430908203
Iteration [7225]: Loss = 0.6796635389328003
Iteration [7226]: Loss = 0.6797950863838196
Iteration [7227]: Loss = 0.6798896789550781
Iteration [7228]: Loss = 5.053203582763672
Iteration [7229]: Loss = 5.052185535430908
Iteration [7230]: Loss = 0.6804338693618774
Iteration [7231]: Loss = 0.6806777119636536
Iteration [7232]: Loss = 0.6808736324310303
Iteration [7233]: Loss = 0.6810259819030762
Iteration [7234]: Loss = 0.6811394691467285
Iteration [7235]: Loss = 0.6812177300453186
Iteration [7236]: Loss = 0.6812641024589539
Iteration [7237]: Loss = 0.681282103061676
Iteration [7238]: Loss = 0.6812742352485657
Iteration [7239]: Loss = 0.6812434196472168
Iteration [7240]: Loss = 0.6811915040016174
Iteration [7241]: Loss = 0.681120753288269
Iteration [7242]: Loss = 0.6810332536697388
Iteration [7243]: Loss = 0.6809303760528564
Iteration [7244]: Loss = 0.6808137893676758
Iteration [7245]: Loss = 0.6806848049163818
Iteration [7246]: Loss = 5.049951076507568
Iteration [7247]: Loss = 0.6805500984191895
Iteration [7248]: Loss = 0.6805307865142822
Iteration [7249]: Loss = 0.6804894804954529
Iteration [7250]: Loss = 0.6804284453392029
Iteration [7251]: Loss = 0.6803494691848755
Iteration [7252]: Loss = 0.680254340171814
Iteration [7253]: Loss = 0.6801447868347168
Iteration [7254]: Loss = 0.6800221800804138
Iteration [7255]: Loss = 0.6798877120018005
Iteration [7256]: Loss = 0.6797428131103516
Iteration [7257]: Loss = 0.6795884966850281
Iteration [7258]: Loss = 0.6794254183769226
Iteration [7259]: Loss = 0.6792548298835754
Iteration [7260]: Loss = 0.6790770888328552
Iteration [7261]: Loss = 5.059009075164795
Iteration [7262]: Loss = 0.6788595914840698
Iteration [7263]: Loss = 0.6788052320480347
Iteration [7264]: Loss = 0.6787323951721191
Iteration [7265]: Loss = 0.6786429286003113
Iteration [7266]: Loss = 5.060958385467529
Iteration [7267]: Loss = 0.678575873374939
Iteration [7268]: Loss = 0.6785856485366821
Iteration [7269]: Loss = 0.6785707473754883
Iteration [7270]: Loss = 0.6785331964492798
Iteration [7271]: Loss = 5.061304092407227
Iteration [7272]: Loss = 0.6785551309585571
Iteration [7273]: Loss = 0.678602933883667
Iteration [7274]: Loss = 0.6786219477653503
Iteration [7275]: Loss = 0.6786153316497803
Iteration [7276]: Loss = 0.6785852313041687
Iteration [7277]: Loss = 0.6785343885421753
Iteration [7278]: Loss = 0.6784645318984985
Iteration [7279]: Loss = 9.445306777954102
Iteration [7280]: Loss = 0.6785848140716553
Iteration [7281]: Loss = 0.6787477135658264
Iteration [7282]: Loss = 5.0591325759887695
Iteration [7283]: Loss = 0.6791112422943115
Iteration [7284]: Loss = 5.056750297546387
Iteration [7285]: Loss = 5.055084228515625
Iteration [7286]: Loss = 0.6800108551979065
Iteration [7287]: Loss = 0.6803500056266785
Iteration [7288]: Loss = 0.6806317567825317
Iteration [7289]: Loss = 0.6808618903160095
Iteration [7290]: Loss = 0.6810452938079834
Iteration [7291]: Loss = 0.6811865568161011
Iteration [7292]: Loss = 0.6812899112701416
Iteration [7293]: Loss = 5.045497894287109
Iteration [7294]: Loss = 0.682973325252533
Iteration [7295]: Loss = 0.6831225156784058
Iteration [7296]: Loss = 0.6832330822944641
Iteration [7297]: Loss = 0.6833085417747498
Iteration [7298]: Loss = 0.6833526492118835
Iteration [7299]: Loss = 0.6833682656288147
Iteration [7300]: Loss = 0.6833583116531372
Iteration [7301]: Loss = 0.683325469493866
Iteration [7302]: Loss = 0.6832717657089233
Iteration [7303]: Loss = 0.6831993460655212
Iteration [7304]: Loss = 0.6831102967262268
Iteration [7305]: Loss = 0.6830058693885803
Iteration [7306]: Loss = 0.682887852191925
Iteration [7307]: Loss = 0.6827577352523804
Iteration [7308]: Loss = 5.03864049911499
Iteration [7309]: Loss = 0.6826202869415283
Iteration [7310]: Loss = 0.682599663734436
Iteration [7311]: Loss = 5.038963794708252
Iteration [7312]: Loss = 5.038461208343506
Iteration [7313]: Loss = 5.037299633026123
Iteration [7314]: Loss = 5.035549163818359
Iteration [7315]: Loss = 0.6836035251617432
Iteration [7316]: Loss = 0.6839573383331299
Iteration [7317]: Loss = 0.6842520833015442
Iteration [7318]: Loss = 5.028440475463867
Iteration [7319]: Loss = 0.6848403811454773
Iteration [7320]: Loss = 0.6851289868354797
Iteration [7321]: Loss = 5.023720741271973
Iteration [7322]: Loss = 5.021871566772461
Iteration [7323]: Loss = 0.6861438155174255
Iteration [7324]: Loss = 0.6865135431289673
Iteration [7325]: Loss = 0.6868226528167725
Iteration [7326]: Loss = 0.6870768070220947
Iteration [7327]: Loss = 0.6872816681861877
Iteration [7328]: Loss = 0.6874419450759888
Iteration [7329]: Loss = 0.6875621676445007
Iteration [7330]: Loss = 0.6876463294029236
Iteration [7331]: Loss = 0.6876978874206543
Iteration [7332]: Loss = 0.6877200603485107
Iteration [7333]: Loss = 5.011034965515137
Iteration [7334]: Loss = 0.6878420114517212
Iteration [7335]: Loss = 0.6879315972328186
Iteration [7336]: Loss = 0.6879879832267761
Iteration [7337]: Loss = 0.6880145072937012
Iteration [7338]: Loss = 0.6880142688751221
Iteration [7339]: Loss = 0.6879896521568298
Iteration [7340]: Loss = 0.687943160533905
Iteration [7341]: Loss = 0.6878771781921387
Iteration [7342]: Loss = 0.6877934336662292
Iteration [7343]: Loss = 0.68769371509552
Iteration [7344]: Loss = 5.0117669105529785
Iteration [7345]: Loss = 0.6876079440116882
Iteration [7346]: Loss = 0.6876088380813599
Iteration [7347]: Loss = 0.6875854730606079
Iteration [7348]: Loss = 0.6875401139259338
Iteration [7349]: Loss = 0.6874752044677734
Iteration [7350]: Loss = 0.6873922348022461
Iteration [7351]: Loss = 0.6872934103012085
Iteration [7352]: Loss = 0.6871802806854248
Iteration [7353]: Loss = 0.6870538592338562
Iteration [7354]: Loss = 0.6869159936904907
Iteration [7355]: Loss = 0.6867674589157104
Iteration [7356]: Loss = 0.6866096258163452
Iteration [7357]: Loss = 0.6864430904388428
Iteration [7358]: Loss = 0.6862689852714539
Iteration [7359]: Loss = 0.6860880255699158
Iteration [7360]: Loss = 0.6859008073806763
Iteration [7361]: Loss = 0.6857079863548279
Iteration [7362]: Loss = 0.6855101585388184
Iteration [7363]: Loss = 0.6853078603744507
Iteration [7364]: Loss = 0.6851015090942383
Iteration [7365]: Loss = 0.6848914623260498
Iteration [7366]: Loss = 0.6846782565116882
Iteration [7367]: Loss = 0.6844620108604431
Iteration [7368]: Loss = 5.029797554016113
Iteration [7369]: Loss = 0.684177815914154
Iteration [7370]: Loss = 5.030603408813477
Iteration [7371]: Loss = 0.6841511726379395
Iteration [7372]: Loss = 5.030152320861816
Iteration [7373]: Loss = 0.6843326687812805
Iteration [7374]: Loss = 0.6844480633735657
Iteration [7375]: Loss = 0.684527575969696
Iteration [7376]: Loss = 0.684575080871582
Iteration [7377]: Loss = 0.684593915939331
Iteration [7378]: Loss = 5.0279364585876465
Iteration [7379]: Loss = 0.6847107410430908
Iteration [7380]: Loss = 5.026787757873535
Iteration [7381]: Loss = 0.6850081086158752
Iteration [7382]: Loss = 0.6851727366447449
Iteration [7383]: Loss = 0.6852967739105225
Iteration [7384]: Loss = 0.6853843927383423
Iteration [7385]: Loss = 0.685438871383667
Iteration [7386]: Loss = 0.6854637861251831
Iteration [7387]: Loss = 0.6854621767997742
Iteration [7388]: Loss = 0.6854363083839417
Iteration [7389]: Loss = 0.6853886842727661
Iteration [7390]: Loss = 0.6853216290473938
Iteration [7391]: Loss = 0.6852369904518127
Iteration [7392]: Loss = 0.6851364374160767
Iteration [7393]: Loss = 5.025577545166016
Iteration [7394]: Loss = 0.6850498914718628
Iteration [7395]: Loss = 0.6850510239601135
Iteration [7396]: Loss = 5.025545597076416
Iteration [7397]: Loss = 0.6851379871368408
Iteration [7398]: Loss = 0.6852128505706787
Iteration [7399]: Loss = 0.6852561831474304
Iteration [7400]: Loss = 0.6852709650993347
Iteration [7401]: Loss = 5.024288654327393
Iteration [7402]: Loss = 5.023632526397705
Iteration [7403]: Loss = 0.6856208443641663
Iteration [7404]: Loss = 0.6858127117156982
Iteration [7405]: Loss = 0.6859610676765442
Iteration [7406]: Loss = 5.019905090332031
Iteration [7407]: Loss = 0.6862998008728027
Iteration [7408]: Loss = 0.6864819526672363
Iteration [7409]: Loss = 0.6866217851638794
Iteration [7410]: Loss = 0.6867234706878662
Iteration [7411]: Loss = 5.016018867492676
Iteration [7412]: Loss = 0.6869820356369019
Iteration [7413]: Loss = 0.6871299147605896
Iteration [7414]: Loss = 0.6872388124465942
Iteration [7415]: Loss = 0.6873126029968262
Iteration [7416]: Loss = 0.6873547434806824
Iteration [7417]: Loss = 0.6873681545257568
Iteration [7418]: Loss = 0.6873559355735779
Iteration [7419]: Loss = 0.6873205304145813
Iteration [7420]: Loss = 0.6872643828392029
Iteration [7421]: Loss = 0.6871894001960754
Iteration [7422]: Loss = 0.687097430229187
Iteration [7423]: Loss = 0.6869902014732361
Iteration [7424]: Loss = 0.6868692636489868
Iteration [7425]: Loss = 0.6867361664772034
Iteration [7426]: Loss = 5.017092227935791
Iteration [7427]: Loss = 0.6865934729576111
Iteration [7428]: Loss = 0.6865707039833069
Iteration [7429]: Loss = 0.6865257024765015
Iteration [7430]: Loss = 0.6864609718322754
Iteration [7431]: Loss = 0.6863782405853271
Iteration [7432]: Loss = 0.6862793564796448
Iteration [7433]: Loss = 0.686165988445282
Iteration [7434]: Loss = 0.6860395073890686
Iteration [7435]: Loss = 5.020820140838623
Iteration [7436]: Loss = 5.020780086517334
Iteration [7437]: Loss = 5.020035266876221
Iteration [7438]: Loss = 0.6863016486167908
Iteration [7439]: Loss = 0.6865072846412659
Iteration [7440]: Loss = 0.6866679191589355
Iteration [7441]: Loss = 0.6867882609367371
Iteration [7442]: Loss = 5.015578269958496
Iteration [7443]: Loss = 9.341848373413086
Iteration [7444]: Loss = 0.6875472068786621
Iteration [7445]: Loss = 0.687944769859314
Iteration [7446]: Loss = 0.6882787346839905
Iteration [7447]: Loss = 5.006521701812744
Iteration [7448]: Loss = 0.6889339089393616
Iteration [7449]: Loss = 0.6892507672309875
Iteration [7450]: Loss = 0.6895118951797485
Iteration [7451]: Loss = 5.000260829925537
Iteration [7452]: Loss = 0.69004225730896
Iteration [7453]: Loss = 0.6903057098388672
Iteration [7454]: Loss = 0.6905187964439392
Iteration [7455]: Loss = 0.6906862854957581
Iteration [7456]: Loss = 0.6908127665519714
Iteration [7457]: Loss = 0.6909021735191345
Iteration [7458]: Loss = 0.6909584403038025
Iteration [7459]: Loss = 0.6909846067428589
Iteration [7460]: Loss = 0.690983772277832
Iteration [7461]: Loss = 0.690958559513092
Iteration [7462]: Loss = 0.6909114122390747
Iteration [7463]: Loss = 0.6908444166183472
Iteration [7464]: Loss = 4.994715213775635
Iteration [7465]: Loss = 0.6908141374588013
Iteration [7466]: Loss = 0.690838634967804
Iteration [7467]: Loss = 0.6908361315727234
Iteration [7468]: Loss = 0.6908096075057983
Iteration [7469]: Loss = 4.994706630706787
Iteration [7470]: Loss = 0.690848171710968
Iteration [7471]: Loss = 4.993954658508301
Iteration [7472]: Loss = 0.6910806894302368
Iteration [7473]: Loss = 0.691217303276062
Iteration [7474]: Loss = 0.6913156509399414
Iteration [7475]: Loss = 0.691379964351654
Iteration [7476]: Loss = 0.691413402557373
Iteration [7477]: Loss = 0.6914188265800476
Iteration [7478]: Loss = 0.6913993954658508
Iteration [7479]: Loss = 0.691357433795929
Iteration [7480]: Loss = 0.6912950873374939
Iteration [7481]: Loss = 0.6912144422531128
Iteration [7482]: Loss = 4.992805004119873
Iteration [7483]: Loss = 0.6911606192588806
Iteration [7484]: Loss = 0.6911751627922058
Iteration [7485]: Loss = 4.992557048797607
Iteration [7486]: Loss = 0.6912840604782104
Iteration [7487]: Loss = 0.6913678646087646
Iteration [7488]: Loss = 9.290972709655762
Iteration [7489]: Loss = 0.69174724817276
Iteration [7490]: Loss = 0.6920188665390015
Iteration [7491]: Loss = 0.6922391057014465
Iteration [7492]: Loss = 0.6924132108688354
Iteration [7493]: Loss = 0.692545473575592
Iteration [7494]: Loss = 0.6926404237747192
Iteration [7495]: Loss = 4.984365463256836
Iteration [7496]: Loss = 0.6928857564926147
Iteration [7497]: Loss = 0.6930273771286011
Iteration [7498]: Loss = 0.693130612373352
Iteration [7499]: Loss = 0.6931990385055542
Iteration [7500]: Loss = 0.693236231803894
Iteration [7501]: Loss = 0.6932454109191895
Iteration [7502]: Loss = 0.693229079246521
Iteration [7503]: Loss = 4.9817681312561035
Iteration [7504]: Loss = 0.6932845115661621
Iteration [7505]: Loss = 0.6933451890945435
Iteration [7506]: Loss = 0.6933754682540894
Iteration [7507]: Loss = 0.693378210067749
Iteration [7508]: Loss = 4.9808855056762695
Iteration [7509]: Loss = 0.6934662461280823
Iteration [7510]: Loss = 0.6935407519340515
Iteration [7511]: Loss = 0.693583607673645
Iteration [7512]: Loss = 0.6935975551605225
Iteration [7513]: Loss = 0.6935856342315674
Iteration [7514]: Loss = 9.266159057617188
Iteration [7515]: Loss = 0.6938008069992065
Iteration [7516]: Loss = 0.6940019130706787
Iteration [7517]: Loss = 0.6941589713096619
Iteration [7518]: Loss = 0.6942759156227112
Iteration [7519]: Loss = 0.6943569183349609
Iteration [7520]: Loss = 0.6944054961204529
Iteration [7521]: Loss = 0.6944248676300049
Iteration [7522]: Loss = 0.6944179534912109
Iteration [7523]: Loss = 0.6943871378898621
Iteration [7524]: Loss = 0.6943351030349731
Iteration [7525]: Loss = 0.6942638158798218
Iteration [7526]: Loss = 0.6941753029823303
Iteration [7527]: Loss = 0.6940711140632629
Iteration [7528]: Loss = 4.977718830108643
Iteration [7529]: Loss = 0.6939760446548462
Iteration [7530]: Loss = 0.6939724683761597
Iteration [7531]: Loss = 0.6939447522163391
Iteration [7532]: Loss = 0.6938955187797546
Iteration [7533]: Loss = 0.6938266754150391
Iteration [7534]: Loss = 0.6937403082847595
Iteration [7535]: Loss = 0.6936382055282593
Iteration [7536]: Loss = 0.6935216784477234
Iteration [7537]: Loss = 0.6933925747871399
Iteration [7538]: Loss = 0.6932517290115356
Iteration [7539]: Loss = 0.6931006908416748
Iteration [7540]: Loss = 0.6929401755332947
Iteration [7541]: Loss = 0.6927712559700012
Iteration [7542]: Loss = 0.6925948858261108
Iteration [7543]: Loss = 0.6924116611480713
Iteration [7544]: Loss = 0.6922222971916199
Iteration [7545]: Loss = 0.6920274496078491
Iteration [7546]: Loss = 0.691827654838562
Iteration [7547]: Loss = 0.691623330116272
Iteration [7548]: Loss = 0.6914151906967163
Iteration [7549]: Loss = 4.992345809936523
Iteration [7550]: Loss = 4.992668151855469
Iteration [7551]: Loss = 0.691218376159668
Iteration [7552]: Loss = 0.6912620067596436
Iteration [7553]: Loss = 0.6912769079208374
Iteration [7554]: Loss = 0.6912660598754883
Iteration [7555]: Loss = 0.691231906414032
Iteration [7556]: Loss = 0.6911767721176147
Iteration [7557]: Loss = 0.6911028027534485
Iteration [7558]: Loss = 4.9933671951293945
Iteration [7559]: Loss = 0.6910600662231445
Iteration [7560]: Loss = 0.6910791397094727
Iteration [7561]: Loss = 13.596999168395996
Iteration [7562]: Loss = 0.691493809223175
Iteration [7563]: Loss = 4.988897323608398
Iteration [7564]: Loss = 0.692297101020813
Iteration [7565]: Loss = 0.6926761865615845
Iteration [7566]: Loss = 0.6929936408996582
Iteration [7567]: Loss = 0.6932557821273804
Iteration [7568]: Loss = 0.693467915058136
Iteration [7569]: Loss = 0.6936349868774414
Iteration [7570]: Loss = 0.6937615275382996
Iteration [7571]: Loss = 4.978256702423096
Iteration [7572]: Loss = 0.694059431552887
Iteration [7573]: Loss = 4.976288318634033
Iteration [7574]: Loss = 0.6944965720176697
Iteration [7575]: Loss = 4.973659992218018
Iteration [7576]: Loss = 0.6950461864471436
Iteration [7577]: Loss = 4.970499515533447
Iteration [7578]: Loss = 0.6956866979598999
Iteration [7579]: Loss = 4.966911315917969
Iteration [7580]: Loss = 0.6964008212089539
Iteration [7581]: Loss = 0.6967414617538452
Iteration [7582]: Loss = 0.6969730257987976
Iteration [7583]: Loss = 0.6971568465232849
Iteration [7584]: Loss = 0.6973032355308533
Iteration [7585]: Loss = 0.6974157094955444
Iteration [7586]: Loss = 4.959001541137695
Iteration [7587]: Loss = 0.6976727247238159
Iteration [7588]: Loss = 0.6978111267089844
Iteration [7589]: Loss = 0.6979163885116577
Iteration [7590]: Loss = 0.6979919075965881
Iteration [7591]: Loss = 0.6980405449867249
Iteration [7592]: Loss = 0.6980649828910828
Iteration [7593]: Loss = 0.6980677247047424
Iteration [7594]: Loss = 0.6980507373809814
Iteration [7595]: Loss = 0.6980161070823669
Iteration [7596]: Loss = 4.956542015075684
Iteration [7597]: Loss = 0.6980217099189758
Iteration [7598]: Loss = 0.6980530023574829
Iteration [7599]: Loss = 0.6980617046356201
Iteration [7600]: Loss = 4.956097602844238
Iteration [7601]: Loss = 4.955618381500244
Iteration [7602]: Loss = 0.698324978351593
Iteration [7603]: Loss = 0.6984707713127136
Iteration [7604]: Loss = 0.6985827088356018
Iteration [7605]: Loss = 0.6986643075942993
Iteration [7606]: Loss = 0.6987183094024658
Iteration [7607]: Loss = 0.698747456073761
Iteration [7608]: Loss = 0.6987543702125549
Iteration [7609]: Loss = 0.6987411975860596
Iteration [7610]: Loss = 0.6987099051475525
Iteration [7611]: Loss = 0.6986623406410217
Iteration [7612]: Loss = 0.6986001133918762
Iteration [7613]: Loss = 0.6985244750976562
Iteration [7614]: Loss = 0.6984370946884155
Iteration [7615]: Loss = 4.9545817375183105
Iteration [7616]: Loss = 0.6983526349067688
Iteration [7617]: Loss = 4.954546928405762
Iteration [7618]: Loss = 4.954046249389648
Iteration [7619]: Loss = 0.6986281871795654
Iteration [7620]: Loss = 0.6987773776054382
Iteration [7621]: Loss = 4.95167875289917
Iteration [7622]: Loss = 0.6990972757339478
Iteration [7623]: Loss = 0.6992625594139099
Iteration [7624]: Loss = 0.6993918418884277
Iteration [7625]: Loss = 0.6994889378547668
Iteration [7626]: Loss = 0.6995569467544556
Iteration [7627]: Loss = 0.6995986700057983
Iteration [7628]: Loss = 0.6996167898178101
Iteration [7629]: Loss = 0.6996135711669922
Iteration [7630]: Loss = 4.948019504547119
Iteration [7631]: Loss = 0.6996729373931885
Iteration [7632]: Loss = 0.6997270584106445
Iteration [7633]: Loss = 0.699756383895874
Iteration [7634]: Loss = 0.6997630596160889
Iteration [7635]: Loss = 0.6997498869895935
Iteration [7636]: Loss = 0.6997182965278625
Iteration [7637]: Loss = 0.6996704339981079
Iteration [7638]: Loss = 0.6996079087257385
Iteration [7639]: Loss = 4.948328495025635
Iteration [7640]: Loss = 0.6995657086372375
Iteration [7641]: Loss = 0.6995766162872314
Iteration [7642]: Loss = 0.6995669007301331
Iteration [7643]: Loss = 9.197050094604492
Iteration [7644]: Loss = 0.6992357969284058
Iteration [7645]: Loss = 0.699393093585968
Iteration [7646]: Loss = 4.948416709899902
Iteration [7647]: Loss = 4.947312355041504
Iteration [7648]: Loss = 0.7000173926353455
Iteration [7649]: Loss = 0.7002599835395813
Iteration [7650]: Loss = 0.7004592418670654
Iteration [7651]: Loss = 0.7006192803382874
Iteration [7652]: Loss = 0.7007439732551575
Iteration [7653]: Loss = 4.9415106773376465
Iteration [7654]: Loss = 0.7010216116905212
Iteration [7655]: Loss = 0.7011685371398926
Iteration [7656]: Loss = 0.7012815475463867
Iteration [7657]: Loss = 0.701363742351532
Iteration [7658]: Loss = 0.7014181613922119
Iteration [7659]: Loss = 4.938323974609375
Iteration [7660]: Loss = 0.7015759944915771
Iteration [7661]: Loss = 0.7016717195510864
Iteration [7662]: Loss = 4.9368109703063965
Iteration [7663]: Loss = 0.701900064945221
Iteration [7664]: Loss = 0.7020258903503418
Iteration [7665]: Loss = 0.7021197080612183
Iteration [7666]: Loss = 4.934489727020264
Iteration [7667]: Loss = 0.7023445963859558
Iteration [7668]: Loss = 0.7024691700935364
Iteration [7669]: Loss = 0.7025615572929382
Iteration [7670]: Loss = 0.7026254534721375
Iteration [7671]: Loss = 0.702663242816925
Iteration [7672]: Loss = 4.931926250457764
Iteration [7673]: Loss = 0.7027924060821533
Iteration [7674]: Loss = 0.7028759121894836
Iteration [7675]: Loss = 0.7029316425323486
Iteration [7676]: Loss = 4.930448532104492
Iteration [7677]: Loss = 0.7030913233757019
Iteration [7678]: Loss = 0.7031880021095276
Iteration [7679]: Loss = 4.928927421569824
Iteration [7680]: Loss = 4.928086757659912
Iteration [7681]: Loss = 0.7036647200584412
Iteration [7682]: Loss = 0.7038677334785461
Iteration [7683]: Loss = 0.7040308713912964
Iteration [7684]: Loss = 0.704158365726471
Iteration [7685]: Loss = 0.7042534947395325
Iteration [7686]: Loss = 0.704319417476654
Iteration [7687]: Loss = 0.704359233379364
Iteration [7688]: Loss = 0.7043753862380981
Iteration [7689]: Loss = 0.7043702006340027
Iteration [7690]: Loss = 0.7043459415435791
Iteration [7691]: Loss = 0.7043042182922363
Iteration [7692]: Loss = 0.7042471170425415
Iteration [7693]: Loss = 4.92415714263916
Iteration [7694]: Loss = 0.7042138576507568
Iteration [7695]: Loss = 0.704228401184082
Iteration [7696]: Loss = 4.923920154571533
Iteration [7697]: Loss = 0.7043173909187317
Iteration [7698]: Loss = 0.704383909702301
Iteration [7699]: Loss = 4.922872066497803
Iteration [7700]: Loss = 0.7045621275901794
Iteration [7701]: Loss = 0.7046665549278259
Iteration [7702]: Loss = 0.7047409415245056
Iteration [7703]: Loss = 0.704788327217102
Iteration [7704]: Loss = 0.704811155796051
Iteration [7705]: Loss = 0.7048119902610779
Iteration [7706]: Loss = 0.7047930359840393
Iteration [7707]: Loss = 0.7047562599182129
Iteration [7708]: Loss = 0.7047033309936523
Iteration [7709]: Loss = 0.7046360373497009
Iteration [7710]: Loss = 0.7045556306838989
Iteration [7711]: Loss = 0.7044634819030762
Iteration [7712]: Loss = 0.7043607831001282
Iteration [7713]: Loss = 0.7042485475540161
Iteration [7714]: Loss = 0.7041279077529907
Iteration [7715]: Loss = 0.703999400138855
Iteration [7716]: Loss = 0.7038639783859253
Iteration [7717]: Loss = 0.7037224173545837
Iteration [7718]: Loss = 0.703575074672699
Iteration [7719]: Loss = 0.7034228444099426
Iteration [7720]: Loss = 0.7032660245895386
Iteration [7721]: Loss = 0.7031050324440002
Iteration [7722]: Loss = 0.7029404640197754
Iteration [7723]: Loss = 0.7027725577354431
Iteration [7724]: Loss = 0.7026017308235168
Iteration [7725]: Loss = 4.933222770690918
Iteration [7726]: Loss = 0.7023748159408569
Iteration [7727]: Loss = 9.165400505065918
Iteration [7728]: Loss = 4.93301248550415
Iteration [7729]: Loss = 0.7027155160903931
Iteration [7730]: Loss = 0.7029180526733398
Iteration [7731]: Loss = 0.7030811905860901
Iteration [7732]: Loss = 0.7032084465026855
Iteration [7733]: Loss = 4.928678512573242
Iteration [7734]: Loss = 0.7034903764724731
Iteration [7735]: Loss = 0.703639030456543
Iteration [7736]: Loss = 0.7037534713745117
Iteration [7737]: Loss = 0.7038368582725525
Iteration [7738]: Loss = 0.7038922905921936
Iteration [7739]: Loss = 0.703922688961029
Iteration [7740]: Loss = 4.92542839050293
Iteration [7741]: Loss = 0.7040387392044067
Iteration [7742]: Loss = 0.7041168212890625
Iteration [7743]: Loss = 0.7041674256324768
Iteration [7744]: Loss = 0.7041933536529541
Iteration [7745]: Loss = 4.924047946929932
Iteration [7746]: Loss = 4.92350435256958
Iteration [7747]: Loss = 0.7044978737831116
Iteration [7748]: Loss = 4.921680450439453
Iteration [7749]: Loss = 0.7048968076705933
Iteration [7750]: Loss = 0.7050953507423401
Iteration [7751]: Loss = 0.7052546143531799
Iteration [7752]: Loss = 0.7053784132003784
Iteration [7753]: Loss = 0.7054701447486877
Iteration [7754]: Loss = 0.7055330276489258
Iteration [7755]: Loss = 0.705569863319397
Iteration [7756]: Loss = 0.7055833339691162
Iteration [7757]: Loss = 0.7055758237838745
Iteration [7758]: Loss = 0.7055492997169495
Iteration [7759]: Loss = 0.7055056095123291
Iteration [7760]: Loss = 0.7054464817047119
Iteration [7761]: Loss = 0.7053735852241516
Iteration [7762]: Loss = 0.7052881717681885
Iteration [7763]: Loss = 0.7051913738250732
Iteration [7764]: Loss = 4.919457912445068
Iteration [7765]: Loss = 0.7050906419754028
Iteration [7766]: Loss = 0.705076277256012
Iteration [7767]: Loss = 0.7050434350967407
Iteration [7768]: Loss = 0.7049943804740906
Iteration [7769]: Loss = 4.920255184173584
Iteration [7770]: Loss = 4.920025825500488
Iteration [7771]: Loss = 0.7051164507865906
Iteration [7772]: Loss = 0.705224335193634
Iteration [7773]: Loss = 0.7053016424179077
Iteration [7774]: Loss = 0.705351710319519
Iteration [7775]: Loss = 0.7053769826889038
Iteration [7776]: Loss = 0.705379843711853
Iteration [7777]: Loss = 0.7053627371788025
Iteration [7778]: Loss = 0.7053276300430298
Iteration [7779]: Loss = 0.7052760720252991
Iteration [7780]: Loss = 4.9188103675842285
Iteration [7781]: Loss = 0.7052525281906128
Iteration [7782]: Loss = 4.91849422454834
Iteration [7783]: Loss = 0.7053898572921753
Iteration [7784]: Loss = 0.7054768800735474
Iteration [7785]: Loss = 0.7055355310440063
Iteration [7786]: Loss = 0.7055686116218567
Iteration [7787]: Loss = 4.916908264160156
Iteration [7788]: Loss = 9.126981735229492
Iteration [7789]: Loss = 0.7060099840164185
Iteration [7790]: Loss = 0.7062791585922241
Iteration [7791]: Loss = 0.7065020203590393
Iteration [7792]: Loss = 0.7066831588745117
Iteration [7793]: Loss = 0.7068266272544861
Iteration [7794]: Loss = 0.7069360017776489
Iteration [7795]: Loss = 0.707014799118042
Iteration [7796]: Loss = 0.7070660591125488
Iteration [7797]: Loss = 0.7070924043655396
Iteration [7798]: Loss = 0.7070963978767395
Iteration [7799]: Loss = 0.7070801854133606
Iteration [7800]: Loss = 0.70704585313797
Iteration [7801]: Loss = 4.909609794616699
Iteration [7802]: Loss = 0.7070512771606445
Iteration [7803]: Loss = 0.7070818543434143
Iteration [7804]: Loss = 0.7070897221565247
Iteration [7805]: Loss = 0.7070770263671875
Iteration [7806]: Loss = 4.9093499183654785
Iteration [7807]: Loss = 0.707119345664978
Iteration [7808]: Loss = 0.7071657776832581
Iteration [7809]: Loss = 0.7071877717971802
Iteration [7810]: Loss = 0.7071877717971802
Iteration [7811]: Loss = 0.7071680426597595
Iteration [7812]: Loss = 0.707130491733551
Iteration [7813]: Loss = 0.7070767879486084
Iteration [7814]: Loss = 0.7070087194442749
Iteration [7815]: Loss = 0.7069276571273804
Iteration [7816]: Loss = 0.7068346738815308
Iteration [7817]: Loss = 0.706731379032135
Iteration [7818]: Loss = 0.7066185474395752
Iteration [7819]: Loss = 0.7064969539642334
Iteration [7820]: Loss = 4.912838459014893
Iteration [7821]: Loss = 0.7063537240028381
Iteration [7822]: Loss = 0.7063212394714355
Iteration [7823]: Loss = 4.913331985473633
Iteration [7824]: Loss = 0.7063297629356384
Iteration [7825]: Loss = 4.912868499755859
Iteration [7826]: Loss = 0.70649254322052
Iteration [7827]: Loss = 0.706590473651886
Iteration [7828]: Loss = 0.7066587805747986
Iteration [7829]: Loss = 0.7067005634307861
Iteration [7830]: Loss = 0.7067183256149292
Iteration [7831]: Loss = 0.7067145705223083
Iteration [7832]: Loss = 4.911173343658447
Iteration [7833]: Loss = 0.7067723274230957
Iteration [7834]: Loss = 0.7068253755569458
Iteration [7835]: Loss = 4.91033935546875
Iteration [7836]: Loss = 0.7069803476333618
Iteration [7837]: Loss = 0.7070748805999756
Iteration [7838]: Loss = 0.7071402668952942
Iteration [7839]: Loss = 0.7071791887283325
Iteration [7840]: Loss = 0.707194447517395
Iteration [7841]: Loss = 0.7071882486343384
Iteration [7842]: Loss = 0.7071629762649536
Iteration [7843]: Loss = 0.7071202993392944
Iteration [7844]: Loss = 0.7070620656013489
Iteration [7845]: Loss = 0.7069896459579468
Iteration [7846]: Loss = 0.7069046497344971
Iteration [7847]: Loss = 0.7068082094192505
Iteration [7848]: Loss = 0.7067015171051025
Iteration [7849]: Loss = 0.7065856456756592
Iteration [7850]: Loss = 0.7064614295959473
Iteration [7851]: Loss = 0.7063297629356384
Iteration [7852]: Loss = 0.70619136095047
Iteration [7853]: Loss = 0.7060469388961792
Iteration [7854]: Loss = 0.7058970928192139
Iteration [7855]: Loss = 4.91606330871582
Iteration [7856]: Loss = 0.7057053446769714
Iteration [7857]: Loss = 0.7056524753570557
Iteration [7858]: Loss = 0.7055848836898804
Iteration [7859]: Loss = 0.705504298210144
Iteration [7860]: Loss = 0.7054118514060974
Iteration [7861]: Loss = 0.7053087949752808
Iteration [7862]: Loss = 4.918881416320801
Iteration [7863]: Loss = 0.705197274684906
Iteration [7864]: Loss = 0.705178439617157
Iteration [7865]: Loss = 0.7051416635513306
Iteration [7866]: Loss = 0.7050887942314148
Iteration [7867]: Loss = 0.7050212621688843
Iteration [7868]: Loss = 0.704940676689148
Iteration [7869]: Loss = 0.7048482894897461
Iteration [7870]: Loss = 0.7047452926635742
Iteration [7871]: Loss = 0.7046327590942383
Iteration [7872]: Loss = 0.7045115828514099
Iteration [7873]: Loss = 0.7043826580047607
Iteration [7874]: Loss = 4.923790454864502
Iteration [7875]: Loss = 0.704227089881897
Iteration [7876]: Loss = 0.7041897177696228
Iteration [7877]: Loss = 0.7041361927986145
Iteration [7878]: Loss = 4.924715518951416
Iteration [7879]: Loss = 0.7041094303131104
Iteration [7880]: Loss = 0.7041268348693848
Iteration [7881]: Loss = 0.70412278175354
Iteration [7882]: Loss = 0.7040993571281433
Iteration [7883]: Loss = 0.7040582299232483
Iteration [7884]: Loss = 0.7040014863014221
Iteration [7885]: Loss = 0.7039306163787842
Iteration [7886]: Loss = 0.7038469910621643
Iteration [7887]: Loss = 0.703751802444458
Iteration [7888]: Loss = 0.7036463618278503
Iteration [7889]: Loss = 4.927495002746582
Iteration [7890]: Loss = 0.70353102684021
Iteration [7891]: Loss = 0.7035107612609863
Iteration [7892]: Loss = 0.7034726738929749
Iteration [7893]: Loss = 0.7034186124801636
Iteration [7894]: Loss = 0.7033501863479614
Iteration [7895]: Loss = 4.928859233856201
Iteration [7896]: Loss = 0.703298032283783
Iteration [7897]: Loss = 0.7033048272132874
Iteration [7898]: Loss = 0.7032910585403442
Iteration [7899]: Loss = 0.7032589316368103
Iteration [7900]: Loss = 4.929162979125977
Iteration [7901]: Loss = 0.7032687664031982
Iteration [7902]: Loss = 0.7033020257949829
Iteration [7903]: Loss = 0.7033120393753052
Iteration [7904]: Loss = 0.7033013105392456
Iteration [7905]: Loss = 0.7032716870307922
Iteration [7906]: Loss = 0.703225314617157
Iteration [7907]: Loss = 0.7031636834144592
Iteration [7908]: Loss = 0.7030884027481079
Iteration [7909]: Loss = 4.930249214172363
Iteration [7910]: Loss = 4.930123805999756
Iteration [7911]: Loss = 0.7031490802764893
Iteration [7912]: Loss = 0.703241229057312
Iteration [7913]: Loss = 0.7033044099807739
Iteration [7914]: Loss = 0.7033414244651794
Iteration [7915]: Loss = 0.7033550143241882
Iteration [7916]: Loss = 0.7033473253250122
Iteration [7917]: Loss = 0.7033205628395081
Iteration [7918]: Loss = 0.7032766342163086
Iteration [7919]: Loss = 0.7032172679901123
Iteration [7920]: Loss = 0.703143835067749
Iteration [7921]: Loss = 0.7030579447746277
Iteration [7922]: Loss = 0.7029607892036438
Iteration [7923]: Loss = 4.931014060974121
Iteration [7924]: Loss = 0.7028599381446838
Iteration [7925]: Loss = 0.7028459906578064
Iteration [7926]: Loss = 0.702813446521759
Iteration [7927]: Loss = 0.7027644515037537
Iteration [7928]: Loss = 0.7027004361152649
Iteration [7929]: Loss = 4.932211399078369
Iteration [7930]: Loss = 4.932038307189941
Iteration [7931]: Loss = 0.7027892470359802
Iteration [7932]: Loss = 0.702889084815979
Iteration [7933]: Loss = 0.7029591202735901
Iteration [7934]: Loss = 4.930240631103516
Iteration [7935]: Loss = 0.7031441926956177
Iteration [7936]: Loss = 0.7032519578933716
Iteration [7937]: Loss = 4.928544521331787
Iteration [7938]: Loss = 0.7035014629364014
Iteration [7939]: Loss = 0.703636646270752
Iteration [7940]: Loss = 0.7037386894226074
Iteration [7941]: Loss = 0.7038105726242065
Iteration [7942]: Loss = 0.7038555145263672
Iteration [7943]: Loss = 0.7038760185241699
Iteration [7944]: Loss = 0.7038745880126953
Iteration [7945]: Loss = 0.7038533687591553
Iteration [7946]: Loss = 0.7038144469261169
Iteration [7947]: Loss = 4.926314353942871
Iteration [7948]: Loss = 0.7038129568099976
Iteration [7949]: Loss = 0.7038414478302002
Iteration [7950]: Loss = 4.92586088180542
Iteration [7951]: Loss = 0.7039551734924316
Iteration [7952]: Loss = 4.924899578094482
Iteration [7953]: Loss = 0.7042050361633301
Iteration [7954]: Loss = 0.7043405771255493
Iteration [7955]: Loss = 0.7044427394866943
Iteration [7956]: Loss = 0.704514741897583
Iteration [7957]: Loss = 0.7045595645904541
Iteration [7958]: Loss = 0.7045800685882568
Iteration [7959]: Loss = 4.9220733642578125
Iteration [7960]: Loss = 0.704680323600769
Iteration [7961]: Loss = 0.7047519087791443
Iteration [7962]: Loss = 0.704796552658081
Iteration [7963]: Loss = 0.7048166990280151
Iteration [7964]: Loss = 4.920852184295654
Iteration [7965]: Loss = 0.7049162983894348
Iteration [7966]: Loss = 0.7049877643585205
Iteration [7967]: Loss = 0.7050321102142334
Iteration [7968]: Loss = 4.919626712799072
Iteration [7969]: Loss = 0.7051730155944824
Iteration [7970]: Loss = 0.7052620649337769
Iteration [7971]: Loss = 0.7053221464157104
Iteration [7972]: Loss = 0.7053562998771667
Iteration [7973]: Loss = 0.7053672075271606
Iteration [7974]: Loss = 0.7053568363189697
Iteration [7975]: Loss = 4.918204307556152
Iteration [7976]: Loss = 0.7054043412208557
Iteration [7977]: Loss = 0.7054535746574402
Iteration [7978]: Loss = 0.7054779529571533
Iteration [7979]: Loss = 0.7054798007011414
Iteration [7980]: Loss = 0.705461323261261
Iteration [7981]: Loss = 0.7054247260093689
Iteration [7982]: Loss = 0.7053719162940979
Iteration [7983]: Loss = 4.9183244705200195
Iteration [7984]: Loss = 0.7053465247154236
Iteration [7985]: Loss = 0.7053647637367249
Iteration [7986]: Loss = 0.705361008644104
Iteration [7987]: Loss = 0.7053378820419312
Iteration [7988]: Loss = 0.7052966952323914
Iteration [7989]: Loss = 0.7052397727966309
Iteration [7990]: Loss = 0.7051683068275452
Iteration [7991]: Loss = 0.7050840258598328
Iteration [7992]: Loss = 0.7049879431724548
Iteration [7993]: Loss = 0.704881489276886
Iteration [7994]: Loss = 0.7047655582427979
Iteration [7995]: Loss = 0.7046411037445068
Iteration [7996]: Loss = 0.7045090794563293
Iteration [7997]: Loss = 0.7043700814247131
Iteration [7998]: Loss = 0.7042249441146851
Iteration [7999]: Loss = 0.7040742635726929
Iteration [8000]: Loss = 0.7039185762405396
Iteration [8001]: Loss = 0.703758180141449
Iteration [8002]: Loss = 0.7035939693450928
Iteration [8003]: Loss = 0.703425943851471
Iteration [8004]: Loss = 0.7032546997070312
Iteration [8005]: Loss = 4.929834365844727
Iteration [8006]: Loss = 0.7030279636383057
Iteration [8007]: Loss = 0.7029605507850647
Iteration [8008]: Loss = 0.7028799057006836
Iteration [8009]: Loss = 4.9313578605651855
Iteration [8010]: Loss = 0.7028077840805054
Iteration [8011]: Loss = 0.7028062343597412
Iteration [8012]: Loss = 0.7027848362922668
Iteration [8013]: Loss = 0.7027456760406494
Iteration [8014]: Loss = 0.7026903629302979
Iteration [8015]: Loss = 0.7026205062866211
Iteration [8016]: Loss = 0.7025375962257385
Iteration [8017]: Loss = 4.933145999908447
Iteration [8018]: Loss = 0.702461838722229
Iteration [8019]: Loss = 4.933063983917236
Iteration [8020]: Loss = 0.702559769153595
Iteration [8021]: Loss = 4.932170867919922
Iteration [8022]: Loss = 4.931300163269043
Iteration [8023]: Loss = 0.703052282333374
Iteration [8024]: Loss = 0.7032610774040222
Iteration [8025]: Loss = 0.7034292221069336
Iteration [8026]: Loss = 0.7035606503486633
Iteration [8027]: Loss = 0.703658938407898
Iteration [8028]: Loss = 0.7037274837493896
Iteration [8029]: Loss = 0.7037691473960876
Iteration [8030]: Loss = 0.7037866115570068
Iteration [8031]: Loss = 4.9261956214904785
Iteration [8032]: Loss = 0.7038821578025818
Iteration [8033]: Loss = 0.7039520740509033
Iteration [8034]: Loss = 0.7039949893951416
Iteration [8035]: Loss = 0.704013466835022
Iteration [8036]: Loss = 0.7040101289749146
Iteration [8037]: Loss = 4.925135135650635
Iteration [8038]: Loss = 0.7040700316429138
Iteration [8039]: Loss = 0.7041248679161072
Iteration [8040]: Loss = 0.7041540741920471
Iteration [8041]: Loss = 0.704160213470459
Iteration [8042]: Loss = 0.7041458487510681
Iteration [8043]: Loss = 0.7041125893592834
Iteration [8044]: Loss = 4.92474365234375
Iteration [8045]: Loss = 0.7041217684745789
Iteration [8046]: Loss = 0.7041547894477844
Iteration [8047]: Loss = 0.7041645050048828
Iteration [8048]: Loss = 4.924275875091553
Iteration [8049]: Loss = 0.7042468786239624
Iteration [8050]: Loss = 0.7043111324310303
Iteration [8051]: Loss = 0.7043488621711731
Iteration [8052]: Loss = 0.7043628096580505
Iteration [8053]: Loss = 0.7043553590774536
Iteration [8054]: Loss = 0.7043283581733704
Iteration [8055]: Loss = 0.7042840123176575
Iteration [8056]: Loss = 4.923908710479736
Iteration [8057]: Loss = 0.7042738795280457
Iteration [8058]: Loss = 4.923521041870117
Iteration [8059]: Loss = 4.922867298126221
Iteration [8060]: Loss = 9.138845443725586
Iteration [8061]: Loss = 0.7050617933273315
Iteration [8062]: Loss = 0.705419659614563
Iteration [8063]: Loss = 0.7057222723960876
Iteration [8064]: Loss = 0.7059746980667114
Iteration [8065]: Loss = 4.913795471191406
Iteration [8066]: Loss = 0.7064716219902039
Iteration [8067]: Loss = 0.7067124247550964
Iteration [8068]: Loss = 0.7069091200828552
Iteration [8069]: Loss = 4.909244537353516
Iteration [8070]: Loss = 0.7073106169700623
Iteration [8071]: Loss = 0.7075107097625732
Iteration [8072]: Loss = 0.7076707482337952
Iteration [8073]: Loss = 0.7077948451042175
Iteration [8074]: Loss = 0.7078863978385925
Iteration [8075]: Loss = 4.9047112464904785
Iteration [8076]: Loss = 0.7081079483032227
Iteration [8077]: Loss = 4.903262615203857
Iteration [8078]: Loss = 9.095887184143066
Iteration [8079]: Loss = 0.7088602781295776
Iteration [8080]: Loss = 0.7092143297195435
Iteration [8081]: Loss = 0.709513247013092
Iteration [8082]: Loss = 0.7097625136375427
Iteration [8083]: Loss = 0.7099668979644775
Iteration [8084]: Loss = 0.710131049156189
Iteration [8085]: Loss = 0.7102586030960083
Iteration [8086]: Loss = 4.892406463623047
Iteration [8087]: Loss = 0.710541307926178
Iteration [8088]: Loss = 0.7106903195381165
Iteration [8089]: Loss = 0.7108043432235718
Iteration [8090]: Loss = 0.7108869552612305
Iteration [8091]: Loss = 0.7109411954879761
Iteration [8092]: Loss = 0.7109697461128235
Iteration [8093]: Loss = 0.7109754085540771
Iteration [8094]: Loss = 4.889312744140625
Iteration [8095]: Loss = 0.7110493183135986
Iteration [8096]: Loss = 0.7111093997955322
Iteration [8097]: Loss = 0.7111432552337646
Iteration [8098]: Loss = 0.7111536264419556
Iteration [8099]: Loss = 0.7111426591873169
Iteration [8100]: Loss = 9.065958023071289
Iteration [8101]: Loss = 0.7113099098205566
Iteration [8102]: Loss = 0.7114675045013428
Iteration [8103]: Loss = 0.7115894556045532
Iteration [8104]: Loss = 0.7116791605949402
Iteration [8105]: Loss = 4.885342597961426
Iteration [8106]: Loss = 0.7118964791297913
Iteration [8107]: Loss = 0.7120174169540405
Iteration [8108]: Loss = 0.7121062278747559
Iteration [8109]: Loss = 0.7121661305427551
Iteration [8110]: Loss = 0.7121998071670532
Iteration [8111]: Loss = 0.7122101187705994
Iteration [8112]: Loss = 0.7121992111206055
Iteration [8113]: Loss = 0.7121691703796387
Iteration [8114]: Loss = 0.7121220231056213
Iteration [8115]: Loss = 0.7120593786239624
Iteration [8116]: Loss = 0.7119828462600708
Iteration [8117]: Loss = 0.7118937969207764
Iteration [8118]: Loss = 0.7117933034896851
Iteration [8119]: Loss = 0.7116826772689819
Iteration [8120]: Loss = 0.7115631103515625
Iteration [8121]: Loss = 0.7114351391792297
Iteration [8122]: Loss = 0.7112997770309448
Iteration [8123]: Loss = 4.8883056640625
Iteration [8124]: Loss = 0.7111327052116394
Iteration [8125]: Loss = 0.7110900282859802
Iteration [8126]: Loss = 0.711031436920166
Iteration [8127]: Loss = 0.7109584212303162
Iteration [8128]: Loss = 0.7108727693557739
Iteration [8129]: Loss = 0.7107753753662109
Iteration [8130]: Loss = 4.890803813934326
Iteration [8131]: Loss = 0.7106733322143555
Iteration [8132]: Loss = 0.7106582522392273
Iteration [8133]: Loss = 4.891022682189941
Iteration [8134]: Loss = 0.7106969952583313
Iteration [8135]: Loss = 0.7107419967651367
Iteration [8136]: Loss = 0.7107625007629395
Iteration [8137]: Loss = 0.7107606530189514
Iteration [8138]: Loss = 4.890440464019775
Iteration [8139]: Loss = 0.7108219265937805
Iteration [8140]: Loss = 0.7108766436576843
Iteration [8141]: Loss = 0.7109056711196899
Iteration [8142]: Loss = 4.889559268951416
Iteration [8143]: Loss = 0.7110196352005005
Iteration [8144]: Loss = 0.7110967636108398
Iteration [8145]: Loss = 0.7111459374427795
Iteration [8146]: Loss = 0.7111701369285583
Iteration [8147]: Loss = 0.7111718058586121
Iteration [8148]: Loss = 0.711152970790863
Iteration [8149]: Loss = 4.888518333435059
Iteration [8150]: Loss = 0.7111853957176208
Iteration [8151]: Loss = 4.887949466705322
Iteration [8152]: Loss = 0.711368203163147
Iteration [8153]: Loss = 0.7114748358726501
Iteration [8154]: Loss = 0.7115504741668701
Iteration [8155]: Loss = 0.7115983963012695
Iteration [8156]: Loss = 0.7116213440895081
Iteration [8157]: Loss = 0.711621880531311
Iteration [8158]: Loss = 0.7116022109985352
Iteration [8159]: Loss = 4.886237621307373
Iteration [8160]: Loss = 0.7116326689720154
Iteration [8161]: Loss = 4.885676383972168
Iteration [8162]: Loss = 0.7118142247200012
Iteration [8163]: Loss = 0.7119201421737671
Iteration [8164]: Loss = 0.7119953036308289
Iteration [8165]: Loss = 4.883803367614746
Iteration [8166]: Loss = 0.7121880054473877
Iteration [8167]: Loss = 0.7122986912727356
Iteration [8168]: Loss = 0.7123780846595764
Iteration [8169]: Loss = 0.712429404258728
Iteration [8170]: Loss = 0.7124553322792053
Iteration [8171]: Loss = 0.7124583721160889
Iteration [8172]: Loss = 0.7124407887458801
Iteration [8173]: Loss = 0.7124047875404358
Iteration [8174]: Loss = 0.7123520374298096
Iteration [8175]: Loss = 0.7122841477394104
Iteration [8176]: Loss = 0.7122027277946472
Iteration [8177]: Loss = 0.7121091485023499
Iteration [8178]: Loss = 0.7120046615600586
Iteration [8179]: Loss = 0.7118903994560242
Iteration [8180]: Loss = 0.7117669582366943
Iteration [8181]: Loss = 4.885872840881348
Iteration [8182]: Loss = 0.7116208672523499
Iteration [8183]: Loss = 4.886119365692139
Iteration [8184]: Loss = 0.7116600871086121
Iteration [8185]: Loss = 0.7117052674293518
Iteration [8186]: Loss = 0.7117258310317993
Iteration [8187]: Loss = 4.88542366027832
Iteration [8188]: Loss = 0.7118252515792847
Iteration [8189]: Loss = 0.7118963003158569
Iteration [8190]: Loss = 0.7119399309158325
Iteration [8191]: Loss = 0.7119590044021606
Iteration [8192]: Loss = 0.7119558453559875
Iteration [8193]: Loss = 4.88436222076416
Iteration [8194]: Loss = 0.7120150327682495
Iteration [8195]: Loss = 0.7120686769485474
Iteration [8196]: Loss = 4.883527755737305
Iteration [8197]: Loss = 0.7122251987457275
Iteration [8198]: Loss = 0.7123204469680786
Iteration [8199]: Loss = 0.7123858332633972
Iteration [8200]: Loss = 0.7124245762825012
Iteration [8201]: Loss = 0.7124390602111816
Iteration [8202]: Loss = 4.881827354431152
Iteration [8203]: Loss = 0.7125282883644104
Iteration [8204]: Loss = 0.7125948667526245
Iteration [8205]: Loss = 0.7126345038414001
Iteration [8206]: Loss = 0.712649941444397
Iteration [8207]: Loss = 4.880752086639404
Iteration [8208]: Loss = 0.7127406001091003
Iteration [8209]: Loss = 0.7128079533576965
Iteration [8210]: Loss = 4.87971305847168
Iteration [8211]: Loss = 0.7129874229431152
Iteration [8212]: Loss = 0.7130925059318542
Iteration [8213]: Loss = 0.7131667137145996
Iteration [8214]: Loss = 0.7132132649421692
Iteration [8215]: Loss = 0.7132346630096436
Iteration [8216]: Loss = 0.7132337093353271
Iteration [8217]: Loss = 0.7132123112678528
Iteration [8218]: Loss = 0.7131726741790771
Iteration [8219]: Loss = 0.7131167054176331
Iteration [8220]: Loss = 0.7130457162857056
Iteration [8221]: Loss = 0.7129615545272827
Iteration [8222]: Loss = 0.7128653526306152
Iteration [8223]: Loss = 0.7127581238746643
Iteration [8224]: Loss = 0.7126414179801941
Iteration [8225]: Loss = 0.7125158905982971
Iteration [8226]: Loss = 0.712382435798645
Iteration [8227]: Loss = 0.7122418284416199
Iteration [8228]: Loss = 0.7120949625968933
Iteration [8229]: Loss = 0.7119422554969788
Iteration [8230]: Loss = 0.7117843627929688
Iteration [8231]: Loss = 0.711621880531311
Iteration [8232]: Loss = 0.7114552855491638
Iteration [8233]: Loss = 4.887658596038818
Iteration [8234]: Loss = 0.7112354040145874
Iteration [8235]: Loss = 0.711170494556427
Iteration [8236]: Loss = 0.7110916972160339
Iteration [8237]: Loss = 0.7110004425048828
Iteration [8238]: Loss = 4.889630317687988
Iteration [8239]: Loss = 0.7109094262123108
Iteration [8240]: Loss = 0.7108994722366333
Iteration [8241]: Loss = 0.710870087146759
Iteration [8242]: Loss = 4.890009880065918
Iteration [8243]: Loss = 0.7108849287033081
Iteration [8244]: Loss = 0.710919976234436
Iteration [8245]: Loss = 0.7109312415122986
Iteration [8246]: Loss = 0.7109209299087524
Iteration [8247]: Loss = 0.7108914852142334
Iteration [8248]: Loss = 0.7108445167541504
Iteration [8249]: Loss = 0.7107817530632019
Iteration [8250]: Loss = 0.7107049822807312
Iteration [8251]: Loss = 0.7106154561042786
Iteration [8252]: Loss = 4.891584396362305
Iteration [8253]: Loss = 0.7105274796485901
Iteration [8254]: Loss = 0.7105188965797424
Iteration [8255]: Loss = 0.7104907631874084
Iteration [8256]: Loss = 0.7104450464248657
Iteration [8257]: Loss = 0.7103836536407471
Iteration [8258]: Loss = 0.7103078365325928
Iteration [8259]: Loss = 0.7102193236351013
Iteration [8260]: Loss = 0.7101191878318787
Iteration [8261]: Loss = 0.7100087404251099
Iteration [8262]: Loss = 0.7098888158798218
Iteration [8263]: Loss = 0.7097604274749756
Iteration [8264]: Loss = 4.8961286544799805
Iteration [8265]: Loss = 4.896220684051514
Iteration [8266]: Loss = 0.7096941471099854
Iteration [8267]: Loss = 0.7097526788711548
Iteration [8268]: Loss = 0.7097850441932678
Iteration [8269]: Loss = 0.7097939252853394
Iteration [8270]: Loss = 0.7097814083099365
Iteration [8271]: Loss = 0.7097499370574951
Iteration [8272]: Loss = 0.7097011804580688
Iteration [8273]: Loss = 0.7096368074417114
Iteration [8274]: Loss = 0.7095585465431213
Iteration [8275]: Loss = 0.7094676494598389
Iteration [8276]: Loss = 0.7093655467033386
Iteration [8277]: Loss = 0.709253191947937
Iteration [8278]: Loss = 0.7091315984725952
Iteration [8279]: Loss = 0.709001898765564
Iteration [8280]: Loss = 0.708864688873291
Iteration [8281]: Loss = 0.7087208032608032
Iteration [8282]: Loss = 0.7085707783699036
Iteration [8283]: Loss = 0.7084155082702637
Iteration [8284]: Loss = 0.7082552313804626
Iteration [8285]: Loss = 0.7080907821655273
Iteration [8286]: Loss = 0.707922101020813
Iteration [8287]: Loss = 0.7077500820159912
Iteration [8288]: Loss = 0.7075748443603516
Iteration [8289]: Loss = 4.907545566558838
Iteration [8290]: Loss = 0.707341194152832
Iteration [8291]: Loss = 0.7072708010673523
Iteration [8292]: Loss = 0.7071871757507324
Iteration [8293]: Loss = 0.7070915699005127
Iteration [8294]: Loss = 0.7069850564002991
Iteration [8295]: Loss = 0.7068687677383423
Iteration [8296]: Loss = 0.7067439556121826
Iteration [8297]: Loss = 4.911585807800293
Iteration [8298]: Loss = 0.706596314907074
Iteration [8299]: Loss = 0.7065626978874207
Iteration [8300]: Loss = 0.7065120935440063
Iteration [8301]: Loss = 0.7064462304115295
Iteration [8302]: Loss = 0.7063666582107544
Iteration [8303]: Loss = 0.7062745690345764
Iteration [8304]: Loss = 0.7061715722084045
Iteration [8305]: Loss = 0.7060583829879761
Iteration [8306]: Loss = 0.7059361934661865
Iteration [8307]: Loss = 4.915735244750977
Iteration [8308]: Loss = 0.7057933807373047
Iteration [8309]: Loss = 0.7057618498802185
Iteration [8310]: Loss = 0.7057130932807922
Iteration [8311]: Loss = 0.7056490182876587
Iteration [8312]: Loss = 4.9169464111328125
Iteration [8313]: Loss = 0.7056055068969727
Iteration [8314]: Loss = 0.7056161761283875
Iteration [8315]: Loss = 4.916767597198486
Iteration [8316]: Loss = 0.7057005167007446
Iteration [8317]: Loss = 0.7057658433914185
Iteration [8318]: Loss = 0.7058043479919434
Iteration [8319]: Loss = 4.915668964385986
Iteration [8320]: Loss = 0.705936074256897
Iteration [8321]: Loss = 0.7060215473175049
Iteration [8322]: Loss = 0.7060782313346863
Iteration [8323]: Loss = 0.7061088681221008
Iteration [8324]: Loss = 0.706116259098053
Iteration [8325]: Loss = 4.914206027984619
Iteration [8326]: Loss = 0.7061947584152222
Iteration [8327]: Loss = 0.7062575817108154
Iteration [8328]: Loss = 0.7062936425209045
Iteration [8329]: Loss = 0.706305980682373
Iteration [8330]: Loss = 0.7062966823577881
Iteration [8331]: Loss = 0.7062679529190063
Iteration [8332]: Loss = 4.9135918617248535
Iteration [8333]: Loss = 0.7062849998474121
Iteration [8334]: Loss = 0.7063214778900146
Iteration [8335]: Loss = 0.7063339948654175
Iteration [8336]: Loss = 4.913059234619141
Iteration [8337]: Loss = 0.7064214944839478
Iteration [8338]: Loss = 0.7064880132675171
Iteration [8339]: Loss = 0.7065277695655823
Iteration [8340]: Loss = 0.7065430283546448
Iteration [8341]: Loss = 0.7065363526344299
Iteration [8342]: Loss = 0.7065101265907288
Iteration [8343]: Loss = 0.7064661979675293
Iteration [8344]: Loss = 4.912641525268555
Iteration [8345]: Loss = 0.7064568400382996
Iteration [8346]: Loss = 0.7064823508262634
Iteration [8347]: Loss = 0.7064849138259888
Iteration [8348]: Loss = 0.706466794013977
Iteration [8349]: Loss = 0.706430196762085
Iteration [8350]: Loss = 0.7063767910003662
Iteration [8351]: Loss = 0.7063083052635193
Iteration [8352]: Loss = 0.7062262892723083
Iteration [8353]: Loss = 4.914053440093994
Iteration [8354]: Loss = 0.7061522603034973
Iteration [8355]: Loss = 0.7061500549316406
Iteration [8356]: Loss = 4.91407585144043
Iteration [8357]: Loss = 4.913639068603516
Iteration [8358]: Loss = 0.7063934206962585
Iteration [8359]: Loss = 0.7065358757972717
Iteration [8360]: Loss = 0.7066439986228943
Iteration [8361]: Loss = 4.9110212326049805
Iteration [8362]: Loss = 0.7068947553634644
Iteration [8363]: Loss = 0.7070308923721313
Iteration [8364]: Loss = 0.7071331143379211
Iteration [8365]: Loss = 0.7072048187255859
Iteration [8366]: Loss = 0.7072489261627197
Iteration [8367]: Loss = 0.7072684168815613
Iteration [8368]: Loss = 4.908221244812012
Iteration [8369]: Loss = 0.7073674201965332
Iteration [8370]: Loss = 0.7074388861656189
Iteration [8371]: Loss = 0.7080960869789124
Iteration [8372]: Loss = 0.7081152200698853
Iteration [8373]: Loss = 0.7081119418144226
Iteration [8374]: Loss = 0.7080884575843811
Iteration [8375]: Loss = 0.7080469727516174
Iteration [8376]: Loss = 0.7079890370368958
Iteration [8377]: Loss = 4.90487813949585
Iteration [8378]: Loss = 0.7079560160636902
Iteration [8379]: Loss = 0.7079713344573975
Iteration [8380]: Loss = 0.7079645991325378
Iteration [8381]: Loss = 0.7079380750656128
Iteration [8382]: Loss = 0.7078937888145447
Iteration [8383]: Loss = 4.910016059875488
Iteration [8384]: Loss = 4.909753322601318
Iteration [8385]: Loss = 0.7071177959442139
Iteration [8386]: Loss = 0.7072330713272095
Iteration [8387]: Loss = 0.7073162794113159
Iteration [8388]: Loss = 0.707370936870575
Iteration [8389]: Loss = 0.7073996067047119
Iteration [8390]: Loss = 0.7074050307273865
Iteration [8391]: Loss = 0.7073894739151001
Iteration [8392]: Loss = 0.7073548436164856
Iteration [8393]: Loss = 0.7073033452033997
Iteration [8394]: Loss = 0.7072363495826721
Iteration [8395]: Loss = 0.7071557641029358
Iteration [8396]: Loss = 0.7070625424385071
Iteration [8397]: Loss = 0.7069582343101501
Iteration [8398]: Loss = 4.910389423370361
Iteration [8399]: Loss = 0.7068461775779724
Iteration [8400]: Loss = 0.7068278193473816
Iteration [8401]: Loss = 0.7067909240722656
Iteration [8402]: Loss = 0.7067371606826782
Iteration [8403]: Loss = 0.7066683173179626
Iteration [8404]: Loss = 0.7065858840942383
Iteration [8405]: Loss = 0.7064911723136902
Iteration [8406]: Loss = 0.7063853740692139
Iteration [8407]: Loss = 0.7062696218490601
Iteration [8408]: Loss = 0.7061449885368347
Iteration [8409]: Loss = 9.123329162597656
Iteration [8410]: Loss = 0.7061234712600708
Iteration [8411]: Loss = 0.7062032222747803
Iteration [8412]: Loss = 0.706254780292511
Iteration [8413]: Loss = 0.7062808871269226
Iteration [8414]: Loss = 4.913269996643066
Iteration [8415]: Loss = 0.7063913941383362
Iteration [8416]: Loss = 0.706467866897583
Iteration [8417]: Loss = 0.7065163254737854
Iteration [8418]: Loss = 0.7065396308898926
Iteration [8419]: Loss = 0.7065403461456299
Iteration [8420]: Loss = 0.7065205574035645
Iteration [8421]: Loss = 0.7064823508262634
Iteration [8422]: Loss = 0.7064276337623596
Iteration [8423]: Loss = 0.7063579559326172
Iteration [8424]: Loss = 0.7062748074531555
Iteration [8425]: Loss = 4.913808345794678
Iteration [8426]: Loss = 0.7061989903450012
Iteration [8427]: Loss = 0.7061959505081177
Iteration [8428]: Loss = 0.7061729431152344
Iteration [8429]: Loss = 0.7061318159103394
Iteration [8430]: Loss = 0.7060744762420654
Iteration [8431]: Loss = 0.7060023546218872
Iteration [8432]: Loss = 0.705917239189148
Iteration [8433]: Loss = 0.7058200836181641
Iteration [8434]: Loss = 0.7057122588157654
Iteration [8435]: Loss = 0.7055947780609131
Iteration [8436]: Loss = 0.7054686546325684
Iteration [8437]: Loss = 0.7053347229957581
Iteration [8438]: Loss = 0.7051939368247986
Iteration [8439]: Loss = 0.7050465941429138
Iteration [8440]: Loss = 0.7048937082290649
Iteration [8441]: Loss = 0.7047356367111206
Iteration [8442]: Loss = 0.7045729756355286
Iteration [8443]: Loss = 0.704406201839447
Iteration [8444]: Loss = 0.7042357921600342
Iteration [8445]: Loss = 0.7040618658065796
Iteration [8446]: Loss = 4.925663471221924
Iteration [8447]: Loss = 0.7038314342498779
Iteration [8448]: Loss = 0.7031607627868652
Iteration [8449]: Loss = 0.7030789256095886
Iteration [8450]: Loss = 0.7029848694801331
Iteration [8451]: Loss = 0.7028799057006836
Iteration [8452]: Loss = 0.7027652263641357
Iteration [8453]: Loss = 9.161588668823242
Iteration [8454]: Loss = 0.7027603983879089
Iteration [8455]: Loss = 0.7028473019599915
Iteration [8456]: Loss = 0.7029054164886475
Iteration [8457]: Loss = 0.702937662601471
Iteration [8458]: Loss = 0.7029464840888977
Iteration [8459]: Loss = 0.7029343247413635
Iteration [8460]: Loss = 0.702903151512146
Iteration [8461]: Loss = 0.7028548717498779
Iteration [8462]: Loss = 0.7027912139892578
Iteration [8463]: Loss = 0.7027137875556946
Iteration [8464]: Loss = 0.7026239037513733
Iteration [8465]: Loss = 0.7025226950645447
Iteration [8466]: Loss = 0.7024115324020386
Iteration [8467]: Loss = 0.7022911906242371
Iteration [8468]: Loss = 4.934604644775391
Iteration [8469]: Loss = 0.7021520137786865
Iteration [8470]: Loss = 4.934814453125
Iteration [8471]: Loss = 0.7022002339363098
Iteration [8472]: Loss = 0.7022504210472107
Iteration [8473]: Loss = 0.7022752165794373
Iteration [8474]: Loss = 0.7022776007652283
Iteration [8475]: Loss = 4.93410062789917
Iteration [8476]: Loss = 4.933640003204346
Iteration [8477]: Loss = 0.7025319933891296
Iteration [8478]: Loss = 0.7026777267456055
Iteration [8479]: Loss = 0.7027885913848877
Iteration [8480]: Loss = 4.930936336517334
Iteration [8481]: Loss = 0.7030447125434875
Iteration [8482]: Loss = 4.929301738739014
Iteration [8483]: Loss = 0.7034123539924622
Iteration [8484]: Loss = 4.927148342132568
Iteration [8485]: Loss = 0.7038701176643372
Iteration [8486]: Loss = 0.7040947675704956
Iteration [8487]: Loss = 0.7042767405509949
Iteration [8488]: Loss = 9.141363143920898
Iteration [8489]: Loss = 4.921053886413574
Iteration [8490]: Loss = 0.7051988840103149
Iteration [8491]: Loss = 9.128449440002441
Iteration [8492]: Loss = 0.706106960773468
Iteration [8493]: Loss = 4.911745548248291
Iteration [8494]: Loss = 0.7071080803871155
Iteration [8495]: Loss = 0.7075639367103577
Iteration [8496]: Loss = 0.7079546451568604
Iteration [8497]: Loss = 0.7082865834236145
Iteration [8498]: Loss = 0.7085655927658081
Iteration [8499]: Loss = 0.7087968587875366
Iteration [8500]: Loss = 0.708984911441803
Iteration [8501]: Loss = 0.7091342806816101
Iteration [8502]: Loss = 0.709248423576355
Iteration [8503]: Loss = 0.709331214427948
Iteration [8504]: Loss = 0.7093856334686279
Iteration [8505]: Loss = 0.7094142436981201
Iteration [8506]: Loss = 0.7094199061393738
Iteration [8507]: Loss = 0.7094048857688904
Iteration [8508]: Loss = 0.7093709707260132
Iteration [8509]: Loss = 0.7093203067779541
Iteration [8510]: Loss = 4.898021697998047
Iteration [8511]: Loss = 0.7092986106872559
Iteration [8512]: Loss = 0.7093181610107422
Iteration [8513]: Loss = 4.897708415985107
Iteration [8514]: Loss = 0.709416389465332
Iteration [8515]: Loss = 0.7094870805740356
Iteration [8516]: Loss = 0.7095305323600769
Iteration [8517]: Loss = 0.7095494866371155
Iteration [8518]: Loss = 0.7095462083816528
Iteration [8519]: Loss = 4.8966474533081055
Iteration [8520]: Loss = 0.7096054553985596
Iteration [8521]: Loss = 0.7096596360206604
Iteration [8522]: Loss = 0.7096879482269287
Iteration [8523]: Loss = 0.7096933126449585
Iteration [8524]: Loss = 0.7096779346466064
Iteration [8525]: Loss = 0.7096438407897949
Iteration [8526]: Loss = 0.7095928192138672
Iteration [8527]: Loss = 0.7095266580581665
Iteration [8528]: Loss = 0.7094468474388123
Iteration [8529]: Loss = 4.8975090980529785
Iteration [8530]: Loss = 0.7093753218650818
Iteration [8531]: Loss = 0.7093737721443176
Iteration [8532]: Loss = 0.7093520760536194
Iteration [8533]: Loss = 0.7093123197555542
Iteration [8534]: Loss = 0.709256112575531
Iteration [8535]: Loss = 0.7091853618621826
Iteration [8536]: Loss = 0.7091014385223389
Iteration [8537]: Loss = 4.899295330047607
Iteration [8538]: Loss = 0.7090229392051697
Iteration [8539]: Loss = 0.7090184688568115
Iteration [8540]: Loss = 0.7089940309524536
Iteration [8541]: Loss = 4.899569034576416
Iteration [8542]: Loss = 0.7090175151824951
Iteration [8543]: Loss = 0.7090564966201782
Iteration [8544]: Loss = 0.7090712785720825
Iteration [8545]: Loss = 0.709064245223999
Iteration [8546]: Loss = 0.709037721157074
Iteration [8547]: Loss = 0.7089934945106506
Iteration [8548]: Loss = 0.7089334726333618
Iteration [8549]: Loss = 0.7088590860366821
Iteration [8550]: Loss = 0.7087717652320862
Iteration [8551]: Loss = 4.900998115539551
Iteration [8552]: Loss = 0.7086880207061768
Iteration [8553]: Loss = 0.7086812257766724
Iteration [8554]: Loss = 0.7086548209190369
Iteration [8555]: Loss = 0.7086108922958374
Iteration [8556]: Loss = 4.901622772216797
Iteration [8557]: Loss = 0.7086008191108704
Iteration [8558]: Loss = 0.7086254954338074
Iteration [8559]: Loss = 0.708627462387085
Iteration [8560]: Loss = 0.7086089849472046
Iteration [8561]: Loss = 0.7085720300674438
Iteration [8562]: Loss = 0.7085185050964355
Iteration [8563]: Loss = 0.7084499597549438
Iteration [8564]: Loss = 0.7083680629730225
Iteration [8565]: Loss = 0.7082738876342773
Iteration [8566]: Loss = 0.7081688046455383
Iteration [8567]: Loss = 0.7080540060997009
Iteration [8568]: Loss = 4.904806613922119
Iteration [8569]: Loss = 0.707923173904419
Iteration [8570]: Loss = 0.7078964710235596
Iteration [8571]: Loss = 0.7078521251678467
Iteration [8572]: Loss = 0.7077919244766235
Iteration [8573]: Loss = 0.7077174186706543
Iteration [8574]: Loss = 0.7076300978660583
Iteration [8575]: Loss = 0.7075311541557312
Iteration [8576]: Loss = 0.7074218392372131
Iteration [8577]: Loss = 0.7073031067848206
Iteration [8578]: Loss = 4.9086809158325195
Iteration [8579]: Loss = 0.7071657776832581
Iteration [8580]: Loss = 0.7071363925933838
Iteration [8581]: Loss = 0.7070896625518799
Iteration [8582]: Loss = 0.7070273756980896
Iteration [8583]: Loss = 0.7069509625434875
Iteration [8584]: Loss = 0.7068617939949036
Iteration [8585]: Loss = 0.706761360168457
Iteration [8586]: Loss = 0.7066506743431091
Iteration [8587]: Loss = 0.7065305709838867
Iteration [8588]: Loss = 4.912660598754883
Iteration [8589]: Loss = 0.7063912749290466
Iteration [8590]: Loss = 0.7063611745834351
Iteration [8591]: Loss = 4.913117408752441
Iteration [8592]: Loss = 0.7063754200935364
Iteration [8593]: Loss = 0.7064105868339539
Iteration [8594]: Loss = 9.118695259094238
Iteration [8595]: Loss = 0.7066591382026672
Iteration [8596]: Loss = 0.7068524360656738
Iteration [8597]: Loss = 4.909552097320557
Iteration [8598]: Loss = 0.7072482109069824
Iteration [8599]: Loss = 0.7074459195137024
Iteration [8600]: Loss = 4.906482219696045
Iteration [8601]: Loss = 0.7078489065170288
Iteration [8602]: Loss = 0.7080496549606323
Iteration [8603]: Loss = 0.7082102298736572
Iteration [8604]: Loss = 0.7083346247673035
Iteration [8605]: Loss = 0.7084265947341919
Iteration [8606]: Loss = 0.7084890604019165
Iteration [8607]: Loss = 0.7085253000259399
Iteration [8608]: Loss = 0.7085375189781189
Iteration [8609]: Loss = 0.7085282802581787
Iteration [8610]: Loss = 0.7084998488426208
Iteration [8611]: Loss = 0.7084538340568542
Iteration [8612]: Loss = 0.7083923816680908
Iteration [8613]: Loss = 0.7083166241645813
Iteration [8614]: Loss = 0.7082282304763794
Iteration [8615]: Loss = 0.7081282734870911
Iteration [8616]: Loss = 4.904355049133301
Iteration [8617]: Loss = 0.7080228924751282
Iteration [8618]: Loss = 0.7080070376396179
Iteration [8619]: Loss = 0.7079724669456482
Iteration [8620]: Loss = 9.101787567138672
Iteration [8621]: Loss = 0.708101212978363
Iteration [8622]: Loss = 0.7082433700561523
Iteration [8623]: Loss = 4.902646541595459
Iteration [8624]: Loss = 9.09469223022461
Iteration [8625]: Loss = 0.708953320980072
Iteration [8626]: Loss = 0.7092957496643066
Iteration [8627]: Loss = 0.7095842361450195
Iteration [8628]: Loss = 4.895109176635742
Iteration [8629]: Loss = 0.7101418375968933
Iteration [8630]: Loss = 0.7104079127311707
Iteration [8631]: Loss = 0.7106276750564575
Iteration [8632]: Loss = 0.7108055353164673
Iteration [8633]: Loss = 0.710945725440979
Iteration [8634]: Loss = 0.7110517621040344
Iteration [8635]: Loss = 4.888461589813232
Iteration [8636]: Loss = 0.711297333240509
Iteration [8637]: Loss = 0.7114303708076477
Iteration [8638]: Loss = 0.7115300297737122
Iteration [8639]: Loss = 9.060511589050293
Iteration [8640]: Loss = 0.7118849158287048
Iteration [8641]: Loss = 0.7121217846870422
Iteration [8642]: Loss = 4.882418632507324
Iteration [8643]: Loss = 0.7125905752182007
Iteration [8644]: Loss = 0.7128185033798218
Iteration [8645]: Loss = 0.7130038738250732
Iteration [8646]: Loss = 0.7131506204605103
Iteration [8647]: Loss = 0.7132629156112671
Iteration [8648]: Loss = 0.7133438587188721
Iteration [8649]: Loss = 0.7133967280387878
Iteration [8650]: Loss = 0.7134239673614502
Iteration [8651]: Loss = 0.7134285569190979
Iteration [8652]: Loss = 0.7134125232696533
Iteration [8653]: Loss = 0.7133779525756836
Iteration [8654]: Loss = 4.877286911010742
Iteration [8655]: Loss = 0.7133824825286865
Iteration [8656]: Loss = 0.7134126424789429
Iteration [8657]: Loss = 0.7134196758270264
Iteration [8658]: Loss = 0.713405966758728
Iteration [8659]: Loss = 0.7133733630180359
Iteration [8660]: Loss = 4.8773016929626465
Iteration [8661]: Loss = 0.7133813500404358
Iteration [8662]: Loss = 0.7134130001068115
Iteration [8663]: Loss = 0.7134212851524353
Iteration [8664]: Loss = 4.876871585845947
Iteration [8665]: Loss = 0.7134993672370911
Iteration [8666]: Loss = 0.7135607004165649
Iteration [8667]: Loss = 9.038248062133789
Iteration [8668]: Loss = 0.7138497233390808
Iteration [8669]: Loss = 0.7140581607818604
Iteration [8670]: Loss = 0.7142259478569031
Iteration [8671]: Loss = 0.7143570780754089
Iteration [8672]: Loss = 0.7144550085067749
Iteration [8673]: Loss = 4.871231555938721
Iteration [8674]: Loss = 0.7146856784820557
Iteration [8675]: Loss = 0.7148120999336243
Iteration [8676]: Loss = 0.7149057984352112
Iteration [8677]: Loss = 0.7149701118469238
Iteration [8678]: Loss = 0.7150079011917114
Iteration [8679]: Loss = 0.7150217890739441
Iteration [8680]: Loss = 4.8687520027160645
Iteration [8681]: Loss = 0.7151087522506714
Iteration [8682]: Loss = 0.7151738405227661
Iteration [8683]: Loss = 4.8677520751953125
Iteration [8684]: Loss = 0.7153482437133789
Iteration [8685]: Loss = 0.715450644493103
Iteration [8686]: Loss = 0.7155227065086365
Iteration [8687]: Loss = 4.865960597991943
Iteration [8688]: Loss = 0.7157090902328491
Iteration [8689]: Loss = 0.7158164978027344
Iteration [8690]: Loss = 0.7158932089805603
Iteration [8691]: Loss = 0.7159420251846313
Iteration [8692]: Loss = 0.715965747833252
Iteration [8693]: Loss = 0.7159669995307922
Iteration [8694]: Loss = 0.7159478664398193
Iteration [8695]: Loss = 0.7159103155136108
Iteration [8696]: Loss = 0.7262147665023804
Iteration [8697]: Loss = 0.7157844305038452
Iteration [8698]: Loss = 0.7156994938850403
Iteration [8699]: Loss = 0.7156025171279907
Iteration [8700]: Loss = 0.7154951095581055
Iteration [8701]: Loss = 4.86691427230835
Iteration [8702]: Loss = 4.866931438446045
Iteration [8703]: Loss = 0.7154738306999207
Iteration [8704]: Loss = 0.7155425548553467
Iteration [8705]: Loss = 0.715584397315979
Iteration [8706]: Loss = 0.7156016826629639
Iteration [8707]: Loss = 0.7155971527099609
Iteration [8708]: Loss = 4.865932941436768
Iteration [8709]: Loss = 0.7156528234481812
Iteration [8710]: Loss = 0.715704619884491
Iteration [8711]: Loss = 0.7157310247421265
Iteration [8712]: Loss = 0.715734601020813
Iteration [8713]: Loss = 0.7157174944877625
Iteration [8714]: Loss = 0.7156819105148315
Iteration [8715]: Loss = 0.7156295776367188
Iteration [8716]: Loss = 4.865986347198486
Iteration [8717]: Loss = 0.715603768825531
Iteration [8718]: Loss = 4.865691661834717
Iteration [8719]: Loss = 0.7157379984855652
Iteration [8720]: Loss = 0.715823233127594
Iteration [8721]: Loss = 0.7158799171447754
Iteration [8722]: Loss = 0.7159106731414795
Iteration [8723]: Loss = 4.864193916320801
Iteration [8724]: Loss = 4.863646984100342
Iteration [8725]: Loss = 4.862643718719482
Iteration [8726]: Loss = 0.7165066003799438
Iteration [8727]: Loss = 0.7167391777038574
Iteration [8728]: Loss = 4.859109401702881
Iteration [8729]: Loss = 4.857743740081787
Iteration [8730]: Loss = 0.7175464630126953
Iteration [8731]: Loss = 0.7178378105163574
Iteration [8732]: Loss = 0.7180800437927246
Iteration [8733]: Loss = 0.7182779312133789
Iteration [8734]: Loss = 0.7184358835220337
Iteration [8735]: Loss = 0.7185577154159546
Iteration [8736]: Loss = 0.7186470627784729
Iteration [8737]: Loss = 0.7187072038650513
Iteration [8738]: Loss = 0.7187409400939941
Iteration [8739]: Loss = 0.7187510132789612
Iteration [8740]: Loss = 0.7187396287918091
Iteration [8741]: Loss = 0.7187090516090393
Iteration [8742]: Loss = 4.850420951843262
Iteration [8743]: Loss = 0.7187197804450989
Iteration [8744]: Loss = 0.7187524437904358
Iteration [8745]: Loss = 0.7187613844871521
Iteration [8746]: Loss = 0.7187491655349731
Iteration [8747]: Loss = 0.7187175750732422
Iteration [8748]: Loss = 0.7186688184738159
Iteration [8749]: Loss = 4.850704193115234
Iteration [8750]: Loss = 0.7186486124992371
Iteration [8751]: Loss = 0.7186680436134338
Iteration [8752]: Loss = 0.7186651229858398
Iteration [8753]: Loss = 0.7186421155929565
Iteration [8754]: Loss = 0.7186009287834167
Iteration [8755]: Loss = 0.7185433506965637
Iteration [8756]: Loss = 0.7184712290763855
Iteration [8757]: Loss = 0.7183857560157776
Iteration [8758]: Loss = 0.7182884216308594
Iteration [8759]: Loss = 0.718180239200592
Iteration [8760]: Loss = 0.7180625200271606
Iteration [8761]: Loss = 0.7179360389709473
Iteration [8762]: Loss = 0.7178017497062683
Iteration [8763]: Loss = 0.7176604270935059
Iteration [8764]: Loss = 0.7175127267837524
Iteration [8765]: Loss = 0.7173593044281006
Iteration [8766]: Loss = 0.7172008156776428
Iteration [8767]: Loss = 0.7170377969741821
Iteration [8768]: Loss = 0.7168705463409424
Iteration [8769]: Loss = 0.7166995406150818
Iteration [8770]: Loss = 0.716525137424469
Iteration [8771]: Loss = 0.716347873210907
Iteration [8772]: Loss = 0.7161678075790405
Iteration [8773]: Loss = 0.7159851789474487
Iteration [8774]: Loss = 4.864785671234131
Iteration [8775]: Loss = 0.7157374024391174
Iteration [8776]: Loss = 0.7156600952148438
Iteration [8777]: Loss = 0.7155699729919434
Iteration [8778]: Loss = 0.7154685854911804
Iteration [8779]: Loss = 0.7153568863868713
Iteration [8780]: Loss = 4.867631912231445
Iteration [8781]: Loss = 4.86766242980957
Iteration [8782]: Loss = 0.7153271436691284
Iteration [8783]: Loss = 0.7153943181037903
Iteration [8784]: Loss = 0.7154344320297241
Iteration [8785]: Loss = 0.7154502868652344
Iteration [8786]: Loss = 0.7154440879821777
Iteration [8787]: Loss = 0.7154181003570557
Iteration [8788]: Loss = 0.7153743505477905
Iteration [8789]: Loss = 4.8672356605529785
Iteration [8790]: Loss = 0.715363621711731
Iteration [8791]: Loss = 4.86686897277832
Iteration [8792]: Loss = 0.7155112028121948
Iteration [8793]: Loss = 0.7156023979187012
Iteration [8794]: Loss = 0.7156642079353333
Iteration [8795]: Loss = 4.865294456481934
Iteration [8796]: Loss = 0.7158337235450745
Iteration [8797]: Loss = 0.7159343361854553
Iteration [8798]: Loss = 0.7160044312477112
Iteration [8799]: Loss = 0.7160471677780151
Iteration [8800]: Loss = 4.8634514808654785
Iteration [8801]: Loss = 0.7161842584609985
Iteration [8802]: Loss = 0.7162708640098572
Iteration [8803]: Loss = 0.7163284420967102
Iteration [8804]: Loss = 0.7163599133491516
Iteration [8805]: Loss = 0.7163678407669067
Iteration [8806]: Loss = 0.716354489326477
Iteration [8807]: Loss = 0.716322124004364
Iteration [8808]: Loss = 0.7162724733352661
Iteration [8809]: Loss = 0.7162073254585266
Iteration [8810]: Loss = 0.7161281108856201
Iteration [8811]: Loss = 0.7160364389419556
Iteration [8812]: Loss = 0.7159333825111389
Iteration [8813]: Loss = 4.864686965942383
Iteration [8814]: Loss = 0.715821385383606
Iteration [8815]: Loss = 0.715802013874054
Iteration [8816]: Loss = 0.7157641053199768
Iteration [8817]: Loss = 0.7157095670700073
Iteration [8818]: Loss = 0.7156400680541992
Iteration [8819]: Loss = 0.7155569195747375
Iteration [8820]: Loss = 0.7154617309570312
Iteration [8821]: Loss = 0.7153554558753967
Iteration [8822]: Loss = 0.7152392864227295
Iteration [8823]: Loss = 0.7151143550872803
Iteration [8824]: Loss = 0.7149813175201416
Iteration [8825]: Loss = 0.7148412466049194
Iteration [8826]: Loss = 0.7146945595741272
Iteration [8827]: Loss = 0.7145420908927917
Iteration [8828]: Loss = 0.7143843770027161
Iteration [8829]: Loss = 4.872754096984863
Iteration [8830]: Loss = 0.7141793370246887
Iteration [8831]: Loss = 0.7141205072402954
Iteration [8832]: Loss = 0.7140471339225769
Iteration [8833]: Loss = 0.713960587978363
Iteration [8834]: Loss = 0.7138622403144836
Iteration [8835]: Loss = 0.713753342628479
Iteration [8836]: Loss = 0.7136347889900208
Iteration [8837]: Loss = 0.7135076522827148
Iteration [8838]: Loss = 0.7133728861808777
Iteration [8839]: Loss = 0.7132310271263123
Iteration [8840]: Loss = 0.7130829095840454
Iteration [8841]: Loss = 0.7129290699958801
Iteration [8842]: Loss = 4.88010835647583
Iteration [8843]: Loss = 0.7127310037612915
Iteration [8844]: Loss = 0.7126752138137817
Iteration [8845]: Loss = 0.7126047015190125
Iteration [8846]: Loss = 0.7125207185745239
Iteration [8847]: Loss = 0.7124248743057251
Iteration [8848]: Loss = 0.7123180031776428
Iteration [8849]: Loss = 0.7122013568878174
Iteration [8850]: Loss = 0.7120761275291443
Iteration [8851]: Loss = 0.7119428515434265
Iteration [8852]: Loss = 0.7118024230003357
Iteration [8853]: Loss = 4.88577127456665
Iteration [8854]: Loss = 0.7116274237632751
Iteration [8855]: Loss = 0.7115815281867981
Iteration [8856]: Loss = 0.7115199565887451
Iteration [8857]: Loss = 0.7114441990852356
Iteration [8858]: Loss = 0.7113555669784546
Iteration [8859]: Loss = 0.7112553119659424
Iteration [8860]: Loss = 0.7111446261405945
Iteration [8861]: Loss = 0.7110247015953064
Iteration [8862]: Loss = 0.7108961939811707
Iteration [8863]: Loss = 0.7107602953910828
Iteration [8864]: Loss = 4.891058444976807
Iteration [8865]: Loss = 0.7105928659439087
Iteration [8866]: Loss = 4.8914008140563965
Iteration [8867]: Loss = 0.7106161713600159
Iteration [8868]: Loss = 0.7106548547744751
Iteration [8869]: Loss = 0.7106694579124451
Iteration [8870]: Loss = 0.7106621265411377
Iteration [8871]: Loss = 0.7106351256370544
Iteration [8872]: Loss = 0.7105904817581177
Iteration [8873]: Loss = 0.7105299234390259
Iteration [8874]: Loss = 0.7104549407958984
Iteration [8875]: Loss = 0.7103671431541443
Iteration [8876]: Loss = 0.7102677226066589
Iteration [8877]: Loss = 0.7101577520370483
Iteration [8878]: Loss = 0.710038423538208
Iteration [8879]: Loss = 0.70991051197052
Iteration [8880]: Loss = 0.7097750306129456
Iteration [8881]: Loss = 4.896087646484375
Iteration [8882]: Loss = 0.7096088528633118
Iteration [8883]: Loss = 0.7095670104026794
Iteration [8884]: Loss = 0.709509015083313
Iteration [8885]: Loss = 4.897091388702393
Iteration [8886]: Loss = 0.709475040435791
Iteration [8887]: Loss = 0.7094895839691162
Iteration [8888]: Loss = 0.7094824314117432
Iteration [8889]: Loss = 4.896993637084961
Iteration [8890]: Loss = 0.7095353007316589
Iteration [8891]: Loss = 0.7095867991447449
Iteration [8892]: Loss = 0.7096128463745117
Iteration [8893]: Loss = 0.7096158862113953
Iteration [8894]: Loss = 0.7095983028411865
Iteration [8895]: Loss = 0.7095620632171631
Iteration [8896]: Loss = 0.709509015083313
Iteration [8897]: Loss = 0.7094408869743347
Iteration [8898]: Loss = 0.7093591094017029
Iteration [8899]: Loss = 0.7092652320861816
Iteration [8900]: Loss = 0.7091602087020874
Iteration [8901]: Loss = 0.7090452313423157
Iteration [8902]: Loss = 0.7089213132858276
Iteration [8903]: Loss = 0.7087894678115845
Iteration [8904]: Loss = 0.7086503505706787
Iteration [8905]: Loss = 0.7085045576095581
Iteration [8906]: Loss = 4.902637004852295
Iteration [8907]: Loss = 0.7083213329315186
Iteration [8908]: Loss = 4.903050899505615
Iteration [8909]: Loss = 0.7083327174186707
Iteration [8910]: Loss = 0.7083665728569031
Iteration [8911]: Loss = 0.7083768844604492
Iteration [8912]: Loss = 4.902573585510254
Iteration [8913]: Loss = 0.7084597945213318
Iteration [8914]: Loss = 0.7085242867469788
Iteration [8915]: Loss = 0.7085619568824768
Iteration [8916]: Loss = 4.901496410369873
Iteration [8917]: Loss = 0.7086921334266663
Iteration [8918]: Loss = 0.7087764739990234
Iteration [8919]: Loss = 4.900182247161865
Iteration [8920]: Loss = 4.899393081665039
Iteration [8921]: Loss = 0.7092289924621582
Iteration [8922]: Loss = 4.897137641906738
Iteration [8923]: Loss = 4.895694732666016
Iteration [8924]: Loss = 0.7100667953491211
Iteration [8925]: Loss = 0.7103683948516846
Iteration [8926]: Loss = 0.7106196880340576
Iteration [8927]: Loss = 4.889997482299805
Iteration [8928]: Loss = 4.888525485992432
Iteration [8929]: Loss = 0.7114783525466919
Iteration [8930]: Loss = 0.7117855548858643
Iteration [8931]: Loss = 0.7120417356491089
Iteration [8932]: Loss = 0.7122520208358765
Iteration [8933]: Loss = 0.7124210596084595
Iteration [8934]: Loss = 4.8812127113342285
Iteration [8935]: Loss = 0.7127750515937805
Iteration [8936]: Loss = 9.045390129089355
Iteration [8937]: Loss = 0.7133413553237915
Iteration [8938]: Loss = 4.87554931640625
Iteration [8939]: Loss = 0.7158780097961426
Iteration [8940]: Loss = 0.7148728370666504
Iteration [8941]: Loss = 0.7146673202514648
Iteration [8942]: Loss = 0.7142021059989929
Iteration [8943]: Loss = 0.7146315574645996
Iteration [8944]: Loss = 0.7151985168457031
Iteration [8945]: Loss = 0.7102102041244507
Iteration [8946]: Loss = 0.7092595100402832
Iteration [8947]: Loss = 0.708242654800415
Iteration [8948]: Loss = 4.908695697784424
Iteration [8949]: Loss = 0.7073054313659668
Iteration [8950]: Loss = 0.7073109745979309
Iteration [8951]: Loss = 0.7072045803070068
Iteration [8952]: Loss = 0.706999659538269
Iteration [8953]: Loss = 0.7067079544067383
Iteration [8954]: Loss = 0.706339955329895
Iteration [8955]: Loss = 0.7059045433998108
Iteration [8956]: Loss = 4.917775630950928
Iteration [8957]: Loss = 0.7055076360702515
Iteration [8958]: Loss = 0.705507755279541
Iteration [8959]: Loss = 0.7054211497306824
Iteration [8960]: Loss = 0.7052572965621948
Iteration [8961]: Loss = 0.7050248384475708
Iteration [8962]: Loss = 4.921284198760986
Iteration [8963]: Loss = 0.7048928141593933
Iteration [8964]: Loss = 4.920091152191162
Iteration [8965]: Loss = 0.7053810358047485
Iteration [8966]: Loss = 0.7056879997253418
Iteration [8967]: Loss = 0.7058941721916199
Iteration [8968]: Loss = 0.7060102224349976
Iteration [8969]: Loss = 0.706045389175415
Iteration [8970]: Loss = 4.914693355560303
Iteration [8971]: Loss = 4.913134574890137
Iteration [8972]: Loss = 0.7068852186203003
Iteration [8973]: Loss = 0.7073405981063843
Iteration [8974]: Loss = 4.906045913696289
Iteration [8975]: Loss = 0.7082901000976562
Iteration [8976]: Loss = 0.7087723016738892
Iteration [8977]: Loss = 4.898569107055664
Iteration [8978]: Loss = 0.7097615599632263
Iteration [8979]: Loss = 0.7102576494216919
Iteration [8980]: Loss = 0.7106473445892334
Iteration [8981]: Loss = 0.7109415531158447
Iteration [8982]: Loss = 0.7111496925354004
Iteration [8983]: Loss = 4.887680530548096
Iteration [8984]: Loss = 0.7116726040840149
Iteration [8985]: Loss = 0.7119708061218262
Iteration [8986]: Loss = 0.7121843695640564
Iteration [8987]: Loss = 0.712321937084198
Iteration [8988]: Loss = 0.7123911380767822
Iteration [8989]: Loss = 0.7123989462852478
Iteration [8990]: Loss = 0.7123515605926514
Iteration [8991]: Loss = 0.7122544646263123
Iteration [8992]: Loss = 0.7121129035949707
Iteration [8993]: Loss = 0.7119312882423401
Iteration [8994]: Loss = 0.7117136716842651
Iteration [8995]: Loss = 4.886746883392334
Iteration [8996]: Loss = 0.7115134000778198
Iteration [8997]: Loss = 0.7115052938461304
Iteration [8998]: Loss = 0.7114453315734863
Iteration [8999]: Loss = 0.7113388180732727
Iteration [9000]: Loss = 0.7111906409263611
Iteration [9001]: Loss = 0.7110046744346619
Iteration [9002]: Loss = 4.890204906463623
Iteration [9003]: Loss = 0.7108529806137085
Iteration [9004]: Loss = 0.7108630537986755
Iteration [9005]: Loss = 0.7108209729194641
Iteration [9006]: Loss = 0.7107320427894592
Iteration [9007]: Loss = 0.7106010317802429
Iteration [9008]: Loss = 4.892005443572998
Iteration [9009]: Loss = 0.7105377912521362
Iteration [9010]: Loss = 0.7105833292007446
Iteration [9011]: Loss = 0.710574209690094
Iteration [9012]: Loss = 0.7105162143707275
Iteration [9013]: Loss = 0.7104142904281616
Iteration [9014]: Loss = 0.7102727890014648
Iteration [9015]: Loss = 0.7100958824157715
Iteration [9016]: Loss = 4.894787788391113
Iteration [9017]: Loss = 0.7099514007568359
Iteration [9018]: Loss = 0.7099608182907104
Iteration [9019]: Loss = 0.7099205851554871
Iteration [9020]: Loss = 0.7098357081413269
Iteration [9021]: Loss = 0.7097107768058777
Iteration [9022]: Loss = 0.7095498442649841
Iteration [9023]: Loss = 0.7093563079833984
Iteration [9024]: Loss = 0.7091337442398071
Iteration [9025]: Loss = 0.708885133266449
Iteration [9026]: Loss = 0.7086129188537598
Iteration [9027]: Loss = 0.7083195447921753
Iteration [9028]: Loss = 0.7080073356628418
Iteration [9029]: Loss = 4.906100749969482
Iteration [9030]: Loss = 4.90634298324585
Iteration [9031]: Loss = 0.70782870054245
Iteration [9032]: Loss = 0.7079600095748901
Iteration [9033]: Loss = 0.7080315947532654
Iteration [9034]: Loss = 0.7080494165420532
Iteration [9035]: Loss = 0.7080186605453491
Iteration [9036]: Loss = 4.904732704162598
Iteration [9037]: Loss = 4.903862476348877
Iteration [9038]: Loss = 4.901902198791504
Iteration [9039]: Loss = 0.7090641260147095
Iteration [9040]: Loss = 4.896608352661133
Iteration [9041]: Loss = 0.7101702094078064
Iteration [9042]: Loss = 0.7107021808624268
Iteration [9043]: Loss = 0.7111369967460632
Iteration [9044]: Loss = 0.7114841341972351
Iteration [9045]: Loss = 0.7117525339126587
Iteration [9046]: Loss = 0.71194988489151
Iteration [9047]: Loss = 0.7120832800865173
Iteration [9048]: Loss = 4.883211612701416
Iteration [9049]: Loss = 9.051032066345215
Iteration [9050]: Loss = 0.7131574153900146
Iteration [9051]: Loss = 0.7137542963027954
Iteration [9052]: Loss = 0.7142503261566162
Iteration [9053]: Loss = 0.714655339717865
Iteration [9054]: Loss = 0.7149785161018372
Iteration [9055]: Loss = 0.7152277231216431
Iteration [9056]: Loss = 0.7154105305671692
Iteration [9057]: Loss = 0.715533435344696
Iteration [9058]: Loss = 0.7156022787094116
Iteration [9059]: Loss = 0.7156226634979248
Iteration [9060]: Loss = 0.7155993580818176
Iteration [9061]: Loss = 0.7155367136001587
Iteration [9062]: Loss = 0.7154386043548584
Iteration [9063]: Loss = 0.7153085470199585
Iteration [9064]: Loss = 0.7151498198509216
Iteration [9065]: Loss = 0.7149654626846313
Iteration [9066]: Loss = 0.7147579193115234
Iteration [9067]: Loss = 0.714529275894165
Iteration [9068]: Loss = 4.872450351715088
Iteration [9069]: Loss = 0.7142701745033264
Iteration [9070]: Loss = 0.714218020439148
Iteration [9071]: Loss = 0.7141300439834595
Iteration [9072]: Loss = 0.7140095233917236
Iteration [9073]: Loss = 0.7138599157333374
Iteration [9074]: Loss = 0.7136842012405396
Iteration [9075]: Loss = 0.7134847640991211
Iteration [9076]: Loss = 0.7132641077041626
Iteration [9077]: Loss = 0.7130244374275208
Iteration [9078]: Loss = 0.7127673625946045
Iteration [9079]: Loss = 9.050514221191406
Iteration [9080]: Loss = 0.7115418314933777
Iteration [9081]: Loss = 0.7116857767105103
Iteration [9082]: Loss = 0.6994891166687012
Iteration [9083]: Loss = 0.6827768087387085
Iteration [9084]: Loss = 5.164614200592041
Iteration [9085]: Loss = 0.6718860864639282
Iteration [9086]: Loss = 0.6722627282142639
Iteration [9087]: Loss = 0.6745699048042297
Iteration [9088]: Loss = 0.6753132343292236
Iteration [9089]: Loss = 0.6683266162872314
Iteration [9090]: Loss = 0.6707662343978882
Iteration [9091]: Loss = 0.6589685082435608
Iteration [9092]: Loss = 0.6564052700996399
Iteration [9093]: Loss = 0.652716875076294
Iteration [9094]: Loss = 0.6578769087791443
Iteration [9095]: Loss = 0.6454162001609802
Iteration [9096]: Loss = 0.6480801701545715
Iteration [9097]: Loss = 0.643973708152771
Iteration [9098]: Loss = 0.6325485706329346
Iteration [9099]: Loss = 0.6367119550704956
Iteration [9100]: Loss = 0.6281077861785889
Iteration [9101]: Loss = 0.6216928958892822
Iteration [9102]: Loss = 0.6170425415039062
Iteration [9103]: Loss = 0.6155022382736206
Iteration [9104]: Loss = 0.604918360710144
Iteration [9105]: Loss = 0.6026978492736816
Iteration [9106]: Loss = 0.5991556644439697
Iteration [9107]: Loss = 0.5974084734916687
Iteration [9108]: Loss = 0.5939697623252869
Iteration [9109]: Loss = 0.5980275869369507
Iteration [9110]: Loss = 0.5987897515296936
Iteration [9111]: Loss = 0.592792809009552
Iteration [9112]: Loss = 0.5890681743621826
Iteration [9113]: Loss = 5.634243488311768
Iteration [9114]: Loss = 0.5833055973052979
Iteration [9115]: Loss = 0.5827679634094238
Iteration [9116]: Loss = 0.5820097923278809
Iteration [9117]: Loss = 0.5810559988021851
Iteration [9118]: Loss = 0.5799286365509033
Iteration [9119]: Loss = 0.5786476135253906
Iteration [9120]: Loss = 0.5772310495376587
Iteration [9121]: Loss = 0.5756949186325073
Iteration [9122]: Loss = 0.5740536451339722
Iteration [9123]: Loss = 0.5723203420639038
Iteration [9124]: Loss = 0.5705065131187439
Iteration [9125]: Loss = 0.5686224699020386
Iteration [9126]: Loss = 0.5667167901992798
Iteration [9127]: Loss = 0.5647754669189453
Iteration [9128]: Loss = 0.5627901554107666
Iteration [9129]: Loss = 0.5607672929763794
Iteration [9130]: Loss = 0.5575054287910461
Iteration [9131]: Loss = 0.5554308891296387
Iteration [9132]: Loss = 0.5526852607727051
Iteration [9133]: Loss = 0.5529460906982422
Iteration [9134]: Loss = 0.551162600517273
Iteration [9135]: Loss = 0.5459421873092651
Iteration [9136]: Loss = 0.5438450574874878
Iteration [9137]: Loss = 0.54173743724823
Iteration [9138]: Loss = 5.961091995239258
Iteration [9139]: Loss = 0.5366814732551575
Iteration [9140]: Loss = 0.5363779067993164
Iteration [9141]: Loss = 0.5359162092208862
Iteration [9142]: Loss = 0.5353127717971802
Iteration [9143]: Loss = 0.5345829129219055
Iteration [9144]: Loss = 0.5337402820587158
Iteration [9145]: Loss = 0.53279709815979
Iteration [9146]: Loss = 0.5317646861076355
Iteration [9147]: Loss = 0.5306527614593506
Iteration [9148]: Loss = 0.5283043384552002
Iteration [9149]: Loss = 6.071731090545654
Iteration [9150]: Loss = 0.5285314917564392
Iteration [9151]: Loss = 0.5286554098129272
Iteration [9152]: Loss = 6.059325695037842
Iteration [9153]: Loss = 0.5297515988349915
Iteration [9154]: Loss = 0.530636191368103
Iteration [9155]: Loss = 0.5312839150428772
Iteration [9156]: Loss = 0.5317183136940002
Iteration [9157]: Loss = 0.531960666179657
Iteration [9158]: Loss = 0.5320301651954651
Iteration [9159]: Loss = 0.5319443941116333
Iteration [9160]: Loss = 0.5317190289497375
Iteration [9161]: Loss = 0.5313685536384583
Iteration [9162]: Loss = 6.040892124176025
Iteration [9163]: Loss = 0.5316140651702881
Iteration [9164]: Loss = 0.5321142673492432
Iteration [9165]: Loss = 6.028769016265869
Iteration [9166]: Loss = 0.533720076084137
Iteration [9167]: Loss = 0.5347551107406616
Iteration [9168]: Loss = 0.5355576276779175
Iteration [9169]: Loss = 0.5360318422317505
Iteration [9170]: Loss = 5.993348598480225
Iteration [9171]: Loss = 0.549859344959259
Iteration [9172]: Loss = 5.892097473144531
Iteration [9173]: Loss = 0.5530705451965332
Iteration [9174]: Loss = 0.554511308670044
Iteration [9175]: Loss = 0.5552358031272888
Iteration [9176]: Loss = 0.5537672638893127
Iteration [9177]: Loss = 0.5545177459716797
Iteration [9178]: Loss = 0.5550701022148132
Iteration [9179]: Loss = 0.5554474592208862
Iteration [9180]: Loss = 0.5556893348693848
Iteration [9181]: Loss = 5.848785400390625
Iteration [9182]: Loss = 0.5567846298217773
Iteration [9183]: Loss = 0.5575670599937439
Iteration [9184]: Loss = 0.5581464767456055
Iteration [9185]: Loss = 0.5585429668426514
Iteration [9186]: Loss = 0.558774471282959
Iteration [9187]: Loss = 0.5588575005531311
Iteration [9188]: Loss = 0.5588067770004272
Iteration [9189]: Loss = 0.5586358904838562
Iteration [9190]: Loss = 0.5583570003509521
Iteration [9191]: Loss = 0.5579809546470642
Iteration [9192]: Loss = 0.5575177669525146
Iteration [9193]: Loss = 0.5569764971733093
Iteration [9194]: Loss = 0.5563651323318481
Iteration [9195]: Loss = 0.5556910037994385
Iteration [9196]: Loss = 0.5549608469009399
Iteration [9197]: Loss = 5.860738754272461
Iteration [9198]: Loss = 5.859101295471191
Iteration [9199]: Loss = 11.146926879882812
Iteration [9200]: Loss = 0.5579254031181335
Iteration [9201]: Loss = 0.5600520372390747
Iteration [9202]: Loss = 0.5618671774864197
Iteration [9203]: Loss = 0.5634005069732666
Iteration [9204]: Loss = 5.783054351806641
Iteration [9205]: Loss = 0.5688307285308838
Iteration [9206]: Loss = 0.5699833631515503
Iteration [9207]: Loss = 0.5671299695968628
Iteration [9208]: Loss = 0.568195641040802
Iteration [9209]: Loss = 0.5690705180168152
Iteration [9210]: Loss = 0.5697384476661682
Iteration [9211]: Loss = 0.5702367424964905
Iteration [9212]: Loss = 5.740300178527832
Iteration [9213]: Loss = 0.5716152191162109
Iteration [9214]: Loss = 5.737276554107666
Iteration [9215]: Loss = 5.7272138595581055
Iteration [9216]: Loss = 0.5743319988250732
Iteration [9217]: Loss = 0.575972318649292
Iteration [9218]: Loss = 0.5773553252220154
Iteration [9219]: Loss = 5.683937072753906
Iteration [9220]: Loss = 0.5802950859069824
Iteration [9221]: Loss = 0.5817199945449829
Iteration [9222]: Loss = 0.5829088091850281
Iteration [9223]: Loss = 0.5838841795921326
Iteration [9224]: Loss = 0.5846667885780334
Iteration [9225]: Loss = 0.5852754712104797
Iteration [9226]: Loss = 0.5857270359992981
Iteration [9227]: Loss = 0.5860370993614197
Iteration [9228]: Loss = 0.5862195491790771
Iteration [9229]: Loss = 0.5862870216369629
Iteration [9230]: Loss = 0.5862510204315186
Iteration [9231]: Loss = 0.5861217975616455
Iteration [9232]: Loss = 0.5859087705612183
Iteration [9233]: Loss = 0.5856203436851501
Iteration [9234]: Loss = 0.5852642059326172
Iteration [9235]: Loss = 0.584847092628479
Iteration [9236]: Loss = 0.5843755006790161
Iteration [9237]: Loss = 0.5838547348976135
Iteration [9238]: Loss = 0.5832899212837219
Iteration [9239]: Loss = 5.654662609100342
Iteration [9240]: Loss = 5.653801441192627
Iteration [9241]: Loss = 0.583567202091217
Iteration [9242]: Loss = 5.644437313079834
Iteration [9243]: Loss = 0.5853177905082703
Iteration [9244]: Loss = 0.5862722396850586
Iteration [9245]: Loss = 5.624502658843994
Iteration [9246]: Loss = 0.5883506536483765
Iteration [9247]: Loss = 0.5894404649734497
Iteration [9248]: Loss = 0.5903308391571045
Iteration [9249]: Loss = 0.5910409688949585
Iteration [9250]: Loss = 0.5915884971618652
Iteration [9251]: Loss = 0.591989278793335
Iteration [9252]: Loss = 5.588800430297852
Iteration [9253]: Loss = 0.593116283416748
Iteration [9254]: Loss = 0.5937985777854919
Iteration [9255]: Loss = 0.5943214893341064
Iteration [9256]: Loss = 0.5947006940841675
Iteration [9257]: Loss = 0.5949503779411316
Iteration [9258]: Loss = 0.5950834155082703
Iteration [9259]: Loss = 0.5951112508773804
Iteration [9260]: Loss = 0.5950443744659424
Iteration [9261]: Loss = 0.594892144203186
Iteration [9262]: Loss = 0.5946633815765381
Iteration [9263]: Loss = 5.574511528015137
Iteration [9264]: Loss = 0.5947138071060181
Iteration [9265]: Loss = 0.5949366688728333
Iteration [9266]: Loss = 0.5950465202331543
Iteration [9267]: Loss = 0.5950546264648438
Iteration [9268]: Loss = 10.545870780944824
Iteration [9269]: Loss = 0.5961431264877319
Iteration [9270]: Loss = 5.555997371673584
Iteration [9271]: Loss = 0.5985508561134338
Iteration [9272]: Loss = 0.5997611880302429
Iteration [9273]: Loss = 0.6007663011550903
Iteration [9274]: Loss = 0.6015860438346863
Iteration [9275]: Loss = 0.6022384166717529
Iteration [9276]: Loss = 0.6027398705482483
Iteration [9277]: Loss = 5.51607608795166
Iteration [9278]: Loss = 0.6039965152740479
Iteration [9279]: Loss = 0.6047138571739197
Iteration [9280]: Loss = 5.501771450042725
Iteration [9281]: Loss = 0.6063340902328491
Iteration [9282]: Loss = 0.6072038412094116
Iteration [9283]: Loss = 5.484547138214111
Iteration [9284]: Loss = 0.6090793013572693
Iteration [9285]: Loss = 0.609965443611145
Iteration [9286]: Loss = 0.6106683015823364
Iteration [9287]: Loss = 0.61106276512146
Iteration [9288]: Loss = 0.6116524338722229
Iteration [9289]: Loss = 0.611960768699646
Iteration [9290]: Loss = 0.6121625900268555
Iteration [9291]: Loss = 0.6122682094573975
Iteration [9292]: Loss = 5.456051349639893
Iteration [9293]: Loss = 5.452800273895264
Iteration [9294]: Loss = 0.6137215495109558
Iteration [9295]: Loss = 0.6144853830337524
Iteration [9296]: Loss = 5.437948226928711
Iteration [9297]: Loss = 0.6161229014396667
Iteration [9298]: Loss = 0.6169716119766235
Iteration [9299]: Loss = 0.6176614165306091
Iteration [9300]: Loss = 5.41807222366333
Iteration [9301]: Loss = 0.6191688776016235
Iteration [9302]: Loss = 0.6199601292610168
Iteration [9303]: Loss = 0.6205984354019165
Iteration [9304]: Loss = 0.6210988163948059
Iteration [9305]: Loss = 0.6214746236801147
Iteration [9306]: Loss = 0.6217382550239563
Iteration [9307]: Loss = 0.6219006776809692
Iteration [9308]: Loss = 0.6219719648361206
Iteration [9309]: Loss = 5.394287109375
Iteration [9310]: Loss = 0.6224205493927002
Iteration [9311]: Loss = 0.6227596998214722
Iteration [9312]: Loss = 5.387800693511963
Iteration [9313]: Loss = 0.6236621141433716
Iteration [9314]: Loss = 0.6241928339004517
Iteration [9315]: Loss = 5.377714157104492
Iteration [9316]: Loss = 0.6254188418388367
Iteration [9317]: Loss = 0.6260856986045837
Iteration [9318]: Loss = 0.6266126036643982
Iteration [9319]: Loss = 0.6270131468772888
Iteration [9320]: Loss = 0.6272999048233032
Iteration [9321]: Loss = 5.359685897827148
Iteration [9322]: Loss = 0.6281059980392456
Iteration [9323]: Loss = 0.6285927295684814
Iteration [9324]: Loss = 0.6289572715759277
Iteration [9325]: Loss = 0.6292119026184082
Iteration [9326]: Loss = 5.347993850708008
Iteration [9327]: Loss = 0.6299602389335632
Iteration [9328]: Loss = 5.341475009918213
Iteration [9329]: Loss = 0.6312835812568665
Iteration [9330]: Loss = 0.6319878101348877
Iteration [9331]: Loss = 0.6325488686561584
Iteration [9332]: Loss = 0.6329808831214905
Iteration [9333]: Loss = 0.6332964897155762
Iteration [9334]: Loss = 0.6335071325302124
Iteration [9335]: Loss = 0.6336233019828796
Iteration [9336]: Loss = 0.6336541175842285
Iteration [9337]: Loss = 0.6336082816123962
Iteration [9338]: Loss = 0.6334933638572693
Iteration [9339]: Loss = 0.6333162784576416
Iteration [9340]: Loss = 0.6330832242965698
Iteration [9341]: Loss = 5.326821804046631
Iteration [9342]: Loss = 10.018248558044434
Iteration [9343]: Loss = 0.6341015696525574
Iteration [9344]: Loss = 0.6350278854370117
Iteration [9345]: Loss = 5.30851411819458
Iteration [9346]: Loss = 0.6369052529335022
Iteration [9347]: Loss = 0.6378380060195923
Iteration [9348]: Loss = 0.6386078000068665
Iteration [9349]: Loss = 0.6392302513122559
Iteration [9350]: Loss = 0.6397198438644409
Iteration [9351]: Loss = 0.640089750289917
Iteration [9352]: Loss = 9.921388626098633
Iteration [9353]: Loss = 0.6414820551872253
Iteration [9354]: Loss = 0.6424317359924316
Iteration [9355]: Loss = 0.6413365602493286
Iteration [9356]: Loss = 0.6418879628181458
Iteration [9357]: Loss = 0.6423244476318359
Iteration [9358]: Loss = 0.642657458782196
Iteration [9359]: Loss = 0.6428971290588379
Iteration [9360]: Loss = 0.6430526971817017
Iteration [9361]: Loss = 0.6431322693824768
Iteration [9362]: Loss = 0.6431436538696289
Iteration [9363]: Loss = 5.264392852783203
Iteration [9364]: Loss = 0.6434081792831421
Iteration [9365]: Loss = 0.6436313390731812
Iteration [9366]: Loss = 0.6437722444534302
Iteration [9367]: Loss = 0.6438390016555786
Iteration [9368]: Loss = 0.6438387632369995
Iteration [9369]: Loss = 0.643778383731842
Iteration [9370]: Loss = 0.6436638832092285
Iteration [9371]: Loss = 5.261956691741943
Iteration [9372]: Loss = 0.6437125205993652
Iteration [9373]: Loss = 0.6438435912132263
Iteration [9374]: Loss = 0.6439015865325928
Iteration [9375]: Loss = 0.6438937783241272
Iteration [9376]: Loss = 0.6438269019126892
Iteration [9377]: Loss = 5.260724067687988
Iteration [9378]: Loss = 5.259235382080078
Iteration [9379]: Loss = 0.6445332765579224
Iteration [9380]: Loss = 0.6449940204620361
Iteration [9381]: Loss = 0.6453496217727661
Iteration [9382]: Loss = 0.6456103920936584
Iteration [9383]: Loss = 0.6457854509353638
Iteration [9384]: Loss = 0.6458835601806641
Iteration [9385]: Loss = 0.6459120512008667
Iteration [9386]: Loss = 9.849669456481934
Iteration [9387]: Loss = 0.6465975642204285
Iteration [9388]: Loss = 0.6471877694129944
Iteration [9389]: Loss = 0.647661030292511
Iteration [9390]: Loss = 5.235013008117676
Iteration [9391]: Loss = 0.6487024426460266
Iteration [9392]: Loss = 0.6492511034011841
Iteration [9393]: Loss = 0.6496868133544922
Iteration [9394]: Loss = 5.22325325012207
Iteration [9395]: Loss = 0.6525815725326538
Iteration [9396]: Loss = 0.65310138463974
Iteration [9397]: Loss = 0.653511106967926
Iteration [9398]: Loss = 0.6538214087486267
Iteration [9399]: Loss = 0.65404212474823
Iteration [9400]: Loss = 9.743563652038574
Iteration [9401]: Loss = 0.6550309658050537
Iteration [9402]: Loss = 0.6557384133338928
Iteration [9403]: Loss = 0.656318187713623
Iteration [9404]: Loss = 0.656782865524292
Iteration [9405]: Loss = 0.6571435928344727
Iteration [9406]: Loss = 0.657410740852356
Iteration [9407]: Loss = 0.6575934886932373
Iteration [9408]: Loss = 0.6577000021934509
Iteration [9409]: Loss = 0.657738208770752
Iteration [9410]: Loss = 0.6577145457267761
Iteration [9411]: Loss = 0.6576352119445801
Iteration [9412]: Loss = 0.6575060486793518
Iteration [9413]: Loss = 0.6573315858840942
Iteration [9414]: Loss = 0.6571168303489685
Iteration [9415]: Loss = 0.6568655371665955
Iteration [9416]: Loss = 0.6565812826156616
Iteration [9417]: Loss = 0.6562676429748535
Iteration [9418]: Loss = 0.6559274196624756
Iteration [9419]: Loss = 0.6555633544921875
Iteration [9420]: Loss = 0.6551779508590698
Iteration [9421]: Loss = 0.6547732353210449
Iteration [9422]: Loss = 0.6543513536453247
Iteration [9423]: Loss = 0.6539138555526733
Iteration [9424]: Loss = 0.6534624695777893
Iteration [9425]: Loss = 0.6529985666275024
Iteration [9426]: Loss = 5.208560943603516
Iteration [9427]: Loss = 0.6524336338043213
Iteration [9428]: Loss = 0.653087317943573
Iteration [9429]: Loss = 0.6529054641723633
Iteration [9430]: Loss = 5.2076191902160645
Iteration [9431]: Loss = 0.6528208255767822
Iteration [9432]: Loss = 0.6528865694999695
Iteration [9433]: Loss = 0.652888298034668
Iteration [9434]: Loss = 0.6528328657150269
Iteration [9435]: Loss = 0.6527255773544312
Iteration [9436]: Loss = 0.6525718569755554
Iteration [9437]: Loss = 0.6523761749267578
Iteration [9438]: Loss = 0.6521430015563965
Iteration [9439]: Loss = 0.6518756747245789
Iteration [9440]: Loss = 0.6515780687332153
Iteration [9441]: Loss = 0.6512529850006104
Iteration [9442]: Loss = 0.6509033441543579
Iteration [9443]: Loss = 5.220249652862549
Iteration [9444]: Loss = 0.650532603263855
Iteration [9445]: Loss = 0.6504768133163452
Iteration [9446]: Loss = 0.6503698825836182
Iteration [9447]: Loss = 0.6502165198326111
Iteration [9448]: Loss = 0.6500217914581299
Iteration [9449]: Loss = 0.6497896313667297
Iteration [9450]: Loss = 0.6495238542556763
Iteration [9451]: Loss = 0.6492277383804321
Iteration [9452]: Loss = 0.6489045023918152
Iteration [9453]: Loss = 0.6485568284988403
Iteration [9454]: Loss = 0.6481871008872986
Iteration [9455]: Loss = 0.6477975845336914
Iteration [9456]: Loss = 0.6473904848098755
Iteration [9457]: Loss = 5.241302013397217
Iteration [9458]: Loss = 0.6469228267669678
Iteration [9459]: Loss = 0.6468265056610107
Iteration [9460]: Loss = 0.6466832756996155
Iteration [9461]: Loss = 0.6464980244636536
Iteration [9462]: Loss = 5.2454142570495605
Iteration [9463]: Loss = 0.6464082598686218
Iteration [9464]: Loss = 0.6464724540710449
Iteration [9465]: Loss = 0.6464738249778748
Iteration [9466]: Loss = 0.646419107913971
Iteration [9467]: Loss = 0.6463136076927185
Iteration [9468]: Loss = 0.6461625099182129
Iteration [9469]: Loss = 0.6459701657295227
Iteration [9470]: Loss = 5.248589515686035
Iteration [9471]: Loss = 0.6458683013916016
Iteration [9472]: Loss = 0.645926833152771
Iteration [9473]: Loss = 0.6459236741065979
Iteration [9474]: Loss = 0.6458650231361389
Iteration [9475]: Loss = 5.248498916625977
Iteration [9476]: Loss = 0.6459900140762329
Iteration [9477]: Loss = 0.6461449861526489
Iteration [9478]: Loss = 0.6462286710739136
Iteration [9479]: Loss = 0.6462482810020447
Iteration [9480]: Loss = 0.6462099552154541
Iteration [9481]: Loss = 5.246336936950684
Iteration [9482]: Loss = 0.6463692784309387
Iteration [9483]: Loss = 0.646538496017456
Iteration [9484]: Loss = 5.243274211883545
Iteration [9485]: Loss = 0.6470509767532349
Iteration [9486]: Loss = 0.6473701000213623
Iteration [9487]: Loss = 0.6476017832756042
Iteration [9488]: Loss = 5.236634731292725
Iteration [9489]: Loss = 0.6482200622558594
Iteration [9490]: Loss = 5.231732368469238
Iteration [9491]: Loss = 5.227878570556641
Iteration [9492]: Loss = 0.6501467227935791
Iteration [9493]: Loss = 5.218012809753418
Iteration [9494]: Loss = 0.6519220471382141
Iteration [9495]: Loss = 0.6527772545814514
Iteration [9496]: Loss = 0.6534923911094666
Iteration [9497]: Loss = 0.6540813446044922
Iteration [9498]: Loss = 0.6545563340187073
Iteration [9499]: Loss = 0.6549285054206848
Iteration [9500]: Loss = 0.6552081108093262
Iteration [9501]: Loss = 5.191760063171387
Iteration [9502]: Loss = 0.6559025049209595
Iteration [9503]: Loss = 0.6562958359718323
Iteration [9504]: Loss = 0.6565943956375122
Iteration [9505]: Loss = 0.6568077802658081
Iteration [9506]: Loss = 0.6569439172744751
Iteration [9507]: Loss = 0.6570107936859131
Iteration [9508]: Loss = 5.182412147521973
Iteration [9509]: Loss = 0.6573410034179688
Iteration [9510]: Loss = 0.6575788259506226
Iteration [9511]: Loss = 0.6577373147010803
Iteration [9512]: Loss = 0.6578242778778076
Iteration [9513]: Loss = 0.6578466892242432
Iteration [9514]: Loss = 0.6578112244606018
Iteration [9515]: Loss = 0.6577234268188477
Iteration [9516]: Loss = 0.6575886011123657
Iteration [9517]: Loss = 0.6574113965034485
Iteration [9518]: Loss = 0.657196044921875
Iteration [9519]: Loss = 0.6569463610649109
Iteration [9520]: Loss = 0.6566659808158875
Iteration [9521]: Loss = 0.6563577651977539
Iteration [9522]: Loss = 0.6560245752334595
Iteration [9523]: Loss = 5.190220832824707
Iteration [9524]: Loss = 0.6556726694107056
Iteration [9525]: Loss = 0.6556203365325928
Iteration [9526]: Loss = 0.6555178761482239
Iteration [9527]: Loss = 0.6553701758384705
Iteration [9528]: Loss = 0.6551815271377563
Iteration [9529]: Loss = 0.6549563407897949
Iteration [9530]: Loss = 0.6546980738639832
Iteration [9531]: Loss = 5.197543621063232
Iteration [9532]: Loss = 0.6544739603996277
Iteration [9533]: Loss = 0.6544761657714844
Iteration [9534]: Loss = 5.197469711303711
Iteration [9535]: Loss = 0.6546957492828369
Iteration [9536]: Loss = 0.6548865437507629
Iteration [9537]: Loss = 0.6550031900405884
Iteration [9538]: Loss = 0.655052900314331
Iteration [9539]: Loss = 0.6550426483154297
Iteration [9540]: Loss = 0.6549780964851379
Iteration [9541]: Loss = 5.1948957443237305
Iteration [9542]: Loss = 0.6550832390785217
Iteration [9543]: Loss = 0.6552249193191528
Iteration [9544]: Loss = 0.6552975177764893
Iteration [9545]: Loss = 0.6553076505661011
Iteration [9546]: Loss = 0.655261754989624
Iteration [9547]: Loss = 0.6551653146743774
Iteration [9548]: Loss = 0.6550233364105225
Iteration [9549]: Loss = 0.6548404097557068
Iteration [9550]: Loss = 0.6546205878257751
Iteration [9551]: Loss = 0.6543676257133484
Iteration [9552]: Loss = 9.744794845581055
Iteration [9553]: Loss = 0.654518723487854
Iteration [9554]: Loss = 0.6548555493354797
Iteration [9555]: Loss = 0.6551048755645752
Iteration [9556]: Loss = 0.655275285243988
Iteration [9557]: Loss = 5.191931247711182
Iteration [9558]: Loss = 0.6557772755622864
Iteration [9559]: Loss = 5.187798976898193
Iteration [9560]: Loss = 0.6566754579544067
Iteration [9561]: Loss = 0.6571525931358337
Iteration [9562]: Loss = 5.179443836212158
Iteration [9563]: Loss = 5.175695896148682
Iteration [9564]: Loss = 0.6590584516525269
Iteration [9565]: Loss = 0.6597962379455566
Iteration [9566]: Loss = 0.6604078412055969
Iteration [9567]: Loss = 0.6609055995941162
Iteration [9568]: Loss = 0.661300778388977
Iteration [9569]: Loss = 0.6616033911705017
Iteration [9570]: Loss = 0.6618225574493408
Iteration [9571]: Loss = 0.6619666218757629
Iteration [9572]: Loss = 0.6620426774024963
Iteration [9573]: Loss = 0.6620579957962036
Iteration [9574]: Loss = 0.6620181798934937
Iteration [9575]: Loss = 0.6619287729263306
Iteration [9576]: Loss = 0.661794900894165
Iteration [9577]: Loss = 0.6616208553314209
Iteration [9578]: Loss = 0.6614107489585876
Iteration [9579]: Loss = 0.661168098449707
Iteration [9580]: Loss = 0.6608962416648865
Iteration [9581]: Loss = 0.66059809923172
Iteration [9582]: Loss = 0.6602762937545776
Iteration [9583]: Loss = 0.6599331498146057
Iteration [9584]: Loss = 0.6595709919929504
Iteration [9585]: Loss = 5.169844627380371
Iteration [9586]: Loss = 0.6591578125953674
Iteration [9587]: Loss = 0.6590741872787476
Iteration [9588]: Loss = 0.6589455008506775
Iteration [9589]: Loss = 0.6587766408920288
Iteration [9590]: Loss = 0.6585716009140015
Iteration [9591]: Loss = 0.6583337187767029
Iteration [9592]: Loss = 0.65806645154953
Iteration [9593]: Loss = 0.6577727198600769
Iteration [9594]: Loss = 0.657455325126648
Iteration [9595]: Loss = 0.6571164131164551
Iteration [9596]: Loss = 0.6567583084106445
Iteration [9597]: Loss = 0.6563829779624939
Iteration [9598]: Loss = 0.6559922099113464
Iteration [9599]: Loss = 0.655587375164032
Iteration [9600]: Loss = 0.6551700830459595
Iteration [9601]: Loss = 5.19561243057251
Iteration [9602]: Loss = 0.6546646356582642
Iteration [9603]: Loss = 0.6545425057411194
Iteration [9604]: Loss = 0.6543799042701721
Iteration [9605]: Loss = 0.654180645942688
Iteration [9606]: Loss = 0.6539485454559326
Iteration [9607]: Loss = 0.6536871194839478
Iteration [9608]: Loss = 0.6533989906311035
Iteration [9609]: Loss = 0.6530868411064148
Iteration [9610]: Loss = 0.6527533531188965
Iteration [9611]: Loss = 0.6524004936218262
Iteration [9612]: Loss = 5.211450099945068
Iteration [9613]: Loss = 0.652005672454834
Iteration [9614]: Loss = 0.6519309878349304
Iteration [9615]: Loss = 0.6518113613128662
Iteration [9616]: Loss = 0.65165114402771
Iteration [9617]: Loss = 0.6514545679092407
Iteration [9618]: Loss = 9.781119346618652
Iteration [9619]: Loss = 0.6516777873039246
Iteration [9620]: Loss = 0.6520341634750366
Iteration [9621]: Loss = 0.6523035168647766
Iteration [9622]: Loss = 0.6524944305419922
Iteration [9623]: Loss = 0.6526148319244385
Iteration [9624]: Loss = 0.6526713967323303
Iteration [9625]: Loss = 0.6526708602905273
Iteration [9626]: Loss = 0.6526185870170593
Iteration [9627]: Loss = 0.6525198221206665
Iteration [9628]: Loss = 0.6523792743682861
Iteration [9629]: Loss = 0.6522009968757629
Iteration [9630]: Loss = 0.651988685131073
Iteration [9631]: Loss = 0.6517459750175476
Iteration [9632]: Loss = 0.6514758467674255
Iteration [9633]: Loss = 0.6511809825897217
Iteration [9634]: Loss = 0.6508639454841614
Iteration [9635]: Loss = 0.6505270004272461
Iteration [9636]: Loss = 0.6501719951629639
Iteration [9637]: Loss = 0.6498008966445923
Iteration [9638]: Loss = 5.226822376251221
Iteration [9639]: Loss = 0.6493726372718811
Iteration [9640]: Loss = 0.6492829322814941
Iteration [9641]: Loss = 5.228384017944336
Iteration [9642]: Loss = 0.649334192276001
Iteration [9643]: Loss = 0.6494482755661011
Iteration [9644]: Loss = 0.6494997143745422
Iteration [9645]: Loss = 5.226355075836182
Iteration [9646]: Loss = 0.6497915387153625
Iteration [9647]: Loss = 0.6500077247619629
Iteration [9648]: Loss = 0.6501511931419373
Iteration [9649]: Loss = 0.6502292156219482
Iteration [9650]: Loss = 0.650248110294342
Iteration [9651]: Loss = 0.6502139568328857
Iteration [9652]: Loss = 0.6501318216323853
Iteration [9653]: Loss = 0.6500065922737122
Iteration [9654]: Loss = 5.224303722381592
Iteration [9655]: Loss = 0.6499966382980347
Iteration [9656]: Loss = 0.6500841975212097
Iteration [9657]: Loss = 5.222718238830566
Iteration [9658]: Loss = 0.6504367589950562
Iteration [9659]: Loss = 0.6506785750389099
Iteration [9660]: Loss = 0.6508450508117676
Iteration [9661]: Loss = 0.6509439945220947
Iteration [9662]: Loss = 0.6509817838668823
Iteration [9663]: Loss = 0.6509647369384766
Iteration [9664]: Loss = 0.6508982181549072
Iteration [9665]: Loss = 0.6507869958877563
Iteration [9666]: Loss = 0.6506356596946716
Iteration [9667]: Loss = 0.6504483222961426
Iteration [9668]: Loss = 0.6502284407615662
Iteration [9669]: Loss = 0.6499792337417603
Iteration [9670]: Loss = 0.649703860282898
Iteration [9671]: Loss = 0.6494047045707703
Iteration [9672]: Loss = 0.6490843892097473
Iteration [9673]: Loss = 0.6487449407577515
Iteration [9674]: Loss = 5.232887268066406
Iteration [9675]: Loss = 5.232997894287109
Iteration [9676]: Loss = 0.6486527323722839
Iteration [9677]: Loss = 5.2301177978515625
Iteration [9678]: Loss = 0.6493391394615173
Iteration [9679]: Loss = 0.6497229337692261
Iteration [9680]: Loss = 0.6500176191329956
Iteration [9681]: Loss = 0.6502324342727661
Iteration [9682]: Loss = 0.6503748893737793
Iteration [9683]: Loss = 0.6504521369934082
Iteration [9684]: Loss = 0.6504709720611572
Iteration [9685]: Loss = 0.6504368782043457
Iteration [9686]: Loss = 0.6503554582595825
Iteration [9687]: Loss = 0.6502310037612915
Iteration [9688]: Loss = 5.2229766845703125
Iteration [9689]: Loss = 0.6502208113670349
Iteration [9690]: Loss = 0.6503075957298279
Iteration [9691]: Loss = 0.6503349542617798
Iteration [9692]: Loss = 5.221560001373291
Iteration [9693]: Loss = 0.6505833864212036
Iteration [9694]: Loss = 5.218787670135498
Iteration [9695]: Loss = 5.216004848480225
Iteration [9696]: Loss = 0.6519749760627747
Iteration [9697]: Loss = 0.6525744199752808
Iteration [9698]: Loss = 0.6530637741088867
Iteration [9699]: Loss = 0.6534537672996521
Iteration [9700]: Loss = 0.653754472732544
Iteration [9701]: Loss = 5.200084686279297
Iteration [9702]: Loss = 0.6544671058654785
Iteration [9703]: Loss = 0.6548603177070618
Iteration [9704]: Loss = 0.655163586139679
Iteration [9705]: Loss = 5.191864490509033
Iteration [9706]: Loss = 0.6558801531791687
Iteration [9707]: Loss = 0.6562747359275818
Iteration [9708]: Loss = 0.6565790176391602
Iteration [9709]: Loss = 0.6568024158477783
Iteration [9710]: Loss = 5.182775497436523
Iteration [9711]: Loss = 5.180293083190918
Iteration [9712]: Loss = 0.6580593585968018
Iteration [9713]: Loss = 0.6586195230484009
Iteration [9714]: Loss = 0.6590732932090759
Iteration [9715]: Loss = 0.659430980682373
Iteration [9716]: Loss = 0.6597023606300354
Iteration [9717]: Loss = 0.6598955988883972
Iteration [9718]: Loss = 0.6600185632705688
Iteration [9719]: Loss = 0.6600781679153442
Iteration [9720]: Loss = 5.164727687835693
Iteration [9721]: Loss = 5.163032531738281
Iteration [9722]: Loss = 5.159836769104004
Iteration [9723]: Loss = 0.6617236137390137
Iteration [9724]: Loss = 0.6623852849006653
Iteration [9725]: Loss = 0.6629306077957153
Iteration [9726]: Loss = 0.6633706092834473
Iteration [9727]: Loss = 0.6637160778045654
Iteration [9728]: Loss = 0.6639760732650757
Iteration [9729]: Loss = 5.141404151916504
Iteration [9730]: Loss = 0.6646137237548828
Iteration [9731]: Loss = 0.6627805233001709
Iteration [9732]: Loss = 0.6630373597145081
Iteration [9733]: Loss = 0.6632037162780762
Iteration [9734]: Loss = 0.6632887721061707
Iteration [9735]: Loss = 0.663300633430481
Iteration [9736]: Loss = 0.6632463335990906
Iteration [9737]: Loss = 0.6631326675415039
Iteration [9738]: Loss = 0.6629655957221985
Iteration [9739]: Loss = 5.149435520172119
Iteration [9740]: Loss = 0.6629260182380676
Iteration [9741]: Loss = 0.6630199551582336
Iteration [9742]: Loss = 0.6630397439002991
Iteration [9743]: Loss = 0.6629930138587952
Iteration [9744]: Loss = 0.6628862619400024
Iteration [9745]: Loss = 0.6627255082130432
Iteration [9746]: Loss = 0.662516176700592
Iteration [9747]: Loss = 0.6622631549835205
Iteration [9748]: Loss = 5.153891086578369
Iteration [9749]: Loss = 0.6620768308639526
Iteration [9750]: Loss = 0.6621078848838806
Iteration [9751]: Loss = 0.662071704864502
Iteration [9752]: Loss = 0.6619746088981628
Iteration [9753]: Loss = 5.1547369956970215
Iteration [9754]: Loss = 0.6620537638664246
Iteration [9755]: Loss = 0.662197470664978
Iteration [9756]: Loss = 0.6622627377510071
Iteration [9757]: Loss = 9.642248153686523
Iteration [9758]: Loss = 0.6630330085754395
Iteration [9759]: Loss = 0.6636691093444824
Iteration [9760]: Loss = 5.141290187835693
Iteration [9761]: Loss = 0.6649940013885498
Iteration [9762]: Loss = 0.6656652688980103
Iteration [9763]: Loss = 0.6662070751190186
Iteration [9764]: Loss = 0.666631817817688
Iteration [9765]: Loss = 0.6669473648071289
Iteration [9766]: Loss = 0.6671280264854431
Iteration [9767]: Loss = 0.6672397255897522
Iteration [9768]: Loss = 0.667288601398468
Iteration [9769]: Loss = 0.6672837138175964
Iteration [9770]: Loss = 0.6672306060791016
Iteration [9771]: Loss = 0.6671340465545654
Iteration [9772]: Loss = 0.6669984459877014
Iteration [9773]: Loss = 0.6668275594711304
Iteration [9774]: Loss = 0.6666249632835388
Iteration [9775]: Loss = 0.6663939952850342
Iteration [9776]: Loss = 0.6661372184753418
Iteration [9777]: Loss = 0.6658573150634766
Iteration [9778]: Loss = 0.665556788444519
Iteration [9779]: Loss = 0.665237545967102
Iteration [9780]: Loss = 5.137182235717773
Iteration [9781]: Loss = 0.6648756265640259
Iteration [9782]: Loss = 0.6648039817810059
Iteration [9783]: Loss = 0.6646907925605774
Iteration [9784]: Loss = 0.6645404100418091
Iteration [9785]: Loss = 5.140279769897461
Iteration [9786]: Loss = 0.6644667387008667
Iteration [9787]: Loss = 0.6645175218582153
Iteration [9788]: Loss = 0.6645148396492004
Iteration [9789]: Loss = 9.614874839782715
Iteration [9790]: Loss = 0.665009081363678
Iteration [9791]: Loss = 0.6654523015022278
Iteration [9792]: Loss = 0.6658036708831787
Iteration [9793]: Loss = 0.6660722494125366
Iteration [9794]: Loss = 0.6662663817405701
Iteration [9795]: Loss = 0.6663931012153625
Iteration [9796]: Loss = 0.6664592027664185
Iteration [9797]: Loss = 0.6664707064628601
Iteration [9798]: Loss = 5.128497123718262
Iteration [9799]: Loss = 0.6666703224182129
Iteration [9800]: Loss = 0.6668360829353333
Iteration [9801]: Loss = 5.125644683837891
Iteration [9802]: Loss = 0.6672989130020142
Iteration [9803]: Loss = 0.6675764322280884
Iteration [9804]: Loss = 5.120893478393555
Iteration [9805]: Loss = 0.6682298183441162
Iteration [9806]: Loss = 0.668588399887085
Iteration [9807]: Loss = 0.6688634157180786
Iteration [9808]: Loss = 0.6690630316734314
Iteration [9809]: Loss = 0.6691948771476746
Iteration [9810]: Loss = 0.6692653894424438
Iteration [9811]: Loss = 0.6692808866500854
Iteration [9812]: Loss = 5.112624645233154
Iteration [9813]: Loss = 0.6694858074188232
Iteration [9814]: Loss = 0.6696531176567078
Iteration [9815]: Loss = 0.6697556376457214
Iteration [9816]: Loss = 5.109516143798828
Iteration [9817]: Loss = 0.6701088547706604
Iteration [9818]: Loss = 0.6703391671180725
Iteration [9819]: Loss = 9.540695190429688
Iteration [9820]: Loss = 0.6712177991867065
Iteration [9821]: Loss = 0.6718184947967529
Iteration [9822]: Loss = 0.6723122000694275
Iteration [9823]: Loss = 0.6727094650268555
Iteration [9824]: Loss = 0.6730194091796875
Iteration [9825]: Loss = 0.6732509732246399
Iteration [9826]: Loss = 5.089322566986084
Iteration [9827]: Loss = 0.6738212704658508
Iteration [9828]: Loss = 0.6741423606872559
Iteration [9829]: Loss = 0.674383819103241
Iteration [9830]: Loss = 0.6745535135269165
Iteration [9831]: Loss = 0.6746585369110107
Iteration [9832]: Loss = 0.6747053861618042
Iteration [9833]: Loss = 0.6746994256973267
Iteration [9834]: Loss = 0.6746464967727661
Iteration [9835]: Loss = 0.6745507121086121
Iteration [9836]: Loss = 0.6744167804718018
Iteration [9837]: Loss = 0.6742482781410217
Iteration [9838]: Loss = 0.6740486025810242
Iteration [9839]: Loss = 0.6738210320472717
Iteration [9840]: Loss = 0.6735684275627136
Iteration [9841]: Loss = 0.6732929348945618
Iteration [9842]: Loss = 0.6729973554611206
Iteration [9843]: Loss = 0.6726833581924438
Iteration [9844]: Loss = 0.6723529100418091
Iteration [9845]: Loss = 0.6720075607299805
Iteration [9846]: Loss = 0.6716490983963013
Iteration [9847]: Loss = 5.101227760314941
Iteration [9848]: Loss = 0.6712126731872559
Iteration [9849]: Loss = 0.671105682849884
Iteration [9850]: Loss = 0.6709616780281067
Iteration [9851]: Loss = 0.6707845330238342
Iteration [9852]: Loss = 0.6705772876739502
Iteration [9853]: Loss = 0.6703432202339172
Iteration [9854]: Loss = 5.107916831970215
Iteration [9855]: Loss = 0.6701192855834961
Iteration [9856]: Loss = 0.6701029539108276
Iteration [9857]: Loss = 0.6700406074523926
Iteration [9858]: Loss = 0.6699370741844177
Iteration [9859]: Loss = 0.6697962880134583
Iteration [9860]: Loss = 0.669622004032135
Iteration [9861]: Loss = 0.6694175004959106
Iteration [9862]: Loss = 5.112965106964111
Iteration [9863]: Loss = 0.669244647026062
Iteration [9864]: Loss = 0.6692500710487366
Iteration [9865]: Loss = 0.6692075133323669
Iteration [9866]: Loss = 0.6691217422485352
Iteration [9867]: Loss = 0.6689971685409546
Iteration [9868]: Loss = 5.114926815032959
Iteration [9869]: Loss = 0.6689605116844177
Iteration [9870]: Loss = 9.558732032775879
Iteration [9871]: Loss = 0.6696517467498779
Iteration [9872]: Loss = 0.6701709032058716
Iteration [9873]: Loss = 0.6705914735794067
Iteration [9874]: Loss = 0.6709235310554504
Iteration [9875]: Loss = 0.6711756587028503
Iteration [9876]: Loss = 0.6713559031486511
Iteration [9877]: Loss = 0.6714709997177124
Iteration [9878]: Loss = 0.6715276837348938
Iteration [9879]: Loss = 0.671531617641449
Iteration [9880]: Loss = 0.6714881062507629
Iteration [9881]: Loss = 0.671401858329773
Iteration [9882]: Loss = 0.6712771654129028
Iteration [9883]: Loss = 5.102128982543945
Iteration [9884]: Loss = 0.6712375283241272
Iteration [9885]: Loss = 0.6712984442710876
Iteration [9886]: Loss = 0.6713062524795532
Iteration [9887]: Loss = 5.101297855377197
Iteration [9888]: Loss = 0.6714928150177002
Iteration [9889]: Loss = 0.6716498732566833
Iteration [9890]: Loss = 0.6717443466186523
Iteration [9891]: Loss = 5.0984110832214355
Iteration [9892]: Loss = 5.096756458282471
Iteration [9893]: Loss = 5.093812465667725
Iteration [9894]: Loss = 0.6733406782150269
Iteration [9895]: Loss = 5.086297512054443
Iteration [9896]: Loss = 0.6747682094573975
Iteration [9897]: Loss = 0.6754534840583801
Iteration [9898]: Loss = 5.074826717376709
Iteration [9899]: Loss = 0.6767958998680115
Iteration [9900]: Loss = 0.6774445176124573
Iteration [9901]: Loss = 5.064020156860352
Iteration [9902]: Loss = 5.059940814971924
Iteration [9903]: Loss = 5.054864883422852
Iteration [9904]: Loss = 0.6807366609573364
Iteration [9905]: Loss = 5.043796539306641
Iteration [9906]: Loss = 0.6827672719955444
Iteration [9907]: Loss = 5.032700061798096
Iteration [9908]: Loss = 0.6848105788230896
Iteration [9909]: Loss = 0.6857567429542542
Iteration [9910]: Loss = 5.017251968383789
Iteration [9911]: Loss = 0.6875414252281189
Iteration [9912]: Loss = 0.6883765459060669
Iteration [9913]: Loss = 0.689081609249115
Iteration [9914]: Loss = 0.6896690130233765
Iteration [9915]: Loss = 0.6901504397392273
Iteration [9916]: Loss = 0.6905362606048584
Iteration [9917]: Loss = 0.6908358931541443
Iteration [9918]: Loss = 0.6910578608512878
Iteration [9919]: Loss = 0.6912094950675964
Iteration [9920]: Loss = 4.99183988571167
Iteration [9921]: Loss = 0.6916335821151733
Iteration [9922]: Loss = 0.691887617111206
Iteration [9923]: Loss = 0.6920684576034546
Iteration [9924]: Loss = 0.6921831369400024
Iteration [9925]: Loss = 0.6922383904457092
Iteration [9926]: Loss = 0.6922400593757629
Iteration [9927]: Loss = 0.6921932697296143
Iteration [9928]: Loss = 0.6921030879020691
Iteration [9929]: Loss = 0.691973865032196
Iteration [9930]: Loss = 0.6918092370033264
Iteration [9931]: Loss = 0.691612958908081
Iteration [9932]: Loss = 0.6913881301879883
Iteration [9933]: Loss = 0.6911376714706421
Iteration [9934]: Loss = 0.690864086151123
Iteration [9935]: Loss = 0.6905696392059326
Iteration [9936]: Loss = 0.6902564167976379
Iteration [9937]: Loss = 0.6899265050888062
Iteration [9938]: Loss = 0.6895815134048462
Iteration [9939]: Loss = 0.6892228722572327
Iteration [9940]: Loss = 0.6888521313667297
Iteration [9941]: Loss = 0.6884704828262329
Iteration [9942]: Loss = 0.6880788207054138
Iteration [9943]: Loss = 0.6876784563064575
Iteration [9944]: Loss = 0.6872701644897461
Iteration [9945]: Loss = 0.6868547201156616
Iteration [9946]: Loss = 0.6864330768585205
Iteration [9947]: Loss = 0.6860056519508362
Iteration [9948]: Loss = 5.022593975067139
Iteration [9949]: Loss = 0.6854428052902222
Iteration [9950]: Loss = 0.6852779388427734
Iteration [9951]: Loss = 0.6850818395614624
Iteration [9952]: Loss = 0.6848574876785278
Iteration [9953]: Loss = 0.684607982635498
Iteration [9954]: Loss = 0.6843356490135193
Iteration [9955]: Loss = 0.684042751789093
Iteration [9956]: Loss = 5.032575607299805
Iteration [9957]: Loss = 5.032690525054932
Iteration [9958]: Loss = 0.6839488744735718
Iteration [9959]: Loss = 5.030486106872559
Iteration [9960]: Loss = 0.68452388048172
Iteration [9961]: Loss = 0.6848434209823608
Iteration [9962]: Loss = 5.025241851806641
Iteration [9963]: Loss = 9.35981273651123
Iteration [9964]: Loss = 0.6865296959877014
Iteration [9965]: Loss = 0.6873601078987122
Iteration [9966]: Loss = 0.6880611777305603
Iteration [9967]: Loss = 0.6886458992958069
Iteration [9968]: Loss = 0.6891252994537354
Iteration [9969]: Loss = 0.6895098686218262
Iteration [9970]: Loss = 0.6898089647293091
Iteration [9971]: Loss = 0.6900309324264526
Iteration [9972]: Loss = 0.6901834011077881
Iteration [9973]: Loss = 0.6902732849121094
Iteration [9974]: Loss = 0.6903066635131836
Iteration [9975]: Loss = 0.6902891993522644
Iteration [9976]: Loss = 0.6902260780334473
Iteration [9977]: Loss = 0.6901216506958008
Iteration [9978]: Loss = 0.6899800896644592
Iteration [9979]: Loss = 0.6898052096366882
Iteration [9980]: Loss = 0.6896001696586609
Iteration [9981]: Loss = 5.002161979675293
Iteration [9982]: Loss = 0.689413845539093
Iteration [9983]: Loss = 5.001950263977051
Iteration [9984]: Loss = 0.6896555423736572
Iteration [9985]: Loss = 0.6898316144943237
Iteration [9986]: Loss = 0.6899425983428955
Iteration [9987]: Loss = 0.6899952292442322
Iteration [9988]: Loss = 0.6899951696395874
Iteration [9989]: Loss = 4.999057292938232
Iteration [9990]: Loss = 0.690158486366272
Iteration [9991]: Loss = 0.6903008818626404
Iteration [9992]: Loss = 0.6903817057609558
Iteration [9993]: Loss = 0.6904069185256958
Iteration [9994]: Loss = 9.303081512451172
Iteration [9995]: Loss = 0.690908670425415
Iteration [9996]: Loss = 0.6913359761238098
Iteration [9997]: Loss = 0.6916736960411072
Iteration [9998]: Loss = 0.6919308304786682
Iteration [9999]: Loss = 0.6921154856681824
Iteration [10000]: Loss = 0.6922343373298645
Iteration [10001]: Loss = 0.6922943592071533
Iteration [10002]: Loss = 0.6923011541366577
Iteration [10003]: Loss = 0.6922600269317627
Iteration [10004]: Loss = 0.6921758651733398
Iteration [10005]: Loss = 0.6920527219772339
Iteration [10006]: Loss = 4.988658428192139
Iteration [10007]: Loss = 0.6920039057731628
Iteration [10008]: Loss = 0.6920551061630249
Iteration [10009]: Loss = 0.6920539140701294
Iteration [10010]: Loss = 0.6920056939125061
Iteration [10011]: Loss = 0.6919152140617371
Iteration [10012]: Loss = 0.6917863488197327
Iteration [10013]: Loss = 0.6916230916976929
Iteration [10014]: Loss = 0.691429078578949
Iteration [10015]: Loss = 0.6912071108818054
Iteration [10016]: Loss = 0.6909599900245667
Iteration [10017]: Loss = 0.6906905770301819
Iteration [10018]: Loss = 4.996634483337402
Iteration [10019]: Loss = 0.6903921365737915
Iteration [10020]: Loss = 4.996972560882568
Iteration [10021]: Loss = 0.6905395984649658
Iteration [10022]: Loss = 0.6906745433807373
Iteration [10023]: Loss = 0.6907489895820618
Iteration [10024]: Loss = 0.6907690763473511
Iteration [10025]: Loss = 0.6907400488853455
Iteration [10026]: Loss = 0.690666675567627
Iteration [10027]: Loss = 0.6905534863471985
Iteration [10028]: Loss = 0.6904045343399048
Iteration [10029]: Loss = 0.690223217010498
Iteration [10030]: Loss = 0.6900129318237305
Iteration [10031]: Loss = 0.6897764801979065
Iteration [10032]: Loss = 0.689516544342041
Iteration [10033]: Loss = 0.6892354488372803
Iteration [10034]: Loss = 0.6889353394508362
Iteration [10035]: Loss = 0.688618004322052
Iteration [10036]: Loss = 0.6882855296134949
Iteration [10037]: Loss = 0.6879390478134155
Iteration [10038]: Loss = 0.6875802278518677
Iteration [10039]: Loss = 0.687210202217102
Iteration [10040]: Loss = 0.6868301033973694
Iteration [10041]: Loss = 0.6864411234855652
Iteration [10042]: Loss = 0.6860439777374268
Iteration [10043]: Loss = 0.6856397390365601
Iteration [10044]: Loss = 0.6852288246154785
Iteration [10045]: Loss = 0.6848121285438538
Iteration [10046]: Loss = 0.6843904256820679
Iteration [10047]: Loss = 0.6839639544487
Iteration [10048]: Loss = 0.6835331916809082
Iteration [10049]: Loss = 0.6830988526344299
Iteration [10050]: Loss = 0.6826611757278442
Iteration [10051]: Loss = 0.682220458984375
Iteration [10052]: Loss = 0.6817770600318909
Iteration [10053]: Loss = 0.68133145570755
Iteration [10054]: Loss = 5.048097133636475
Iteration [10055]: Loss = 0.680736243724823
Iteration [10056]: Loss = 0.6805570721626282
Iteration [10057]: Loss = 0.6803492307662964
Iteration [10058]: Loss = 0.6801155805587769
Iteration [10059]: Loss = 0.6798586249351501
Iteration [10060]: Loss = 5.055232048034668
Iteration [10061]: Loss = 0.6795862317085266
Iteration [10062]: Loss = 0.6795443296432495
Iteration [10063]: Loss = 9.432326316833496
Iteration [10064]: Loss = 0.6799344420433044
Iteration [10065]: Loss = 0.6803156137466431
Iteration [10066]: Loss = 0.6806129217147827
Iteration [10067]: Loss = 0.6808347702026367
Iteration [10068]: Loss = 0.6809884905815125
Iteration [10069]: Loss = 0.6810808777809143
Iteration [10070]: Loss = 0.6811180114746094
Iteration [10071]: Loss = 0.6811052560806274
Iteration [10072]: Loss = 0.681047797203064
Iteration [10073]: Loss = 0.680949866771698
Iteration [10074]: Loss = 5.0484700202941895
Iteration [10075]: Loss = 0.6809466481208801
Iteration [10076]: Loss = 0.681018590927124
Iteration [10077]: Loss = 0.681037425994873
Iteration [10078]: Loss = 0.6810082197189331
Iteration [10079]: Loss = 0.6809358596801758
Iteration [10080]: Loss = 0.6808244585990906
Iteration [10081]: Loss = 0.6806781888008118
Iteration [10082]: Loss = 5.050194263458252
Iteration [10083]: Loss = 0.68059241771698
Iteration [10084]: Loss = 0.6806293725967407
Iteration [10085]: Loss = 0.6806166768074036
Iteration [10086]: Loss = 5.049872875213623
Iteration [10087]: Loss = 0.6807590126991272
Iteration [10088]: Loss = 0.6808928847312927
Iteration [10089]: Loss = 0.6809675693511963
Iteration [10090]: Loss = 0.6809887290000916
Iteration [10091]: Loss = 0.6809616088867188
Iteration [10092]: Loss = 0.6808910369873047
Iteration [10093]: Loss = 0.6807814836502075
Iteration [10094]: Loss = 0.6806368231773376
Iteration [10095]: Loss = 0.6804603338241577
Iteration [10096]: Loss = 5.051535606384277
Iteration [10097]: Loss = 0.6803233623504639
Iteration [10098]: Loss = 0.6803385019302368
Iteration [10099]: Loss = 0.680306077003479
Iteration [10100]: Loss = 5.051669120788574
Iteration [10101]: Loss = 0.6804149150848389
Iteration [10102]: Loss = 5.0500054359436035
Iteration [10103]: Loss = 0.6808937191963196
Iteration [10104]: Loss = 0.6811710000038147
Iteration [10105]: Loss = 5.045413494110107
Iteration [10106]: Loss = 0.681808590888977
Iteration [10107]: Loss = 0.6821532249450684
Iteration [10108]: Loss = 0.6824177503585815
Iteration [10109]: Loss = 0.6826099157333374
Iteration [10110]: Loss = 0.6827366948127747
Iteration [10111]: Loss = 0.6828048229217529
Iteration [10112]: Loss = 0.6828201413154602
Iteration [10113]: Loss = 0.6827874779701233
Iteration [10114]: Loss = 0.6827120780944824
Iteration [10115]: Loss = 0.6825978755950928
Iteration [10116]: Loss = 0.6824489831924438
Iteration [10117]: Loss = 0.6822686791419983
Iteration [10118]: Loss = 0.6820601224899292
Iteration [10119]: Loss = 0.6818261742591858
Iteration [10120]: Loss = 0.6815693974494934
Iteration [10121]: Loss = 0.6812921166419983
Iteration [10122]: Loss = 0.680996298789978
Iteration [10123]: Loss = 5.049190044403076
Iteration [10124]: Loss = 0.680655300617218
Iteration [10125]: Loss = 0.6805835962295532
Iteration [10126]: Loss = 5.050343990325928
Iteration [10127]: Loss = 5.049511432647705
Iteration [10128]: Loss = 0.6810128092765808
Iteration [10129]: Loss = 0.6813162565231323
Iteration [10130]: Loss = 0.6815434694290161
Iteration [10131]: Loss = 0.6817020177841187
Iteration [10132]: Loss = 0.6817988753318787
Iteration [10133]: Loss = 0.6818398833274841
Iteration [10134]: Loss = 0.681830644607544
Iteration [10135]: Loss = 0.6817762851715088
Iteration [10136]: Loss = 0.6816812753677368
Iteration [10137]: Loss = 0.681549608707428
Iteration [10138]: Loss = 0.6813849210739136
Iteration [10139]: Loss = 0.6811904311180115
Iteration [10140]: Loss = 0.6809692978858948
Iteration [10141]: Loss = 0.6807240843772888
Iteration [10142]: Loss = 0.6804574131965637
Iteration [10143]: Loss = 0.6801709532737732
Iteration [10144]: Loss = 0.6798670887947083
Iteration [10145]: Loss = 0.6795475482940674
Iteration [10146]: Loss = 0.6792138814926147
Iteration [10147]: Loss = 9.439430236816406
Iteration [10148]: Loss = 0.6791048645973206
Iteration [10149]: Loss = 0.6792730689048767
Iteration [10150]: Loss = 0.6793789863586426
Iteration [10151]: Loss = 0.6794288158416748
Iteration [10152]: Loss = 0.6794281005859375
Iteration [10153]: Loss = 0.6793819069862366
Iteration [10154]: Loss = 0.6792945861816406
Iteration [10155]: Loss = 0.6791704297065735
Iteration [10156]: Loss = 0.6790130734443665
Iteration [10157]: Loss = 0.6788257956504822
Iteration [10158]: Loss = 0.6786114573478699
Iteration [10159]: Loss = 0.6783729195594788
Iteration [10160]: Loss = 0.6781126260757446
Iteration [10161]: Loss = 0.6778326034545898
Iteration [10162]: Loss = 0.6775349974632263
Iteration [10163]: Loss = 0.6772215962409973
Iteration [10164]: Loss = 0.676893949508667
Iteration [10165]: Loss = 5.0718994140625
Iteration [10166]: Loss = 0.6764988303184509
Iteration [10167]: Loss = 0.6764041185379028
Iteration [10168]: Loss = 0.6762735843658447
Iteration [10169]: Loss = 0.676110565662384
Iteration [10170]: Loss = 0.6759181022644043
Iteration [10171]: Loss = 0.6756996512413025
Iteration [10172]: Loss = 0.6754574775695801
Iteration [10173]: Loss = 0.6751939654350281
Iteration [10174]: Loss = 0.6749114394187927
Iteration [10175]: Loss = 0.6746116876602173
Iteration [10176]: Loss = 0.6742964386940002
Iteration [10177]: Loss = 0.6739672422409058
Iteration [10178]: Loss = 0.673625648021698
Iteration [10179]: Loss = 0.6732727289199829
Iteration [10180]: Loss = 0.6729097962379456
Iteration [10181]: Loss = 0.6725377440452576
Iteration [10182]: Loss = 5.096314430236816
Iteration [10183]: Loss = 0.6720686554908752
Iteration [10184]: Loss = 5.097511291503906
Iteration [10185]: Loss = 0.6720829010009766
Iteration [10186]: Loss = 0.6721634864807129
Iteration [10187]: Loss = 0.6721906065940857
Iteration [10188]: Loss = 0.6721700429916382
Iteration [10189]: Loss = 0.6721063256263733
Iteration [10190]: Loss = 0.6720038056373596
Iteration [10191]: Loss = 5.09794282913208
Iteration [10192]: Loss = 0.6719946265220642
Iteration [10193]: Loss = 0.672065258026123
Iteration [10194]: Loss = 0.6720836162567139
Iteration [10195]: Loss = 0.6720548272132874
Iteration [10196]: Loss = 0.6719839572906494
Iteration [10197]: Loss = 0.6718748211860657
Iteration [10198]: Loss = 0.6717315912246704
Iteration [10199]: Loss = 0.6715571880340576
Iteration [10200]: Loss = 0.6713552474975586
Iteration [10201]: Loss = 0.6711280345916748
Iteration [10202]: Loss = 0.6708784103393555
Iteration [10203]: Loss = 0.670608639717102
Iteration [10204]: Loss = 0.6703205108642578
Iteration [10205]: Loss = 0.6700159311294556
Iteration [10206]: Loss = 0.6696968078613281
Iteration [10207]: Loss = 0.6693645119667053
Iteration [10208]: Loss = 0.6690201163291931
Iteration [10209]: Loss = 5.115895748138428
Iteration [10210]: Loss = 5.116265296936035
Iteration [10211]: Loss = 0.6687935590744019
Iteration [10212]: Loss = 0.6689232587814331
Iteration [10213]: Loss = 5.114039421081543
Iteration [10214]: Loss = 0.6693119406700134
Iteration [10215]: Loss = 5.110906600952148
Iteration [10216]: Loss = 0.6700199842453003
Iteration [10217]: Loss = 0.6703963279724121
Iteration [10218]: Loss = 0.6706905364990234
Iteration [10219]: Loss = 0.6709104180335999
Iteration [10220]: Loss = 0.6710634827613831
Iteration [10221]: Loss = 0.6711562871932983
Iteration [10222]: Loss = 0.6711947917938232
Iteration [10223]: Loss = 0.6711843013763428
Iteration [10224]: Loss = 0.6711297631263733
Iteration [10225]: Loss = 0.671035647392273
Iteration [10226]: Loss = 0.6709057688713074
Iteration [10227]: Loss = 0.6707435846328735
Iteration [10228]: Loss = 0.6705525517463684
Iteration [10229]: Loss = 0.6703354120254517
Iteration [10230]: Loss = 0.6700949668884277
Iteration [10231]: Loss = 0.6698333621025085
Iteration [10232]: Loss = 0.6695528030395508
Iteration [10233]: Loss = 5.112576484680176
Iteration [10234]: Loss = 0.6692407727241516
Iteration [10235]: Loss = 5.112983703613281
Iteration [10236]: Loss = 0.6693831086158752
Iteration [10237]: Loss = 0.6695186495780945
Iteration [10238]: Loss = 0.6695956587791443
Iteration [10239]: Loss = 0.6696200370788574
Iteration [10240]: Loss = 0.6695971488952637
Iteration [10241]: Loss = 0.6695314645767212
Iteration [10242]: Loss = 0.669427216053009
Iteration [10243]: Loss = 0.6692883968353271
Iteration [10244]: Loss = 0.6691184043884277
Iteration [10245]: Loss = 0.6689204573631287
Iteration [10246]: Loss = 0.6686970591545105
Iteration [10247]: Loss = 0.6684511303901672
Iteration [10248]: Loss = 0.6681845188140869
Iteration [10249]: Loss = 0.6678996086120605
Iteration [10250]: Loss = 0.667598307132721
Iteration [10251]: Loss = 0.667281985282898
Iteration [10252]: Loss = 0.6669524312019348
Iteration [10253]: Loss = 0.6666107177734375
Iteration [10254]: Loss = 0.6662582755088806
Iteration [10255]: Loss = 0.6658961772918701
Iteration [10256]: Loss = 0.6655253767967224
Iteration [10257]: Loss = 0.6651467680931091
Iteration [10258]: Loss = 0.6647611260414124
Iteration [10259]: Loss = 5.140208721160889
Iteration [10260]: Loss = 0.6642715930938721
Iteration [10261]: Loss = 0.6641392707824707
Iteration [10262]: Loss = 0.6639753580093384
Iteration [10263]: Loss = 0.6637829542160034
Iteration [10264]: Loss = 0.6635651588439941
Iteration [10265]: Loss = 0.6633242964744568
Iteration [10266]: Loss = 5.147651672363281
Iteration [10267]: Loss = 0.6630825996398926
Iteration [10268]: Loss = 0.6630557179450989
Iteration [10269]: Loss = 0.6629869341850281
Iteration [10270]: Loss = 0.6628803014755249
Iteration [10271]: Loss = 0.6627396941184998
Iteration [10272]: Loss = 0.6625684499740601
Iteration [10273]: Loss = 0.6623696684837341
Iteration [10274]: Loss = 0.662146270275116
Iteration [10275]: Loss = 0.6619002819061279
Iteration [10276]: Loss = 0.6616343855857849
Iteration [10277]: Loss = 0.6613503098487854
Iteration [10278]: Loss = 0.661050021648407
Iteration [10279]: Loss = 0.6607351899147034
Iteration [10280]: Loss = 5.162853240966797
Iteration [10281]: Loss = 5.163078308105469
Iteration [10282]: Loss = 0.660587728023529
Iteration [10283]: Loss = 0.6607411503791809
Iteration [10284]: Loss = 0.6608349084854126
Iteration [10285]: Loss = 0.6608748435974121
Iteration [10286]: Loss = 0.660866379737854
Iteration [10287]: Loss = 0.6608141660690308
Iteration [10288]: Loss = 0.6607227921485901
Iteration [10289]: Loss = 5.161769866943359
Iteration [10290]: Loss = 0.6607369184494019
Iteration [10291]: Loss = 0.660819411277771
Iteration [10292]: Loss = 0.6608492732048035
Iteration [10293]: Loss = 5.160417079925537
Iteration [10294]: Loss = 0.6610702872276306
Iteration [10295]: Loss = 0.6612408757209778
Iteration [10296]: Loss = 0.6613500714302063
Iteration [10297]: Loss = 0.6614038348197937
Iteration [10298]: Loss = 0.6614078283309937
Iteration [10299]: Loss = 0.6613669395446777
Iteration [10300]: Loss = 0.6612856388092041
Iteration [10301]: Loss = 0.6611678004264832
Iteration [10302]: Loss = 0.6610173583030701
Iteration [10303]: Loss = 0.6608372330665588
Iteration [10304]: Loss = 5.161570072174072
Iteration [10305]: Loss = 0.6607002019882202
Iteration [10306]: Loss = 0.6607182621955872
Iteration [10307]: Loss = 0.6606900691986084
Iteration [10308]: Loss = 0.6606202125549316
Iteration [10309]: Loss = 0.6605128645896912
Iteration [10310]: Loss = 0.6603718996047974
Iteration [10311]: Loss = 0.660200297832489
Iteration [10312]: Loss = 5.16518497467041
Iteration [10313]: Loss = 0.6600779294967651
Iteration [10314]: Loss = 0.6601022481918335
Iteration [10315]: Loss = 0.6600798964500427
Iteration [10316]: Loss = 0.6600154042243958
Iteration [10317]: Loss = 0.6599129438400269
Iteration [10318]: Loss = 0.6597760319709778
Iteration [10319]: Loss = 0.6596084833145142
Iteration [10320]: Loss = 0.6594131588935852
Iteration [10321]: Loss = 0.6591930389404297
Iteration [10322]: Loss = 0.6589503288269043
Iteration [10323]: Loss = 0.6586874127388
Iteration [10324]: Loss = 0.6584063768386841
Iteration [10325]: Loss = 0.6581090688705444
Iteration [10326]: Loss = 0.6577969789505005
Iteration [10327]: Loss = 0.657471776008606
Iteration [10328]: Loss = 0.6571345925331116
Iteration [10329]: Loss = 0.6567868590354919
Iteration [10330]: Loss = 0.6564294099807739
Iteration [10331]: Loss = 0.6560634970664978
Iteration [10332]: Loss = 0.6556897759437561
Iteration [10333]: Loss = 0.6553090214729309
Iteration [10334]: Loss = 0.6549222469329834
Iteration [10335]: Loss = 0.6545298099517822
Iteration [10336]: Loss = 0.6541324257850647
Iteration [10337]: Loss = 0.6537305116653442
Iteration [10338]: Loss = 0.6533246040344238
Iteration [10339]: Loss = 0.6529151797294617
Iteration [10340]: Loss = 0.6525024771690369
Iteration [10341]: Loss = 0.6520869135856628
Iteration [10342]: Loss = 0.651668906211853
Iteration [10343]: Loss = 0.6512484550476074
Iteration [10344]: Loss = 0.6508262157440186
Iteration [10345]: Loss = 0.6504020094871521
Iteration [10346]: Loss = 0.6499762535095215
Iteration [10347]: Loss = 0.6495490074157715
Iteration [10348]: Loss = 0.649120569229126
Iteration [10349]: Loss = 0.6486910581588745
Iteration [10350]: Loss = 0.6482605338096619
Iteration [10351]: Loss = 0.6478292346000671
Iteration [10352]: Loss = 0.6473972201347351
Iteration [10353]: Loss = 0.6469644904136658
Iteration [10354]: Loss = 0.6465312242507935
Iteration [10355]: Loss = 5.246467590332031
Iteration [10356]: Loss = 0.645967960357666
Iteration [10357]: Loss = 5.248191833496094
Iteration [10358]: Loss = 0.6459228992462158
Iteration [10359]: Loss = 0.6459829807281494
Iteration [10360]: Loss = 0.6459934711456299
Iteration [10361]: Loss = 0.6459594964981079
Iteration [10362]: Loss = 0.645885169506073
Iteration [10363]: Loss = 0.6457746028900146
Iteration [10364]: Loss = 0.6456313729286194
Iteration [10365]: Loss = 0.6454588174819946
Iteration [10366]: Loss = 0.6452598571777344
Iteration [10367]: Loss = 0.6450371742248535
Iteration [10368]: Loss = 0.6447929739952087
Iteration [10369]: Loss = 0.6445295810699463
Iteration [10370]: Loss = 0.644248902797699
Iteration [10371]: Loss = 0.643952488899231
Iteration [10372]: Loss = 0.6436421871185303
Iteration [10373]: Loss = 0.6433193683624268
Iteration [10374]: Loss = 0.6429851651191711
Iteration [10375]: Loss = 0.6426407098770142
Iteration [10376]: Loss = 5.269226551055908
Iteration [10377]: Loss = 0.6422305703163147
Iteration [10378]: Loss = 0.6421360969543457
Iteration [10379]: Loss = 0.64200758934021
Iteration [10380]: Loss = 0.6418484449386597
Iteration [10381]: Loss = 0.6416618227958679
Iteration [10382]: Loss = 0.6414504051208496
Iteration [10383]: Loss = 0.6412166357040405
Iteration [10384]: Loss = 0.6409626603126526
Iteration [10385]: Loss = 0.6406906843185425
Iteration [10386]: Loss = 0.6404025554656982
Iteration [10387]: Loss = 0.6400996446609497
Iteration [10388]: Loss = 0.6397837400436401
Iteration [10389]: Loss = 0.6394559741020203
Iteration [10390]: Loss = 0.6391175985336304
Iteration [10391]: Loss = 0.6387696862220764
Iteration [10392]: Loss = 9.946751594543457
Iteration [10393]: Loss = 0.6386570334434509
Iteration [10394]: Loss = 0.6388338208198547
Iteration [10395]: Loss = 0.6389502286911011
Iteration [10396]: Loss = 0.639012336730957
Iteration [10397]: Loss = 0.6390254497528076
Iteration [10398]: Loss = 5.289064884185791
Iteration [10399]: Loss = 0.6392248868942261
Iteration [10400]: Loss = 0.63938969373703
Iteration [10401]: Loss = 0.6394953727722168
Iteration [10402]: Loss = 0.6395476460456848
Iteration [10403]: Loss = 0.6395519971847534
Iteration [10404]: Loss = 0.6395129561424255
Iteration [10405]: Loss = 0.6394351124763489
Iteration [10406]: Loss = 0.6393219828605652
Iteration [10407]: Loss = 0.6391773223876953
Iteration [10408]: Loss = 0.6390042901039124
Iteration [10409]: Loss = 0.638805627822876
Iteration [10410]: Loss = 0.6385838985443115
Iteration [10411]: Loss = 0.6383413672447205
Iteration [10412]: Loss = 0.6380802392959595
Iteration [10413]: Loss = 0.6378024220466614
Iteration [10414]: Loss = 0.6375094056129456
Iteration [10415]: Loss = 0.6372029185295105
Iteration [10416]: Loss = 0.6368841528892517
Iteration [10417]: Loss = 0.636554479598999
Iteration [10418]: Loss = 0.6362148523330688
Iteration [10419]: Loss = 0.6358665227890015
Iteration [10420]: Loss = 0.6355100870132446
Iteration [10421]: Loss = 0.6351466774940491
Iteration [10422]: Loss = 0.6347768306732178
Iteration [10423]: Loss = 0.6344011425971985
Iteration [10424]: Loss = 0.6340203881263733
Iteration [10425]: Loss = 0.6336349844932556
Iteration [10426]: Loss = 0.6332454681396484
Iteration [10427]: Loss = 0.6328523755073547
Iteration [10428]: Loss = 0.6324557662010193
Iteration [10429]: Loss = 0.6320562958717346
Iteration [10430]: Loss = 0.6316540837287903
Iteration [10431]: Loss = 0.6312496662139893
Iteration [10432]: Loss = 5.338869094848633
Iteration [10433]: Loss = 0.6307399868965149
Iteration [10434]: Loss = 10.05007553100586
Iteration [10435]: Loss = 0.6310427188873291
Iteration [10436]: Loss = 0.6313952803611755
Iteration [10437]: Loss = 0.6316710114479065
Iteration [10438]: Loss = 0.6318774223327637
Iteration [10439]: Loss = 0.6320213079452515
Iteration [10440]: Loss = 0.6321088075637817
Iteration [10441]: Loss = 0.6321456432342529
Iteration [10442]: Loss = 0.6321367621421814
Iteration [10443]: Loss = 0.6320867538452148
Iteration [10444]: Loss = 0.6319996118545532
Iteration [10445]: Loss = 0.6318791508674622
Iteration [10446]: Loss = 0.6317286491394043
Iteration [10447]: Loss = 0.6315510869026184
Iteration [10448]: Loss = 0.6313490271568298
Iteration [10449]: Loss = 0.6311252117156982
Iteration [10450]: Loss = 0.630881667137146
Iteration [10451]: Loss = 0.6306203603744507
Iteration [10452]: Loss = 0.6303430199623108
Iteration [10453]: Loss = 0.6300513744354248
Iteration [10454]: Loss = 5.34564208984375
Iteration [10455]: Loss = 0.6297329664230347
Iteration [10456]: Loss = 0.6296784281730652
Iteration [10457]: Loss = 5.3466291427612305
Iteration [10458]: Loss = 0.6297646164894104
Iteration [10459]: Loss = 0.6298823952674866
Iteration [10460]: Loss = 0.6299464702606201
Iteration [10461]: Loss = 0.6299623250961304
Iteration [10462]: Loss = 5.344481468200684
Iteration [10463]: Loss = 5.343035697937012
Iteration [10464]: Loss = 0.6306359171867371
Iteration [10465]: Loss = 0.631015419960022
Iteration [10466]: Loss = 10.040596008300781
Iteration [10467]: Loss = 0.6321313977241516
Iteration [10468]: Loss = 0.6328253149986267
Iteration [10469]: Loss = 5.323082447052002
Iteration [10470]: Loss = 0.6341873407363892
Iteration [10471]: Loss = 0.6348469853401184
Iteration [10472]: Loss = 0.6353999376296997
Iteration [10473]: Loss = 0.6358563899993896
Iteration [10474]: Loss = 0.6362258195877075
Iteration [10475]: Loss = 0.6365169882774353
Iteration [10476]: Loss = 5.302754878997803
Iteration [10477]: Loss = 0.6371886730194092
Iteration [10478]: Loss = 0.6375535726547241
Iteration [10479]: Loss = 0.6378403306007385
Iteration [10480]: Loss = 0.6380569338798523
Iteration [10481]: Loss = 5.293814659118652
Iteration [10482]: Loss = 0.6386005878448486
Iteration [10483]: Loss = 0.6389105319976807
Iteration [10484]: Loss = 0.6391478180885315
Iteration [10485]: Loss = 0.6393197774887085
Iteration [10486]: Loss = 0.6394324898719788
Iteration [10487]: Loss = 0.6394921541213989
Iteration [10488]: Loss = 0.6395039558410645
Iteration [10489]: Loss = 5.2861738204956055
Iteration [10490]: Loss = 0.6396974325180054
Iteration [10491]: Loss = 5.283846855163574
Iteration [10492]: Loss = 0.6402544975280762
Iteration [10493]: Loss = 0.6405698657035828
Iteration [10494]: Loss = 0.6408119201660156
Iteration [10495]: Loss = 0.6409879922866821
Iteration [10496]: Loss = 0.6411045789718628
Iteration [10497]: Loss = 0.6411675214767456
Iteration [10498]: Loss = 0.6411821246147156
Iteration [10499]: Loss = 0.6411533355712891
Iteration [10500]: Loss = 0.6410853862762451
Iteration [10501]: Loss = 0.6409819722175598
Iteration [10502]: Loss = 0.6408469080924988
Iteration [10503]: Loss = 0.6406832337379456
Iteration [10504]: Loss = 0.6404938101768494
Iteration [10505]: Loss = 0.6402812004089355
Iteration [10506]: Loss = 0.6400476694107056
Iteration [10507]: Loss = 0.6397955417633057
Iteration [10508]: Loss = 0.6395264863967896
Iteration [10509]: Loss = 0.6392421126365662
Iteration [10510]: Loss = 0.638944149017334
Iteration [10511]: Loss = 0.6386339664459229
Iteration [10512]: Loss = 0.6383126974105835
Iteration [10513]: Loss = 0.637981653213501
Iteration [10514]: Loss = 5.297262191772461
Iteration [10515]: Loss = 0.6375904083251953
Iteration [10516]: Loss = 0.6375026106834412
Iteration [10517]: Loss = 0.6373816728591919
Iteration [10518]: Loss = 0.6372308135032654
Iteration [10519]: Loss = 0.6370531320571899
Iteration [10520]: Loss = 0.6368512511253357
Iteration [10521]: Loss = 5.303422927856445
Iteration [10522]: Loss = 0.636681318283081
Iteration [10523]: Loss = 0.636687695980072
Iteration [10524]: Loss = 0.6366515159606934
Iteration [10525]: Loss = 5.303730010986328
Iteration [10526]: Loss = 5.302590847015381
Iteration [10527]: Loss = 0.6371856927871704
Iteration [10528]: Loss = 0.6375234127044678
Iteration [10529]: Loss = 0.6377859115600586
Iteration [10530]: Loss = 0.637980580329895
Iteration [10531]: Loss = 0.6381139755249023
Iteration [10532]: Loss = 0.6381922960281372
Iteration [10533]: Loss = 0.638221025466919
Iteration [10534]: Loss = 0.6382049322128296
Iteration [10535]: Loss = 0.6381484866142273
Iteration [10536]: Loss = 5.294748306274414
Iteration [10537]: Loss = 5.2937164306640625
Iteration [10538]: Loss = 0.6386317610740662
Iteration [10539]: Loss = 5.289300918579102
Iteration [10540]: Loss = 0.6394980549812317
Iteration [10541]: Loss = 0.6399452090263367
Iteration [10542]: Loss = 0.6403062343597412
Iteration [10543]: Loss = 0.6405895948410034
Iteration [10544]: Loss = 0.6408028602600098
Iteration [10545]: Loss = 0.640953004360199
Iteration [10546]: Loss = 0.6410462856292725
Iteration [10547]: Loss = 5.276431560516357
Iteration [10548]: Loss = 0.6413779258728027
Iteration [10549]: Loss = 0.6415970325469971
Iteration [10550]: Loss = 0.641752302646637
Iteration [10551]: Loss = 0.6418502330780029
Iteration [10552]: Loss = 0.6418962478637695
Iteration [10553]: Loss = 0.6418957710266113
Iteration [10554]: Loss = 0.6418531537055969
Iteration [10555]: Loss = 0.6417727470397949
Iteration [10556]: Loss = 5.273003101348877
Iteration [10557]: Loss = 5.272104263305664
Iteration [10558]: Loss = 0.6421936750411987
Iteration [10559]: Loss = 0.6424992084503174
Iteration [10560]: Loss = 0.6427325010299683
Iteration [10561]: Loss = 0.6429004669189453
Iteration [10562]: Loss = 0.6430098414421082
Iteration [10563]: Loss = 0.6430661678314209
Iteration [10564]: Loss = 5.264504909515381
Iteration [10565]: Loss = 0.6433340311050415
Iteration [10566]: Loss = 0.6435254812240601
Iteration [10567]: Loss = 0.6436557769775391
Iteration [10568]: Loss = 0.6437311172485352
Iteration [10569]: Loss = 5.2604241371154785
Iteration [10570]: Loss = 0.6440309882164001
Iteration [10571]: Loss = 0.6442359685897827
Iteration [10572]: Loss = 0.6443785429000854
Iteration [10573]: Loss = 0.6444646120071411
Iteration [10574]: Loss = 0.6445000767707825
Iteration [10575]: Loss = 0.6444897651672363
Iteration [10576]: Loss = 0.6444383859634399
Iteration [10577]: Loss = 0.6443498134613037
Iteration [10578]: Loss = 5.257607936859131
Iteration [10579]: Loss = 5.256760120391846
Iteration [10580]: Loss = 0.6447482109069824
Iteration [10581]: Loss = 0.6450470089912415
Iteration [10582]: Loss = 0.6452739238739014
Iteration [10583]: Loss = 0.64543616771698
Iteration [10584]: Loss = 0.6455400586128235
Iteration [10585]: Loss = 0.6455913782119751
Iteration [10586]: Loss = 0.6455953121185303
Iteration [10587]: Loss = 9.853815078735352
Iteration [10588]: Loss = 0.6460604667663574
Iteration [10589]: Loss = 0.6464724540710449
Iteration [10590]: Loss = 0.6468017101287842
Iteration [10591]: Loss = 0.6470564007759094
Iteration [10592]: Loss = 0.6472439765930176
Iteration [10593]: Loss = 0.6473708748817444
Iteration [10594]: Loss = 0.6474432349205017
Iteration [10595]: Loss = 0.6474663615226746
Iteration [10596]: Loss = 0.6474453210830688
Iteration [10597]: Loss = 0.6473843455314636
Iteration [10598]: Loss = 0.6472874283790588
Iteration [10599]: Loss = 0.647158145904541
Iteration [10600]: Loss = 0.6469997763633728
Iteration [10601]: Loss = 0.6468151211738586
Iteration [10602]: Loss = 0.646606981754303
Iteration [10603]: Loss = 0.646377444267273
Iteration [10604]: Loss = 0.6461288928985596
Iteration [10605]: Loss = 0.6458631157875061
Iteration [10606]: Loss = 0.6455819606781006
Iteration [10607]: Loss = 0.6452868580818176
Iteration [10608]: Loss = 0.6449793577194214
Iteration [10609]: Loss = 0.6446604132652283
Iteration [10610]: Loss = 0.6443314552307129
Iteration [10611]: Loss = 0.6439934372901917
Iteration [10612]: Loss = 0.643647313117981
Iteration [10613]: Loss = 0.6432938575744629
Iteration [10614]: Loss = 0.64293372631073
Iteration [10615]: Loss = 0.6425678133964539
Iteration [10616]: Loss = 0.6421965956687927
Iteration [10617]: Loss = 0.6418205499649048
Iteration [10618]: Loss = 0.6414403319358826
Iteration [10619]: Loss = 0.6410564184188843
Iteration [10620]: Loss = 0.6406689286231995
Iteration [10621]: Loss = 0.6402784585952759
Iteration [10622]: Loss = 0.6398851871490479
Iteration [10623]: Loss = 5.286070823669434
Iteration [10624]: Loss = 0.6393861174583435
Iteration [10625]: Loss = 0.6392512321472168
Iteration [10626]: Loss = 0.6390880942344666
Iteration [10627]: Loss = 0.6388996243476868
Iteration [10628]: Loss = 0.6386883854866028
Iteration [10629]: Loss = 0.6384566426277161
Iteration [10630]: Loss = 0.6382063627243042
Iteration [10631]: Loss = 0.6379395127296448
Iteration [10632]: Loss = 0.6376575827598572
Iteration [10633]: Loss = 0.6373623013496399
Iteration [10634]: Loss = 0.6370550394058228
Iteration [10635]: Loss = 0.6367368698120117
Iteration [10636]: Loss = 5.304754734039307
Iteration [10637]: Loss = 0.6363666653633118
Iteration [10638]: Loss = 0.636287271976471
Iteration [10639]: Loss = 0.6361744403839111
Iteration [10640]: Loss = 0.6360312700271606
Iteration [10641]: Loss = 0.6358609199523926
Iteration [10642]: Loss = 0.6356661915779114
Iteration [10643]: Loss = 0.6354492902755737
Iteration [10644]: Loss = 0.6352126598358154
Iteration [10645]: Loss = 0.6349582672119141
Iteration [10646]: Loss = 0.6346878409385681
Iteration [10647]: Loss = 0.634402871131897
Iteration [10648]: Loss = 0.6341049671173096
Iteration [10649]: Loss = 5.320715427398682
Iteration [10650]: Loss = 0.6337705850601196
Iteration [10651]: Loss = 0.6337069272994995
Iteration [10652]: Loss = 0.6336082816123962
Iteration [10653]: Loss = 0.6334782838821411
Iteration [10654]: Loss = 0.6333197355270386
Iteration [10655]: Loss = 0.6331356763839722
Iteration [10656]: Loss = 0.632928729057312
Iteration [10657]: Loss = 0.6327010989189148
Iteration [10658]: Loss = 0.6324548125267029
Iteration [10659]: Loss = 0.6321918368339539
Iteration [10660]: Loss = 5.332269668579102
Iteration [10661]: Loss = 0.6319177150726318
Iteration [10662]: Loss = 0.6318802833557129
Iteration [10663]: Loss = 0.6318051218986511
Iteration [10664]: Loss = 0.6316964030265808
Iteration [10665]: Loss = 0.6315571665763855
Iteration [10666]: Loss = 0.6313905715942383
Iteration [10667]: Loss = 0.6311993598937988
Iteration [10668]: Loss = 0.6309859752655029
Iteration [10669]: Loss = 0.6307527422904968
Iteration [10670]: Loss = 0.6305014491081238
Iteration [10671]: Loss = 0.6302341818809509
Iteration [10672]: Loss = 0.6299522519111633
Iteration [10673]: Loss = 5.346197605133057
Iteration [10674]: Loss = 0.629646897315979
Iteration [10675]: Loss = 0.629596471786499
Iteration [10676]: Loss = 0.6295099258422852
Iteration [10677]: Loss = 0.6293908953666687
Iteration [10678]: Loss = 0.6292426586151123
Iteration [10679]: Loss = 0.6290680170059204
Iteration [10680]: Loss = 0.6288697123527527
Iteration [10681]: Loss = 5.3524394035339355
Iteration [10682]: Loss = 0.628707230091095
Iteration [10683]: Loss = 0.628717839717865
Iteration [10684]: Loss = 0.6286863088607788
Iteration [10685]: Loss = 0.6286168694496155
Iteration [10686]: Loss = 0.6285132169723511
Iteration [10687]: Loss = 0.6283789277076721
Iteration [10688]: Loss = 0.6282169222831726
Iteration [10689]: Loss = 0.628030002117157
Iteration [10690]: Loss = 0.6278205513954163
Iteration [10691]: Loss = 0.6275911331176758
Iteration [10692]: Loss = 0.6273434162139893
Iteration [10693]: Loss = 5.362204074859619
Iteration [10694]: Loss = 0.6270974278450012
Iteration [10695]: Loss = 5.362245082855225
Iteration [10696]: Loss = 0.6273050308227539
Iteration [10697]: Loss = 0.6274733543395996
Iteration [10698]: Loss = 5.359062671661377
Iteration [10699]: Loss = 0.627937376499176
Iteration [10700]: Loss = 0.6282147169113159
Iteration [10701]: Loss = 0.6284236907958984
Iteration [10702]: Loss = 0.6274535655975342
Iteration [10703]: Loss = 5.3593645095825195
Iteration [10704]: Loss = 0.6279182434082031
Iteration [10705]: Loss = 0.6282034516334534
Iteration [10706]: Loss = 0.6284044981002808
Iteration [10707]: Loss = 0.628541886806488
Iteration [10708]: Loss = 0.6286221146583557
Iteration [10709]: Loss = 0.6286507248878479
Iteration [10710]: Loss = 0.6286328434944153
Iteration [10711]: Loss = 0.6285730600357056
Iteration [10712]: Loss = 0.628475546836853
Iteration [10713]: Loss = 0.6283442378044128
Iteration [10714]: Loss = 5.355343818664551
Iteration [10715]: Loss = 0.6283073425292969
Iteration [10716]: Loss = 0.6283764839172363
Iteration [10717]: Loss = 0.6283950805664062
Iteration [10718]: Loss = 5.354187965393066
Iteration [10719]: Loss = 0.6286141276359558
Iteration [10720]: Loss = 0.6287921667098999
Iteration [10721]: Loss = 0.6289088726043701
Iteration [10722]: Loss = 0.6289702653884888
Iteration [10723]: Loss = 0.6289820671081543
Iteration [10724]: Loss = 5.350584506988525
Iteration [10725]: Loss = 0.6291891932487488
Iteration [10726]: Loss = 0.6293619275093079
Iteration [10727]: Loss = 0.6294738054275513
Iteration [10728]: Loss = 0.6295310258865356
Iteration [10729]: Loss = 0.629538893699646
Iteration [10730]: Loss = 0.6295022368431091
Iteration [10731]: Loss = 0.6294256448745728
Iteration [10732]: Loss = 0.6293129920959473
Iteration [10733]: Loss = 0.6291678547859192
Iteration [10734]: Loss = 0.628993570804596
Iteration [10735]: Loss = 0.628792941570282
Iteration [10736]: Loss = 5.3529438972473145
Iteration [10737]: Loss = 5.352515697479248
Iteration [10738]: Loss = 0.6289690732955933
Iteration [10739]: Loss = 0.6292243003845215
Iteration [10740]: Loss = 5.347724437713623
Iteration [10741]: Loss = 0.6298465728759766
Iteration [10742]: Loss = 0.6301959753036499
Iteration [10743]: Loss = 0.6304646134376526
Iteration [10744]: Loss = 0.6306533813476562
Iteration [10745]: Loss = 0.6307823657989502
Iteration [10746]: Loss = 0.6308573484420776
Iteration [10747]: Loss = 0.6308839917182922
Iteration [10748]: Loss = 0.6308666467666626
Iteration [10749]: Loss = 5.339071273803711
Iteration [10750]: Loss = 0.6310123205184937
Iteration [10751]: Loss = 0.6311532258987427
Iteration [10752]: Loss = 0.6312392354011536
Iteration [10753]: Loss = 0.6312755346298218
Iteration [10754]: Loss = 5.3362531661987305
Iteration [10755]: Loss = 0.6315123438835144
Iteration [10756]: Loss = 0.631692111492157
Iteration [10757]: Loss = 0.6318128108978271
Iteration [10758]: Loss = 0.631880521774292
Iteration [10759]: Loss = 0.6319003701210022
Iteration [10760]: Loss = 0.6318771839141846
Iteration [10761]: Loss = 0.6318150758743286
Iteration [10762]: Loss = 5.333474636077881
Iteration [10763]: Loss = 0.6318836808204651
Iteration [10764]: Loss = 0.6319918036460876
Iteration [10765]: Loss = 0.6320478320121765
Iteration [10766]: Loss = 0.6320574283599854
Iteration [10767]: Loss = 0.6320248246192932
Iteration [10768]: Loss = 0.6319543123245239
Iteration [10769]: Loss = 0.6318498253822327
Iteration [10770]: Loss = 0.6317145228385925
Iteration [10771]: Loss = 0.6315515637397766
Iteration [10772]: Loss = 0.631363570690155
Iteration [10773]: Loss = 0.631153404712677
Iteration [10774]: Loss = 5.338375568389893
Iteration [10775]: Loss = 0.6309692859649658
Iteration [10776]: Loss = 0.6309700608253479
Iteration [10777]: Loss = 0.6309295892715454
Iteration [10778]: Loss = 5.338812828063965
Iteration [10779]: Loss = 0.6310354471206665
Iteration [10780]: Loss = 0.6311594247817993
Iteration [10781]: Loss = 0.6312301158905029
Iteration [10782]: Loss = 0.6312527656555176
Iteration [10783]: Loss = 5.336470127105713
Iteration [10784]: Loss = 0.6314659118652344
Iteration [10785]: Loss = 0.6316356062889099
Iteration [10786]: Loss = 0.6317474246025085
Iteration [10787]: Loss = 5.332927703857422
Iteration [10788]: Loss = 0.6321128606796265
Iteration [10789]: Loss = 0.6323471665382385
Iteration [10790]: Loss = 0.6325170993804932
Iteration [10791]: Loss = 0.6326291561126709
Iteration [10792]: Loss = 0.6326888799667358
Iteration [10793]: Loss = 0.6327015161514282
Iteration [10794]: Loss = 0.6326719522476196
Iteration [10795]: Loss = 0.6326038837432861
Iteration [10796]: Loss = 5.3286542892456055
Iteration [10797]: Loss = 0.6326620578765869
Iteration [10798]: Loss = 0.632765531539917
Iteration [10799]: Loss = 0.6328176259994507
Iteration [10800]: Loss = 0.6328233480453491
Iteration [10801]: Loss = 0.6327873468399048
Iteration [10802]: Loss = 5.32735013961792
Iteration [10803]: Loss = 0.6328999400138855
Iteration [10804]: Loss = 0.6330264806747437
Iteration [10805]: Loss = 0.6330993175506592
Iteration [10806]: Loss = 0.6331237554550171
Iteration [10807]: Loss = 0.6331045627593994
Iteration [10808]: Loss = 0.6330462098121643
Iteration [10809]: Loss = 5.325884819030762
Iteration [10810]: Loss = 0.6331203579902649
Iteration [10811]: Loss = 0.6332306861877441
Iteration [10812]: Loss = 0.6332887411117554
Iteration [10813]: Loss = 0.6332998871803284
Iteration [10814]: Loss = 0.6332685947418213
Iteration [10815]: Loss = 0.6331994533538818
Iteration [10816]: Loss = 0.6330958604812622
Iteration [10817]: Loss = 0.6329615712165833
Iteration [10818]: Loss = 0.6327992081642151
Iteration [10819]: Loss = 0.6326120495796204
Iteration [10820]: Loss = 0.6324023604393005
Iteration [10821]: Loss = 0.6321723461151123
Iteration [10822]: Loss = 0.631924033164978
Iteration [10823]: Loss = 0.6316593885421753
Iteration [10824]: Loss = 0.6313799619674683
Iteration [10825]: Loss = 0.6310872435569763
Iteration [10826]: Loss = 0.6307827234268188
Iteration [10827]: Loss = 0.6304673552513123
Iteration [10828]: Loss = 0.6301423907279968
Iteration [10829]: Loss = 0.629808783531189
Iteration [10830]: Loss = 0.6294673681259155
Iteration [10831]: Loss = 0.6291190981864929
Iteration [10832]: Loss = 0.628764271736145
Iteration [10833]: Loss = 5.353965759277344
Iteration [10834]: Loss = 0.6283350586891174
Iteration [10835]: Loss = 0.6282317638397217
Iteration [10836]: Loss = 0.6280980110168457
Iteration [10837]: Loss = 0.6279364824295044
Iteration [10838]: Loss = 0.6277502775192261
Iteration [10839]: Loss = 0.6275416016578674
Iteration [10840]: Loss = 0.6273127794265747
Iteration [10841]: Loss = 0.6270658373832703
Iteration [10842]: Loss = 0.6268026828765869
Iteration [10843]: Loss = 0.6265247464179993
Iteration [10844]: Loss = 0.6262337565422058
Iteration [10845]: Loss = 5.369368076324463
Iteration [10846]: Loss = 0.6259138584136963
Iteration [10847]: Loss = 0.6258577704429626
Iteration [10848]: Loss = 10.115023612976074
Iteration [10849]: Loss = 0.6262287497520447
Iteration [10850]: Loss = 10.103716850280762
Iteration [10851]: Loss = 0.6274750828742981
Iteration [10852]: Loss = 0.6282195448875427
Iteration [10853]: Loss = 0.6288503408432007
Iteration [10854]: Loss = 0.6293785572052002
Iteration [10855]: Loss = 0.6298143863677979
Iteration [10856]: Loss = 0.6301667094230652
Iteration [10857]: Loss = 5.341333389282227
Iteration [10858]: Loss = 0.6309406757354736
Iteration [10859]: Loss = 0.6313481330871582
Iteration [10860]: Loss = 0.6316747665405273
Iteration [10861]: Loss = 5.33217716217041
Iteration [10862]: Loss = 0.6324044466018677
Iteration [10863]: Loss = 0.6327925324440002
Iteration [10864]: Loss = 0.6331018209457397
Iteration [10865]: Loss = 0.6333400011062622
Iteration [10866]: Loss = 0.6335141658782959
Iteration [10867]: Loss = 0.6336305737495422
Iteration [10868]: Loss = 0.6336948871612549
Iteration [10869]: Loss = 5.321224212646484
Iteration [10870]: Loss = 0.6339754462242126
Iteration [10871]: Loss = 0.6341720819473267
Iteration [10872]: Loss = 0.6343085169792175
Iteration [10873]: Loss = 0.6343910694122314
Iteration [10874]: Loss = 5.316862106323242
Iteration [10875]: Loss = 0.6347023248672485
Iteration [10876]: Loss = 0.6349118947982788
Iteration [10877]: Loss = 0.6350600719451904
Iteration [10878]: Loss = 0.6351529359817505
Iteration [10879]: Loss = 0.6351961493492126
Iteration [10880]: Loss = 0.6351944208145142
Iteration [10881]: Loss = 0.635152280330658
Iteration [10882]: Loss = 0.6350736618041992
Iteration [10883]: Loss = 0.6349624395370483
Iteration [10884]: Loss = 0.6348215341567993
Iteration [10885]: Loss = 5.315459251403809
Iteration [10886]: Loss = 5.314863681793213
Iteration [10887]: Loss = 5.312819957733154
Iteration [10888]: Loss = 0.6356330513954163
Iteration [10889]: Loss = 0.6360853314399719
Iteration [10890]: Loss = 0.6364522576332092
Iteration [10891]: Loss = 5.302725791931152
Iteration [10892]: Loss = 0.6372487545013428
Iteration [10893]: Loss = 0.6376646161079407
Iteration [10894]: Loss = 0.6379985809326172
Iteration [10895]: Loss = 0.6382587552070618
Iteration [10896]: Loss = 0.638452410697937
Iteration [10897]: Loss = 0.638586163520813
Iteration [10898]: Loss = 0.6386659145355225
Iteration [10899]: Loss = 0.6386969089508057
Iteration [10900]: Loss = 0.6386840343475342
Iteration [10901]: Loss = 5.291259765625
Iteration [10902]: Loss = 5.290053367614746
Iteration [10903]: Loss = 0.6392557621002197
Iteration [10904]: Loss = 0.6395975351333618
Iteration [10905]: Loss = 0.6398648023605347
Iteration [10906]: Loss = 0.6400647759437561
Iteration [10907]: Loss = 0.6402040719985962
Iteration [10908]: Loss = 5.281248092651367
Iteration [10909]: Loss = 5.27931022644043
Iteration [10910]: Loss = 0.6411439776420593
Iteration [10911]: Loss = 5.273449420928955
Iteration [10912]: Loss = 0.6422240734100342
Iteration [10913]: Loss = 0.6427597999572754
Iteration [10914]: Loss = 0.6432017087936401
Iteration [10915]: Loss = 5.2616071701049805
Iteration [10916]: Loss = 0.644123911857605
Iteration [10917]: Loss = 0.6445920467376709
Iteration [10918]: Loss = 0.6449728012084961
Iteration [10919]: Loss = 0.6452747583389282
Iteration [10920]: Loss = 0.6455056667327881
Iteration [10921]: Loss = 0.6456725001335144
Iteration [10922]: Loss = 0.6457818150520325
Iteration [10923]: Loss = 5.248005390167236
Iteration [10924]: Loss = 5.2462477684021
Iteration [10925]: Loss = 0.6466435194015503
Iteration [10926]: Loss = 0.6470609903335571
Iteration [10927]: Loss = 0.6473960876464844
Iteration [10928]: Loss = 0.6476566791534424
Iteration [10929]: Loss = 0.6478502154350281
Iteration [10930]: Loss = 0.647983193397522
Iteration [10931]: Loss = 5.234817981719971
Iteration [10932]: Loss = 0.6483758687973022
Iteration [10933]: Loss = 0.6486174464225769
Iteration [10934]: Loss = 0.6487938761711121
Iteration [10935]: Loss = 0.6489115953445435
Iteration [10936]: Loss = 0.6489760279655457
Iteration [10937]: Loss = 0.6489928960800171
Iteration [10938]: Loss = 0.6489667892456055
Iteration [10939]: Loss = 0.6489018797874451
Iteration [10940]: Loss = 0.6488021016120911
Iteration [10941]: Loss = 5.231217384338379
Iteration [10942]: Loss = 0.6487969160079956
Iteration [10943]: Loss = 5.230046272277832
Iteration [10944]: Loss = 0.6491771936416626
Iteration [10945]: Loss = 0.649413526058197
Iteration [10946]: Loss = 0.6495848894119263
Iteration [10947]: Loss = 0.6496980786323547
Iteration [10948]: Loss = 0.6497585773468018
Iteration [10949]: Loss = 0.6497716903686523
Iteration [10950]: Loss = 0.649742066860199
Iteration [10951]: Loss = 0.649674117565155
Iteration [10952]: Loss = 5.225902080535889
Iteration [10953]: Loss = 0.6497228145599365
Iteration [10954]: Loss = 0.6498177647590637
Iteration [10955]: Loss = 0.6498619318008423
Iteration [10956]: Loss = 0.6498603224754333
Iteration [10957]: Loss = 0.6498173475265503
Iteration [10958]: Loss = 5.224924564361572
Iteration [10959]: Loss = 0.6499089002609253
Iteration [10960]: Loss = 0.6500222682952881
Iteration [10961]: Loss = 0.6500827670097351
Iteration [10962]: Loss = 0.6500958800315857
Iteration [10963]: Loss = 0.6500662565231323
Iteration [10964]: Loss = 0.6499981880187988
Iteration [10965]: Loss = 0.649895429611206
Iteration [10966]: Loss = 0.6497614979743958
Iteration [10967]: Loss = 14.378009796142578
Iteration [10968]: Loss = 0.6502501368522644
Iteration [10969]: Loss = 0.6507961750030518
Iteration [10970]: Loss = 5.21604061126709
Iteration [10971]: Loss = 5.212271213531494
Iteration [10972]: Loss = 0.6527042388916016
Iteration [10973]: Loss = 0.6533973217010498
Iteration [10974]: Loss = 0.6539813280105591
Iteration [10975]: Loss = 0.6544668674468994
Iteration [10976]: Loss = 0.654863715171814
Iteration [10977]: Loss = 0.6551804542541504
Iteration [10978]: Loss = 5.1916375160217285
Iteration [10979]: Loss = 0.6558811664581299
Iteration [10980]: Loss = 5.186841011047363
Iteration [10981]: Loss = 5.183545112609863
Iteration [10982]: Loss = 0.6575659513473511
Iteration [10983]: Loss = 0.6581977605819702
Iteration [10984]: Loss = 0.6587262749671936
Iteration [10985]: Loss = 0.6591613292694092
Iteration [10986]: Loss = 5.167996883392334
Iteration [10987]: Loss = 0.6600631475448608
Iteration [10988]: Loss = 0.6605182886123657
Iteration [10989]: Loss = 0.6608873605728149
Iteration [10990]: Loss = 0.6611785888671875
Iteration [10991]: Loss = 0.6613999605178833
Iteration [10992]: Loss = 0.661558210849762
Iteration [10993]: Loss = 0.6616594791412354
Iteration [10994]: Loss = 0.6617094874382019
Iteration [10995]: Loss = 0.6617133617401123
Iteration [10996]: Loss = 5.155579566955566
Iteration [10997]: Loss = 0.6618773937225342
Iteration [10998]: Loss = 0.6620176434516907
Iteration [10999]: Loss = 0.6621028184890747
Iteration [11000]: Loss = 0.6621384620666504
Iteration [11001]: Loss = 0.6621291637420654
Iteration [11002]: Loss = 0.6620795130729675
Iteration [11003]: Loss = 0.6619937419891357
Iteration [11004]: Loss = 0.6618751883506775
Iteration [11005]: Loss = 0.6617270708084106
Iteration [11006]: Loss = 0.6615526080131531
Iteration [11007]: Loss = 0.6613541841506958
Iteration [11008]: Loss = 0.6611343026161194
Iteration [11009]: Loss = 0.6608951091766357
Iteration [11010]: Loss = 0.6606385707855225
Iteration [11011]: Loss = 5.163087368011475
Iteration [11012]: Loss = 0.6603582501411438
Iteration [11013]: Loss = 0.6603099703788757
Iteration [11014]: Loss = 0.6602250337600708
Iteration [11015]: Loss = 0.6601076126098633
Iteration [11016]: Loss = 0.6599606275558472
Iteration [11017]: Loss = 5.166417598724365
Iteration [11018]: Loss = 0.6598677635192871
Iteration [11019]: Loss = 5.165772438049316
Iteration [11020]: Loss = 9.668344497680664
Iteration [11021]: Loss = 5.1599884033203125
Iteration [11022]: Loss = 0.6618071794509888
Iteration [11023]: Loss = 0.6625783443450928
Iteration [11024]: Loss = 0.6632323861122131
Iteration [11025]: Loss = 0.663780927658081
Iteration [11026]: Loss = 5.140976905822754
Iteration [11027]: Loss = 5.137337684631348
Iteration [11028]: Loss = 0.6656818389892578
Iteration [11029]: Loss = 0.6663687229156494
Iteration [11030]: Loss = 0.6669465899467468
Iteration [11031]: Loss = 5.122883319854736
Iteration [11032]: Loss = 0.6680890321731567
Iteration [11033]: Loss = 0.6686451435089111
Iteration [11034]: Loss = 0.6691049337387085
Iteration [11035]: Loss = 0.6694778203964233
Iteration [11036]: Loss = 0.6697723865509033
Iteration [11037]: Loss = 0.6699963212013245
Iteration [11038]: Loss = 0.6701565384864807
Iteration [11039]: Loss = 0.6702593564987183
Iteration [11040]: Loss = 5.106651306152344
Iteration [11041]: Loss = 5.1050920486450195
Iteration [11042]: Loss = 0.6710703372955322
Iteration [11043]: Loss = 0.6714627742767334
Iteration [11044]: Loss = 0.6717749238014221
Iteration [11045]: Loss = 0.6720145344734192
Iteration [11046]: Loss = 0.6721887588500977
Iteration [11047]: Loss = 0.6723040342330933
Iteration [11048]: Loss = 0.6723662614822388
Iteration [11049]: Loss = 0.6723807454109192
Iteration [11050]: Loss = 5.095230579376221
Iteration [11051]: Loss = 0.6725581884384155
Iteration [11052]: Loss = 0.6727022528648376
Iteration [11053]: Loss = 0.6727904677391052
Iteration [11054]: Loss = 0.672828197479248
Iteration [11055]: Loss = 0.6728203892707825
Iteration [11056]: Loss = 0.672771692276001
Iteration [11057]: Loss = 5.09336519241333
Iteration [11058]: Loss = 0.6728415489196777
Iteration [11059]: Loss = 0.6729397773742676
Iteration [11060]: Loss = 0.6729865074157715
Iteration [11061]: Loss = 0.6729868650436401
Iteration [11062]: Loss = 5.091920375823975
Iteration [11063]: Loss = 0.6731403470039368
Iteration [11064]: Loss = 0.6732741594314575
Iteration [11065]: Loss = 9.50594711303711
Iteration [11066]: Loss = 0.6739242672920227
Iteration [11067]: Loss = 5.083842754364014
Iteration [11068]: Loss = 0.675052285194397
Iteration [11069]: Loss = 9.47873592376709
Iteration [11070]: Loss = 0.6765855550765991
Iteration [11071]: Loss = 0.6774318218231201
Iteration [11072]: Loss = 0.6781532168388367
Iteration [11073]: Loss = 0.6787618398666382
Iteration [11074]: Loss = 0.6792688369750977
Iteration [11075]: Loss = 0.6796841621398926
Iteration [11076]: Loss = 0.6800166964530945
Iteration [11077]: Loss = 0.6802747845649719
Iteration [11078]: Loss = 5.050384044647217
Iteration [11079]: Loss = 0.6808643937110901
Iteration [11080]: Loss = 0.6811820268630981
Iteration [11081]: Loss = 0.6814263463020325
Iteration [11082]: Loss = 0.6816049814224243
Iteration [11083]: Loss = 0.6817240118980408
Iteration [11084]: Loss = 0.6817893981933594
Iteration [11085]: Loss = 0.6818065047264099
Iteration [11086]: Loss = 0.681780219078064
Iteration [11087]: Loss = 0.6817148327827454
Iteration [11088]: Loss = 0.6816141605377197
Iteration [11089]: Loss = 0.681481659412384
Iteration [11090]: Loss = 0.6813206076622009
Iteration [11091]: Loss = 0.6811338663101196
Iteration [11092]: Loss = 0.6809238791465759
Iteration [11093]: Loss = 0.6806930899620056
Iteration [11094]: Loss = 0.6804436445236206
Iteration [11095]: Loss = 0.6801770925521851
Iteration [11096]: Loss = 0.6798956394195557
Iteration [11097]: Loss = 0.6796003580093384
Iteration [11098]: Loss = 0.6792928576469421
Iteration [11099]: Loss = 0.6789743304252625
Iteration [11100]: Loss = 0.6786459684371948
Iteration [11101]: Loss = 0.6783084869384766
Iteration [11102]: Loss = 0.6779632568359375
Iteration [11103]: Loss = 5.066064834594727
Iteration [11104]: Loss = 0.6775233745574951
Iteration [11105]: Loss = 0.6774031519889832
Iteration [11106]: Loss = 0.677253246307373
Iteration [11107]: Loss = 0.6770766973495483
Iteration [11108]: Loss = 0.6768762469291687
Iteration [11109]: Loss = 0.6766541004180908
Iteration [11110]: Loss = 5.072678089141846
Iteration [11111]: Loss = 5.072608470916748
Iteration [11112]: Loss = 0.6766654849052429
Iteration [11113]: Loss = 0.6768404245376587
Iteration [11114]: Loss = 0.6769564747810364
Iteration [11115]: Loss = 0.677019476890564
Iteration [11116]: Loss = 0.6770344972610474
Iteration [11117]: Loss = 5.069397449493408
Iteration [11118]: Loss = 0.6772104501724243
Iteration [11119]: Loss = 0.6773527264595032
Iteration [11120]: Loss = 0.6774390935897827
Iteration [11121]: Loss = 0.6774752140045166
Iteration [11122]: Loss = 5.066862106323242
Iteration [11123]: Loss = 0.6776872873306274
Iteration [11124]: Loss = 5.064776420593262
Iteration [11125]: Loss = 5.062736988067627
Iteration [11126]: Loss = 0.6787762641906738
Iteration [11127]: Loss = 0.6792404055595398
Iteration [11128]: Loss = 0.6796167492866516
Iteration [11129]: Loss = 5.05340576171875
Iteration [11130]: Loss = 0.6804096698760986
Iteration [11131]: Loss = 0.6808142066001892
Iteration [11132]: Loss = 0.681136965751648
Iteration [11133]: Loss = 0.6813858151435852
Iteration [11134]: Loss = 0.6815680861473083
Iteration [11135]: Loss = 0.6816903948783875
Iteration [11136]: Loss = 0.6817585229873657
Iteration [11137]: Loss = 0.6817781329154968
Iteration [11138]: Loss = 0.6817536950111389
Iteration [11139]: Loss = 0.6816898584365845
Iteration [11140]: Loss = 0.6815903782844543
Iteration [11141]: Loss = 0.6814588308334351
Iteration [11142]: Loss = 0.6812983751296997
Iteration [11143]: Loss = 0.6811120510101318
Iteration [11144]: Loss = 0.6809023022651672
Iteration [11145]: Loss = 0.6806715130805969
Iteration [11146]: Loss = 0.680421769618988
Iteration [11147]: Loss = 5.052084445953369
Iteration [11148]: Loss = 0.6801449060440063
Iteration [11149]: Loss = 5.052420616149902
Iteration [11150]: Loss = 0.6802770495414734
Iteration [11151]: Loss = 0.6804001331329346
Iteration [11152]: Loss = 0.6804691553115845
Iteration [11153]: Loss = 0.6804893016815186
Iteration [11154]: Loss = 0.6804656386375427
Iteration [11155]: Loss = 0.6804022789001465
Iteration [11156]: Loss = 0.6803034543991089
Iteration [11157]: Loss = 0.6801725029945374
Iteration [11158]: Loss = 0.680012583732605
Iteration [11159]: Loss = 0.6798267960548401
Iteration [11160]: Loss = 0.6796175241470337
Iteration [11161]: Loss = 0.6793872117996216
Iteration [11162]: Loss = 5.05766487121582
Iteration [11163]: Loss = 0.6791437268257141
Iteration [11164]: Loss = 0.679107129573822
Iteration [11165]: Loss = 5.0582427978515625
Iteration [11166]: Loss = 0.6791949272155762
Iteration [11167]: Loss = 0.6792993545532227
Iteration [11168]: Loss = 0.6793515086174011
Iteration [11169]: Loss = 0.6793566942214966
Iteration [11170]: Loss = 0.6793192625045776
Iteration [11171]: Loss = 0.679243803024292
Iteration [11172]: Loss = 5.057685852050781
Iteration [11173]: Loss = 0.679265022277832
Iteration [11174]: Loss = 0.679341197013855
Iteration [11175]: Loss = 5.056401252746582
Iteration [11176]: Loss = 5.055009841918945
Iteration [11177]: Loss = 0.6800785660743713
Iteration [11178]: Loss = 0.6804484128952026
Iteration [11179]: Loss = 0.68073970079422
Iteration [11180]: Loss = 0.6809602379798889
Iteration [11181]: Loss = 0.6811166405677795
Iteration [11182]: Loss = 0.6812156438827515
Iteration [11183]: Loss = 0.6812626123428345
Iteration [11184]: Loss = 0.6812629699707031
Iteration [11185]: Loss = 0.6812211275100708
Iteration [11186]: Loss = 0.6811414361000061
Iteration [11187]: Loss = 0.6810275316238403
Iteration [11188]: Loss = 0.6808830499649048
Iteration [11189]: Loss = 0.6807107925415039
Iteration [11190]: Loss = 0.6805136203765869
Iteration [11191]: Loss = 5.051324367523193
Iteration [11192]: Loss = 0.6803268194198608
Iteration [11193]: Loss = 0.6803141832351685
Iteration [11194]: Loss = 0.6802610158920288
Iteration [11195]: Loss = 0.6801709532737732
Iteration [11196]: Loss = 0.680047869682312
Iteration [11197]: Loss = 0.6798948049545288
Iteration [11198]: Loss = 0.6797151565551758
Iteration [11199]: Loss = 0.6795112490653992
Iteration [11200]: Loss = 0.6792856454849243
Iteration [11201]: Loss = 0.6790405511856079
Iteration [11202]: Loss = 0.678777813911438
Iteration [11203]: Loss = 9.44384765625
Iteration [11204]: Loss = 0.6787504553794861
Iteration [11205]: Loss = 0.6789349317550659
Iteration [11206]: Loss = 0.6790595650672913
Iteration [11207]: Loss = 0.6791300177574158
Iteration [11208]: Loss = 0.679151713848114
Iteration [11209]: Loss = 0.679129421710968
Iteration [11210]: Loss = 0.6790676712989807
Iteration [11211]: Loss = 0.6789703369140625
Iteration [11212]: Loss = 0.6788408160209656
Iteration [11213]: Loss = 0.6786824464797974
Iteration [11214]: Loss = 0.6784981489181519
Iteration [11215]: Loss = 0.6782904267311096
Iteration [11216]: Loss = 0.6780616641044617
Iteration [11217]: Loss = 0.6778138875961304
Iteration [11218]: Loss = 0.6775492429733276
Iteration [11219]: Loss = 0.6772690415382385
Iteration [11220]: Loss = 0.6769753098487854
Iteration [11221]: Loss = 5.071260929107666
Iteration [11222]: Loss = 0.6766240000724792
Iteration [11223]: Loss = 0.6765419244766235
Iteration [11224]: Loss = 0.6764262914657593
Iteration [11225]: Loss = 0.6762804985046387
Iteration [11226]: Loss = 0.67610764503479
Iteration [11227]: Loss = 0.675910234451294
Iteration [11228]: Loss = 0.6756908297538757
Iteration [11229]: Loss = 0.6754516959190369
Iteration [11230]: Loss = 0.6751946806907654
Iteration [11231]: Loss = 0.6749218106269836
Iteration [11232]: Loss = 0.6746343374252319
Iteration [11233]: Loss = 0.6743340492248535
Iteration [11234]: Loss = 0.6740220785140991
Iteration [11235]: Loss = 0.673699676990509
Iteration [11236]: Loss = 5.0895676612854
Iteration [11237]: Loss = 0.6733010411262512
Iteration [11238]: Loss = 0.6731993556022644
Iteration [11239]: Loss = 0.673066258430481
Iteration [11240]: Loss = 0.672904908657074
Iteration [11241]: Loss = 0.6727180480957031
Iteration [11242]: Loss = 0.6725082993507385
Iteration [11243]: Loss = 0.6722779870033264
Iteration [11244]: Loss = 0.6720291972160339
Iteration [11245]: Loss = 0.67176353931427
Iteration [11246]: Loss = 0.6714830994606018
Iteration [11247]: Loss = 0.67118901014328
Iteration [11248]: Loss = 0.6708827614784241
Iteration [11249]: Loss = 0.670565664768219
Iteration [11250]: Loss = 0.6702389121055603
Iteration [11251]: Loss = 0.6699031591415405
Iteration [11252]: Loss = 0.6695595383644104
Iteration [11253]: Loss = 0.6692088842391968
Iteration [11254]: Loss = 0.6688517928123474
Iteration [11255]: Loss = 0.6684891581535339
Iteration [11256]: Loss = 0.6681211590766907
Iteration [11257]: Loss = 5.121062278747559
Iteration [11258]: Loss = 5.121635913848877
Iteration [11259]: Loss = 0.6677881479263306
Iteration [11260]: Loss = 0.667874276638031
Iteration [11261]: Loss = 5.120150089263916
Iteration [11262]: Loss = 0.6681750416755676
Iteration [11263]: Loss = 0.6683722734451294
Iteration [11264]: Loss = 0.6685085296630859
Iteration [11265]: Loss = 0.6685901880264282
Iteration [11266]: Loss = 0.6686221361160278
Iteration [11267]: Loss = 0.6686096787452698
Iteration [11268]: Loss = 0.6685572266578674
Iteration [11269]: Loss = 0.6684685349464417
Iteration [11270]: Loss = 0.6683473587036133
Iteration [11271]: Loss = 0.6681969165802002
Iteration [11272]: Loss = 5.119531631469727
Iteration [11273]: Loss = 5.119114398956299
Iteration [11274]: Loss = 0.6683927774429321
Iteration [11275]: Loss = 5.116147518157959
Iteration [11276]: Loss = 0.6690573692321777
Iteration [11277]: Loss = 5.111710071563721
Iteration [11278]: Loss = 0.6699577569961548
Iteration [11279]: Loss = 0.6704102754592896
Iteration [11280]: Loss = 5.104038715362549
Iteration [11281]: Loss = 0.6713371276855469
Iteration [11282]: Loss = 0.6718007326126099
Iteration [11283]: Loss = 0.6721770167350769
Iteration [11284]: Loss = 0.6724743843078613
Iteration [11285]: Loss = 0.6727007031440735
Iteration [11286]: Loss = 0.6728629469871521
Iteration [11287]: Loss = 0.6729675531387329
Iteration [11288]: Loss = 0.6730201244354248
Iteration [11289]: Loss = 0.6730257272720337
Iteration [11290]: Loss = 0.6729891896247864
Iteration [11291]: Loss = 0.6729145050048828
Iteration [11292]: Loss = 0.6728057861328125
Iteration [11293]: Loss = 0.6726661920547485
Iteration [11294]: Loss = 0.6724987626075745
Iteration [11295]: Loss = 0.6723064184188843
Iteration [11296]: Loss = 0.6720916628837585
Iteration [11297]: Loss = 0.6718566417694092
Iteration [11298]: Loss = 0.6716033220291138
Iteration [11299]: Loss = 0.6713336706161499
Iteration [11300]: Loss = 9.533974647521973
Iteration [11301]: Loss = 0.6712985634803772
Iteration [11302]: Loss = 9.528698921203613
Iteration [11303]: Loss = 0.672142744064331
Iteration [11304]: Loss = 5.093303680419922
Iteration [11305]: Loss = 0.6734238266944885
Iteration [11306]: Loss = 0.6740373969078064
Iteration [11307]: Loss = 0.6745492219924927
Iteration [11308]: Loss = 0.6749691963195801
Iteration [11309]: Loss = 5.078801155090332
Iteration [11310]: Loss = 0.6758371591567993
Iteration [11311]: Loss = 0.676274299621582
Iteration [11312]: Loss = 0.6766266822814941
Iteration [11313]: Loss = 0.6769028306007385
Iteration [11314]: Loss = 0.6771103143692017
Iteration [11315]: Loss = 5.068023204803467
Iteration [11316]: Loss = 0.677614152431488
Iteration [11317]: Loss = 0.677895724773407
Iteration [11318]: Loss = 0.6781079173088074
Iteration [11319]: Loss = 0.6782575845718384
Iteration [11320]: Loss = 5.061989784240723
Iteration [11321]: Loss = 0.6786625385284424
Iteration [11322]: Loss = 5.058960914611816
Iteration [11323]: Loss = 0.6793441772460938
Iteration [11324]: Loss = 0.6797012090682983
Iteration [11325]: Loss = 0.6799813508987427
Iteration [11326]: Loss = 0.6801919937133789
Iteration [11327]: Loss = 0.6803402900695801
Iteration [11328]: Loss = 0.680432140827179
Iteration [11329]: Loss = 0.6804732084274292
Iteration [11330]: Loss = 0.6804686188697815
Iteration [11331]: Loss = 9.420814514160156
Iteration [11332]: Loss = 5.048145771026611
Iteration [11333]: Loss = 0.6815066337585449
Iteration [11334]: Loss = 0.6820346713066101
Iteration [11335]: Loss = 0.682468831539154
Iteration [11336]: Loss = 5.037539958953857
Iteration [11337]: Loss = 0.6833583116531372
Iteration [11338]: Loss = 0.6838030815124512
Iteration [11339]: Loss = 0.6841621398925781
Iteration [11340]: Loss = 0.6844439506530762
Iteration [11341]: Loss = 0.6846562027931213
Iteration [11342]: Loss = 0.6848058700561523
Iteration [11343]: Loss = 0.684898853302002
Iteration [11344]: Loss = 0.6849409937858582
Iteration [11345]: Loss = 0.684937059879303
Iteration [11346]: Loss = 0.6848918795585632
Iteration [11347]: Loss = 0.6848096251487732
Iteration [11348]: Loss = 0.6846935749053955
Iteration [11349]: Loss = 0.6845474243164062
Iteration [11350]: Loss = 0.684374213218689
Iteration [11351]: Loss = 5.0301594734191895
Iteration [11352]: Loss = 0.6842249631881714
Iteration [11353]: Loss = 0.6842267513275146
Iteration [11354]: Loss = 0.6841868758201599
Iteration [11355]: Loss = 0.6841091513633728
Iteration [11356]: Loss = 0.6839975714683533
Iteration [11357]: Loss = 0.6838552355766296
Iteration [11358]: Loss = 0.683685302734375
Iteration [11359]: Loss = 0.6834907531738281
Iteration [11360]: Loss = 0.6832737922668457
Iteration [11361]: Loss = 0.6830366849899292
Iteration [11362]: Loss = 0.6827817559242249
Iteration [11363]: Loss = 0.6825103163719177
Iteration [11364]: Loss = 0.6822243928909302
Iteration [11365]: Loss = 0.6819252371788025
Iteration [11366]: Loss = 0.6816143989562988
Iteration [11367]: Loss = 0.6812928915023804
Iteration [11368]: Loss = 0.6809617280960083
Iteration [11369]: Loss = 5.049528121948242
Iteration [11370]: Loss = 0.680544376373291
Iteration [11371]: Loss = 0.6804330348968506
Iteration [11372]: Loss = 0.6802910566329956
Iteration [11373]: Loss = 0.6801216006278992
Iteration [11374]: Loss = 0.6799275279045105
Iteration [11375]: Loss = 5.054516792297363
Iteration [11376]: Loss = 0.6797446012496948
Iteration [11377]: Loss = 0.679733157157898
Iteration [11378]: Loss = 9.429683685302734
Iteration [11379]: Loss = 0.6801272630691528
Iteration [11380]: Loss = 0.6804877519607544
Iteration [11381]: Loss = 0.6807713508605957
Iteration [11382]: Loss = 5.047540187835693
Iteration [11383]: Loss = 0.6814031004905701
Iteration [11384]: Loss = 9.405118942260742
Iteration [11385]: Loss = 0.6825244426727295
Iteration [11386]: Loss = 5.035508155822754
Iteration [11387]: Loss = 0.6840152144432068
Iteration [11388]: Loss = 0.6847159266471863
Iteration [11389]: Loss = 0.6853061318397522
Iteration [11390]: Loss = 0.6857966184616089
Iteration [11391]: Loss = 0.6861971616744995
Iteration [11392]: Loss = 0.6865165829658508
Iteration [11393]: Loss = 0.6867630481719971
Iteration [11394]: Loss = 5.015194892883301
Iteration [11395]: Loss = 0.687328577041626
Iteration [11396]: Loss = 0.6876341700553894
Iteration [11397]: Loss = 0.6878678202629089
Iteration [11398]: Loss = 5.009307861328125
Iteration [11399]: Loss = 0.6884115934371948
Iteration [11400]: Loss = 0.6887078285217285
Iteration [11401]: Loss = 5.004495620727539
Iteration [11402]: Loss = 0.6893579959869385
Iteration [11403]: Loss = 0.6896992325782776
Iteration [11404]: Loss = 0.689965009689331
Iteration [11405]: Loss = 0.690162718296051
Iteration [11406]: Loss = 0.6902990937232971
Iteration [11407]: Loss = 0.6903801560401917
Iteration [11408]: Loss = 0.6904114484786987
Iteration [11409]: Loss = 4.99664831161499
Iteration [11410]: Loss = 0.6906086802482605
Iteration [11411]: Loss = 0.6907566785812378
Iteration [11412]: Loss = 0.690848171710968
Iteration [11413]: Loss = 0.6908889412879944
Iteration [11414]: Loss = 0.6908836960792542
Iteration [11415]: Loss = 0.6908372044563293
Iteration [11416]: Loss = 0.6907535195350647
Iteration [11417]: Loss = 4.995373725891113
Iteration [11418]: Loss = 0.690754234790802
Iteration [11419]: Loss = 4.994400501251221
Iteration [11420]: Loss = 9.294700622558594
Iteration [11421]: Loss = 0.6918330788612366
Iteration [11422]: Loss = 0.6924527883529663
Iteration [11423]: Loss = 0.6929696202278137
Iteration [11424]: Loss = 0.6933934092521667
Iteration [11425]: Loss = 0.6937336325645447
Iteration [11426]: Loss = 0.6939983367919922
Iteration [11427]: Loss = 4.976436614990234
Iteration [11428]: Loss = 0.6945925951004028
Iteration [11429]: Loss = 0.6949090957641602
Iteration [11430]: Loss = 0.6951524019241333
Iteration [11431]: Loss = 0.6953296661376953
Iteration [11432]: Loss = 0.6954473257064819
Iteration [11433]: Loss = 4.9694695472717285
Iteration [11434]: Loss = 0.6957902312278748
Iteration [11435]: Loss = 4.966894149780273
Iteration [11436]: Loss = 0.6964080929756165
Iteration [11437]: Loss = 0.6967344284057617
Iteration [11438]: Loss = 0.6969862580299377
Iteration [11439]: Loss = 0.6971712112426758
Iteration [11440]: Loss = 0.6972956657409668
Iteration [11441]: Loss = 0.6973658204078674
Iteration [11442]: Loss = 0.6973869204521179
Iteration [11443]: Loss = 0.6973636746406555
Iteration [11444]: Loss = 0.6973007917404175
Iteration [11445]: Loss = 0.6972019672393799
Iteration [11446]: Loss = 0.6970708966255188
Iteration [11447]: Loss = 0.6969109177589417
Iteration [11448]: Loss = 0.6967247128486633
Iteration [11449]: Loss = 0.6965147852897644
Iteration [11450]: Loss = 0.6962839365005493
Iteration [11451]: Loss = 0.6960339546203613
Iteration [11452]: Loss = 0.6957666873931885
Iteration [11453]: Loss = 0.6954842805862427
Iteration [11454]: Loss = 0.6951877474784851
Iteration [11455]: Loss = 0.6948787569999695
Iteration [11456]: Loss = 0.6945586800575256
Iteration [11457]: Loss = 0.6942285299301147
Iteration [11458]: Loss = 0.693889319896698
Iteration [11459]: Loss = 0.6935418248176575
Iteration [11460]: Loss = 4.981782913208008
Iteration [11461]: Loss = 0.6930913925170898
Iteration [11462]: Loss = 0.692963182926178
Iteration [11463]: Loss = 4.983809947967529
Iteration [11464]: Loss = 0.6928869485855103
Iteration [11465]: Loss = 0.6929181218147278
Iteration [11466]: Loss = 0.6929042935371399
Iteration [11467]: Loss = 0.69284987449646
Iteration [11468]: Loss = 0.6927590370178223
Iteration [11469]: Loss = 0.692635178565979
Iteration [11470]: Loss = 0.6924818754196167
Iteration [11471]: Loss = 0.692301869392395
Iteration [11472]: Loss = 0.6920979022979736
Iteration [11473]: Loss = 4.988779067993164
Iteration [11474]: Loss = 0.6918925642967224
Iteration [11475]: Loss = 0.6918690800666809
Iteration [11476]: Loss = 0.6918059587478638
Iteration [11477]: Loss = 0.6917073726654053
Iteration [11478]: Loss = 0.6915766596794128
Iteration [11479]: Loss = 0.6914169192314148
Iteration [11480]: Loss = 0.6912313103675842
Iteration [11481]: Loss = 0.6910221576690674
Iteration [11482]: Loss = 0.6907920837402344
Iteration [11483]: Loss = 0.6905428767204285
Iteration [11484]: Loss = 0.6902768611907959
Iteration [11485]: Loss = 0.6899954080581665
Iteration [11486]: Loss = 5.000381946563721
Iteration [11487]: Loss = 0.6896588802337646
Iteration [11488]: Loss = 0.6895798444747925
Iteration [11489]: Loss = 0.6894669532775879
Iteration [11490]: Loss = 0.6893234252929688
Iteration [11491]: Loss = 0.6891523599624634
Iteration [11492]: Loss = 5.004368305206299
Iteration [11493]: Loss = 0.6890045404434204
Iteration [11494]: Loss = 0.6890062093734741
Iteration [11495]: Loss = 0.6889658570289612
Iteration [11496]: Loss = 0.6888875961303711
Iteration [11497]: Loss = 0.6887753009796143
Iteration [11498]: Loss = 0.6886324882507324
Iteration [11499]: Loss = 0.6884620189666748
Iteration [11500]: Loss = 0.6882667541503906
Iteration [11501]: Loss = 0.6880491375923157
Iteration [11502]: Loss = 0.6878113746643066
Iteration [11503]: Loss = 0.6875554919242859
Iteration [11504]: Loss = 0.6872833967208862
Iteration [11505]: Loss = 5.014907360076904
Iteration [11506]: Loss = 0.6869639158248901
Iteration [11507]: Loss = 5.015467643737793
Iteration [11508]: Loss = 0.6870536208152771
Iteration [11509]: Loss = 0.687156617641449
Iteration [11510]: Loss = 0.6872076988220215
Iteration [11511]: Loss = 0.6872118711471558
Iteration [11512]: Loss = 0.6871739625930786
Iteration [11513]: Loss = 0.6870979070663452
Iteration [11514]: Loss = 0.6869878172874451
Iteration [11515]: Loss = 0.6868467330932617
Iteration [11516]: Loss = 0.6866779923439026
Iteration [11517]: Loss = 0.6864843368530273
Iteration [11518]: Loss = 0.6862680912017822
Iteration [11519]: Loss = 0.6860318183898926
Iteration [11520]: Loss = 0.6857770681381226
Iteration [11521]: Loss = 0.6855062246322632
Iteration [11522]: Loss = 0.6852204203605652
Iteration [11523]: Loss = 0.6849214434623718
Iteration [11524]: Loss = 0.6846106648445129
Iteration [11525]: Loss = 0.6842892169952393
Iteration [11526]: Loss = 0.6839579343795776
Iteration [11527]: Loss = 0.6836181282997131
Iteration [11528]: Loss = 0.6832705736160278
Iteration [11529]: Loss = 0.6829161643981934
Iteration [11530]: Loss = 5.038973331451416
Iteration [11531]: Loss = 0.6824579834938049
Iteration [11532]: Loss = 0.682328462600708
Iteration [11533]: Loss = 0.6821704506874084
Iteration [11534]: Loss = 0.6819866895675659
Iteration [11535]: Loss = 0.6817794442176819
Iteration [11536]: Loss = 0.6815512776374817
Iteration [11537]: Loss = 5.045797348022461
Iteration [11538]: Loss = 0.6813094615936279
Iteration [11539]: Loss = 0.6812724471092224
Iteration [11540]: Loss = 0.6811976432800293
Iteration [11541]: Loss = 5.046976566314697
Iteration [11542]: Loss = 0.6812174916267395
Iteration [11543]: Loss = 0.6812919974327087
Iteration [11544]: Loss = 0.6813175082206726
Iteration [11545]: Loss = 0.6812988519668579
Iteration [11546]: Loss = 0.6812406778335571
Iteration [11547]: Loss = 0.6811466217041016
Iteration [11548]: Loss = 0.6810204386711121
Iteration [11549]: Loss = 0.6808651089668274
Iteration [11550]: Loss = 0.6806837320327759
Iteration [11551]: Loss = 5.05031156539917
Iteration [11552]: Loss = 5.050075531005859
Iteration [11553]: Loss = 0.6807878017425537
Iteration [11554]: Loss = 0.6809855103492737
Iteration [11555]: Loss = 0.6811222434043884
Iteration [11556]: Loss = 0.6812036037445068
Iteration [11557]: Loss = 0.6812353730201721
Iteration [11558]: Loss = 0.6812224388122559
Iteration [11559]: Loss = 5.046535968780518
Iteration [11560]: Loss = 0.6813482046127319
Iteration [11561]: Loss = 0.6814680099487305
Iteration [11562]: Loss = 0.6815341711044312
Iteration [11563]: Loss = 0.6815521717071533
Iteration [11564]: Loss = 0.6815266609191895
Iteration [11565]: Loss = 0.6814622282981873
Iteration [11566]: Loss = 5.045480728149414
Iteration [11567]: Loss = 0.6814999580383301
Iteration [11568]: Loss = 0.6815821528434753
Iteration [11569]: Loss = 5.044103622436523
Iteration [11570]: Loss = 0.6818705201148987
Iteration [11571]: Loss = 0.6820595264434814
Iteration [11572]: Loss = 0.6821881532669067
Iteration [11573]: Loss = 0.6822623014450073
Iteration [11574]: Loss = 0.6822871565818787
Iteration [11575]: Loss = 0.6822680234909058
Iteration [11576]: Loss = 0.6822089552879333
Iteration [11577]: Loss = 0.6821140646934509
Iteration [11578]: Loss = 0.681986927986145
Iteration [11579]: Loss = 0.681830644607544
Iteration [11580]: Loss = 0.6816481947898865
Iteration [11581]: Loss = 0.6814422011375427
Iteration [11582]: Loss = 5.046284198760986
Iteration [11583]: Loss = 0.6812387704849243
Iteration [11584]: Loss = 0.6812183260917664
Iteration [11585]: Loss = 0.6811583638191223
Iteration [11586]: Loss = 0.6810624599456787
Iteration [11587]: Loss = 0.680934488773346
Iteration [11588]: Loss = 0.6807776093482971
Iteration [11589]: Loss = 0.6805945634841919
Iteration [11590]: Loss = 0.6803880333900452
Iteration [11591]: Loss = 0.6801605224609375
Iteration [11592]: Loss = 0.6799138188362122
Iteration [11593]: Loss = 0.679650068283081
Iteration [11594]: Loss = 0.6793710589408875
Iteration [11595]: Loss = 5.0579915046691895
Iteration [11596]: Loss = 0.6790435910224915
Iteration [11597]: Loss = 0.6789708733558655
Iteration [11598]: Loss = 0.6788637042045593
Iteration [11599]: Loss = 0.6787256002426147
Iteration [11600]: Loss = 0.6785597205162048
Iteration [11601]: Loss = 0.6783685684204102
Iteration [11602]: Loss = 0.6781550645828247
Iteration [11603]: Loss = 0.6779211759567261
Iteration [11604]: Loss = 0.6776688694953918
Iteration [11605]: Loss = 0.6774001717567444
Iteration [11606]: Loss = 0.6771166324615479
Iteration [11607]: Loss = 0.676819920539856
Iteration [11608]: Loss = 0.6765112280845642
Iteration [11609]: Loss = 0.6761915683746338
Iteration [11610]: Loss = 0.6758624911308289
Iteration [11611]: Loss = 5.077590465545654
Iteration [11612]: Loss = 0.6754510402679443
Iteration [11613]: Loss = 0.6753432750701904
Iteration [11614]: Loss = 5.079363822937012
Iteration [11615]: Loss = 0.6753096580505371
Iteration [11616]: Loss = 0.6753628849983215
Iteration [11617]: Loss = 0.6753692030906677
Iteration [11618]: Loss = 0.675333559513092
Iteration [11619]: Loss = 0.6752599477767944
Iteration [11620]: Loss = 0.6751522421836853
Iteration [11621]: Loss = 5.080422878265381
Iteration [11622]: Loss = 0.6751189231872559
Iteration [11623]: Loss = 0.6751722097396851
Iteration [11624]: Loss = 0.6751787662506104
Iteration [11625]: Loss = 0.6751432418823242
Iteration [11626]: Loss = 5.080112457275391
Iteration [11627]: Loss = 5.07920503616333
Iteration [11628]: Loss = 0.6756096482276917
Iteration [11629]: Loss = 5.075473308563232
Iteration [11630]: Loss = 5.072727680206299
Iteration [11631]: Loss = 5.068999767303467
Iteration [11632]: Loss = 0.6779134273529053
Iteration [11633]: Loss = 0.6786245107650757
Iteration [11634]: Loss = 0.6792234778404236
Iteration [11635]: Loss = 0.6797217130661011
Iteration [11636]: Loss = 5.052229404449463
Iteration [11637]: Loss = 0.6807226538658142
Iteration [11638]: Loss = 0.6812160611152649
Iteration [11639]: Loss = 0.6816187500953674
Iteration [11640]: Loss = 0.6819396615028381
Iteration [11641]: Loss = 0.6821867823600769
Iteration [11642]: Loss = 0.6823675632476807
Iteration [11643]: Loss = 0.6824883818626404
Iteration [11644]: Loss = 0.6825553774833679
Iteration [11645]: Loss = 0.6825736165046692
Iteration [11646]: Loss = 5.039012908935547
Iteration [11647]: Loss = 0.6827534437179565
Iteration [11648]: Loss = 5.037116527557373
Iteration [11649]: Loss = 0.6832528710365295
Iteration [11650]: Loss = 0.6835319995880127
Iteration [11651]: Loss = 0.6837413907051086
Iteration [11652]: Loss = 0.6838879585266113
Iteration [11653]: Loss = 0.6839780807495117
Iteration [11654]: Loss = 0.6840168237686157
Iteration [11655]: Loss = 0.6840099096298218
Iteration [11656]: Loss = 0.6839613914489746
Iteration [11657]: Loss = 0.6838756799697876
Iteration [11658]: Loss = 0.6837564706802368
Iteration [11659]: Loss = 0.6836068034172058
Iteration [11660]: Loss = 0.6834300756454468
Iteration [11661]: Loss = 9.387384414672852
Iteration [11662]: Loss = 0.6835448145866394
Iteration [11663]: Loss = 0.6837877631187439
Iteration [11664]: Loss = 0.6839646100997925
Iteration [11665]: Loss = 0.6840822100639343
Iteration [11666]: Loss = 0.6841461658477783
Iteration [11667]: Loss = 0.6841617822647095
Iteration [11668]: Loss = 0.6841341853141785
Iteration [11669]: Loss = 0.6840673089027405
Iteration [11670]: Loss = 0.6839650869369507
Iteration [11671]: Loss = 0.6838313341140747
Iteration [11672]: Loss = 0.683668851852417
Iteration [11673]: Loss = 0.6834807395935059
Iteration [11674]: Loss = 0.6832694411277771
Iteration [11675]: Loss = 0.6830374002456665
Iteration [11676]: Loss = 0.6827865242958069
Iteration [11677]: Loss = 0.682518720626831
Iteration [11678]: Loss = 0.682235836982727
Iteration [11679]: Loss = 0.6819394826889038
Iteration [11680]: Loss = 0.6816304922103882
Iteration [11681]: Loss = 0.6813108325004578
Iteration [11682]: Loss = 0.6809811592102051
Iteration [11683]: Loss = 0.6806424260139465
Iteration [11684]: Loss = 0.6802958846092224
Iteration [11685]: Loss = 0.6799419522285461
Iteration [11686]: Loss = 5.055226802825928
Iteration [11687]: Loss = 0.6794871091842651
Iteration [11688]: Loss = 0.6793600916862488
Iteration [11689]: Loss = 0.6792040467262268
Iteration [11690]: Loss = 0.6790218353271484
Iteration [11691]: Loss = 0.6788159608840942
Iteration [11692]: Loss = 0.6785891652107239
Iteration [11693]: Loss = 5.062033176422119
Iteration [11694]: Loss = 0.6783510446548462
Iteration [11695]: Loss = 0.6783167123794556
Iteration [11696]: Loss = 0.6782441139221191
Iteration [11697]: Loss = 0.6781370043754578
Iteration [11698]: Loss = 5.063926696777344
Iteration [11699]: Loss = 0.678104043006897
Iteration [11700]: Loss = 5.0630574226379395
Iteration [11701]: Loss = 0.6784332394599915
Iteration [11702]: Loss = 0.6786404848098755
Iteration [11703]: Loss = 0.6787855625152588
Iteration [11704]: Loss = 0.6788743734359741
Iteration [11705]: Loss = 0.6789127588272095
Iteration [11706]: Loss = 0.6789056658744812
Iteration [11707]: Loss = 9.439549446105957
Iteration [11708]: Loss = 0.6793099045753479
Iteration [11709]: Loss = 0.6796759963035583
Iteration [11710]: Loss = 0.6799644231796265
Iteration [11711]: Loss = 0.6801826357841492
Iteration [11712]: Loss = 0.6803376078605652
Iteration [11713]: Loss = 0.6804357767105103
Iteration [11714]: Loss = 5.050291061401367
Iteration [11715]: Loss = 0.6807516813278198
Iteration [11716]: Loss = 0.6809526681900024
Iteration [11717]: Loss = 0.6810919046401978
Iteration [11718]: Loss = 0.6811755895614624
Iteration [11719]: Loss = 0.6812096238136292
Iteration [11720]: Loss = 0.6811984777450562
Iteration [11721]: Loss = 0.6811468601226807
Iteration [11722]: Loss = 0.6810587048530579
Iteration [11723]: Loss = 0.6809377074241638
Iteration [11724]: Loss = 0.6807870268821716
Iteration [11725]: Loss = 0.6806097626686096
Iteration [11726]: Loss = 0.6804084777832031
Iteration [11727]: Loss = 0.6801855564117432
Iteration [11728]: Loss = 0.6799433827400208
Iteration [11729]: Loss = 0.6796835660934448
Iteration [11730]: Loss = 9.432950973510742
Iteration [11731]: Loss = 0.6796565055847168
Iteration [11732]: Loss = 0.6798388957977295
Iteration [11733]: Loss = 0.6799616813659668
Iteration [11734]: Loss = 0.6800310611724854
Iteration [11735]: Loss = 0.6800522804260254
Iteration [11736]: Loss = 0.6800299882888794
Iteration [11737]: Loss = 5.053107738494873
Iteration [11738]: Loss = 0.6801395416259766
Iteration [11739]: Loss = 0.6802523136138916
Iteration [11740]: Loss = 0.6803125143051147
Iteration [11741]: Loss = 0.6803252100944519
Iteration [11742]: Loss = 0.6802954077720642
Iteration [11743]: Loss = 0.6802270412445068
Iteration [11744]: Loss = 0.6801241636276245
Iteration [11745]: Loss = 0.6799900531768799
Iteration [11746]: Loss = 0.6798279285430908
Iteration [11747]: Loss = 0.6796404123306274
Iteration [11748]: Loss = 0.6794302463531494
Iteration [11749]: Loss = 5.057324409484863
Iteration [11750]: Loss = 0.6792196035385132
Iteration [11751]: Loss = 0.6791960597038269
Iteration [11752]: Loss = 0.679133415222168
Iteration [11753]: Loss = 0.6790357232093811
Iteration [11754]: Loss = 0.6789063811302185
Iteration [11755]: Loss = 5.059803009033203
Iteration [11756]: Loss = 0.6788340210914612
Iteration [11757]: Loss = 0.678869366645813
Iteration [11758]: Loss = 0.6788600087165833
Iteration [11759]: Loss = 0.678810179233551
Iteration [11760]: Loss = 9.441153526306152
Iteration [11761]: Loss = 0.6791385412216187
Iteration [11762]: Loss = 0.6794711351394653
Iteration [11763]: Loss = 0.6797294616699219
Iteration [11764]: Loss = 0.6799211502075195
Iteration [11765]: Loss = 0.6800525784492493
Iteration [11766]: Loss = 0.6801297068595886
Iteration [11767]: Loss = 0.6801578998565674
Iteration [11768]: Loss = 0.6801420450210571
Iteration [11769]: Loss = 0.6800865530967712
Iteration [11770]: Loss = 0.6799953579902649
Iteration [11771]: Loss = 0.6798719167709351
Iteration [11772]: Loss = 0.6797195076942444
Iteration [11773]: Loss = 0.6795411109924316
Iteration [11774]: Loss = 0.6793391704559326
Iteration [11775]: Loss = 0.6791161298751831
Iteration [11776]: Loss = 0.6788741946220398
Iteration [11777]: Loss = 0.6786149740219116
Iteration [11778]: Loss = 0.6783404350280762
Iteration [11779]: Loss = 0.6780520677566528
Iteration [11780]: Loss = 0.677751362323761
Iteration [11781]: Loss = 0.6774393320083618
Iteration [11782]: Loss = 0.6771173477172852
Iteration [11783]: Loss = 0.6767861843109131
Iteration [11784]: Loss = 0.6764469742774963
Iteration [11785]: Loss = 0.6761006116867065
Iteration [11786]: Loss = 0.6757475733757019
Iteration [11787]: Loss = 0.6753886342048645
Iteration [11788]: Loss = 9.485701560974121
Iteration [11789]: Loss = 0.6751922965049744
Iteration [11790]: Loss = 0.6753026843070984
Iteration [11791]: Loss = 0.6753612756729126
Iteration [11792]: Loss = 0.6753733158111572
Iteration [11793]: Loss = 5.078595161437988
Iteration [11794]: Loss = 0.6755420565605164
Iteration [11795]: Loss = 0.67568039894104
Iteration [11796]: Loss = 5.076265335083008
Iteration [11797]: Loss = 0.6760647892951965
Iteration [11798]: Loss = 5.073328495025635
Iteration [11799]: Loss = 0.6767269372940063
Iteration [11800]: Loss = 0.6770752668380737
Iteration [11801]: Loss = 0.6773481369018555
Iteration [11802]: Loss = 0.6775529980659485
Iteration [11803]: Loss = 0.6776966452598572
Iteration [11804]: Loss = 0.6777850389480591
Iteration [11805]: Loss = 5.064891815185547
Iteration [11806]: Loss = 0.6780837178230286
Iteration [11807]: Loss = 5.062396049499512
Iteration [11808]: Loss = 0.6786755919456482
Iteration [11809]: Loss = 0.678993821144104
Iteration [11810]: Loss = 0.6792393326759338
Iteration [11811]: Loss = 0.6794195175170898
Iteration [11812]: Loss = 0.6795406341552734
Iteration [11813]: Loss = 0.6796086430549622
Iteration [11814]: Loss = 0.6796287894248962
Iteration [11815]: Loss = 0.6796058416366577
Iteration [11816]: Loss = 5.0554351806640625
Iteration [11817]: Loss = 0.6797137260437012
Iteration [11818]: Loss = 0.6798253655433655
Iteration [11819]: Loss = 0.6798849701881409
Iteration [11820]: Loss = 0.6798973083496094
Iteration [11821]: Loss = 0.6798674464225769
Iteration [11822]: Loss = 0.6797993183135986
Iteration [11823]: Loss = 0.6796967387199402
Iteration [11824]: Loss = 0.6795631051063538
Iteration [11825]: Loss = 0.6794018149375916
Iteration [11826]: Loss = 0.6792152523994446
Iteration [11827]: Loss = 0.6790061593055725
Iteration [11828]: Loss = 0.678776741027832
Iteration [11829]: Loss = 0.6785288453102112
Iteration [11830]: Loss = 5.062463760375977
Iteration [11831]: Loss = 5.06252384185791
Iteration [11832]: Loss = 0.6784694790840149
Iteration [11833]: Loss = 0.678622841835022
Iteration [11834]: Loss = 0.6787197589874268
Iteration [11835]: Loss = 0.6787659525871277
Iteration [11836]: Loss = 0.6787663698196411
Iteration [11837]: Loss = 0.67872554063797
Iteration [11838]: Loss = 0.6786476373672485
Iteration [11839]: Loss = 5.060969829559326
Iteration [11840]: Loss = 0.6786623597145081
Iteration [11841]: Loss = 0.6787348389625549
Iteration [11842]: Loss = 0.6787588000297546
Iteration [11843]: Loss = 5.059854030609131
Iteration [11844]: Loss = 0.6789476871490479
Iteration [11845]: Loss = 0.6790941953659058
Iteration [11846]: Loss = 0.6791850328445435
Iteration [11847]: Loss = 9.435139656066895
Iteration [11848]: Loss = 5.054302215576172
Iteration [11849]: Loss = 0.6804463267326355
Iteration [11850]: Loss = 9.413535118103027
Iteration [11851]: Loss = 0.6820387840270996
Iteration [11852]: Loss = 0.6829053163528442
Iteration [11853]: Loss = 5.033042907714844
Iteration [11854]: Loss = 0.6845323443412781
Iteration [11855]: Loss = 0.6852907538414001
Iteration [11856]: Loss = 5.020646572113037
Iteration [11857]: Loss = 0.6867319941520691
Iteration [11858]: Loss = 0.6874107718467712
Iteration [11859]: Loss = 0.6879812479019165
Iteration [11860]: Loss = 0.6884540319442749
Iteration [11861]: Loss = 5.005000114440918
Iteration [11862]: Loss = 0.689405620098114
Iteration [11863]: Loss = 0.689875066280365
Iteration [11864]: Loss = 0.6902565360069275
Iteration [11865]: Loss = 0.6905587911605835
Iteration [11866]: Loss = 9.298317909240723
Iteration [11867]: Loss = 0.6914750337600708
Iteration [11868]: Loss = 0.6920512914657593
Iteration [11869]: Loss = 4.985280513763428
Iteration [11870]: Loss = 0.6931780576705933
Iteration [11871]: Loss = 4.978947639465332
Iteration [11872]: Loss = 0.6944283246994019
Iteration [11873]: Loss = 0.6950241327285767
Iteration [11874]: Loss = 0.6955195665359497
Iteration [11875]: Loss = 0.6959244608879089
Iteration [11876]: Loss = 0.6962476968765259
Iteration [11877]: Loss = 0.6964973211288452
Iteration [11878]: Loss = 4.963302135467529
Iteration [11879]: Loss = 4.961283206939697
Iteration [11880]: Loss = 0.6976269483566284
Iteration [11881]: Loss = 0.6980927586555481
Iteration [11882]: Loss = 0.6984705328941345
Iteration [11883]: Loss = 0.6987692713737488
Iteration [11884]: Loss = 4.951132774353027
Iteration [11885]: Loss = 0.6994193196296692
Iteration [11886]: Loss = 0.6997584104537964
Iteration [11887]: Loss = 0.7000219821929932
Iteration [11888]: Loss = 0.7002173662185669
Iteration [11889]: Loss = 0.7003517150878906
Iteration [11890]: Loss = 0.7004308700561523
Iteration [11891]: Loss = 0.7004601955413818
Iteration [11892]: Loss = 0.7004446983337402
Iteration [11893]: Loss = 0.7003888487815857
Iteration [11894]: Loss = 0.7002965211868286
Iteration [11895]: Loss = 0.7001715302467346
Iteration [11896]: Loss = 0.7000170946121216
Iteration [11897]: Loss = 0.699836015701294
Iteration [11898]: Loss = 0.6996312141418457
Iteration [11899]: Loss = 0.6994047164916992
Iteration [11900]: Loss = 0.6991590857505798
Iteration [11901]: Loss = 0.6988959908485413
Iteration [11902]: Loss = 0.698617160320282
Iteration [11903]: Loss = 4.954658508300781
Iteration [11904]: Loss = 0.6982807517051697
Iteration [11905]: Loss = 0.6981997489929199
Iteration [11906]: Loss = 0.6980849504470825
Iteration [11907]: Loss = 0.6979396343231201
Iteration [11908]: Loss = 0.6977670788764954
Iteration [11909]: Loss = 0.697569727897644
Iteration [11910]: Loss = 0.697350263595581
Iteration [11911]: Loss = 4.961036205291748
Iteration [11912]: Loss = 0.6971156597137451
Iteration [11913]: Loss = 4.961207866668701
Iteration [11914]: Loss = 0.6972643136978149
Iteration [11915]: Loss = 0.6973901391029358
Iteration [11916]: Loss = 4.95919132232666
Iteration [11917]: Loss = 0.6977455019950867
Iteration [11918]: Loss = 0.697959303855896
Iteration [11919]: Loss = 0.6981101036071777
Iteration [11920]: Loss = 4.955291271209717
Iteration [11921]: Loss = 0.6985077261924744
Iteration [11922]: Loss = 0.6987396478652954
Iteration [11923]: Loss = 0.6989065408706665
Iteration [11924]: Loss = 4.9510369300842285
Iteration [11925]: Loss = 0.6993317604064941
Iteration [11926]: Loss = 0.6995751857757568
Iteration [11927]: Loss = 0.6997525095939636
Iteration [11928]: Loss = 0.6998701095581055
Iteration [11929]: Loss = 0.6999341249465942
Iteration [11930]: Loss = 4.946145057678223
Iteration [11931]: Loss = 4.944924354553223
Iteration [11932]: Loss = 0.7006121873855591
Iteration [11933]: Loss = 4.9408860206604
Iteration [11934]: Loss = 0.7014853954315186
Iteration [11935]: Loss = 0.7019195556640625
Iteration [11936]: Loss = 0.7022686004638672
Iteration [11937]: Loss = 0.7025408744812012
Iteration [11938]: Loss = 0.7027437686920166
Iteration [11939]: Loss = 0.7028843760490417
Iteration [11940]: Loss = 0.7029687762260437
Iteration [11941]: Loss = 0.7030024528503418
Iteration [11942]: Loss = 0.7029904127120972
Iteration [11943]: Loss = 4.930578231811523
Iteration [11944]: Loss = 0.7031090259552002
Iteration [11945]: Loss = 0.7032212018966675
Iteration [11946]: Loss = 0.703279972076416
Iteration [11947]: Loss = 0.703290581703186
Iteration [11948]: Loss = 0.7032577991485596
Iteration [11949]: Loss = 0.7031859755516052
Iteration [11950]: Loss = 0.7030788064002991
Iteration [11951]: Loss = 0.7029399871826172
Iteration [11952]: Loss = 0.7027726769447327
Iteration [11953]: Loss = 0.7025796175003052
Iteration [11954]: Loss = 0.7023634910583496
Iteration [11955]: Loss = 4.9347920417785645
Iteration [11956]: Loss = 0.7021335959434509
Iteration [11957]: Loss = 0.7020977735519409
Iteration [11958]: Loss = 0.7020232081413269
Iteration [11959]: Loss = 0.7019136548042297
Iteration [11960]: Loss = 0.7017725706100464
Iteration [11961]: Loss = 0.7016034126281738
Iteration [11962]: Loss = 0.7014086842536926
Iteration [11963]: Loss = 0.7011910080909729
Iteration [11964]: Loss = 0.7009527683258057
Iteration [11965]: Loss = 0.7006959319114685
Iteration [11966]: Loss = 0.7004224061965942
Iteration [11967]: Loss = 0.7001338601112366
Iteration [11968]: Loss = 0.6998318433761597
Iteration [11969]: Loss = 0.6995176076889038
Iteration [11970]: Loss = 0.6991924047470093
Iteration [11971]: Loss = 0.6988574862480164
Iteration [11972]: Loss = 0.6985138058662415
Iteration [11973]: Loss = 0.6981622576713562
Iteration [11974]: Loss = 0.6978034973144531
Iteration [11975]: Loss = 0.6974383592605591
Iteration [11976]: Loss = 4.961263656616211
Iteration [11977]: Loss = 0.6969561576843262
Iteration [11978]: Loss = 0.6968137621879578
Iteration [11979]: Loss = 0.6966433525085449
Iteration [11980]: Loss = 0.6964479088783264
Iteration [11981]: Loss = 0.6962298154830933
Iteration [11982]: Loss = 0.6959912776947021
Iteration [11983]: Loss = 0.6957345008850098
Iteration [11984]: Loss = 0.6954612731933594
Iteration [11985]: Loss = 0.6951731443405151
Iteration [11986]: Loss = 0.694871723651886
Iteration [11987]: Loss = 4.97451114654541
Iteration [11988]: Loss = 0.694499135017395
Iteration [11989]: Loss = 4.97532844543457
Iteration [11990]: Loss = 0.6945405006408691
Iteration [11991]: Loss = 0.6946215629577637
Iteration [11992]: Loss = 4.9740118980407715
Iteration [11993]: Loss = 4.972689628601074
Iteration [11994]: Loss = 0.6953489184379578
Iteration [11995]: Loss = 0.6957091689109802
Iteration [11996]: Loss = 0.6959915161132812
Iteration [11997]: Loss = 4.965815544128418
Iteration [11998]: Loss = 0.6966161131858826
Iteration [11999]: Loss = 0.6969455480575562
Iteration [12000]: Loss = 0.6972001791000366
Iteration [12001]: Loss = 0.6973872780799866
Iteration [12002]: Loss = 0.6975135803222656
Iteration [12003]: Loss = 0.6975850462913513
Iteration [12004]: Loss = 0.6976072192192078
Iteration [12005]: Loss = 0.6975849270820618
Iteration [12006]: Loss = 0.6975224018096924
Iteration [12007]: Loss = 0.6974239945411682
Iteration [12008]: Loss = 0.6972931623458862
Iteration [12009]: Loss = 0.6971330046653748
Iteration [12010]: Loss = 0.6969464421272278
Iteration [12011]: Loss = 0.696736216545105
Iteration [12012]: Loss = 0.6965047121047974
Iteration [12013]: Loss = 0.6962540745735168
Iteration [12014]: Loss = 0.695986270904541
Iteration [12015]: Loss = 0.695702850818634
Iteration [12016]: Loss = 0.6954054236412048
Iteration [12017]: Loss = 0.695095419883728
Iteration [12018]: Loss = 0.6947741508483887
Iteration [12019]: Loss = 0.6944427490234375
Iteration [12020]: Loss = 0.6941022872924805
Iteration [12021]: Loss = 4.978776454925537
Iteration [12022]: Loss = 0.6936638355255127
Iteration [12023]: Loss = 0.6935408115386963
Iteration [12024]: Loss = 0.6933879852294922
Iteration [12025]: Loss = 0.6932083368301392
Iteration [12026]: Loss = 0.6930043697357178
Iteration [12027]: Loss = 0.6927786469459534
Iteration [12028]: Loss = 0.6925333142280579
Iteration [12029]: Loss = 0.6922703981399536
Iteration [12030]: Loss = 0.6919916272163391
Iteration [12031]: Loss = 0.6916984915733337
Iteration [12032]: Loss = 0.6913925409317017
Iteration [12033]: Loss = 0.6910750865936279
Iteration [12034]: Loss = 0.6907473206520081
Iteration [12035]: Loss = 0.6904101967811584
Iteration [12036]: Loss = 0.6900646686553955
Iteration [12037]: Loss = 0.6897116899490356
Iteration [12038]: Loss = 0.6893518567085266
Iteration [12039]: Loss = 0.68898606300354
Iteration [12040]: Loss = 0.6886148452758789
Iteration [12041]: Loss = 0.6882386207580566
Iteration [12042]: Loss = 0.6878581643104553
Iteration [12043]: Loss = 5.012337684631348
Iteration [12044]: Loss = 0.6873538494110107
Iteration [12045]: Loss = 0.6872040033340454
Iteration [12046]: Loss = 0.6870273351669312
Iteration [12047]: Loss = 0.6868263483047485
Iteration [12048]: Loss = 0.6866035461425781
Iteration [12049]: Loss = 0.6863610744476318
Iteration [12050]: Loss = 0.6861010789871216
Iteration [12051]: Loss = 0.6858251094818115
Iteration [12052]: Loss = 5.022800445556641
Iteration [12053]: Loss = 0.6855000257492065
Iteration [12054]: Loss = 5.023385047912598
Iteration [12055]: Loss = 0.6855867505073547
Iteration [12056]: Loss = 0.6856889128684998
Iteration [12057]: Loss = 0.6857392191886902
Iteration [12058]: Loss = 0.6857427954673767
Iteration [12059]: Loss = 0.6857040524482727
Iteration [12060]: Loss = 0.6856276392936707
Iteration [12061]: Loss = 0.6855168342590332
Iteration [12062]: Loss = 0.6853752732276917
Iteration [12063]: Loss = 0.6852059960365295
Iteration [12064]: Loss = 5.025632381439209
Iteration [12065]: Loss = 0.685063362121582
Iteration [12066]: Loss = 0.6850681304931641
Iteration [12067]: Loss = 0.6850305199623108
Iteration [12068]: Loss = 0.6849550008773804
Iteration [12069]: Loss = 0.6848450899124146
Iteration [12070]: Loss = 0.6847043037414551
Iteration [12071]: Loss = 0.6845358610153198
Iteration [12072]: Loss = 0.6843423843383789
Iteration [12073]: Loss = 0.6841263175010681
Iteration [12074]: Loss = 0.6838899850845337
Iteration [12075]: Loss = 0.6836354732513428
Iteration [12076]: Loss = 0.6833645105361938
Iteration [12077]: Loss = 0.6830790042877197
Iteration [12078]: Loss = 0.6827800273895264
Iteration [12079]: Loss = 5.039442539215088
Iteration [12080]: Loss = 0.682417094707489
Iteration [12081]: Loss = 0.6823285818099976
Iteration [12082]: Loss = 0.6822071671485901
Iteration [12083]: Loss = 0.6820560693740845
Iteration [12084]: Loss = 0.6818783283233643
Iteration [12085]: Loss = 0.6816767454147339
Iteration [12086]: Loss = 0.68145352602005
Iteration [12087]: Loss = 0.6812108159065247
Iteration [12088]: Loss = 0.6809505820274353
Iteration [12089]: Loss = 0.6806745529174805
Iteration [12090]: Loss = 0.6803845167160034
Iteration [12091]: Loss = 5.052486896514893
Iteration [12092]: Loss = 0.6800377368927002
Iteration [12093]: Loss = 0.6799564361572266
Iteration [12094]: Loss = 0.6798416972160339
Iteration [12095]: Loss = 0.6796967387199402
Iteration [12096]: Loss = 0.6795246601104736
Iteration [12097]: Loss = 5.0566205978393555
Iteration [12098]: Loss = 0.6793795228004456
Iteration [12099]: Loss = 0.679384171962738
Iteration [12100]: Loss = 5.056516170501709
Iteration [12101]: Loss = 0.6795412302017212
Iteration [12102]: Loss = 0.6796747446060181
Iteration [12103]: Loss = 0.679753303527832
Iteration [12104]: Loss = 0.6797825694084167
Iteration [12105]: Loss = 5.054210186004639
Iteration [12106]: Loss = 0.6799811720848083
Iteration [12107]: Loss = 0.6801323890686035
Iteration [12108]: Loss = 0.6802268624305725
Iteration [12109]: Loss = 0.6802704334259033
Iteration [12110]: Loss = 0.680267870426178
Iteration [12111]: Loss = 0.6802238821983337
Iteration [12112]: Loss = 0.6801427602767944
Iteration [12113]: Loss = 0.6800277829170227
Iteration [12114]: Loss = 0.6798826456069946
Iteration [12115]: Loss = 5.054522514343262
Iteration [12116]: Loss = 0.6797837615013123
Iteration [12117]: Loss = 5.053986072540283
Iteration [12118]: Loss = 5.052614688873291
Iteration [12119]: Loss = 5.050138473510742
Iteration [12120]: Loss = 0.6811444163322449
Iteration [12121]: Loss = 0.6816738843917847
Iteration [12122]: Loss = 0.6821091175079346
Iteration [12123]: Loss = 0.6824595928192139
Iteration [12124]: Loss = 5.038002967834473
Iteration [12125]: Loss = 0.6832067370414734
Iteration [12126]: Loss = 0.6835911273956299
Iteration [12127]: Loss = 0.6838957667350769
Iteration [12128]: Loss = 5.030422210693359
Iteration [12129]: Loss = 0.6845638751983643
Iteration [12130]: Loss = 0.6849144697189331
Iteration [12131]: Loss = 0.6851884722709656
Iteration [12132]: Loss = 0.6853932738304138
Iteration [12133]: Loss = 0.6855355501174927
Iteration [12134]: Loss = 0.6856217980384827
Iteration [12135]: Loss = 0.6856574416160583
Iteration [12136]: Loss = 5.022191524505615
Iteration [12137]: Loss = 0.6858654618263245
Iteration [12138]: Loss = 0.686019778251648
Iteration [12139]: Loss = 0.6861167550086975
Iteration [12140]: Loss = 5.019411563873291
Iteration [12141]: Loss = 5.017967700958252
Iteration [12142]: Loss = 0.686896562576294
Iteration [12143]: Loss = 0.687275230884552
Iteration [12144]: Loss = 0.6875742673873901
Iteration [12145]: Loss = 0.6878014206886292
Iteration [12146]: Loss = 5.009700775146484
Iteration [12147]: Loss = 0.6883362531661987
Iteration [12148]: Loss = 5.006122589111328
Iteration [12149]: Loss = 0.6891194581985474
Iteration [12150]: Loss = 0.6895185708999634
Iteration [12151]: Loss = 4.999657154083252
Iteration [12152]: Loss = 0.6903467178344727
Iteration [12153]: Loss = 0.6907649040222168
Iteration [12154]: Loss = 0.6910991668701172
Iteration [12155]: Loss = 4.991520881652832
Iteration [12156]: Loss = 4.989077091217041
Iteration [12157]: Loss = 0.6924537420272827
Iteration [12158]: Loss = 0.6929856538772583
Iteration [12159]: Loss = 4.980533599853516
Iteration [12160]: Loss = 0.6940402984619141
Iteration [12161]: Loss = 0.6945545077323914
Iteration [12162]: Loss = 0.6949750185012817
Iteration [12163]: Loss = 0.6953112483024597
Iteration [12164]: Loss = 0.6955714821815491
Iteration [12165]: Loss = 4.968140602111816
Iteration [12166]: Loss = 0.6961605548858643
Iteration [12167]: Loss = 0.6964758038520813
Iteration [12168]: Loss = 0.6967169642448425
Iteration [12169]: Loss = 0.6968913674354553
Iteration [12170]: Loss = 4.961589813232422
Iteration [12171]: Loss = 0.6973335146903992
Iteration [12172]: Loss = 0.6975858807563782
Iteration [12173]: Loss = 0.6977704167366028
Iteration [12174]: Loss = 0.6978936791419983
Iteration [12175]: Loss = 0.6979618072509766
Iteration [12176]: Loss = 0.6979801654815674
Iteration [12177]: Loss = 4.95660400390625
Iteration [12178]: Loss = 4.9555463790893555
Iteration [12179]: Loss = 0.6985612511634827
Iteration [12180]: Loss = 0.698884129524231
Iteration [12181]: Loss = 0.6991318464279175
Iteration [12182]: Loss = 0.6993120908737183
Iteration [12183]: Loss = 0.6994313597679138
Iteration [12184]: Loss = 0.6994957327842712
Iteration [12185]: Loss = 0.6995106339454651
Iteration [12186]: Loss = 0.6994810104370117
Iteration [12187]: Loss = 0.699411153793335
Iteration [12188]: Loss = 4.949516296386719
Iteration [12189]: Loss = 0.6994354128837585
Iteration [12190]: Loss = 0.6995095610618591
Iteration [12191]: Loss = 0.6995331645011902
Iteration [12192]: Loss = 9.197362899780273
Iteration [12193]: Loss = 0.6999815106391907
Iteration [12194]: Loss = 0.7003622055053711
Iteration [12195]: Loss = 0.7006624341011047
Iteration [12196]: Loss = 4.941234111785889
Iteration [12197]: Loss = 0.701317548751831
Iteration [12198]: Loss = 0.7016600370407104
Iteration [12199]: Loss = 0.7019255757331848
Iteration [12200]: Loss = 0.7021217346191406
Iteration [12201]: Loss = 0.702255368232727
Iteration [12202]: Loss = 0.7023328542709351
Iteration [12203]: Loss = 0.7023594379425049
Iteration [12204]: Loss = 0.7023404240608215
Iteration [12205]: Loss = 0.7022801637649536
Iteration [12206]: Loss = 0.7021828293800354
Iteration [12207]: Loss = 0.7020521759986877
Iteration [12208]: Loss = 0.701891303062439
Iteration [12209]: Loss = 0.7017035484313965
Iteration [12210]: Loss = 0.7014912366867065
Iteration [12211]: Loss = 4.93931770324707
Iteration [12212]: Loss = 4.939245700836182
Iteration [12213]: Loss = 4.938014507293701
Iteration [12214]: Loss = 0.7019434571266174
Iteration [12215]: Loss = 0.7022932767868042
Iteration [12216]: Loss = 9.162458419799805
Iteration [12217]: Loss = 0.7032937407493591
Iteration [12218]: Loss = 0.7039074897766113
Iteration [12219]: Loss = 0.7044175863265991
Iteration [12220]: Loss = 0.7048341035842896
Iteration [12221]: Loss = 0.7051665186882019
Iteration [12222]: Loss = 0.7054229378700256
Iteration [12223]: Loss = 0.7056108713150024
Iteration [12224]: Loss = 0.7057368755340576
Iteration [12225]: Loss = 0.7058075070381165
Iteration [12226]: Loss = 0.7058277726173401
Iteration [12227]: Loss = 0.7058031558990479
Iteration [12228]: Loss = 0.7057377099990845
Iteration [12229]: Loss = 0.7056357264518738
Iteration [12230]: Loss = 0.7055007815361023
Iteration [12231]: Loss = 0.7053360342979431
Iteration [12232]: Loss = 0.7051445841789246
Iteration [12233]: Loss = 0.7049292325973511
Iteration [12234]: Loss = 0.7046921253204346
Iteration [12235]: Loss = 4.922813892364502
Iteration [12236]: Loss = 0.7044277787208557
Iteration [12237]: Loss = 0.7043777704238892
Iteration [12238]: Loss = 4.923567771911621
Iteration [12239]: Loss = 0.7044330835342407
Iteration [12240]: Loss = 0.7045193314552307
Iteration [12241]: Loss = 0.7045537829399109
Iteration [12242]: Loss = 0.7045417428016663
Iteration [12243]: Loss = 0.7044877409934998
Iteration [12244]: Loss = 0.7043959498405457
Iteration [12245]: Loss = 0.7042702436447144
Iteration [12246]: Loss = 0.7041140198707581
Iteration [12247]: Loss = 0.703930139541626
Iteration [12248]: Loss = 0.7037214636802673
Iteration [12249]: Loss = 0.7034904956817627
Iteration [12250]: Loss = 0.7032394409179688
Iteration [12251]: Loss = 0.7029704451560974
Iteration [12252]: Loss = 0.7026851177215576
Iteration [12253]: Loss = 0.7023851871490479
Iteration [12254]: Loss = 0.702072024345398
Iteration [12255]: Loss = 0.7017471194267273
Iteration [12256]: Loss = 0.7014116644859314
Iteration [12257]: Loss = 0.7010665535926819
Iteration [12258]: Loss = 0.7007128596305847
Iteration [12259]: Loss = 0.7003515958786011
Iteration [12260]: Loss = 0.6999834179878235
Iteration [12261]: Loss = 0.6996090412139893
Iteration [12262]: Loss = 0.6992290019989014
Iteration [12263]: Loss = 0.6988440752029419
Iteration [12264]: Loss = 0.6984546184539795
Iteration [12265]: Loss = 4.9560394287109375
Iteration [12266]: Loss = 0.6979327201843262
Iteration [12267]: Loss = 0.6977742314338684
Iteration [12268]: Loss = 0.6975888013839722
Iteration [12269]: Loss = 4.959625244140625
Iteration [12270]: Loss = 4.959433555603027
Iteration [12271]: Loss = 0.6976728439331055
Iteration [12272]: Loss = 0.6978617906570435
Iteration [12273]: Loss = 0.6979892253875732
Iteration [12274]: Loss = 0.6980612277984619
Iteration [12275]: Loss = 0.6980831623077393
Iteration [12276]: Loss = 0.6980600357055664
Iteration [12277]: Loss = 4.956380367279053
Iteration [12278]: Loss = 0.6981640458106995
Iteration [12279]: Loss = 0.6982721090316772
Iteration [12280]: Loss = 0.6983266472816467
Iteration [12281]: Loss = 0.6983327269554138
Iteration [12282]: Loss = 0.6982954740524292
Iteration [12283]: Loss = 0.6982188820838928
Iteration [12284]: Loss = 0.6981070041656494
Iteration [12285]: Loss = 0.6979634761810303
Iteration [12286]: Loss = 4.95745849609375
Iteration [12287]: Loss = 0.6978616714477539
Iteration [12288]: Loss = 0.6978822946548462
Iteration [12289]: Loss = 4.957108020782471
Iteration [12290]: Loss = 0.6980611085891724
Iteration [12291]: Loss = 0.698201060295105
Iteration [12292]: Loss = 4.954868316650391
Iteration [12293]: Loss = 0.6985839605331421
Iteration [12294]: Loss = 0.6988109946250916
Iteration [12295]: Loss = 0.6989724636077881
Iteration [12296]: Loss = 0.6990748643875122
Iteration [12297]: Loss = 0.6991241574287415
Iteration [12298]: Loss = 4.9504570960998535
Iteration [12299]: Loss = 0.6993516683578491
Iteration [12300]: Loss = 0.6995124816894531
Iteration [12301]: Loss = 0.6996140480041504
Iteration [12302]: Loss = 4.9476447105407715
Iteration [12303]: Loss = 4.94624137878418
Iteration [12304]: Loss = 0.7003968954086304
Iteration [12305]: Loss = 4.9418416023254395
Iteration [12306]: Loss = 0.7013360857963562
Iteration [12307]: Loss = 0.7017999887466431
Iteration [12308]: Loss = 0.7021747827529907
Iteration [12309]: Loss = 0.7024692893028259
Iteration [12310]: Loss = 0.7026913166046143
Iteration [12311]: Loss = 0.702847957611084
Iteration [12312]: Loss = 0.70294588804245
Iteration [12313]: Loss = 0.7029906511306763
Iteration [12314]: Loss = 0.702987790107727
Iteration [12315]: Loss = 0.7029417753219604
Iteration [12316]: Loss = 0.7028571367263794
Iteration [12317]: Loss = 4.931615829467773
Iteration [12318]: Loss = 0.7028547525405884
Iteration [12319]: Loss = 4.930683612823486
Iteration [12320]: Loss = 4.929227352142334
Iteration [12321]: Loss = 0.7036737203598022
Iteration [12322]: Loss = 0.7040595412254333
Iteration [12323]: Loss = 0.7043636441230774
Iteration [12324]: Loss = 0.7045941948890686
Iteration [12325]: Loss = 0.7047584652900696
Iteration [12326]: Loss = 0.7048629522323608
Iteration [12327]: Loss = 0.7049136757850647
Iteration [12328]: Loss = 0.7049157023429871
Iteration [12329]: Loss = 0.7048742175102234
Iteration [12330]: Loss = 0.7047931551933289
Iteration [12331]: Loss = 0.7046769261360168
Iteration [12332]: Loss = 4.922332286834717
Iteration [12333]: Loss = 0.7046200037002563
Iteration [12334]: Loss = 0.7046589255332947
Iteration [12335]: Loss = 4.9217023849487305
Iteration [12336]: Loss = 0.7048673629760742
Iteration [12337]: Loss = 4.919795513153076
Iteration [12338]: Loss = 0.7053799629211426
Iteration [12339]: Loss = 0.7056615352630615
Iteration [12340]: Loss = 0.70587158203125
Iteration [12341]: Loss = 0.7060171365737915
Iteration [12342]: Loss = 4.914194107055664
Iteration [12343]: Loss = 4.912633419036865
Iteration [12344]: Loss = 0.7069039344787598
Iteration [12345]: Loss = 0.7073073387145996
Iteration [12346]: Loss = 0.7076271772384644
Iteration [12347]: Loss = 0.707871675491333
Iteration [12348]: Loss = 0.7080480456352234
Iteration [12349]: Loss = 0.7081632614135742
Iteration [12350]: Loss = 0.7082231640815735
Iteration [12351]: Loss = 0.7082334756851196
Iteration [12352]: Loss = 0.7081989645957947
Iteration [12353]: Loss = 0.7081239223480225
Iteration [12354]: Loss = 0.7080126404762268
Iteration [12355]: Loss = 0.707868754863739
Iteration [12356]: Loss = 0.7076953053474426
Iteration [12357]: Loss = 0.7074952721595764
Iteration [12358]: Loss = 4.908189296722412
Iteration [12359]: Loss = 0.7072952389717102
Iteration [12360]: Loss = 0.7072728872299194
Iteration [12361]: Loss = 0.7072088718414307
Iteration [12362]: Loss = 0.7071074843406677
Iteration [12363]: Loss = 0.7069724798202515
Iteration [12364]: Loss = 0.706807017326355
Iteration [12365]: Loss = 0.7066144347190857
Iteration [12366]: Loss = 4.912688255310059
Iteration [12367]: Loss = 0.7064271569252014
Iteration [12368]: Loss = 0.7064103484153748
Iteration [12369]: Loss = 0.7063515186309814
Iteration [12370]: Loss = 4.913421154022217
Iteration [12371]: Loss = 0.7063929438591003
Iteration [12372]: Loss = 0.7064736485481262
Iteration [12373]: Loss = 0.7065025568008423
Iteration [12374]: Loss = 0.7064847946166992
Iteration [12375]: Loss = 0.7064250707626343
Iteration [12376]: Loss = 0.706327497959137
Iteration [12377]: Loss = 0.7061958312988281
Iteration [12378]: Loss = 0.7060335278511047
Iteration [12379]: Loss = 0.7058436870574951
Iteration [12380]: Loss = 4.916647911071777
Iteration [12381]: Loss = 0.705661416053772
Iteration [12382]: Loss = 0.7056470513343811
Iteration [12383]: Loss = 0.7055903077125549
Iteration [12384]: Loss = 0.7054955959320068
Iteration [12385]: Loss = 0.705366313457489
Iteration [12386]: Loss = 0.7052063345909119
Iteration [12387]: Loss = 0.7050185203552246
Iteration [12388]: Loss = 0.7048056125640869
Iteration [12389]: Loss = 0.7045701742172241
Iteration [12390]: Loss = 0.7043144702911377
Iteration [12391]: Loss = 0.70404052734375
Iteration [12392]: Loss = 4.926362991333008
Iteration [12393]: Loss = 0.7037156820297241
Iteration [12394]: Loss = 0.7036409378051758
Iteration [12395]: Loss = 0.7035298943519592
Iteration [12396]: Loss = 13.377973556518555
Iteration [12397]: Loss = 0.7040097713470459
Iteration [12398]: Loss = 0.7045287489891052
Iteration [12399]: Loss = 0.7049534916877747
Iteration [12400]: Loss = 0.7052931189537048
Iteration [12401]: Loss = 0.7055560350418091
Iteration [12402]: Loss = 0.7057498693466187
Iteration [12403]: Loss = 0.7058814167976379
Iteration [12404]: Loss = 0.7059568166732788
Iteration [12405]: Loss = 0.7059816122055054
Iteration [12406]: Loss = 0.7059608697891235
Iteration [12407]: Loss = 0.7058991193771362
Iteration [12408]: Loss = 4.9157633781433105
Iteration [12409]: Loss = 0.705933690071106
Iteration [12410]: Loss = 0.7060105800628662
Iteration [12411]: Loss = 0.7060366868972778
Iteration [12412]: Loss = 0.7060171365737915
Iteration [12413]: Loss = 0.7059565186500549
Iteration [12414]: Loss = 0.7058587074279785
Iteration [12415]: Loss = 4.916139125823975
Iteration [12416]: Loss = 0.70583176612854
Iteration [12417]: Loss = 4.915339469909668
Iteration [12418]: Loss = 0.7061501741409302
Iteration [12419]: Loss = 4.91294002532959
Iteration [12420]: Loss = 0.706747829914093
Iteration [12421]: Loss = 0.7070647478103638
Iteration [12422]: Loss = 0.7073071002960205
Iteration [12423]: Loss = 0.7074819803237915
Iteration [12424]: Loss = 0.7075964212417603
Iteration [12425]: Loss = 4.906213283538818
Iteration [12426]: Loss = 0.7079316973686218
Iteration [12427]: Loss = 0.7081364989280701
Iteration [12428]: Loss = 0.7082777619361877
Iteration [12429]: Loss = 0.7083616256713867
Iteration [12430]: Loss = 0.7083938121795654
Iteration [12431]: Loss = 0.7083793878555298
Iteration [12432]: Loss = 0.7083231210708618
Iteration [12433]: Loss = 4.903273105621338
Iteration [12434]: Loss = 4.902568340301514
Iteration [12435]: Loss = 0.7086907625198364
Iteration [12436]: Loss = 0.7089232802391052
Iteration [12437]: Loss = 0.7090950012207031
Iteration [12438]: Loss = 0.7092119455337524
Iteration [12439]: Loss = 0.709279477596283
Iteration [12440]: Loss = 0.7093027830123901
Iteration [12441]: Loss = 0.7092859148979187
Iteration [12442]: Loss = 0.7092331051826477
Iteration [12443]: Loss = 0.7091478109359741
Iteration [12444]: Loss = 0.7090332508087158
Iteration [12445]: Loss = 0.7088924050331116
Iteration [12446]: Loss = 0.7087277173995972
Iteration [12447]: Loss = 0.7085418701171875
Iteration [12448]: Loss = 0.7083367109298706
Iteration [12449]: Loss = 0.7081143856048584
Iteration [12450]: Loss = 0.7078763842582703
Iteration [12451]: Loss = 0.7076244354248047
Iteration [12452]: Loss = 0.7073599696159363
Iteration [12453]: Loss = 0.7070841789245605
Iteration [12454]: Loss = 0.7067981958389282
Iteration [12455]: Loss = 4.912143230438232
Iteration [12456]: Loss = 0.7064316272735596
Iteration [12457]: Loss = 0.7063297629356384
Iteration [12458]: Loss = 0.7062004208564758
Iteration [12459]: Loss = 0.7060462236404419
Iteration [12460]: Loss = 0.7058697938919067
Iteration [12461]: Loss = 0.7056733965873718
Iteration [12462]: Loss = 0.7054588794708252
Iteration [12463]: Loss = 0.7052280306816101
Iteration [12464]: Loss = 0.7049826383590698
Iteration [12465]: Loss = 0.7047241926193237
Iteration [12466]: Loss = 0.704453706741333
Iteration [12467]: Loss = 0.7041728496551514
Iteration [12468]: Loss = 0.7038821578025818
Iteration [12469]: Loss = 0.7035830020904541
Iteration [12470]: Loss = 0.7032761573791504
Iteration [12471]: Loss = 0.7029623985290527
Iteration [12472]: Loss = 4.93211030960083
Iteration [12473]: Loss = 0.7025496363639832
Iteration [12474]: Loss = 0.7024286985397339
Iteration [12475]: Loss = 0.7022824287414551
Iteration [12476]: Loss = 0.7021130323410034
Iteration [12477]: Loss = 0.701923131942749
Iteration [12478]: Loss = 0.7017146348953247
Iteration [12479]: Loss = 0.7014894485473633
Iteration [12480]: Loss = 0.7012491822242737
Iteration [12481]: Loss = 0.7009953856468201
Iteration [12482]: Loss = 0.7007294297218323
Iteration [12483]: Loss = 0.7004525065422058
Iteration [12484]: Loss = 0.7001657485961914
Iteration [12485]: Loss = 4.946560382843018
Iteration [12486]: Loss = 0.6998002529144287
Iteration [12487]: Loss = 0.6996999382972717
Iteration [12488]: Loss = 0.6995722055435181
Iteration [12489]: Loss = 0.6994196772575378
Iteration [12490]: Loss = 0.699245035648346
Iteration [12491]: Loss = 0.6990503072738647
Iteration [12492]: Loss = 4.95196533203125
Iteration [12493]: Loss = 0.6988424062728882
Iteration [12494]: Loss = 0.6988092660903931
Iteration [12495]: Loss = 0.698742151260376
Iteration [12496]: Loss = 0.69864422082901
Iteration [12497]: Loss = 0.6985187530517578
Iteration [12498]: Loss = 4.954427719116211
Iteration [12499]: Loss = 4.954108238220215
Iteration [12500]: Loss = 0.6986794471740723
Iteration [12501]: Loss = 0.6988675594329834
Iteration [12502]: Loss = 0.6989997029304504
Iteration [12503]: Loss = 0.6990812420845032
Iteration [12504]: Loss = 0.6991171836853027
Iteration [12505]: Loss = 0.6991122961044312
Iteration [12506]: Loss = 0.6990703344345093
Iteration [12507]: Loss = 0.6989951133728027
Iteration [12508]: Loss = 0.6988898515701294
Iteration [12509]: Loss = 4.952385425567627
Iteration [12510]: Loss = 0.6988350749015808
Iteration [12511]: Loss = 0.6988673210144043
Iteration [12512]: Loss = 4.951854705810547
Iteration [12513]: Loss = 0.6990472674369812
Iteration [12514]: Loss = 0.6991795897483826
Iteration [12515]: Loss = 4.949747085571289
Iteration [12516]: Loss = 0.6995301842689514
Iteration [12517]: Loss = 0.6997352242469788
Iteration [12518]: Loss = 0.6998822689056396
Iteration [12519]: Loss = 4.9459991455078125
Iteration [12520]: Loss = 0.7002584338188171
Iteration [12521]: Loss = 0.7004740834236145
Iteration [12522]: Loss = 0.7006309032440186
Iteration [12523]: Loss = 0.7007344961166382
Iteration [12524]: Loss = 0.7007902264595032
Iteration [12525]: Loss = 4.941688060760498
Iteration [12526]: Loss = 0.7010100483894348
Iteration [12527]: Loss = 9.178502082824707
Iteration [12528]: Loss = 0.7017170190811157
Iteration [12529]: Loss = 0.7021824717521667
Iteration [12530]: Loss = 0.7025644183158875
Iteration [12531]: Loss = 0.7028710842132568
Iteration [12532]: Loss = 0.703109860420227
Iteration [12533]: Loss = 0.7032874822616577
Iteration [12534]: Loss = 0.7034099698066711
Iteration [12535]: Loss = 0.7034828066825867
Iteration [12536]: Loss = 0.7035107612609863
Iteration [12537]: Loss = 4.927666664123535
Iteration [12538]: Loss = 4.9267168045043945
Iteration [12539]: Loss = 0.70404052734375
Iteration [12540]: Loss = 0.7043261528015137
Iteration [12541]: Loss = 0.7045459747314453
Iteration [12542]: Loss = 0.7047061920166016
Iteration [12543]: Loss = 0.7048130631446838
Iteration [12544]: Loss = 0.7048717141151428
Iteration [12545]: Loss = 0.704886794090271
Iteration [12546]: Loss = 0.7048627734184265
Iteration [12547]: Loss = 4.920910358428955
Iteration [12548]: Loss = 0.7049444913864136
Iteration [12549]: Loss = 0.705034077167511
Iteration [12550]: Loss = 0.7050768733024597
Iteration [12551]: Loss = 0.7050777077674866
Iteration [12552]: Loss = 0.7050409317016602
Iteration [12553]: Loss = 4.920050621032715
Iteration [12554]: Loss = 0.7051008939743042
Iteration [12555]: Loss = 0.7051808834075928
Iteration [12556]: Loss = 0.7052153944969177
Iteration [12557]: Loss = 0.7052085995674133
Iteration [12558]: Loss = 0.7051649689674377
Iteration [12559]: Loss = 0.7050878405570984
Iteration [12560]: Loss = 0.704980731010437
Iteration [12561]: Loss = 4.920687675476074
Iteration [12562]: Loss = 0.704920768737793
Iteration [12563]: Loss = 0.7049497365951538
Iteration [12564]: Loss = 0.7049382925033569
Iteration [12565]: Loss = 9.136034965515137
Iteration [12566]: Loss = 0.7052708864212036
Iteration [12567]: Loss = 0.705576479434967
Iteration [12568]: Loss = 4.91569185256958
Iteration [12569]: Loss = 0.7062208652496338
Iteration [12570]: Loss = 4.911902904510498
Iteration [12571]: Loss = 0.7070381045341492
Iteration [12572]: Loss = 0.7074406147003174
Iteration [12573]: Loss = 0.7077655792236328
Iteration [12574]: Loss = 13.296987533569336
Iteration [12575]: Loss = 4.899911403656006
Iteration [12576]: Loss = 0.7098512649536133
Iteration [12577]: Loss = 0.7106851935386658
Iteration [12578]: Loss = 0.7113996744155884
Iteration [12579]: Loss = 0.7120063900947571
Iteration [12580]: Loss = 0.7125160098075867
Iteration [12581]: Loss = 0.7129377126693726
Iteration [12582]: Loss = 0.7132805585861206
Iteration [12583]: Loss = 0.7135518193244934
Iteration [12584]: Loss = 0.7137590646743774
Iteration [12585]: Loss = 0.7139082551002502
Iteration [12586]: Loss = 0.7140052318572998
Iteration [12587]: Loss = 0.7140552997589111
Iteration [12588]: Loss = 0.7140628099441528
Iteration [12589]: Loss = 0.7140322923660278
Iteration [12590]: Loss = 0.7139673829078674
Iteration [12591]: Loss = 9.035184860229492
Iteration [12592]: Loss = 4.872872352600098
Iteration [12593]: Loss = 4.870438098907471
Iteration [12594]: Loss = 0.715300977230072
Iteration [12595]: Loss = 0.7158228754997253
Iteration [12596]: Loss = 0.7162558436393738
Iteration [12597]: Loss = 0.7166035175323486
Iteration [12598]: Loss = 0.7168261408805847
Iteration [12599]: Loss = 0.7169970273971558
Iteration [12600]: Loss = 0.7171210646629333
Iteration [12601]: Loss = 0.7172033786773682
Iteration [12602]: Loss = 0.7172475457191467
Iteration [12603]: Loss = 0.7172578573226929
Iteration [12604]: Loss = 0.7172371745109558
Iteration [12605]: Loss = 0.7171889543533325
Iteration [12606]: Loss = 0.7171157002449036
Iteration [12607]: Loss = 0.7170200943946838
Iteration [12608]: Loss = 0.7169041037559509
Iteration [12609]: Loss = 0.7167701721191406
Iteration [12610]: Loss = 4.860662460327148
Iteration [12611]: Loss = 0.7166339755058289
Iteration [12612]: Loss = 0.7166170477867126
Iteration [12613]: Loss = 0.7165719866752625
Iteration [12614]: Loss = 0.7165018320083618
Iteration [12615]: Loss = 0.7164088487625122
Iteration [12616]: Loss = 0.7162953615188599
Iteration [12617]: Loss = 0.7161633968353271
Iteration [12618]: Loss = 4.863706111907959
Iteration [12619]: Loss = 0.7160311937332153
Iteration [12620]: Loss = 0.7160159349441528
Iteration [12621]: Loss = 0.7161288857460022
Iteration [12622]: Loss = 0.716057538986206
Iteration [12623]: Loss = 0.715955913066864
Iteration [12624]: Loss = 0.7158267498016357
Iteration [12625]: Loss = 0.71567302942276
Iteration [12626]: Loss = 0.7154969573020935
Iteration [12627]: Loss = 0.715300977230072
Iteration [12628]: Loss = 0.7150871157646179
Iteration [12629]: Loss = 0.7148568630218506
Iteration [12630]: Loss = 0.7146120071411133
Iteration [12631]: Loss = 0.7143542766571045
Iteration [12632]: Loss = 0.7140846252441406
Iteration [12633]: Loss = 4.8748674392700195
Iteration [12634]: Loss = 4.875182151794434
Iteration [12635]: Loss = 0.7138757705688477
Iteration [12636]: Loss = 0.7139585018157959
Iteration [12637]: Loss = 0.713995635509491
Iteration [12638]: Loss = 0.713991641998291
Iteration [12639]: Loss = 0.7139503359794617
Iteration [12640]: Loss = 0.7138758897781372
Iteration [12641]: Loss = 0.7137712240219116
Iteration [12642]: Loss = 4.875701427459717
Iteration [12643]: Loss = 0.7137108445167542
Iteration [12644]: Loss = 0.7137376070022583
Iteration [12645]: Loss = 0.7137241363525391
Iteration [12646]: Loss = 0.7136745452880859
Iteration [12647]: Loss = 0.7135924696922302
Iteration [12648]: Loss = 4.876504898071289
Iteration [12649]: Loss = 0.7135704159736633
Iteration [12650]: Loss = 0.7136136293411255
Iteration [12651]: Loss = 0.7136150598526001
Iteration [12652]: Loss = 0.7135788202285767
Iteration [12653]: Loss = 0.7135084867477417
Iteration [12654]: Loss = 0.7134078741073608
Iteration [12655]: Loss = 0.7132795453071594
Iteration [12656]: Loss = 0.713126540184021
Iteration [12657]: Loss = 0.7129513025283813
Iteration [12658]: Loss = 0.7127559185028076
Iteration [12659]: Loss = 0.7125424742698669
Iteration [12660]: Loss = 0.7123128175735474
Iteration [12661]: Loss = 0.7120684385299683
Iteration [12662]: Loss = 0.7118109464645386
Iteration [12663]: Loss = 0.7115417122840881
Iteration [12664]: Loss = 0.7112617492675781
Iteration [12665]: Loss = 0.7109723091125488
Iteration [12666]: Loss = 0.7106741666793823
Iteration [12667]: Loss = 4.892330646514893
Iteration [12668]: Loss = 0.7102845907211304
Iteration [12669]: Loss = 0.7101718187332153
Iteration [12670]: Loss = 0.7100327014923096
Iteration [12671]: Loss = 4.894874095916748
Iteration [12672]: Loss = 0.7099148631095886
Iteration [12673]: Loss = 0.7099179029464722
Iteration [12674]: Loss = 0.7098832726478577
Iteration [12675]: Loss = 0.7098146677017212
Iteration [12676]: Loss = 4.895665168762207
Iteration [12677]: Loss = 4.895144939422607
Iteration [12678]: Loss = 0.7100993990898132
Iteration [12679]: Loss = 0.7103163599967957
Iteration [12680]: Loss = 4.891788959503174
Iteration [12681]: Loss = 0.7108069062232971
Iteration [12682]: Loss = 0.7110689878463745
Iteration [12683]: Loss = 0.7112677097320557
Iteration [12684]: Loss = 4.887025833129883
Iteration [12685]: Loss = 0.7117269039154053
Iteration [12686]: Loss = 0.711975634098053
Iteration [12687]: Loss = 9.054230690002441
Iteration [12688]: Loss = 0.7127439379692078
Iteration [12689]: Loss = 0.7132307887077332
Iteration [12690]: Loss = 0.7136319875717163
Iteration [12691]: Loss = 0.7139559984207153
Iteration [12692]: Loss = 0.7142105102539062
Iteration [12693]: Loss = 0.7144021391868591
Iteration [12694]: Loss = 0.7145373225212097
Iteration [12695]: Loss = 0.7146216034889221
Iteration [12696]: Loss = 0.7146598100662231
Iteration [12697]: Loss = 4.8705573081970215
Iteration [12698]: Loss = 0.7148432731628418
Iteration [12699]: Loss = 0.7142230272293091
Iteration [12700]: Loss = 0.7143027782440186
Iteration [12701]: Loss = 0.7143371105194092
Iteration [12702]: Loss = 0.7143304347991943
Iteration [12703]: Loss = 0.7142868041992188
Iteration [12704]: Loss = 0.7142101526260376
Iteration [12705]: Loss = 0.7141033411026001
Iteration [12706]: Loss = 0.7139697074890137
Iteration [12707]: Loss = 0.7138118743896484
Iteration [12708]: Loss = 0.7136321067810059
Iteration [12709]: Loss = 0.7134327292442322
Iteration [12710]: Loss = 0.713215708732605
Iteration [12711]: Loss = 0.7129826545715332
Iteration [12712]: Loss = 0.7127352952957153
Iteration [12713]: Loss = 0.7124751806259155
Iteration [12714]: Loss = 0.712203323841095
Iteration [12715]: Loss = 0.7119210958480835
Iteration [12716]: Loss = 0.7116296291351318
Iteration [12717]: Loss = 0.7113296389579773
Iteration [12718]: Loss = 0.7110220193862915
Iteration [12719]: Loss = 0.7107076644897461
Iteration [12720]: Loss = 0.7103872299194336
Iteration [12721]: Loss = 0.7100611925125122
Iteration [12722]: Loss = 0.7097302675247192
Iteration [12723]: Loss = 0.7093949913978577
Iteration [12724]: Loss = 0.7090557813644409
Iteration [12725]: Loss = 0.7087129354476929
Iteration [12726]: Loss = 0.7083668112754822
Iteration [12727]: Loss = 0.7080180644989014
Iteration [12728]: Loss = 0.7076666355133057
Iteration [12729]: Loss = 0.7073128819465637
Iteration [12730]: Loss = 0.7069571018218994
Iteration [12731]: Loss = 4.911645889282227
Iteration [12732]: Loss = 0.706470251083374
Iteration [12733]: Loss = 4.913101673126221
Iteration [12734]: Loss = 0.70637047290802
Iteration [12735]: Loss = 0.7063817381858826
Iteration [12736]: Loss = 0.706354558467865
Iteration [12737]: Loss = 0.7062926888465881
Iteration [12738]: Loss = 0.7061999440193176
Iteration [12739]: Loss = 0.706078827381134
Iteration [12740]: Loss = 0.7059325575828552
Iteration [12741]: Loss = 0.7057636976242065
Iteration [12742]: Loss = 0.7055742740631104
Iteration [12743]: Loss = 0.705366313457489
Iteration [12744]: Loss = 0.7051419019699097
Iteration [12745]: Loss = 0.7049025893211365
Iteration [12746]: Loss = 4.92170524597168
Iteration [12747]: Loss = 0.7046152949333191
Iteration [12748]: Loss = 0.7045470476150513
Iteration [12749]: Loss = 0.7044482827186584
Iteration [12750]: Loss = 0.704322099685669
Iteration [12751]: Loss = 4.9241814613342285
Iteration [12752]: Loss = 0.7042282819747925
Iteration [12753]: Loss = 0.7042424082756042
Iteration [12754]: Loss = 4.923939228057861
Iteration [12755]: Loss = 0.7043883800506592
Iteration [12756]: Loss = 0.7045047283172607
Iteration [12757]: Loss = 0.7045722603797913
Iteration [12758]: Loss = 0.7045957446098328
Iteration [12759]: Loss = 0.7045795917510986
Iteration [12760]: Loss = 0.704527735710144
Iteration [12761]: Loss = 0.7044438123703003
Iteration [12762]: Loss = 0.7043309211730957
Iteration [12763]: Loss = 0.704192042350769
Iteration [12764]: Loss = 4.924915313720703
Iteration [12765]: Loss = 0.7040765285491943
Iteration [12766]: Loss = 0.7040815949440002
Iteration [12767]: Loss = 0.7040489315986633
Iteration [12768]: Loss = 0.7039820551872253
Iteration [12769]: Loss = 0.7038846015930176
Iteration [12770]: Loss = 0.7037596106529236
Iteration [12771]: Loss = 0.7036096453666687
Iteration [12772]: Loss = 0.7034372687339783
Iteration [12773]: Loss = 0.7032448053359985
Iteration [12774]: Loss = 0.7030343413352966
Iteration [12775]: Loss = 0.7028074264526367
Iteration [12776]: Loss = 0.7025659084320068
Iteration [12777]: Loss = 4.933831691741943
Iteration [12778]: Loss = 0.7022759318351746
Iteration [12779]: Loss = 0.7022069692611694
Iteration [12780]: Loss = 0.7021076679229736
Iteration [12781]: Loss = 0.7019810080528259
Iteration [12782]: Loss = 0.7018296122550964
Iteration [12783]: Loss = 0.7016561031341553
Iteration [12784]: Loss = 0.7014623880386353
Iteration [12785]: Loss = 0.7012509703636169
Iteration [12786]: Loss = 0.701023280620575
Iteration [12787]: Loss = 0.7007811069488525
Iteration [12788]: Loss = 0.7005257606506348
Iteration [12789]: Loss = 0.7002585530281067
Iteration [12790]: Loss = 0.6999809145927429
Iteration [12791]: Loss = 0.6996937394142151
Iteration [12792]: Loss = 0.69939786195755
Iteration [12793]: Loss = 0.6990944147109985
Iteration [12794]: Loss = 4.952247142791748
Iteration [12795]: Loss = 0.698699951171875
Iteration [12796]: Loss = 0.69858717918396
Iteration [12797]: Loss = 0.6984483599662781
Iteration [12798]: Loss = 0.698286235332489
Iteration [12799]: Loss = 0.6981031894683838
Iteration [12800]: Loss = 0.69790118932724
Iteration [12801]: Loss = 0.6976821422576904
Iteration [12802]: Loss = 0.6974478363990784
Iteration [12803]: Loss = 0.697199821472168
Iteration [12804]: Loss = 4.961939334869385
Iteration [12805]: Loss = 0.696900486946106
Iteration [12806]: Loss = 0.6968286037445068
Iteration [12807]: Loss = 0.6967266201972961
Iteration [12808]: Loss = 0.6965978145599365
Iteration [12809]: Loss = 4.964545249938965
Iteration [12810]: Loss = 0.6965024471282959
Iteration [12811]: Loss = 0.6965174078941345
Iteration [12812]: Loss = 0.6964937448501587
Iteration [12813]: Loss = 0.6964353919029236
Iteration [12814]: Loss = 0.6963456869125366
Iteration [12815]: Loss = 0.6962277889251709
Iteration [12816]: Loss = 0.6960844993591309
Iteration [12817]: Loss = 0.6959184408187866
Iteration [12818]: Loss = 0.6957317590713501
Iteration [12819]: Loss = 0.6973385214805603
Iteration [12820]: Loss = 4.961005687713623
Iteration [12821]: Loss = 0.697113037109375
Iteration [12822]: Loss = 0.6970725655555725
Iteration [12823]: Loss = 0.6969988346099854
Iteration [12824]: Loss = 0.6968953609466553
Iteration [12825]: Loss = 0.6967649459838867
Iteration [12826]: Loss = 0.6966100931167603
Iteration [12827]: Loss = 4.964603900909424
Iteration [12828]: Loss = 0.696471095085144
Iteration [12829]: Loss = 0.6946541666984558
Iteration [12830]: Loss = 0.6946136951446533
Iteration [12831]: Loss = 0.6945401430130005
Iteration [12832]: Loss = 0.6944369077682495
Iteration [12833]: Loss = 0.6943067908287048
Iteration [12834]: Loss = 0.6941525936126709
Iteration [12835]: Loss = 0.693976640701294
Iteration [12836]: Loss = 0.6937810778617859
Iteration [12837]: Loss = 0.6935679316520691
Iteration [12838]: Loss = 4.980976581573486
Iteration [12839]: Loss = 0.6933300495147705
Iteration [12840]: Loss = 0.6932848691940308
Iteration [12841]: Loss = 0.6932071447372437
Iteration [12842]: Loss = 0.693100094795227
Iteration [12843]: Loss = 0.6929667592048645
Iteration [12844]: Loss = 0.692809522151947
Iteration [12845]: Loss = 4.984740734100342
Iteration [12846]: Loss = 0.6926672458648682
Iteration [12847]: Loss = 0.6926630735397339
Iteration [12848]: Loss = 4.984786033630371
Iteration [12849]: Loss = 0.6927821040153503
Iteration [12850]: Loss = 0.6928890943527222
Iteration [12851]: Loss = 0.6929485201835632
Iteration [12852]: Loss = 4.982964038848877
Iteration [12853]: Loss = 0.69317626953125
Iteration [12854]: Loss = 0.6933295726776123
Iteration [12855]: Loss = 0.6934307217597961
Iteration [12856]: Loss = 0.6934844851493835
Iteration [12857]: Loss = 0.6934959292411804
Iteration [12858]: Loss = 4.980286121368408
Iteration [12859]: Loss = 0.6936416625976562
Iteration [12860]: Loss = 0.6937599778175354
Iteration [12861]: Loss = 4.978374004364014
Iteration [12862]: Loss = 0.6940882802009583
Iteration [12863]: Loss = 0.6942844986915588
Iteration [12864]: Loss = 0.694424033164978
Iteration [12865]: Loss = 0.6945124864578247
Iteration [12866]: Loss = 0.6945549845695496
Iteration [12867]: Loss = 4.974523544311523
Iteration [12868]: Loss = 0.6947535276412964
Iteration [12869]: Loss = 0.6948943138122559
Iteration [12870]: Loss = 0.6959488391876221
Iteration [12871]: Loss = 0.6959713101387024
Iteration [12872]: Loss = 0.6959341168403625
Iteration [12873]: Loss = 0.6958437561988831
Iteration [12874]: Loss = 0.6957062482833862
Iteration [12875]: Loss = 0.695526659488678
Iteration [12876]: Loss = 0.6953098177909851
Iteration [12877]: Loss = 0.695059597492218
Iteration [12878]: Loss = 4.973339080810547
Iteration [12879]: Loss = 4.973110675811768
Iteration [12880]: Loss = 0.6951177716255188
Iteration [12881]: Loss = 0.6953345537185669
Iteration [12882]: Loss = 0.6954811811447144
Iteration [12883]: Loss = 0.6955646872520447
Iteration [12884]: Loss = 0.6955914497375488
Iteration [12885]: Loss = 0.6955673098564148
Iteration [12886]: Loss = 0.6954973936080933
Iteration [12887]: Loss = 0.6953862905502319
Iteration [12888]: Loss = 0.6952384114265442
Iteration [12889]: Loss = 0.6950570940971375
Iteration [12890]: Loss = 0.6948461532592773
Iteration [12891]: Loss = 0.6946083307266235
Iteration [12892]: Loss = 0.69434654712677
Iteration [12893]: Loss = 0.694063127040863
Iteration [12894]: Loss = 0.693760335445404
Iteration [12895]: Loss = 4.98043966293335
Iteration [12896]: Loss = 0.6934072375297546
Iteration [12897]: Loss = 0.6933309435844421
Iteration [12898]: Loss = 4.981630325317383
Iteration [12899]: Loss = 0.6933567523956299
Iteration [12900]: Loss = 0.6934379935264587
Iteration [12901]: Loss = 0.6934654116630554
Iteration [12902]: Loss = 0.6934444308280945
Iteration [12903]: Loss = 0.6933798789978027
Iteration [12904]: Loss = 0.6932764053344727
Iteration [12905]: Loss = 4.982046604156494
Iteration [12906]: Loss = 0.6932530403137207
Iteration [12907]: Loss = 0.6933120489120483
Iteration [12908]: Loss = 0.6933203935623169
Iteration [12909]: Loss = 0.6932828426361084
Iteration [12910]: Loss = 0.6932042837142944
Iteration [12911]: Loss = 0.6930885314941406
Iteration [12912]: Loss = 0.6929395794868469
Iteration [12913]: Loss = 0.692760705947876
Iteration [12914]: Loss = 0.692554771900177
Iteration [12915]: Loss = 0.6923244595527649
Iteration [12916]: Loss = 0.6920724511146545
Iteration [12917]: Loss = 0.6918007731437683
Iteration [12918]: Loss = 0.691511332988739
Iteration [12919]: Loss = 0.691206157207489
Iteration [12920]: Loss = 0.6908866763114929
Iteration [12921]: Loss = 0.6905542016029358
Iteration [12922]: Loss = 4.99765157699585
Iteration [12923]: Loss = 0.6901413202285767
Iteration [12924]: Loss = 9.307144165039062
Iteration [12925]: Loss = 0.6904398202896118
Iteration [12926]: Loss = 0.6907616853713989
Iteration [12927]: Loss = 4.993382930755615
Iteration [12928]: Loss = 4.9909987449646
Iteration [12929]: Loss = 0.6920798420906067
Iteration [12930]: Loss = 0.6925997734069824
Iteration [12931]: Loss = 0.6930258274078369
Iteration [12932]: Loss = 0.6933673620223999
Iteration [12933]: Loss = 0.6936327219009399
Iteration [12934]: Loss = 0.6938295364379883
Iteration [12935]: Loss = 0.6939644813537598
Iteration [12936]: Loss = 0.6940438151359558
Iteration [12937]: Loss = 0.6940727829933167
Iteration [12938]: Loss = 4.977169036865234
Iteration [12939]: Loss = 0.6942652463912964
Iteration [12940]: Loss = 4.975292205810547
Iteration [12941]: Loss = 0.69476318359375
Iteration [12942]: Loss = 0.6950385570526123
Iteration [12943]: Loss = 0.6952446103096008
Iteration [12944]: Loss = 0.6953880786895752
Iteration [12945]: Loss = 0.6954752802848816
Iteration [12946]: Loss = 0.6955118179321289
Iteration [12947]: Loss = 0.695502519607544
Iteration [12948]: Loss = 0.6954523324966431
Iteration [12949]: Loss = 0.6953650116920471
Iteration [12950]: Loss = 0.6952443718910217
Iteration [12951]: Loss = 0.6950936317443848
Iteration [12952]: Loss = 0.6949158906936646
Iteration [12953]: Loss = 0.6947140097618103
Iteration [12954]: Loss = 0.6944900155067444
Iteration [12955]: Loss = 0.6942464113235474
Iteration [12956]: Loss = 0.693985104560852
Iteration [12957]: Loss = 0.6937078833580017
Iteration [12958]: Loss = 4.980566501617432
Iteration [12959]: Loss = 0.6933771371841431
Iteration [12960]: Loss = 0.6933001279830933
Iteration [12961]: Loss = 0.6931890249252319
Iteration [12962]: Loss = 0.693047046661377
Iteration [12963]: Loss = 4.983429431915283
Iteration [12964]: Loss = 0.6929469704627991
Iteration [12965]: Loss = 0.6929677128791809
Iteration [12966]: Loss = 0.6929448246955872
Iteration [12967]: Loss = 0.6928825378417969
Iteration [12968]: Loss = 4.983921527862549
Iteration [12969]: Loss = 0.6929178833961487
Iteration [12970]: Loss = 0.6929962635040283
Iteration [12971]: Loss = 0.6930253505706787
Iteration [12972]: Loss = 0.6930098533630371
Iteration [12973]: Loss = 0.6929541826248169
Iteration [12974]: Loss = 0.6928625106811523
Iteration [12975]: Loss = 0.6927382946014404
Iteration [12976]: Loss = 0.6925849914550781
Iteration [12977]: Loss = 4.985941410064697
Iteration [12978]: Loss = 4.985623836517334
Iteration [12979]: Loss = 0.6927380561828613
Iteration [12980]: Loss = 0.6929429173469543
Iteration [12981]: Loss = 0.6930859088897705
Iteration [12982]: Loss = 0.6931732892990112
Iteration [12983]: Loss = 0.6932106018066406
Iteration [12984]: Loss = 0.6932026147842407
Iteration [12985]: Loss = 0.693153977394104
Iteration [12986]: Loss = 0.6930687427520752
Iteration [12987]: Loss = 0.6929505467414856
Iteration [12988]: Loss = 4.983826637268066
Iteration [12989]: Loss = 0.6928898096084595
Iteration [12990]: Loss = 4.983165740966797
Iteration [12991]: Loss = 0.6931791305541992
Iteration [12992]: Loss = 0.6933650970458984
Iteration [12993]: Loss = 0.6934912800788879
Iteration [12994]: Loss = 0.6935635209083557
Iteration [12995]: Loss = 0.6935874223709106
Iteration [12996]: Loss = 4.979763507843018
Iteration [12997]: Loss = 0.6937682628631592
Iteration [12998]: Loss = 0.6939079165458679
Iteration [12999]: Loss = 0.6939922571182251
Iteration [13000]: Loss = 0.6940269470214844
Iteration [13001]: Loss = 9.260741233825684
Iteration [13002]: Loss = 0.6944794058799744
Iteration [13003]: Loss = 0.6948549747467041
Iteration [13004]: Loss = 0.6951528787612915
Iteration [13005]: Loss = 0.6953802108764648
Iteration [13006]: Loss = 0.6955441236495972
Iteration [13007]: Loss = 0.6956509947776794
Iteration [13008]: Loss = 0.6957064867019653
Iteration [13009]: Loss = 0.6957154870033264
Iteration [13010]: Loss = 0.6956828832626343
Iteration [13011]: Loss = 0.6956125497817993
Iteration [13012]: Loss = 0.6955084204673767
Iteration [13013]: Loss = 0.6953737735748291
Iteration [13014]: Loss = 0.6952117681503296
Iteration [13015]: Loss = 0.695024847984314
Iteration [13016]: Loss = 4.973148345947266
Iteration [13017]: Loss = 0.6948440074920654
Iteration [13018]: Loss = 0.6948285102844238
Iteration [13019]: Loss = 0.69477379322052
Iteration [13020]: Loss = 0.6946837902069092
Iteration [13021]: Loss = 0.6945618987083435
Iteration [13022]: Loss = 4.975289821624756
Iteration [13023]: Loss = 0.6944917440414429
Iteration [13024]: Loss = 4.974696159362793
Iteration [13025]: Loss = 9.252046585083008
Iteration [13026]: Loss = 0.6954469680786133
Iteration [13027]: Loss = 0.6960195899009705
Iteration [13028]: Loss = 0.6964950561523438
Iteration [13029]: Loss = 0.6968832612037659
Iteration [13030]: Loss = 0.6971926093101501
Iteration [13031]: Loss = 0.6974308490753174
Iteration [13032]: Loss = 0.6976050138473511
Iteration [13033]: Loss = 0.697721540927887
Iteration [13034]: Loss = 0.6977859735488892
Iteration [13035]: Loss = 0.6978037357330322
Iteration [13036]: Loss = 0.6977791786193848
Iteration [13037]: Loss = 4.957849502563477
Iteration [13038]: Loss = 4.957030296325684
Iteration [13039]: Loss = 0.6982240676879883
Iteration [13040]: Loss = 0.6985002756118774
Iteration [13041]: Loss = 0.6987088322639465
Iteration [13042]: Loss = 0.6988561749458313
Iteration [13043]: Loss = 0.6989485025405884
Iteration [13044]: Loss = 0.7068231105804443
Iteration [13045]: Loss = 4.951206207275391
Iteration [13046]: Loss = 4.950139045715332
Iteration [13047]: Loss = 0.699580192565918
Iteration [13048]: Loss = 0.6998946070671082
Iteration [13049]: Loss = 0.7001373171806335
Iteration [13050]: Loss = 4.94423246383667
Iteration [13051]: Loss = 0.7006863355636597
Iteration [13052]: Loss = 0.7009797692298889
Iteration [13053]: Loss = 4.939596652984619
Iteration [13054]: Loss = 0.7016149759292603
Iteration [13055]: Loss = 4.935735702514648
Iteration [13056]: Loss = 0.7024514675140381
Iteration [13057]: Loss = 0.7028671503067017
Iteration [13058]: Loss = 0.7032012343406677
Iteration [13059]: Loss = 0.7034615874290466
Iteration [13060]: Loss = 0.7036555409431458
Iteration [13061]: Loss = 0.7037897706031799
Iteration [13062]: Loss = 0.7038699984550476
Iteration [13063]: Loss = 0.7039017081260681
Iteration [13064]: Loss = 0.703889787197113
Iteration [13065]: Loss = 0.7038382887840271
Iteration [13066]: Loss = 0.7037514448165894
Iteration [13067]: Loss = 0.7036325335502625
Iteration [13068]: Loss = 0.703484833240509
Iteration [13069]: Loss = 4.92863655090332
Iteration [13070]: Loss = 0.7033657431602478
Iteration [13071]: Loss = 0.7033742666244507
Iteration [13072]: Loss = 4.9284820556640625
Iteration [13073]: Loss = 0.7035216093063354
Iteration [13074]: Loss = 0.7036435008049011
Iteration [13075]: Loss = 0.7037127614021301
Iteration [13076]: Loss = 0.7037345767021179
Iteration [13077]: Loss = 0.703713595867157
Iteration [13078]: Loss = 0.7036541104316711
Iteration [13079]: Loss = 4.927347660064697
Iteration [13080]: Loss = 4.926697731018066
Iteration [13081]: Loss = 0.704007625579834
Iteration [13082]: Loss = 0.7042573690414429
Iteration [13083]: Loss = 0.7044417858123779
Iteration [13084]: Loss = 0.7045673131942749
Iteration [13085]: Loss = 0.7046397924423218
Iteration [13086]: Loss = 0.7046644687652588
Iteration [13087]: Loss = 0.7046460509300232
Iteration [13088]: Loss = 0.704588770866394
Iteration [13089]: Loss = 0.7044966220855713
Iteration [13090]: Loss = 0.7043731808662415
Iteration [13091]: Loss = 0.7042213082313538
Iteration [13092]: Loss = 0.704043984413147
Iteration [13093]: Loss = 0.7038437128067017
Iteration [13094]: Loss = 0.7036227583885193
Iteration [13095]: Loss = 0.703383207321167
Iteration [13096]: Loss = 4.929593563079834
Iteration [13097]: Loss = 0.7031072974205017
Iteration [13098]: Loss = 0.7030489444732666
Iteration [13099]: Loss = 0.7029558420181274
Iteration [13100]: Loss = 4.931127071380615
Iteration [13101]: Loss = 0.7029299736022949
Iteration [13102]: Loss = 0.702978253364563
Iteration [13103]: Loss = 0.7029812932014465
Iteration [13104]: Loss = 0.7029432058334351
Iteration [13105]: Loss = 0.7028685808181763
Iteration [13106]: Loss = 0.7027608752250671
Iteration [13107]: Loss = 0.702623188495636
Iteration [13108]: Loss = 0.7024587988853455
Iteration [13109]: Loss = 0.7022702693939209
Iteration [13110]: Loss = 0.7020599842071533
Iteration [13111]: Loss = 4.936334609985352
Iteration [13112]: Loss = 0.7018341422080994
Iteration [13113]: Loss = 0.7017974853515625
Iteration [13114]: Loss = 0.7017239928245544
Iteration [13115]: Loss = 0.7016172409057617
Iteration [13116]: Loss = 0.7014806866645813
Iteration [13117]: Loss = 4.939005374908447
Iteration [13118]: Loss = 0.7013810276985168
Iteration [13119]: Loss = 0.7013982534408569
Iteration [13120]: Loss = 4.938714981079102
Iteration [13121]: Loss = 0.7015608549118042
Iteration [13122]: Loss = 0.701689600944519
Iteration [13123]: Loss = 0.7017650008201599
Iteration [13124]: Loss = 0.7017925381660461
Iteration [13125]: Loss = 0.701776921749115
Iteration [13126]: Loss = 0.7017223238945007
Iteration [13127]: Loss = 0.7016327381134033
Iteration [13128]: Loss = 4.937994003295898
Iteration [13129]: Loss = 0.701613187789917
Iteration [13130]: Loss = 0.7016642689704895
Iteration [13131]: Loss = 0.7016698122024536
Iteration [13132]: Loss = 0.7016343474388123
Iteration [13133]: Loss = 0.7015619277954102
Iteration [13134]: Loss = 4.938281059265137
Iteration [13135]: Loss = 0.7015718221664429
Iteration [13136]: Loss = 4.937348365783691
Iteration [13137]: Loss = 0.7019028067588806
Iteration [13138]: Loss = 0.7021031379699707
Iteration [13139]: Loss = 4.934185028076172
Iteration [13140]: Loss = 0.7025787830352783
Iteration [13141]: Loss = 0.7028406858444214
Iteration [13142]: Loss = 0.7030360698699951
Iteration [13143]: Loss = 0.7031714916229248
Iteration [13144]: Loss = 0.7032531499862671
Iteration [13145]: Loss = 0.7032859921455383
Iteration [13146]: Loss = 0.7032750844955444
Iteration [13147]: Loss = 0.7032247185707092
Iteration [13148]: Loss = 0.7031387686729431
Iteration [13149]: Loss = 4.930144786834717
Iteration [13150]: Loss = 0.7031251192092896
Iteration [13151]: Loss = 0.703178346157074
Iteration [13152]: Loss = 0.7031859755516052
Iteration [13153]: Loss = 0.7031521201133728
Iteration [13154]: Loss = 0.7030811905860901
Iteration [13155]: Loss = 0.7029768228530884
Iteration [13156]: Loss = 0.702842116355896
Iteration [13157]: Loss = 4.931912422180176
Iteration [13158]: Loss = 0.7027454376220703
Iteration [13159]: Loss = 0.7027634978294373
Iteration [13160]: Loss = 0.7027391791343689
Iteration [13161]: Loss = 0.7026768922805786
Iteration [13162]: Loss = 0.7025802135467529
Iteration [13163]: Loss = 0.702452540397644
Iteration [13164]: Loss = 0.7022972106933594
Iteration [13165]: Loss = 0.7021166682243347
Iteration [13166]: Loss = 4.935898780822754
Iteration [13167]: Loss = 0.7019420266151428
Iteration [13168]: Loss = 0.7019268870353699
Iteration [13169]: Loss = 0.7018728852272034
Iteration [13170]: Loss = 4.936575889587402
Iteration [13171]: Loss = 0.7019141316413879
Iteration [13172]: Loss = 0.7019909620285034
Iteration [13173]: Loss = 0.7020198106765747
Iteration [13174]: Loss = 0.7020052671432495
Iteration [13175]: Loss = 0.7019516229629517
Iteration [13176]: Loss = 0.7018628120422363
Iteration [13177]: Loss = 4.93679141998291
Iteration [13178]: Loss = 4.936258316040039
Iteration [13179]: Loss = 0.7021467089653015
Iteration [13180]: Loss = 0.7023784518241882
Iteration [13181]: Loss = 4.932608127593994
Iteration [13182]: Loss = 4.9307332038879395
Iteration [13183]: Loss = 0.7034412622451782
Iteration [13184]: Loss = 0.7038816809654236
Iteration [13185]: Loss = 0.7042378187179565
Iteration [13186]: Loss = 0.7045183181762695
Iteration [13187]: Loss = 0.704730212688446
Iteration [13188]: Loss = 0.7048805952072144
Iteration [13189]: Loss = 0.704975426197052
Iteration [13190]: Loss = 0.7050201892852783
Iteration [13191]: Loss = 0.7050198316574097
Iteration [13192]: Loss = 0.7049788236618042
Iteration [13193]: Loss = 0.7049012184143066
Iteration [13194]: Loss = 0.7047908902168274
Iteration [13195]: Loss = 0.7046507596969604
Iteration [13196]: Loss = 0.7044839859008789
Iteration [13197]: Loss = 0.7042931318283081
Iteration [13198]: Loss = 0.7040806412696838
Iteration [13199]: Loss = 0.703848659992218
Iteration [13200]: Loss = 0.7035992741584778
Iteration [13201]: Loss = 0.7033340930938721
Iteration [13202]: Loss = 0.7030547261238098
Iteration [13203]: Loss = 0.7027626633644104
Iteration [13204]: Loss = 0.7024590373039246
Iteration [13205]: Loss = 0.7021451592445374
Iteration [13206]: Loss = 0.7018219828605652
Iteration [13207]: Loss = 0.7014905214309692
Iteration [13208]: Loss = 0.7011516094207764
Iteration [13209]: Loss = 4.941671848297119
Iteration [13210]: Loss = 4.942188739776611
Iteration [13211]: Loss = 0.7008286714553833
Iteration [13212]: Loss = 0.7008979916572571
Iteration [13213]: Loss = 0.7009198069572449
Iteration [13214]: Loss = 0.7008991241455078
Iteration [13215]: Loss = 0.7008400559425354
Iteration [13216]: Loss = 0.7007462978363037
Iteration [13217]: Loss = 0.7006214261054993
Iteration [13218]: Loss = 0.7004684805870056
Iteration [13219]: Loss = 0.7002902626991272
Iteration [13220]: Loss = 0.7000893950462341
Iteration [13221]: Loss = 0.6998679637908936
Iteration [13222]: Loss = 0.6996283531188965
Iteration [13223]: Loss = 0.6993719339370728
Iteration [13224]: Loss = 0.6991006731987
Iteration [13225]: Loss = 0.6988161206245422
Iteration [13226]: Loss = 0.6985194683074951
Iteration [13227]: Loss = 0.6982118487358093
Iteration [13228]: Loss = 0.6978946328163147
Iteration [13229]: Loss = 0.6975686550140381
Iteration [13230]: Loss = 0.6972346305847168
Iteration [13231]: Loss = 0.6968938112258911
Iteration [13232]: Loss = 0.6965463757514954
Iteration [13233]: Loss = 0.6961933374404907
Iteration [13234]: Loss = 0.6958351731300354
Iteration [13235]: Loss = 0.6954724192619324
Iteration [13236]: Loss = 0.6951055526733398
Iteration [13237]: Loss = 0.6947349905967712
Iteration [13238]: Loss = 0.6943610906600952
Iteration [13239]: Loss = 0.6939843893051147
Iteration [13240]: Loss = 4.979565143585205
Iteration [13241]: Loss = 0.6934775710105896
Iteration [13242]: Loss = 4.981062889099121
Iteration [13243]: Loss = 0.6933968663215637
Iteration [13244]: Loss = 0.693423330783844
Iteration [13245]: Loss = 0.6934070587158203
Iteration [13246]: Loss = 4.9809064865112305
Iteration [13247]: Loss = 0.6935158371925354
Iteration [13248]: Loss = 0.6936231851577759
Iteration [13249]: Loss = 0.6936795711517334
Iteration [13250]: Loss = 0.6936900615692139
Iteration [13251]: Loss = 0.6936595439910889
Iteration [13252]: Loss = 0.693591833114624
Iteration [13253]: Loss = 17.8402156829834
Iteration [13254]: Loss = 0.6943312883377075
Iteration [13255]: Loss = 0.6950503587722778
Iteration [13256]: Loss = 0.6956599950790405
Iteration [13257]: Loss = 0.6961706280708313
Iteration [13258]: Loss = 0.6965920329093933
Iteration [13259]: Loss = 0.6969330310821533
Iteration [13260]: Loss = 0.6972016096115112
Iteration [13261]: Loss = 0.6974047422409058
Iteration [13262]: Loss = 0.6975489854812622
Iteration [13263]: Loss = 0.6976402401924133
Iteration [13264]: Loss = 4.958023548126221
Iteration [13265]: Loss = 0.697925865650177
Iteration [13266]: Loss = 0.6981053352355957
Iteration [13267]: Loss = 4.955163478851318
Iteration [13268]: Loss = 0.6985417604446411
Iteration [13269]: Loss = 9.205696105957031
Iteration [13270]: Loss = 4.948795795440674
Iteration [13271]: Loss = 0.7002347707748413
Iteration [13272]: Loss = 0.7009100914001465
Iteration [13273]: Loss = 0.7014798521995544
Iteration [13274]: Loss = 0.7019546627998352
Iteration [13275]: Loss = 4.933662414550781
Iteration [13276]: Loss = 0.7028940916061401
Iteration [13277]: Loss = 0.7033510208129883
Iteration [13278]: Loss = 4.926497459411621
Iteration [13279]: Loss = 0.7047268152236938
Iteration [13280]: Loss = 4.919074058532715
Iteration [13281]: Loss = 0.7058008909225464
Iteration [13282]: Loss = 0.706307053565979
Iteration [13283]: Loss = 0.7067186236381531
Iteration [13284]: Loss = 0.7070504426956177
Iteration [13285]: Loss = 0.7073104977607727
Iteration [13286]: Loss = 4.906986236572266
Iteration [13287]: Loss = 0.707880973815918
Iteration [13288]: Loss = 0.7081798315048218
Iteration [13289]: Loss = 0.7084101438522339
Iteration [13290]: Loss = 0.7085785865783691
Iteration [13291]: Loss = 4.900904655456543
Iteration [13292]: Loss = 0.7089921832084656
Iteration [13293]: Loss = 0.7092241644859314
Iteration [13294]: Loss = 0.709394097328186
Iteration [13295]: Loss = 0.709507942199707
Iteration [13296]: Loss = 0.7095714211463928
Iteration [13297]: Loss = 0.709589421749115
Iteration [13298]: Loss = 0.7095664143562317
Iteration [13299]: Loss = 0.7095065712928772
Iteration [13300]: Loss = 4.897207260131836
Iteration [13301]: Loss = 0.7095300555229187
Iteration [13302]: Loss = 0.7095957398414612
Iteration [13303]: Loss = 4.89617395401001
Iteration [13304]: Loss = 4.895061016082764
Iteration [13305]: Loss = 0.7102288007736206
Iteration [13306]: Loss = 0.7105457186698914
Iteration [13307]: Loss = 4.890169620513916
Iteration [13308]: Loss = 0.7112128138542175
Iteration [13309]: Loss = 0.7115368843078613
Iteration [13310]: Loss = 4.885087490081787
Iteration [13311]: Loss = 0.7122064828872681
Iteration [13312]: Loss = 0.7125445604324341
Iteration [13313]: Loss = 0.7128117680549622
Iteration [13314]: Loss = 0.7130151391029358
Iteration [13315]: Loss = 0.7131609916687012
Iteration [13316]: Loss = 4.877650737762451
Iteration [13317]: Loss = 0.7135284543037415
Iteration [13318]: Loss = 0.7137373685836792
Iteration [13319]: Loss = 0.7138882875442505
Iteration [13320]: Loss = 0.7139867544174194
Iteration [13321]: Loss = 0.7140380144119263
Iteration [13322]: Loss = 0.7140466570854187
Iteration [13323]: Loss = 0.7140170335769653
Iteration [13324]: Loss = 0.713952898979187
Iteration [13325]: Loss = 0.7138577103614807
Iteration [13326]: Loss = 4.87522029876709
Iteration [13327]: Loss = 0.713813304901123
Iteration [13328]: Loss = 0.7138468027114868
Iteration [13329]: Loss = 4.874690055847168
Iteration [13330]: Loss = 0.714022159576416
Iteration [13331]: Loss = 0.7141492366790771
Iteration [13332]: Loss = 0.7142263054847717
Iteration [13333]: Loss = 0.7142581939697266
Iteration [13334]: Loss = 0.7142493724822998
Iteration [13335]: Loss = 4.872845649719238
Iteration [13336]: Loss = 0.7143526077270508
Iteration [13337]: Loss = 0.7144488096237183
Iteration [13338]: Loss = 0.7144981026649475
Iteration [13339]: Loss = 0.7145048975944519
Iteration [13340]: Loss = 0.7144736051559448
Iteration [13341]: Loss = 0.714407742023468
Iteration [13342]: Loss = 0.7143108248710632
Iteration [13343]: Loss = 0.7141861319541931
Iteration [13344]: Loss = 0.7140361666679382
Iteration [13345]: Loss = 0.7138636708259583
Iteration [13346]: Loss = 0.7136707305908203
Iteration [13347]: Loss = 0.7134594917297363
Iteration [13348]: Loss = 0.7132317423820496
Iteration [13349]: Loss = 0.7129891514778137
Iteration [13350]: Loss = 0.7127333283424377
Iteration [13351]: Loss = 0.7124652862548828
Iteration [13352]: Loss = 0.7121865749359131
Iteration [13353]: Loss = 0.711898148059845
Iteration [13354]: Loss = 0.7116009593009949
Iteration [13355]: Loss = 0.7112958431243896
Iteration [13356]: Loss = 4.889191627502441
Iteration [13357]: Loss = 4.8896484375
Iteration [13358]: Loss = 0.7110043168067932
Iteration [13359]: Loss = 0.7110661268234253
Iteration [13360]: Loss = 4.888679504394531
Iteration [13361]: Loss = 0.7112911343574524
Iteration [13362]: Loss = 4.886869430541992
Iteration [13363]: Loss = 0.7117639183998108
Iteration [13364]: Loss = 0.7120184302330017
Iteration [13365]: Loss = 0.7122101187705994
Iteration [13366]: Loss = 0.7123451232910156
Iteration [13367]: Loss = 0.7124294638633728
Iteration [13368]: Loss = 0.712467610836029
Iteration [13369]: Loss = 0.7124645709991455
Iteration [13370]: Loss = 0.7124242186546326
Iteration [13371]: Loss = 4.882240295410156
Iteration [13372]: Loss = 0.7124743461608887
Iteration [13373]: Loss = 0.7125486731529236
Iteration [13374]: Loss = 0.7125778794288635
Iteration [13375]: Loss = 0.7125666737556458
Iteration [13376]: Loss = 0.7125190496444702
Iteration [13377]: Loss = 4.88179349899292
Iteration [13378]: Loss = 0.7125567197799683
Iteration [13379]: Loss = 0.7126256227493286
Iteration [13380]: Loss = 0.7126501798629761
Iteration [13381]: Loss = 0.7126346230506897
Iteration [13382]: Loss = 0.7125829458236694
Iteration [13383]: Loss = 0.7124987244606018
Iteration [13384]: Loss = 0.712385356426239
Iteration [13385]: Loss = 4.882772445678711
Iteration [13386]: Loss = 0.7123109698295593
Iteration [13387]: Loss = 0.7123323678970337
Iteration [13388]: Loss = 4.882425785064697
Iteration [13389]: Loss = 0.7124881744384766
Iteration [13390]: Loss = 0.7126075029373169
Iteration [13391]: Loss = 0.7126772999763489
Iteration [13392]: Loss = 0.7127025723457336
Iteration [13393]: Loss = 0.7126874923706055
Iteration [13394]: Loss = 0.7126364707946777
Iteration [13395]: Loss = 0.7125527262687683
Iteration [13396]: Loss = 4.881786823272705
Iteration [13397]: Loss = 0.7125291228294373
Iteration [13398]: Loss = 0.7125720381736755
Iteration [13399]: Loss = 4.881109237670898
Iteration [13400]: Loss = 0.7144278287887573
Iteration [13401]: Loss = 0.7125723958015442
Iteration [13402]: Loss = 0.7146016359329224
Iteration [13403]: Loss = 0.7146315574645996
Iteration [13404]: Loss = 0.7146283984184265
Iteration [13405]: Loss = 0.7145956754684448
Iteration [13406]: Loss = 0.7145359516143799
Iteration [13407]: Loss = 0.7144522070884705
Iteration [13408]: Loss = 4.872124195098877
Iteration [13409]: Loss = 0.7144037485122681
Iteration [13410]: Loss = 0.7144249081611633
Iteration [13411]: Loss = 0.7144140601158142
Iteration [13412]: Loss = 0.7143742442131042
Iteration [13413]: Loss = 0.7143082618713379
Iteration [13414]: Loss = 0.71421879529953
Iteration [13415]: Loss = 0.7141081094741821
Iteration [13416]: Loss = 0.7139783501625061
Iteration [13417]: Loss = 0.7138314247131348
Iteration [13418]: Loss = 0.7136691212654114
Iteration [13419]: Loss = 0.7134928107261658
Iteration [13420]: Loss = 0.7133041620254517
Iteration [13421]: Loss = 0.7131041288375854
Iteration [13422]: Loss = 0.7128939628601074
Iteration [13423]: Loss = 0.712674617767334
Iteration [13424]: Loss = 0.7124472260475159
Iteration [13425]: Loss = 0.712212324142456
Iteration [13426]: Loss = 0.7119708061218262
Iteration [13427]: Loss = 0.711723268032074
Iteration [13428]: Loss = 0.7114704251289368
Iteration [13429]: Loss = 0.7112128138542175
Iteration [13430]: Loss = 0.7109507322311401
Iteration [13431]: Loss = 0.7106848359107971
Iteration [13432]: Loss = 0.7104153633117676
Iteration [13433]: Loss = 0.7101427912712097
Iteration [13434]: Loss = 0.7098674774169922
Iteration [13435]: Loss = 0.7095896005630493
Iteration [13436]: Loss = 0.709309458732605
Iteration [13437]: Loss = 0.7090271711349487
Iteration [13438]: Loss = 0.7087430953979492
Iteration [13439]: Loss = 0.7084574699401855
Iteration [13440]: Loss = 0.7081702947616577
Iteration [13441]: Loss = 0.7078818082809448
Iteration [13442]: Loss = 4.906541347503662
Iteration [13443]: Loss = 0.7074856758117676
Iteration [13444]: Loss = 0.7073599696159363
Iteration [13445]: Loss = 4.908470630645752
Iteration [13446]: Loss = 0.7072417140007019
Iteration [13447]: Loss = 0.7072343230247498
Iteration [13448]: Loss = 0.7071977853775024
Iteration [13449]: Loss = 0.7071348428726196
Iteration [13450]: Loss = 0.7070482969284058
Iteration [13451]: Loss = 0.7069404721260071
Iteration [13452]: Loss = 0.7068134546279907
Iteration [13453]: Loss = 4.911287307739258
Iteration [13454]: Loss = 0.7066932916641235
Iteration [13455]: Loss = 0.7066852450370789
Iteration [13456]: Loss = 0.7066479921340942
Iteration [13457]: Loss = 4.911722660064697
Iteration [13458]: Loss = 0.7066813707351685
Iteration [13459]: Loss = 0.7067386507987976
Iteration [13460]: Loss = 0.7067602872848511
Iteration [13461]: Loss = 0.7067498564720154
Iteration [13462]: Loss = 0.7067105770111084
Iteration [13463]: Loss = 0.7066452503204346
Iteration [13464]: Loss = 0.7065564393997192
Iteration [13465]: Loss = 0.7064464688301086
Iteration [13466]: Loss = 0.7063176035881042
Iteration [13467]: Loss = 0.7061715722084045
Iteration [13468]: Loss = 4.914681911468506
Iteration [13469]: Loss = 0.7060192823410034
Iteration [13470]: Loss = 0.7059975266456604
Iteration [13471]: Loss = 0.7059481739997864
Iteration [13472]: Loss = 0.7058737277984619
Iteration [13473]: Loss = 0.7057766914367676
Iteration [13474]: Loss = 0.7056595087051392
Iteration [13475]: Loss = 0.7055238485336304
Iteration [13476]: Loss = 0.7053719162940979
Iteration [13477]: Loss = 0.7052050232887268
Iteration [13478]: Loss = 0.7050248980522156
Iteration [13479]: Loss = 0.7048327326774597
Iteration [13480]: Loss = 0.7046298980712891
Iteration [13481]: Loss = 0.7044171690940857
Iteration [13482]: Loss = 0.7041958570480347
Iteration [13483]: Loss = 0.7039666175842285
Iteration [13484]: Loss = 0.7037303447723389
Iteration [13485]: Loss = 0.7034876346588135
Iteration [13486]: Loss = 0.7032393217086792
Iteration [13487]: Loss = 0.7029857039451599
Iteration [13488]: Loss = 0.7027274966239929
Iteration [13489]: Loss = 0.702465295791626
Iteration [13490]: Loss = 0.7021992206573486
Iteration [13491]: Loss = 0.7019297480583191
Iteration [13492]: Loss = 4.937233924865723
Iteration [13493]: Loss = 0.7015681862831116
Iteration [13494]: Loss = 4.938271999359131
Iteration [13495]: Loss = 0.7015143632888794
Iteration [13496]: Loss = 0.701535165309906
Iteration [13497]: Loss = 4.93792724609375
Iteration [13498]: Loss = 0.7016695737838745
Iteration [13499]: Loss = 0.701770544052124
Iteration [13500]: Loss = 0.7018316388130188
Iteration [13501]: Loss = 0.7018567323684692
Iteration [13502]: Loss = 4.9362335205078125
Iteration [13503]: Loss = 0.7019983530044556
Iteration [13504]: Loss = 0.7021024823188782
Iteration [13505]: Loss = 0.7021663188934326
Iteration [13506]: Loss = 4.934441089630127
Iteration [13507]: Loss = 0.7023741006851196
Iteration [13508]: Loss = 0.7025061845779419
Iteration [13509]: Loss = 4.932353973388672
Iteration [13510]: Loss = 0.7028307914733887
Iteration [13511]: Loss = 0.7030127048492432
Iteration [13512]: Loss = 0.7031466960906982
Iteration [13513]: Loss = 0.7032374739646912
Iteration [13514]: Loss = 0.703289270401001
Iteration [13515]: Loss = 0.7033059000968933
Iteration [13516]: Loss = 0.7032909393310547
Iteration [13517]: Loss = 0.7032475471496582
Iteration [13518]: Loss = 0.703178346157074
Iteration [13519]: Loss = 0.703086256980896
Iteration [13520]: Loss = 0.7029733061790466
Iteration [13521]: Loss = 0.7028415203094482
Iteration [13522]: Loss = 0.702692985534668
Iteration [13523]: Loss = 0.7025293111801147
Iteration [13524]: Loss = 0.7023518681526184
Iteration [13525]: Loss = 0.7021621465682983
Iteration [13526]: Loss = 0.7019613981246948
Iteration [13527]: Loss = 0.7017505764961243
Iteration [13528]: Loss = 0.701530933380127
Iteration [13529]: Loss = 4.9390788078308105
Iteration [13530]: Loss = 0.7012546062469482
Iteration [13531]: Loss = 0.7011809349060059
Iteration [13532]: Loss = 9.179353713989258
Iteration [13533]: Loss = 0.7013378143310547
Iteration [13534]: Loss = 0.701536238193512
Iteration [13535]: Loss = 4.9370903968811035
Iteration [13536]: Loss = 0.7019734382629395
Iteration [13537]: Loss = 0.7022033929824829
Iteration [13538]: Loss = 9.164557456970215
Iteration [13539]: Loss = 0.7028750777244568
Iteration [13540]: Loss = 0.7032907009124756
Iteration [13541]: Loss = 0.703635573387146
Iteration [13542]: Loss = 0.7039164900779724
Iteration [13543]: Loss = 0.7041400671005249
Iteration [13544]: Loss = 0.7043116092681885
Iteration [13545]: Loss = 0.7044364809989929
Iteration [13546]: Loss = 0.7045192122459412
Iteration [13547]: Loss = 0.7045640349388123
Iteration [13548]: Loss = 0.7045745849609375
Iteration [13549]: Loss = 0.7045543789863586
Iteration [13550]: Loss = 0.7045063972473145
Iteration [13551]: Loss = 0.7044335007667542
Iteration [13552]: Loss = 0.7043381333351135
Iteration [13553]: Loss = 0.7042225003242493
Iteration [13554]: Loss = 4.924609661102295
Iteration [13555]: Loss = 0.7041221261024475
Iteration [13556]: Loss = 0.7041226029396057
Iteration [13557]: Loss = 0.7021695971488953
Iteration [13558]: Loss = 0.7021135091781616
Iteration [13559]: Loss = 0.7020336389541626
Iteration [13560]: Loss = 0.701931893825531
Iteration [13561]: Loss = 4.936435699462891
Iteration [13562]: Loss = 0.7018558979034424
Iteration [13563]: Loss = 0.7018671035766602
Iteration [13564]: Loss = 0.7018473744392395
Iteration [13565]: Loss = 0.7017999887466431
Iteration [13566]: Loss = 4.936867713928223
Iteration [13567]: Loss = 0.703740119934082
Iteration [13568]: Loss = 4.926152229309082
Iteration [13569]: Loss = 4.925119876861572
Iteration [13570]: Loss = 0.7043230533599854
Iteration [13571]: Loss = 0.7045931220054626
Iteration [13572]: Loss = 0.7048065662384033
Iteration [13573]: Loss = 0.7049691677093506
Iteration [13574]: Loss = 0.705085813999176
Iteration [13575]: Loss = 0.7051609754562378
Iteration [13576]: Loss = 0.7051988840103149
Iteration [13577]: Loss = 0.7052030563354492
Iteration [13578]: Loss = 0.7051770091056824
Iteration [13579]: Loss = 4.91925573348999
Iteration [13580]: Loss = 0.7052298784255981
Iteration [13581]: Loss = 0.705295741558075
Iteration [13582]: Loss = 0.7053249478340149
Iteration [13583]: Loss = 0.7053215503692627
Iteration [13584]: Loss = 0.7052885293960571
Iteration [13585]: Loss = 0.7052289247512817
Iteration [13586]: Loss = 0.7051454186439514
Iteration [13587]: Loss = 0.7050403356552124
Iteration [13588]: Loss = 0.7049158215522766
Iteration [13589]: Loss = 4.9210638999938965
Iteration [13590]: Loss = 0.704800546169281
Iteration [13591]: Loss = 0.7047947645187378
Iteration [13592]: Loss = 0.7047595977783203
Iteration [13593]: Loss = 4.921455383300781
Iteration [13594]: Loss = 0.7047971487045288
Iteration [13595]: Loss = 0.7048565149307251
Iteration [13596]: Loss = 0.7048799991607666
Iteration [13597]: Loss = 4.920560359954834
Iteration [13598]: Loss = 0.7050177454948425
Iteration [13599]: Loss = 4.919276237487793
Iteration [13600]: Loss = 0.7053654789924622
Iteration [13601]: Loss = 4.917019367218018
Iteration [13602]: Loss = 0.7058830857276917
Iteration [13603]: Loss = 0.706146776676178
Iteration [13604]: Loss = 0.7056436538696289
Iteration [13605]: Loss = 0.7082020044326782
Iteration [13606]: Loss = 0.7058471441268921
Iteration [13607]: Loss = 0.7060770988464355
Iteration [13608]: Loss = 0.7061101198196411
Iteration [13609]: Loss = 0.7060160636901855
Iteration [13610]: Loss = 0.7058790922164917
Iteration [13611]: Loss = 0.7059299349784851
Iteration [13612]: Loss = 0.7058491706848145
Iteration [13613]: Loss = 0.7057464122772217
Iteration [13614]: Loss = 0.7054468393325806
Iteration [13615]: Loss = 0.7061994671821594
Iteration [13616]: Loss = 0.706043541431427
Iteration [13617]: Loss = 4.919084548950195
Iteration [13618]: Loss = 0.7034789323806763
Iteration [13619]: Loss = 0.7034217715263367
Iteration [13620]: Loss = 4.928549766540527
Iteration [13621]: Loss = 0.7034595608711243
Iteration [13622]: Loss = 0.7035366296768188
Iteration [13623]: Loss = 0.7035649418830872
Iteration [13624]: Loss = 0.703549325466156
Iteration [13625]: Loss = 4.927689552307129
Iteration [13626]: Loss = 4.926854133605957
Iteration [13627]: Loss = 0.7040048241615295
Iteration [13628]: Loss = 0.7042797803878784
Iteration [13629]: Loss = 4.922545433044434
Iteration [13630]: Loss = 0.7048757672309875
Iteration [13631]: Loss = 4.918932914733887
Iteration [13632]: Loss = 0.7055866122245789
Iteration [13633]: Loss = 0.7058888673782349
Iteration [13634]: Loss = 4.914058208465576
Iteration [13635]: Loss = 4.912141799926758
Iteration [13636]: Loss = 0.706991970539093
Iteration [13637]: Loss = 4.907517910003662
Iteration [13638]: Loss = 0.7079251408576965
Iteration [13639]: Loss = 0.7083662152290344
Iteration [13640]: Loss = 0.7087333798408508
Iteration [13641]: Loss = 0.7090340852737427
Iteration [13642]: Loss = 0.7092746496200562
Iteration [13643]: Loss = 0.7094613909721375
Iteration [13644]: Loss = 0.7095991373062134
Iteration [13645]: Loss = 0.7096930742263794
Iteration [13646]: Loss = 0.7097474336624146
Iteration [13647]: Loss = 0.709766149520874
Iteration [13648]: Loss = 0.7097526788711548
Iteration [13649]: Loss = 0.709710419178009
Iteration [13650]: Loss = 0.7096420526504517
Iteration [13651]: Loss = 0.7095502018928528
Iteration [13652]: Loss = 0.7094372510910034
Iteration [13653]: Loss = 0.7093051671981812
Iteration [13654]: Loss = 0.7091561555862427
Iteration [13655]: Loss = 0.7089917063713074
Iteration [13656]: Loss = 0.7088133096694946
Iteration [13657]: Loss = 0.708622395992279
Iteration [13658]: Loss = 0.7084202170372009
Iteration [13659]: Loss = 0.7082080841064453
Iteration [13660]: Loss = 4.904516220092773
Iteration [13661]: Loss = 0.7079430222511292
Iteration [13662]: Loss = 0.7078733444213867
Iteration [13663]: Loss = 0.7077804803848267
Iteration [13664]: Loss = 9.104652404785156
Iteration [13665]: Loss = 4.904947280883789
Iteration [13666]: Loss = 0.7082685232162476
Iteration [13667]: Loss = 0.708568274974823
Iteration [13668]: Loss = 0.7088080644607544
Iteration [13669]: Loss = 0.7089939713478088
Iteration [13670]: Loss = 0.7091314792633057
Iteration [13671]: Loss = 0.7092251181602478
Iteration [13672]: Loss = 0.7092792391777039
Iteration [13673]: Loss = 0.7092980146408081
Iteration [13674]: Loss = 0.709284782409668
Iteration [13675]: Loss = 0.7092427015304565
Iteration [13676]: Loss = 0.7091745734214783
Iteration [13677]: Loss = 0.7090832591056824
Iteration [13678]: Loss = 0.708970844745636
Iteration [13679]: Loss = 0.7088393568992615
Iteration [13680]: Loss = 0.708690881729126
Iteration [13681]: Loss = 0.7085270881652832
Iteration [13682]: Loss = 0.7083494663238525
Iteration [13683]: Loss = 0.7081593871116638
Iteration [13684]: Loss = 0.7079581618309021
Iteration [13685]: Loss = 0.707746684551239
Iteration [13686]: Loss = 0.7075263261795044
Iteration [13687]: Loss = 0.707297682762146
Iteration [13688]: Loss = 0.7070618271827698
Iteration [13689]: Loss = 4.910515308380127
Iteration [13690]: Loss = 0.7067562937736511
Iteration [13691]: Loss = 0.7066693902015686
Iteration [13692]: Loss = 0.7065610885620117
Iteration [13693]: Loss = 0.7064334154129028
Iteration [13694]: Loss = 0.7062883377075195
Iteration [13695]: Loss = 0.7061277031898499
Iteration [13696]: Loss = 0.7059530019760132
Iteration [13697]: Loss = 4.915942668914795
Iteration [13698]: Loss = 0.7057521939277649
Iteration [13699]: Loss = 0.7057100534439087
Iteration [13700]: Loss = 0.7056422233581543
Iteration [13701]: Loss = 0.7055508494377136
Iteration [13702]: Loss = 0.7054386138916016
Iteration [13703]: Loss = 0.7053074240684509
Iteration [13704]: Loss = 0.7051591873168945
Iteration [13705]: Loss = 0.7049955725669861
Iteration [13706]: Loss = 0.7048182487487793
Iteration [13707]: Loss = 0.704628586769104
Iteration [13708]: Loss = 0.7044275403022766
Iteration [13709]: Loss = 0.704216718673706
Iteration [13710]: Loss = 0.7039965391159058
Iteration [13711]: Loss = 4.926267623901367
Iteration [13712]: Loss = 0.7037191390991211
Iteration [13713]: Loss = 0.7036446928977966
Iteration [13714]: Loss = 0.7035475969314575
Iteration [13715]: Loss = 0.70343017578125
Iteration [13716]: Loss = 0.7032943367958069
Iteration [13717]: Loss = 0.703141987323761
Iteration [13718]: Loss = 0.7029749155044556
Iteration [13719]: Loss = 0.7027941942214966
Iteration [13720]: Loss = 0.7026014924049377
Iteration [13721]: Loss = 0.7023980617523193
Iteration [13722]: Loss = 0.7021847367286682
Iteration [13723]: Loss = 0.7019627094268799
Iteration [13724]: Loss = 0.7017326951026917
Iteration [13725]: Loss = 0.7014957070350647
Iteration [13726]: Loss = 0.7012522220611572
Iteration [13727]: Loss = 4.940644264221191
Iteration [13728]: Loss = 0.7009356021881104
Iteration [13729]: Loss = 0.7008447647094727
Iteration [13730]: Loss = 0.7007333040237427
Iteration [13731]: Loss = 0.7006025910377502
Iteration [13732]: Loss = 0.7004551291465759
Iteration [13733]: Loss = 0.7002922296524048
Iteration [13734]: Loss = 0.7001155614852905
Iteration [13735]: Loss = 0.6999265551567078
Iteration [13736]: Loss = 0.6997263431549072
Iteration [13737]: Loss = 4.9484124183654785
Iteration [13738]: Loss = 0.69948410987854
Iteration [13739]: Loss = 0.6994253396987915
Iteration [13740]: Loss = 0.6993423104286194
Iteration [13741]: Loss = 0.6992376446723938
Iteration [13742]: Loss = 0.6991134881973267
Iteration [13743]: Loss = 0.6989716291427612
Iteration [13744]: Loss = 4.952090740203857
Iteration [13745]: Loss = 0.6988292932510376
Iteration [13746]: Loss = 0.6988131403923035
Iteration [13747]: Loss = 0.698768675327301
Iteration [13748]: Loss = 4.952695846557617
Iteration [13749]: Loss = 0.6987925171852112
Iteration [13750]: Loss = 0.6988471746444702
Iteration [13751]: Loss = 0.6988664865493774
Iteration [13752]: Loss = 0.6988537907600403
Iteration [13753]: Loss = 0.6988124251365662
Iteration [13754]: Loss = 0.6987452507019043
Iteration [13755]: Loss = 0.6986547708511353
Iteration [13756]: Loss = 4.953510284423828
Iteration [13757]: Loss = 4.953211784362793
Iteration [13758]: Loss = 0.6988081932067871
Iteration [13759]: Loss = 0.6989656090736389
Iteration [13760]: Loss = 0.6990773677825928
Iteration [13761]: Loss = 0.6991479992866516
Iteration [13762]: Loss = 0.6991817355155945
Iteration [13763]: Loss = 0.6991820335388184
Iteration [13764]: Loss = 0.6991522312164307
Iteration [13765]: Loss = 0.6990953683853149
Iteration [13766]: Loss = 0.6990141868591309
Iteration [13767]: Loss = 4.951581001281738
Iteration [13768]: Loss = 0.698975682258606
Iteration [13769]: Loss = 0.6990036368370056
Iteration [13770]: Loss = 4.951120376586914
Iteration [13771]: Loss = 0.6991517543792725
Iteration [13772]: Loss = 0.699259340763092
Iteration [13773]: Loss = 0.6993262767791748
Iteration [13774]: Loss = 4.949248313903809
Iteration [13775]: Loss = 0.6995406150817871
Iteration [13776]: Loss = 0.6996763348579407
Iteration [13777]: Loss = 0.699768602848053
Iteration [13778]: Loss = 0.6998216509819031
Iteration [13779]: Loss = 0.6998392939567566
Iteration [13780]: Loss = 4.946795463562012
Iteration [13781]: Loss = 0.6999694108963013
Iteration [13782]: Loss = 0.7000692486763
Iteration [13783]: Loss = 0.7001292705535889
Iteration [13784]: Loss = 0.7001530528068542
Iteration [13785]: Loss = 0.7001445293426514
Iteration [13786]: Loss = 0.7001065611839294
Iteration [13787]: Loss = 0.7000423669815063
Iteration [13788]: Loss = 0.6999545097351074
Iteration [13789]: Loss = 0.6998451948165894
Iteration [13790]: Loss = 0.6997166275978088
Iteration [13791]: Loss = 4.948126316070557
Iteration [13792]: Loss = 0.6995971202850342
Iteration [13793]: Loss = 0.699590802192688
Iteration [13794]: Loss = 0.6995550394058228
Iteration [13795]: Loss = 9.197578430175781
Iteration [13796]: Loss = 0.6997790336608887
Iteration [13797]: Loss = 0.7000072002410889
Iteration [13798]: Loss = 0.7001826763153076
Iteration [13799]: Loss = 0.7003109455108643
Iteration [13800]: Loss = 0.7003965377807617
Iteration [13801]: Loss = 0.7004436254501343
Iteration [13802]: Loss = 4.943498134613037
Iteration [13803]: Loss = 0.7006233930587769
Iteration [13804]: Loss = 0.700744092464447
Iteration [13805]: Loss = 0.7008230090141296
Iteration [13806]: Loss = 4.941369533538818
Iteration [13807]: Loss = 0.7010568976402283
Iteration [13808]: Loss = 0.7012007832527161
Iteration [13809]: Loss = 0.7013003826141357
Iteration [13810]: Loss = 0.7013599872589111
Iteration [13811]: Loss = 0.7013837099075317
Iteration [13812]: Loss = 0.7013750076293945
Iteration [13813]: Loss = 0.7013371586799622
Iteration [13814]: Loss = 0.7012729644775391
Iteration [13815]: Loss = 4.939694404602051
Iteration [13816]: Loss = 0.7012626528739929
Iteration [13817]: Loss = 0.7013024091720581
Iteration [13818]: Loss = 0.7013081908226013
Iteration [13819]: Loss = 0.70128333568573
Iteration [13820]: Loss = 0.7012309432029724
Iteration [13821]: Loss = 0.7011536359786987
Iteration [13822]: Loss = 0.701054036617279
Iteration [13823]: Loss = 0.7009343504905701
Iteration [13824]: Loss = 4.941722393035889
Iteration [13825]: Loss = 0.700829267501831
Iteration [13826]: Loss = 0.7008285522460938
Iteration [13827]: Loss = 0.7007981538772583
Iteration [13828]: Loss = 0.7007404565811157
Iteration [13829]: Loss = 4.942440509796143
Iteration [13830]: Loss = 0.7007418274879456
Iteration [13831]: Loss = 0.7007865905761719
Iteration [13832]: Loss = 4.941720008850098
Iteration [13833]: Loss = 4.940855026245117
Iteration [13834]: Loss = 0.7012680768966675
Iteration [13835]: Loss = 0.7015129923820496
Iteration [13836]: Loss = 0.701703667640686
Iteration [13837]: Loss = 4.936255931854248
Iteration [13838]: Loss = 9.167431831359863
Iteration [13839]: Loss = 4.931702136993408
Iteration [13840]: Loss = 0.703407883644104
Iteration [13841]: Loss = 4.925083160400391
Iteration [13842]: Loss = 0.7046812772750854
Iteration [13843]: Loss = 4.918511390686035
Iteration [13844]: Loss = 4.914995193481445
Iteration [13845]: Loss = 0.7067162990570068
Iteration [13846]: Loss = 0.7073773741722107
Iteration [13847]: Loss = 0.7079430222511292
Iteration [13848]: Loss = 0.7084227800369263
Iteration [13849]: Loss = 0.7088246941566467
Iteration [13850]: Loss = 4.8985209465026855
Iteration [13851]: Loss = 0.7096090912818909
Iteration [13852]: Loss = 0.7099865078926086
Iteration [13853]: Loss = 0.7102962136268616
Iteration [13854]: Loss = 0.7105449438095093
Iteration [13855]: Loss = 0.7107388377189636
Iteration [13856]: Loss = 0.7108832001686096
Iteration [13857]: Loss = 0.7109828591346741
Iteration [13858]: Loss = 0.7110422849655151
Iteration [13859]: Loss = 0.7110655307769775
Iteration [13860]: Loss = 4.88882303237915
Iteration [13861]: Loss = 4.88808012008667
Iteration [13862]: Loss = 0.7114870548248291
Iteration [13863]: Loss = 0.711713433265686
Iteration [13864]: Loss = 0.7118872404098511
Iteration [13865]: Loss = 0.7120131850242615
Iteration [13866]: Loss = 0.7120962738990784
Iteration [13867]: Loss = 0.7121408581733704
Iteration [13868]: Loss = 0.7121505737304688
Iteration [13869]: Loss = 0.7121289372444153
Iteration [13870]: Loss = 0.7120790481567383
Iteration [13871]: Loss = 4.8840012550354
Iteration [13872]: Loss = 0.7120903134346008
Iteration [13873]: Loss = 0.7121379375457764
Iteration [13874]: Loss = 0.712150514125824
Iteration [13875]: Loss = 0.7121313810348511
Iteration [13876]: Loss = 0.712083637714386
Iteration [13877]: Loss = 0.7120102643966675
Iteration [13878]: Loss = 0.7119139432907104
Iteration [13879]: Loss = 0.711796760559082
Iteration [13880]: Loss = 0.7116607427597046
Iteration [13881]: Loss = 4.886523723602295
Iteration [13882]: Loss = 0.7115250825881958
Iteration [13883]: Loss = 0.7115102410316467
Iteration [13884]: Loss = 0.7114664316177368
Iteration [13885]: Loss = 0.7113966345787048
Iteration [13886]: Loss = 0.7113034129142761
Iteration [13887]: Loss = 0.7111889123916626
Iteration [13888]: Loss = 0.7110555171966553
Iteration [13889]: Loss = 0.7109049558639526
Iteration [13890]: Loss = 0.7107388377189636
Iteration [13891]: Loss = 0.7105590105056763
Iteration [13892]: Loss = 0.7103666663169861
Iteration [13893]: Loss = 0.7101629376411438
Iteration [13894]: Loss = 0.7099493145942688
Iteration [13895]: Loss = 0.7097264528274536
Iteration [13896]: Loss = 0.7094954252243042
Iteration [13897]: Loss = 4.898007869720459
Iteration [13898]: Loss = 0.7091983556747437
Iteration [13899]: Loss = 4.8987345695495605
Iteration [13900]: Loss = 0.7091953158378601
Iteration [13901]: Loss = 0.7092373371124268
Iteration [13902]: Loss = 0.7092447280883789
Iteration [13903]: Loss = 0.7092211246490479
Iteration [13904]: Loss = 0.7091695070266724
Iteration [13905]: Loss = 0.7090924978256226
Iteration [13906]: Loss = 0.7089928984642029
Iteration [13907]: Loss = 4.899974346160889
Iteration [13908]: Loss = 4.899731636047363
Iteration [13909]: Loss = 4.89871883392334
Iteration [13910]: Loss = 0.7094509601593018
Iteration [13911]: Loss = 0.7097204327583313
Iteration [13912]: Loss = 0.7099326848983765
Iteration [13913]: Loss = 0.71009361743927
Iteration [13914]: Loss = 0.7102080583572388
Iteration [13915]: Loss = 4.892777919769287
Iteration [13916]: Loss = 0.7105010747909546
Iteration [13917]: Loss = 0.7106690406799316
Iteration [13918]: Loss = 0.7107897996902466
Iteration [13919]: Loss = 0.7108681797981262
Iteration [13920]: Loss = 0.7109084129333496
Iteration [13921]: Loss = 0.7109140157699585
Iteration [13922]: Loss = 0.7108886241912842
Iteration [13923]: Loss = 0.7108352184295654
Iteration [13924]: Loss = 0.7107566595077515
Iteration [13925]: Loss = 0.7106554508209229
Iteration [13926]: Loss = 0.7105336785316467
Iteration [13927]: Loss = 0.7103937268257141
Iteration [13928]: Loss = 0.7102370262145996
Iteration [13929]: Loss = 0.7100656032562256
Iteration [13930]: Loss = 0.7098805904388428
Iteration [13931]: Loss = 0.7096835970878601
Iteration [13932]: Loss = 0.7094756364822388
Iteration [13933]: Loss = 0.7092580795288086
Iteration [13934]: Loss = 0.7090316414833069
Iteration [13935]: Loss = 4.900361061096191
Iteration [13936]: Loss = 0.7087427377700806
Iteration [13937]: Loss = 0.7086631655693054
Iteration [13938]: Loss = 0.70856112241745
Iteration [13939]: Loss = 0.7084386348724365
Iteration [13940]: Loss = 0.7082979679107666
Iteration [13941]: Loss = 4.903725624084473
Iteration [13942]: Loss = 0.7081557512283325
Iteration [13943]: Loss = 0.7081387042999268
Iteration [13944]: Loss = 0.708092987537384
Iteration [13945]: Loss = 0.7080212235450745
Iteration [13946]: Loss = 0.7079261541366577
Iteration [13947]: Loss = 0.7078102231025696
Iteration [13948]: Loss = 0.7076752185821533
Iteration [13949]: Loss = 0.7075232863426208
Iteration [13950]: Loss = 0.7073559761047363
Iteration [13951]: Loss = 0.7071748375892639
Iteration [13952]: Loss = 4.9096808433532715
Iteration [13953]: Loss = 0.7069641351699829
Iteration [13954]: Loss = 0.7069181203842163
Iteration [13955]: Loss = 0.7068461179733276
Iteration [13956]: Loss = 0.7067509293556213
Iteration [13957]: Loss = 0.7066348195075989
Iteration [13958]: Loss = 0.7064996361732483
Iteration [13959]: Loss = 0.706347644329071
Iteration [13960]: Loss = 0.7061803936958313
Iteration [13961]: Loss = 0.7059992551803589
Iteration [13962]: Loss = 0.7058057188987732
Iteration [13963]: Loss = 0.7056009769439697
Iteration [13964]: Loss = 0.705386221408844
Iteration [13965]: Loss = 0.705162525177002
Iteration [13966]: Loss = 4.920253276824951
Iteration [13967]: Loss = 0.7048795223236084
Iteration [13968]: Loss = 0.7048030495643616
Iteration [13969]: Loss = 0.704703688621521
Iteration [13970]: Loss = 4.922045707702637
Iteration [13971]: Loss = 0.704633355140686
Iteration [13972]: Loss = 0.7046474814414978
Iteration [13973]: Loss = 4.92180871963501
Iteration [13974]: Loss = 0.7047708630561829
Iteration [13975]: Loss = 0.7048676013946533
Iteration [13976]: Loss = 0.7049241662025452
Iteration [13977]: Loss = 0.7049446702003479
Iteration [13978]: Loss = 0.7049328684806824
Iteration [13979]: Loss = 0.7048917412757874
Iteration [13980]: Loss = 0.7048242688179016
Iteration [13981]: Loss = 0.7047330141067505
Iteration [13982]: Loss = 4.92185640335083
Iteration [13983]: Loss = 4.921566486358643
Iteration [13984]: Loss = 0.7048839926719666
Iteration [13985]: Loss = 0.7050403356552124
Iteration [13986]: Loss = 4.919116497039795
Iteration [13987]: Loss = 0.7054067850112915
Iteration [13988]: Loss = 0.705606997013092
Iteration [13989]: Loss = 0.7057569026947021
Iteration [13990]: Loss = 0.7058614492416382
Iteration [13991]: Loss = 0.7059251070022583
Iteration [13992]: Loss = 0.7059520483016968
Iteration [13993]: Loss = 0.7059457302093506
Iteration [13994]: Loss = 0.7059095501899719
Iteration [13995]: Loss = 0.70584636926651
Iteration [13996]: Loss = 0.7057591080665588
Iteration [13997]: Loss = 9.127429008483887
Iteration [13998]: Loss = 0.7058947682380676
Iteration [13999]: Loss = 0.7060850858688354
Iteration [14000]: Loss = 0.7062261700630188
Iteration [14001]: Loss = 0.7063229084014893
Iteration [14002]: Loss = 0.7063796520233154
Iteration [14003]: Loss = 0.7064003348350525
Iteration [14004]: Loss = 0.7063887119293213
Iteration [14005]: Loss = 0.7063478231430054
Iteration [14006]: Loss = 0.7062807679176331
Iteration [14007]: Loss = 0.7061899304389954
Iteration [14008]: Loss = 0.7060777544975281
Iteration [14009]: Loss = 0.7059463262557983
Iteration [14010]: Loss = 0.7057977318763733
Iteration [14011]: Loss = 4.916624546051025
Iteration [14012]: Loss = 0.7056424617767334
Iteration [14013]: Loss = 0.7056201696395874
Iteration [14014]: Loss = 0.7055696845054626
Iteration [14015]: Loss = 0.7054940462112427
Iteration [14016]: Loss = 0.7053954005241394
Iteration [14017]: Loss = 0.7052763104438782
Iteration [14018]: Loss = 0.7051385641098022
Iteration [14019]: Loss = 0.7049842476844788
Iteration [14020]: Loss = 0.7048150300979614
Iteration [14021]: Loss = 0.7046321630477905
Iteration [14022]: Loss = 0.7044371962547302
Iteration [14023]: Loss = 0.704231321811676
Iteration [14024]: Loss = 0.7040155529975891
Iteration [14025]: Loss = 0.7037909626960754
Iteration [14026]: Loss = 0.7035584449768066
Iteration [14027]: Loss = 0.7033187747001648
Iteration [14028]: Loss = 0.7030725479125977
Iteration [14029]: Loss = 0.7028205394744873
Iteration [14030]: Loss = 0.7025633454322815
Iteration [14031]: Loss = 0.702301561832428
Iteration [14032]: Loss = 4.935265064239502
Iteration [14033]: Loss = 0.701954185962677
Iteration [14034]: Loss = 0.7018506526947021
Iteration [14035]: Loss = 0.7017271518707275
Iteration [14036]: Loss = 0.7015855312347412
Iteration [14037]: Loss = 0.7014279365539551
Iteration [14038]: Loss = 0.7012555599212646
Iteration [14039]: Loss = 0.7010700106620789
Iteration [14040]: Loss = 0.7008728384971619
Iteration [14041]: Loss = 4.942407608032227
Iteration [14042]: Loss = 0.7006362080574036
Iteration [14043]: Loss = 4.9428510665893555
Iteration [14044]: Loss = 0.7006872892379761
Iteration [14045]: Loss = 0.7007535696029663
Iteration [14046]: Loss = 0.7007830142974854
Iteration [14047]: Loss = 0.7007792592048645
Iteration [14048]: Loss = 0.7007456421852112
Iteration [14049]: Loss = 0.7006850838661194
Iteration [14050]: Loss = 0.7006003260612488
Iteration [14051]: Loss = 9.18610954284668
Iteration [14052]: Loss = 0.7007419466972351
Iteration [14053]: Loss = 0.7009353637695312
Iteration [14054]: Loss = 13.418571472167969
Iteration [14055]: Loss = 4.936882972717285
Iteration [14056]: Loss = 0.7024577260017395
Iteration [14057]: Loss = 0.7030887603759766
Iteration [14058]: Loss = 0.7036278247833252
Iteration [14059]: Loss = 4.924633026123047
Iteration [14060]: Loss = 0.70464688539505
Iteration [14061]: Loss = 0.70512455701828
Iteration [14062]: Loss = 4.9171833992004395
Iteration [14063]: Loss = 0.7060381174087524
Iteration [14064]: Loss = 0.7064703702926636
Iteration [14065]: Loss = 0.7068302035331726
Iteration [14066]: Loss = 0.707124650478363
Iteration [14067]: Loss = 0.7073600888252258
Iteration [14068]: Loss = 0.7075423002243042
Iteration [14069]: Loss = 4.9061079025268555
Iteration [14070]: Loss = 0.7079500555992126
Iteration [14071]: Loss = 0.7081666588783264
Iteration [14072]: Loss = 0.708331823348999
Iteration [14073]: Loss = 0.7084508538246155
Iteration [14074]: Loss = 0.7085280418395996
Iteration [14075]: Loss = 0.7085677981376648
Iteration [14076]: Loss = 0.708573579788208
Iteration [14077]: Loss = 0.708548903465271
Iteration [14078]: Loss = 0.7084968090057373
Iteration [14079]: Loss = 0.7084199786186218
Iteration [14080]: Loss = 4.902802467346191
Iteration [14081]: Loss = 0.7083851099014282
Iteration [14082]: Loss = 0.7084129452705383
Iteration [14083]: Loss = 4.902355670928955
Iteration [14084]: Loss = 0.7085567712783813
Iteration [14085]: Loss = 0.708660900592804
Iteration [14086]: Loss = 0.7087246775627136
Iteration [14087]: Loss = 0.7087522745132446
Iteration [14088]: Loss = 0.7087470293045044
Iteration [14089]: Loss = 0.7087124586105347
Iteration [14090]: Loss = 4.901108741760254
Iteration [14091]: Loss = 0.7087497711181641
Iteration [14092]: Loss = 0.7088083624839783
Iteration [14093]: Loss = 0.7088311314582825
Iteration [14094]: Loss = 0.7088217735290527
Iteration [14095]: Loss = 0.7087832689285278
Iteration [14096]: Loss = 4.900763511657715
Iteration [14097]: Loss = 4.900276184082031
Iteration [14098]: Loss = 0.7090526819229126
Iteration [14099]: Loss = 0.709237813949585
Iteration [14100]: Loss = 9.085439682006836
Iteration [14101]: Loss = 0.7098299264907837
Iteration [14102]: Loss = 0.710210382938385
Iteration [14103]: Loss = 0.710523247718811
Iteration [14104]: Loss = 0.7107752561569214
Iteration [14105]: Loss = 0.7109724283218384
Iteration [14106]: Loss = 0.7111201286315918
Iteration [14107]: Loss = 0.7112232446670532
Iteration [14108]: Loss = 0.7112862467765808
Iteration [14109]: Loss = 0.711313009262085
Iteration [14110]: Loss = 0.7113072872161865
Iteration [14111]: Loss = 0.7112720608711243
Iteration [14112]: Loss = 0.7112104296684265
Iteration [14113]: Loss = 0.7111249566078186
Iteration [14114]: Loss = 0.7110180258750916
Iteration [14115]: Loss = 0.7108919620513916
Iteration [14116]: Loss = 0.7107484340667725
Iteration [14117]: Loss = 0.7105891108512878
Iteration [14118]: Loss = 0.710415780544281
Iteration [14119]: Loss = 9.07584285736084
Iteration [14120]: Loss = 0.7103968858718872
Iteration [14121]: Loss = 0.7105175256729126
Iteration [14122]: Loss = 0.71059650182724
Iteration [14123]: Loss = 0.7106377482414246
Iteration [14124]: Loss = 0.7106451988220215
Iteration [14125]: Loss = 0.7106220722198486
Iteration [14126]: Loss = 0.7105714082717896
Iteration [14127]: Loss = 0.710496187210083
Iteration [14128]: Loss = 0.7103985548019409
Iteration [14129]: Loss = 0.7102807760238647
Iteration [14130]: Loss = 0.7101448774337769
Iteration [14131]: Loss = 0.7099928259849548
Iteration [14132]: Loss = 0.7098261713981628
Iteration [14133]: Loss = 0.7096461653709412
Iteration [14134]: Loss = 4.896997928619385
Iteration [14135]: Loss = 0.7094343304634094
Iteration [14136]: Loss = 0.7093864679336548
Iteration [14137]: Loss = 0.7093135714530945
Iteration [14138]: Loss = 0.7092180848121643
Iteration [14139]: Loss = 0.7091023921966553
Iteration [14140]: Loss = 0.708968460559845
Iteration [14141]: Loss = 0.7088179588317871
Iteration [14142]: Loss = 0.7086527347564697
Iteration [14143]: Loss = 0.7084742188453674
Iteration [14144]: Loss = 0.7082836627960205
Iteration [14145]: Loss = 0.7080821990966797
Iteration [14146]: Loss = 0.7078711986541748
Iteration [14147]: Loss = 0.7076513767242432
Iteration [14148]: Loss = 0.7074236869812012
Iteration [14149]: Loss = 0.7071889638900757
Iteration [14150]: Loss = 0.7069476842880249
Iteration [14151]: Loss = 0.7067009210586548
Iteration [14152]: Loss = 0.706449031829834
Iteration [14153]: Loss = 0.7061923146247864
Iteration [14154]: Loss = 0.7059316039085388
Iteration [14155]: Loss = 0.7056670784950256
Iteration [14156]: Loss = 0.7053991556167603
Iteration [14157]: Loss = 0.7051282525062561
Iteration [14158]: Loss = 4.9206461906433105
Iteration [14159]: Loss = 4.9211225509643555
Iteration [14160]: Loss = 0.7048328518867493
Iteration [14161]: Loss = 0.7048666477203369
Iteration [14162]: Loss = 0.7048673629760742
Iteration [14163]: Loss = 0.7048381567001343
Iteration [14164]: Loss = 4.921020030975342
Iteration [14165]: Loss = 0.7048854231834412
Iteration [14166]: Loss = 0.7049486637115479
Iteration [14167]: Loss = 0.7049757838249207
Iteration [14168]: Loss = 0.7049704790115356
Iteration [14169]: Loss = 0.7049360871315002
Iteration [14170]: Loss = 0.7048752903938293
Iteration [14171]: Loss = 0.7047908902168274
Iteration [14172]: Loss = 0.7046850919723511
Iteration [14173]: Loss = 0.7045602202415466
Iteration [14174]: Loss = 0.7044180631637573
Iteration [14175]: Loss = 0.7042601108551025
Iteration [14176]: Loss = 0.7040883898735046
Iteration [14177]: Loss = 0.70390385389328
Iteration [14178]: Loss = 0.7037080526351929
Iteration [14179]: Loss = 0.7035020589828491
Iteration [14180]: Loss = 0.70328688621521
Iteration [14181]: Loss = 0.7030633687973022
Iteration [14182]: Loss = 0.7028324604034424
Iteration [14183]: Loss = 0.7025948762893677
Iteration [14184]: Loss = 0.7023512125015259
Iteration [14185]: Loss = 0.7021022439002991
Iteration [14186]: Loss = 0.7018482685089111
Iteration [14187]: Loss = 0.7015899419784546
Iteration [14188]: Loss = 4.93895149230957
Iteration [14189]: Loss = 0.7012467980384827
Iteration [14190]: Loss = 0.7011441588401794
Iteration [14191]: Loss = 0.701022207736969
Iteration [14192]: Loss = 0.7008827328681946
Iteration [14193]: Loss = 0.7007274031639099
Iteration [14194]: Loss = 0.7005579471588135
Iteration [14195]: Loss = 0.7003755569458008
Iteration [14196]: Loss = 0.7001817226409912
Iteration [14197]: Loss = 0.6999776363372803
Iteration [14198]: Loss = 0.6997641324996948
Iteration [14199]: Loss = 4.9482741355896
Iteration [14200]: Loss = 0.699498176574707
Iteration [14201]: Loss = 0.6994287967681885
Iteration [14202]: Loss = 0.699336588382721
Iteration [14203]: Loss = 0.6992239356040955
Iteration [14204]: Loss = 0.6990928649902344
Iteration [14205]: Loss = 0.6989452242851257
Iteration [14206]: Loss = 0.6987825632095337
Iteration [14207]: Loss = 0.6986066102981567
Iteration [14208]: Loss = 0.6984185576438904
Iteration [14209]: Loss = 0.6982194781303406
Iteration [14210]: Loss = 4.956305027008057
Iteration [14211]: Loss = 0.6979785561561584
Iteration [14212]: Loss = 0.697920024394989
Iteration [14213]: Loss = 0.6978377103805542
Iteration [14214]: Loss = 0.697733998298645
Iteration [14215]: Loss = 0.6976110339164734
Iteration [14216]: Loss = 0.6974706053733826
Iteration [14217]: Loss = 0.6973145008087158
Iteration [14218]: Loss = 0.6971443891525269
Iteration [14219]: Loss = 4.961821556091309
Iteration [14220]: Loss = 0.6969532370567322
Iteration [14221]: Loss = 0.6969160437583923
Iteration [14222]: Loss = 0.6968529224395752
Iteration [14223]: Loss = 0.6967664957046509
Iteration [14224]: Loss = 0.6966590285301208
Iteration [14225]: Loss = 4.964080810546875
Iteration [14226]: Loss = 0.6965751647949219
Iteration [14227]: Loss = 4.963812351226807
Iteration [14228]: Loss = 0.6967471241950989
Iteration [14229]: Loss = 0.6968646049499512
Iteration [14230]: Loss = 0.6969409584999084
Iteration [14231]: Loss = 0.6969799399375916
Iteration [14232]: Loss = 0.6969855427742004
Iteration [14233]: Loss = 0.6969609260559082
Iteration [14234]: Loss = 4.962097644805908
Iteration [14235]: Loss = 0.6970183849334717
Iteration [14236]: Loss = 4.961160659790039
Iteration [14237]: Loss = 0.6973046660423279
Iteration [14238]: Loss = 0.6974708437919617
Iteration [14239]: Loss = 0.6975908875465393
Iteration [14240]: Loss = 0.6976694464683533
Iteration [14241]: Loss = 0.697710394859314
Iteration [14242]: Loss = 0.6977177262306213
Iteration [14243]: Loss = 0.6976945996284485
Iteration [14244]: Loss = 0.697644054889679
Iteration [14245]: Loss = 0.6975690126419067
Iteration [14246]: Loss = 0.697471559047699
Iteration [14247]: Loss = 0.6973540782928467
Iteration [14248]: Loss = 0.6972187161445618
Iteration [14249]: Loss = 0.6970670819282532
Iteration [14250]: Loss = 0.6969008445739746
Iteration [14251]: Loss = 0.6967214941978455
Iteration [14252]: Loss = 0.6965303421020508
Iteration [14253]: Loss = 0.6963285803794861
Iteration [14254]: Loss = 0.6961171627044678
Iteration [14255]: Loss = 0.6958970427513123
Iteration [14256]: Loss = 4.968636989593506
Iteration [14257]: Loss = 0.6956213116645813
Iteration [14258]: Loss = 4.969274520874023
Iteration [14259]: Loss = 0.6956394910812378
Iteration [14260]: Loss = 0.695691704750061
Iteration [14261]: Loss = 4.968425750732422
Iteration [14262]: Loss = 0.6958811283111572
Iteration [14263]: Loss = 0.6960063576698303
Iteration [14264]: Loss = 0.6960895657539368
Iteration [14265]: Loss = 4.966179847717285
Iteration [14266]: Loss = 0.6963315606117249
Iteration [14267]: Loss = 0.6964792609214783
Iteration [14268]: Loss = 4.963818550109863
Iteration [14269]: Loss = 0.696831464767456
Iteration [14270]: Loss = 0.6970260143280029
Iteration [14271]: Loss = 0.6971715688705444
Iteration [14272]: Loss = 0.6972729563713074
Iteration [14273]: Loss = 0.6973344683647156
Iteration [14274]: Loss = 0.6973601579666138
Iteration [14275]: Loss = 0.6973534822463989
Iteration [14276]: Loss = 0.6973178386688232
Iteration [14277]: Loss = 0.6972557902336121
Iteration [14278]: Loss = 0.6971703767776489
Iteration [14279]: Loss = 0.6970635652542114
Iteration [14280]: Loss = 4.961947441101074
Iteration [14281]: Loss = 4.961719989776611
Iteration [14282]: Loss = 0.6971763372421265
Iteration [14283]: Loss = 0.6973224878311157
Iteration [14284]: Loss = 0.6974244713783264
Iteration [14285]: Loss = 0.6974865198135376
Iteration [14286]: Loss = 0.6975125074386597
Iteration [14287]: Loss = 0.6975062489509583
Iteration [14288]: Loss = 0.6974707245826721
Iteration [14289]: Loss = 0.6974090337753296
Iteration [14290]: Loss = 0.6973235607147217
Iteration [14291]: Loss = 0.6972169280052185
Iteration [14292]: Loss = 0.6970909833908081
Iteration [14293]: Loss = 0.6969478130340576
Iteration [14294]: Loss = 0.6967890858650208
Iteration [14295]: Loss = 0.6966164112091064
Iteration [14296]: Loss = 0.6975337862968445
Iteration [14297]: Loss = 0.6962344646453857
Iteration [14298]: Loss = 4.966744899749756
Iteration [14299]: Loss = 4.962911605834961
Iteration [14300]: Loss = 0.6972523331642151
Iteration [14301]: Loss = 0.6974223256111145
Iteration [14302]: Loss = 0.6974719166755676
Iteration [14303]: Loss = 0.6974867582321167
Iteration [14304]: Loss = 0.6974701285362244
Iteration [14305]: Loss = 0.6974253058433533
Iteration [14306]: Loss = 0.6973550319671631
Iteration [14307]: Loss = 0.6972619295120239
Iteration [14308]: Loss = 0.6971482038497925
Iteration [14309]: Loss = 0.6970159411430359
Iteration [14310]: Loss = 0.6968668699264526
Iteration [14311]: Loss = 0.6967028379440308
Iteration [14312]: Loss = 0.6965252161026001
Iteration [14313]: Loss = 0.6963353753089905
Iteration [14314]: Loss = 0.696134626865387
Iteration [14315]: Loss = 0.6959239840507507
Iteration [14316]: Loss = 0.6957045197486877
Iteration [14317]: Loss = 0.6954768300056458
Iteration [14318]: Loss = 0.6952421069145203
Iteration [14319]: Loss = 0.695000946521759
Iteration [14320]: Loss = 0.6947540044784546
Iteration [14321]: Loss = 0.6945015788078308
Iteration [14322]: Loss = 0.6942447423934937
Iteration [14323]: Loss = 0.6939835548400879
Iteration [14324]: Loss = 4.978961944580078
Iteration [14325]: Loss = 0.6936386823654175
Iteration [14326]: Loss = 4.97992467880249
Iteration [14327]: Loss = 0.6936037540435791
Iteration [14328]: Loss = 0.6936339139938354
Iteration [14329]: Loss = 0.6936314105987549
Iteration [14330]: Loss = 0.6935993432998657
Iteration [14331]: Loss = 0.6935405135154724
Iteration [14332]: Loss = 0.6934577822685242
Iteration [14333]: Loss = 0.6933534145355225
Iteration [14334]: Loss = 0.6932296752929688
Iteration [14335]: Loss = 0.6930884122848511
Iteration [14336]: Loss = 0.6929313540458679
Iteration [14337]: Loss = 0.6927602291107178
Iteration [14338]: Loss = 4.9850311279296875
Iteration [14339]: Loss = 0.6925694346427917
Iteration [14340]: Loss = 0.6925334334373474
Iteration [14341]: Loss = 0.6924713850021362
Iteration [14342]: Loss = 0.6923856139183044
Iteration [14343]: Loss = 0.6922785639762878
Iteration [14344]: Loss = 0.6921523213386536
Iteration [14345]: Loss = 0.6920087933540344
Iteration [14346]: Loss = 0.6918498277664185
Iteration [14347]: Loss = 0.6916767358779907
Iteration [14348]: Loss = 4.990809440612793
Iteration [14349]: Loss = 0.6914834976196289
Iteration [14350]: Loss = 0.6914466023445129
Iteration [14351]: Loss = 0.6913837194442749
Iteration [14352]: Loss = 0.6912972331047058
Iteration [14353]: Loss = 0.6911894083023071
Iteration [14354]: Loss = 0.6910625100135803
Iteration [14355]: Loss = 0.6909186244010925
Iteration [14356]: Loss = 0.6907591819763184
Iteration [14357]: Loss = 0.690585732460022
Iteration [14358]: Loss = 0.6903998851776123
Iteration [14359]: Loss = 0.6902026534080505
Iteration [14360]: Loss = 0.6899953484535217
Iteration [14361]: Loss = 0.6897788643836975
Iteration [14362]: Loss = 0.6895540952682495
Iteration [14363]: Loss = 0.6893221139907837
Iteration [14364]: Loss = 5.003688335418701
Iteration [14365]: Loss = 0.6890285611152649
Iteration [14366]: Loss = 0.688949465751648
Iteration [14367]: Loss = 0.6888483762741089
Iteration [14368]: Loss = 0.6887276768684387
Iteration [14369]: Loss = 0.6885892748832703
Iteration [14370]: Loss = 0.6884347796440125
Iteration [14371]: Loss = 0.6882658004760742
Iteration [14372]: Loss = 0.688084065914154
Iteration [14373]: Loss = 5.010094165802002
Iteration [14374]: Loss = 0.68787682056427
Iteration [14375]: Loss = 0.6878347396850586
Iteration [14376]: Loss = 0.6877669095993042
Iteration [14377]: Loss = 0.687676191329956
Iteration [14378]: Loss = 0.6875647902488708
Iteration [14379]: Loss = 0.6874345541000366
Iteration [14380]: Loss = 0.6872876882553101
Iteration [14381]: Loss = 0.6871256232261658
Iteration [14382]: Loss = 0.6869499087333679
Iteration [14383]: Loss = 0.6867620944976807
Iteration [14384]: Loss = 0.6865630745887756
Iteration [14385]: Loss = 0.6863543391227722
Iteration [14386]: Loss = 0.6861365437507629
Iteration [14387]: Loss = 0.6859106421470642
Iteration [14388]: Loss = 0.6856775879859924
Iteration [14389]: Loss = 5.023324489593506
Iteration [14390]: Loss = 0.685383677482605
Iteration [14391]: Loss = 0.6853049397468567
Iteration [14392]: Loss = 5.024588584899902
Iteration [14393]: Loss = 0.6852744221687317
Iteration [14394]: Loss = 0.6853079795837402
Iteration [14395]: Loss = 0.6853084564208984
Iteration [14396]: Loss = 0.685279369354248
Iteration [14397]: Loss = 0.6852232217788696
Iteration [14398]: Loss = 0.6851429343223572
Iteration [14399]: Loss = 0.685041069984436
Iteration [14400]: Loss = 0.6849195957183838
Iteration [14401]: Loss = 0.6847804188728333
Iteration [14402]: Loss = 0.6846253871917725
Iteration [14403]: Loss = 0.6844561696052551
Iteration [14404]: Loss = 5.029630184173584
Iteration [14405]: Loss = 0.6842714548110962
Iteration [14406]: Loss = 0.6842395067214966
Iteration [14407]: Loss = 0.6841809153556824
Iteration [14408]: Loss = 0.6840986013412476
Iteration [14409]: Loss = 0.6839946508407593
Iteration [14410]: Loss = 0.6838714480400085
Iteration [14411]: Loss = 0.6837306618690491
Iteration [14412]: Loss = 0.6835743188858032
Iteration [14413]: Loss = 0.6834036707878113
Iteration [14414]: Loss = 0.6832205057144165
Iteration [14415]: Loss = 5.036412239074707
Iteration [14416]: Loss = 5.036484718322754
Iteration [14417]: Loss = 9.388187408447266
Iteration [14418]: Loss = 0.6836424469947815
Iteration [14419]: Loss = 0.6840465068817139
Iteration [14420]: Loss = 5.029050350189209
Iteration [14421]: Loss = 5.0265583992004395
Iteration [14422]: Loss = 0.685413122177124
Iteration [14423]: Loss = 0.6858993768692017
Iteration [14424]: Loss = 0.686307966709137
Iteration [14425]: Loss = 0.6866465210914612
Iteration [14426]: Loss = 0.6869218349456787
Iteration [14427]: Loss = 0.6871404647827148
Iteration [14428]: Loss = 5.013232231140137
Iteration [14429]: Loss = 0.6876168251037598
Iteration [14430]: Loss = 0.6878659129142761
Iteration [14431]: Loss = 5.009180545806885
Iteration [14432]: Loss = 0.6883942484855652
Iteration [14433]: Loss = 0.6886652112007141
Iteration [14434]: Loss = 0.6888797879219055
Iteration [14435]: Loss = 0.6890431642532349
Iteration [14436]: Loss = 0.689160943031311
Iteration [14437]: Loss = 0.6892370581626892
Iteration [14438]: Loss = 0.6892760992050171
Iteration [14439]: Loss = 0.6892815232276917
Iteration [14440]: Loss = 5.002758502960205
Iteration [14441]: Loss = 0.6893932819366455
Iteration [14442]: Loss = 0.6894866824150085
Iteration [14443]: Loss = 0.6895410418510437
Iteration [14444]: Loss = 0.6895602345466614
Iteration [14445]: Loss = 0.6895480155944824
Iteration [14446]: Loss = 0.6895070672035217
Iteration [14447]: Loss = 0.6894404292106628
Iteration [14448]: Loss = 0.6893509030342102
Iteration [14449]: Loss = 0.6892403364181519
Iteration [14450]: Loss = 0.6891112327575684
Iteration [14451]: Loss = 0.6889650225639343
Iteration [14452]: Loss = 0.6888037323951721
Iteration [14453]: Loss = 5.006128311157227
Iteration [14454]: Loss = 0.6886310577392578
Iteration [14455]: Loss = 0.6886035799980164
Iteration [14456]: Loss = 5.006556034088135
Iteration [14457]: Loss = 5.0059638023376465
Iteration [14458]: Loss = 0.6889175176620483
Iteration [14459]: Loss = 0.6891204118728638
Iteration [14460]: Loss = 0.6892735958099365
Iteration [14461]: Loss = 0.6893815994262695
Iteration [14462]: Loss = 0.6894491910934448
Iteration [14463]: Loss = 0.6894804239273071
Iteration [14464]: Loss = 0.6894786357879639
Iteration [14465]: Loss = 0.6894474029541016
Iteration [14466]: Loss = 0.6893894672393799
Iteration [14467]: Loss = 5.002486228942871
Iteration [14468]: Loss = 0.6893930435180664
Iteration [14469]: Loss = 5.001771926879883
Iteration [14470]: Loss = 0.6896424889564514
Iteration [14471]: Loss = 0.6897945404052734
Iteration [14472]: Loss = 0.68990159034729
Iteration [14473]: Loss = 0.6899683475494385
Iteration [14474]: Loss = 0.6899986267089844
Iteration [14475]: Loss = 0.6899961829185486
Iteration [14476]: Loss = 0.6899640560150146
Iteration [14477]: Loss = 0.6899052262306213
Iteration [14478]: Loss = 0.6898226737976074
Iteration [14479]: Loss = 0.6897183656692505
Iteration [14480]: Loss = 0.6895946264266968
Iteration [14481]: Loss = 0.6894534826278687
Iteration [14482]: Loss = 0.6892964839935303
Iteration [14483]: Loss = 5.003463268280029
Iteration [14484]: Loss = 0.6891312599182129
Iteration [14485]: Loss = 5.0035624504089355
Iteration [14486]: Loss = 0.6892446279525757
Iteration [14487]: Loss = 0.6893386244773865
Iteration [14488]: Loss = 0.6893936395645142
Iteration [14489]: Loss = 5.001918792724609
Iteration [14490]: Loss = 0.689590573310852
Iteration [14491]: Loss = 0.6897203326225281
Iteration [14492]: Loss = 0.6898074150085449
Iteration [14493]: Loss = 0.6898559927940369
Iteration [14494]: Loss = 0.6898699402809143
Iteration [14495]: Loss = 0.6898525953292847
Iteration [14496]: Loss = 0.6898071765899658
Iteration [14497]: Loss = 0.689736545085907
Iteration [14498]: Loss = 0.6896427869796753
Iteration [14499]: Loss = 0.6895286440849304
Iteration [14500]: Loss = 0.6893961429595947
Iteration [14501]: Loss = 0.6892468333244324
Iteration [14502]: Loss = 0.6890825033187866
Iteration [14503]: Loss = 0.6889047622680664
Iteration [14504]: Loss = 5.005665302276611
Iteration [14505]: Loss = 5.005721092224121
Iteration [14506]: Loss = 5.004914283752441
Iteration [14507]: Loss = 0.6891494989395142
Iteration [14508]: Loss = 0.6893852949142456
Iteration [14509]: Loss = 5.001091957092285
Iteration [14510]: Loss = 4.99936056137085
Iteration [14511]: Loss = 0.6903406977653503
Iteration [14512]: Loss = 0.6907161474227905
Iteration [14513]: Loss = 0.6910244226455688
Iteration [14514]: Loss = 0.6912721991539001
Iteration [14515]: Loss = 4.9909467697143555
Iteration [14516]: Loss = 0.6917983293533325
Iteration [14517]: Loss = 0.6920682191848755
Iteration [14518]: Loss = 4.986599445343018
Iteration [14519]: Loss = 4.984735012054443
Iteration [14520]: Loss = 0.6931054592132568
Iteration [14521]: Loss = 0.6935021281242371
Iteration [14522]: Loss = 0.6938296556472778
Iteration [14523]: Loss = 0.6940947771072388
Iteration [14524]: Loss = 0.6943033337593079
Iteration [14525]: Loss = 0.6944613456726074
Iteration [14526]: Loss = 0.6945735812187195
Iteration [14527]: Loss = 0.6946447491645813
Iteration [14528]: Loss = 0.6946786642074585
Iteration [14529]: Loss = 0.6946791410446167
Iteration [14530]: Loss = 0.6946495175361633
Iteration [14531]: Loss = 4.974328994750977
Iteration [14532]: Loss = 0.6947007179260254
Iteration [14533]: Loss = 4.9734015464782715
Iteration [14534]: Loss = 0.6949870586395264
Iteration [14535]: Loss = 4.9713568687438965
Iteration [14536]: Loss = 0.6954633593559265
Iteration [14537]: Loss = 0.6957115530967712
Iteration [14538]: Loss = 0.6959050893783569
Iteration [14539]: Loss = 0.6960492730140686
Iteration [14540]: Loss = 0.6961491107940674
Iteration [14541]: Loss = 0.6962087750434875
Iteration [14542]: Loss = 0.6962324380874634
Iteration [14543]: Loss = 0.6962234973907471
Iteration [14544]: Loss = 0.6961853504180908
Iteration [14545]: Loss = 0.6961208581924438
Iteration [14546]: Loss = 0.6960326433181763
Iteration [14547]: Loss = 0.6959230303764343
Iteration [14548]: Loss = 0.6957941651344299
Iteration [14549]: Loss = 0.6956479549407959
Iteration [14550]: Loss = 0.6954861879348755
Iteration [14551]: Loss = 0.6953102946281433
Iteration [14552]: Loss = 0.6951218247413635
Iteration [14553]: Loss = 0.6949218511581421
Iteration [14554]: Loss = 0.6947118639945984
Iteration [14555]: Loss = 0.694492518901825
Iteration [14556]: Loss = 0.6942647695541382
Iteration [14557]: Loss = 4.977311611175537
Iteration [14558]: Loss = 0.6939783096313477
Iteration [14559]: Loss = 0.6939018368721008
Iteration [14560]: Loss = 0.6938029527664185
Iteration [14561]: Loss = 0.6936835050582886
Iteration [14562]: Loss = 0.6935459971427917
Iteration [14563]: Loss = 0.6933922171592712
Iteration [14564]: Loss = 0.6932234764099121
Iteration [14565]: Loss = 0.6930414438247681
Iteration [14566]: Loss = 0.6928474307060242
Iteration [14567]: Loss = 0.6926425695419312
Iteration [14568]: Loss = 0.6924281716346741
Iteration [14569]: Loss = 4.987006664276123
Iteration [14570]: Loss = 4.987221717834473
Iteration [14571]: Loss = 0.6922880411148071
Iteration [14572]: Loss = 0.6923694014549255
Iteration [14573]: Loss = 4.985901832580566
Iteration [14574]: Loss = 0.692611038684845
Iteration [14575]: Loss = 0.6927597522735596
Iteration [14576]: Loss = 0.6928635835647583
Iteration [14577]: Loss = 0.6929269433021545
Iteration [14578]: Loss = 0.6929540038108826
Iteration [14579]: Loss = 0.6929481625556946
Iteration [14580]: Loss = 0.6929128766059875
Iteration [14581]: Loss = 0.6928509473800659
Iteration [14582]: Loss = 0.692764937877655
Iteration [14583]: Loss = 0.6926575899124146
Iteration [14584]: Loss = 0.692530632019043
Iteration [14585]: Loss = 0.692386269569397
Iteration [14586]: Loss = 0.692225992679596
Iteration [14587]: Loss = 4.987823009490967
Iteration [14588]: Loss = 0.692055344581604
Iteration [14589]: Loss = 4.987946033477783
Iteration [14590]: Loss = 0.6921646595001221
Iteration [14591]: Loss = 0.6922570466995239
Iteration [14592]: Loss = 0.6923102140426636
Iteration [14593]: Loss = 0.6923279166221619
Iteration [14594]: Loss = 0.6923137903213501
Iteration [14595]: Loss = 0.6922708749771118
Iteration [14596]: Loss = 0.6922020316123962
Iteration [14597]: Loss = 0.692110002040863
Iteration [14598]: Loss = 0.6919969916343689
Iteration [14599]: Loss = 0.691865086555481
Iteration [14600]: Loss = 4.989610195159912
Iteration [14601]: Loss = 0.6917427778244019
Iteration [14602]: Loss = 0.6917366981506348
Iteration [14603]: Loss = 0.6917011141777039
Iteration [14604]: Loss = 0.6916388869285583
Iteration [14605]: Loss = 0.6915526390075684
Iteration [14606]: Loss = 0.6914450526237488
Iteration [14607]: Loss = 0.6913178563117981
Iteration [14608]: Loss = 4.9925055503845215
Iteration [14609]: Loss = 0.6912040710449219
Iteration [14610]: Loss = 0.6912016868591309
Iteration [14611]: Loss = 0.6911693215370178
Iteration [14612]: Loss = 4.9928436279296875
Iteration [14613]: Loss = 0.6912175416946411
Iteration [14614]: Loss = 4.991915225982666
Iteration [14615]: Loss = 0.6915042400360107
Iteration [14616]: Loss = 0.6916725039482117
Iteration [14617]: Loss = 0.6917937994003296
Iteration [14618]: Loss = 4.988774299621582
Iteration [14619]: Loss = 0.6921044588088989
Iteration [14620]: Loss = 4.986591815948486
Iteration [14621]: Loss = 0.6926030516624451
Iteration [14622]: Loss = 0.6928614377975464
Iteration [14623]: Loss = 0.6930639743804932
Iteration [14624]: Loss = 0.6932162046432495
Iteration [14625]: Loss = 4.98106050491333
Iteration [14626]: Loss = 0.6935793161392212
Iteration [14627]: Loss = 0.6937796473503113
Iteration [14628]: Loss = 0.6939300298690796
Iteration [14629]: Loss = 0.6940352916717529
Iteration [14630]: Loss = 0.6940997838973999
Iteration [14631]: Loss = 0.6941275596618652
Iteration [14632]: Loss = 0.694122314453125
Iteration [14633]: Loss = 0.6940873265266418
Iteration [14634]: Loss = 0.6940256357192993
Iteration [14635]: Loss = 0.693939745426178
Iteration [14636]: Loss = 4.978359699249268
Iteration [14637]: Loss = 0.6938958764076233
Iteration [14638]: Loss = 0.6939229369163513
Iteration [14639]: Loss = 0.6939170956611633
Iteration [14640]: Loss = 0.6938815712928772
Iteration [14641]: Loss = 4.978427886962891
Iteration [14642]: Loss = 4.977874279022217
Iteration [14643]: Loss = 0.6941774487495422
Iteration [14644]: Loss = 4.97547721862793
Iteration [14645]: Loss = 0.6947141289710999
Iteration [14646]: Loss = 0.6949883699417114
Iteration [14647]: Loss = 0.6952052116394043
Iteration [14648]: Loss = 0.6953701972961426
Iteration [14649]: Loss = 0.6954885721206665
Iteration [14650]: Loss = 0.6955648064613342
Iteration [14651]: Loss = 4.9689860343933105
Iteration [14652]: Loss = 0.6957975029945374
Iteration [14653]: Loss = 0.6959421038627625
Iteration [14654]: Loss = 0.6960421800613403
Iteration [14655]: Loss = 0.6961018443107605
Iteration [14656]: Loss = 4.966229438781738
Iteration [14657]: Loss = 0.6979178190231323
Iteration [14658]: Loss = 0.6980502605438232
Iteration [14659]: Loss = 0.6981391310691833
Iteration [14660]: Loss = 0.6981885433197021
Iteration [14661]: Loss = 0.6982026100158691
Iteration [14662]: Loss = 0.6981847882270813
Iteration [14663]: Loss = 0.6981382369995117
Iteration [14664]: Loss = 0.6980658173561096
Iteration [14665]: Loss = 4.95651912689209
Iteration [14666]: Loss = 0.6980440020561218
Iteration [14667]: Loss = 0.6980801820755005
Iteration [14668]: Loss = 4.955929279327393
Iteration [14669]: Loss = 0.6982440948486328
Iteration [14670]: Loss = 0.6983593106269836
Iteration [14671]: Loss = 0.6984325647354126
Iteration [14672]: Loss = 0.6984679698944092
Iteration [14673]: Loss = 4.953897953033447
Iteration [14674]: Loss = 0.6986304521560669
Iteration [14675]: Loss = 0.6987451314926147
Iteration [14676]: Loss = 0.698817789554596
Iteration [14677]: Loss = 0.6988527178764343
Iteration [14678]: Loss = 0.6988536715507507
Iteration [14679]: Loss = 0.6988238096237183
Iteration [14680]: Loss = 0.6987663507461548
Iteration [14681]: Loss = 4.952771186828613
Iteration [14682]: Loss = 0.6987703442573547
Iteration [14683]: Loss = 0.6988174319267273
Iteration [14684]: Loss = 0.6988292932510376
Iteration [14685]: Loss = 0.6988092660903931
Iteration [14686]: Loss = 0.6987607479095459
Iteration [14687]: Loss = 0.6986865401268005
Iteration [14688]: Loss = 0.6985889673233032
Iteration [14689]: Loss = 0.6984706521034241
Iteration [14690]: Loss = 0.6983333826065063
Iteration [14691]: Loss = 0.6981793642044067
Iteration [14692]: Loss = 0.6980099678039551
Iteration [14693]: Loss = 4.957270622253418
Iteration [14694]: Loss = 0.6978229880332947
Iteration [14695]: Loss = 4.957470417022705
Iteration [14696]: Loss = 0.6979185938835144
Iteration [14697]: Loss = 0.698004961013794
Iteration [14698]: Loss = 0.6980519890785217
Iteration [14699]: Loss = 4.956026077270508
Iteration [14700]: Loss = 4.955127716064453
Iteration [14701]: Loss = 0.698548436164856
Iteration [14702]: Loss = 0.6988004446029663
Iteration [14703]: Loss = 0.6989967823028564
Iteration [14704]: Loss = 4.950366020202637
Iteration [14705]: Loss = 0.6994342803955078
Iteration [14706]: Loss = 9.195589065551758
Iteration [14707]: Loss = 0.7002198100090027
Iteration [14708]: Loss = 0.7006881237030029
Iteration [14709]: Loss = 0.7010797262191772
Iteration [14710]: Loss = 0.7014020681381226
Iteration [14711]: Loss = 0.7016619443893433
Iteration [14712]: Loss = 0.701865553855896
Iteration [14713]: Loss = 0.7020183801651001
Iteration [14714]: Loss = 0.7021255493164062
Iteration [14715]: Loss = 0.7021914720535278
Iteration [14716]: Loss = 0.7022202014923096
Iteration [14717]: Loss = 0.7022157907485962
Iteration [14718]: Loss = 0.7021809816360474
Iteration [14719]: Loss = 0.7021191716194153
Iteration [14720]: Loss = 4.93527889251709
Iteration [14721]: Loss = 0.7021143436431885
Iteration [14722]: Loss = 0.7021569609642029
Iteration [14723]: Loss = 0.702164888381958
Iteration [14724]: Loss = 0.7021414637565613
Iteration [14725]: Loss = 0.7020896673202515
Iteration [14726]: Loss = 0.7020124793052673
Iteration [14727]: Loss = 0.7019124627113342
Iteration [14728]: Loss = 0.7017917037010193
Iteration [14729]: Loss = 0.701652467250824
Iteration [14730]: Loss = 0.701496422290802
Iteration [14731]: Loss = 9.17660140991211
Iteration [14732]: Loss = 0.7015191316604614
Iteration [14733]: Loss = 4.9372029304504395
Iteration [14734]: Loss = 0.7019506692886353
Iteration [14735]: Loss = 0.7021790742874146
Iteration [14736]: Loss = 0.7023544907569885
Iteration [14737]: Loss = 0.7024820446968079
Iteration [14738]: Loss = 0.7025665044784546
Iteration [14739]: Loss = 0.7026121020317078
Iteration [14740]: Loss = 4.932211399078369
Iteration [14741]: Loss = 0.7027902603149414
Iteration [14742]: Loss = 0.7029106616973877
Iteration [14743]: Loss = 0.7029886245727539
Iteration [14744]: Loss = 0.7030284404754639
Iteration [14745]: Loss = 0.7030337452888489
Iteration [14746]: Loss = 0.7030081152915955
Iteration [14747]: Loss = 0.7029545307159424
Iteration [14748]: Loss = 0.7028757929801941
Iteration [14749]: Loss = 0.7027744650840759
Iteration [14750]: Loss = 0.7026526927947998
Iteration [14751]: Loss = 4.932784557342529
Iteration [14752]: Loss = 0.7025448679924011
Iteration [14753]: Loss = 0.7025436162948608
Iteration [14754]: Loss = 0.7025118470191956
Iteration [14755]: Loss = 0.7024528980255127
Iteration [14756]: Loss = 0.7023692727088928
Iteration [14757]: Loss = 0.7022635340690613
Iteration [14758]: Loss = 0.70213782787323
Iteration [14759]: Loss = 0.7019941210746765
Iteration [14760]: Loss = 4.936312675476074
Iteration [14761]: Loss = 0.7018490433692932
Iteration [14762]: Loss = 0.7018320560455322
Iteration [14763]: Loss = 0.7017861604690552
Iteration [14764]: Loss = 0.7017145156860352
Iteration [14765]: Loss = 0.7016193866729736
Iteration [14766]: Loss = 0.7015032768249512
Iteration [14767]: Loss = 0.7013682723045349
Iteration [14768]: Loss = 0.7012161612510681
Iteration [14769]: Loss = 0.7010488510131836
Iteration [14770]: Loss = 0.7008675932884216
Iteration [14771]: Loss = 0.7006740570068359
Iteration [14772]: Loss = 0.7004691958427429
Iteration [14773]: Loss = 0.7002543807029724
Iteration [14774]: Loss = 0.700030505657196
Iteration [14775]: Loss = 0.6997983455657959
Iteration [14776]: Loss = 13.445446014404297
Iteration [14777]: Loss = 0.6998754143714905
Iteration [14778]: Loss = 0.7001304626464844
Iteration [14779]: Loss = 4.944153785705566
Iteration [14780]: Loss = 0.7006658911705017
Iteration [14781]: Loss = 0.7009381055831909
Iteration [14782]: Loss = 0.7011533975601196
Iteration [14783]: Loss = 0.701317310333252
Iteration [14784]: Loss = 4.938390731811523
Iteration [14785]: Loss = 0.7016966342926025
Iteration [14786]: Loss = 0.7019022107124329
Iteration [14787]: Loss = 4.935151100158691
Iteration [14788]: Loss = 4.933618068695068
Iteration [14789]: Loss = 0.7027726769447327
Iteration [14790]: Loss = 0.7031214237213135
Iteration [14791]: Loss = 0.7034056186676025
Iteration [14792]: Loss = 0.703631579875946
Iteration [14793]: Loss = 0.7038050293922424
Iteration [14794]: Loss = 0.7039313316345215
Iteration [14795]: Loss = 0.7040149569511414
Iteration [14796]: Loss = 0.7040602564811707
Iteration [14797]: Loss = 0.7040711045265198
Iteration [14798]: Loss = 0.7040506601333618
Iteration [14799]: Loss = 0.7040020823478699
Iteration [14800]: Loss = 0.7039284706115723
Iteration [14801]: Loss = 0.7038319110870361
Iteration [14802]: Loss = 0.7037149667739868
Iteration [14803]: Loss = 0.7035795450210571
Iteration [14804]: Loss = 0.7034276723861694
Iteration [14805]: Loss = 0.703260600566864
Iteration [14806]: Loss = 4.929836750030518
Iteration [14807]: Loss = 0.7030740976333618
Iteration [14808]: Loss = 0.7030385732650757
Iteration [14809]: Loss = 0.7029765844345093
Iteration [14810]: Loss = 0.7028906345367432
Iteration [14811]: Loss = 0.7027829885482788
Iteration [14812]: Loss = 0.7026561498641968
Iteration [14813]: Loss = 0.7025118470191956
Iteration [14814]: Loss = 0.7023518681526184
Iteration [14815]: Loss = 0.7021776437759399
Iteration [14816]: Loss = 0.7019908428192139
Iteration [14817]: Loss = 0.7017924189567566
Iteration [14818]: Loss = 0.7015838027000427
Iteration [14819]: Loss = 0.7013658881187439
Iteration [14820]: Loss = 0.7011395692825317
Iteration [14821]: Loss = 0.7009059190750122
Iteration [14822]: Loss = 0.7006654143333435
Iteration [14823]: Loss = 4.943693161010742
Iteration [14824]: Loss = 4.944031715393066
Iteration [14825]: Loss = 0.7004525065422058
Iteration [14826]: Loss = 0.7005112171173096
Iteration [14827]: Loss = 0.7005340456962585
Iteration [14828]: Loss = 0.7005245089530945
Iteration [14829]: Loss = 0.70048588514328
Iteration [14830]: Loss = 0.700421154499054
Iteration [14831]: Loss = 0.700332760810852
Iteration [14832]: Loss = 0.7002231478691101
Iteration [14833]: Loss = 4.945388317108154
Iteration [14834]: Loss = 0.7001355290412903
Iteration [14835]: Loss = 0.7001426219940186
Iteration [14836]: Loss = 4.9452595710754395
Iteration [14837]: Loss = 0.7002543807029724
Iteration [14838]: Loss = 0.7003463506698608
Iteration [14839]: Loss = 0.7003990411758423
Iteration [14840]: Loss = 0.7004164457321167
Iteration [14841]: Loss = 0.7004021406173706
Iteration [14842]: Loss = 0.7003591656684875
Iteration [14843]: Loss = 0.7002903819084167
Iteration [14844]: Loss = 0.7001984119415283
Iteration [14845]: Loss = 0.700085461139679
Iteration [14846]: Loss = 0.6999536752700806
Iteration [14847]: Loss = 0.6998050808906555
Iteration [14848]: Loss = 4.947758674621582
Iteration [14849]: Loss = 0.6996510028839111
Iteration [14850]: Loss = 0.6996299028396606
Iteration [14851]: Loss = 0.6995806694030762
Iteration [14852]: Loss = 4.948463439941406
Iteration [14853]: Loss = 0.6995967626571655
Iteration [14854]: Loss = 0.6996481418609619
Iteration [14855]: Loss = 0.6996643543243408
Iteration [14856]: Loss = 0.6996488571166992
Iteration [14857]: Loss = 0.6996047496795654
Iteration [14858]: Loss = 0.6995350122451782
Iteration [14859]: Loss = 0.6994421482086182
Iteration [14860]: Loss = 0.6993284225463867
Iteration [14861]: Loss = 0.6991958618164062
Iteration [14862]: Loss = 0.6990465521812439
Iteration [14863]: Loss = 0.6988820433616638
Iteration [14864]: Loss = 0.6987038254737854
Iteration [14865]: Loss = 0.6985130906105042
Iteration [14866]: Loss = 0.6983113884925842
Iteration [14867]: Loss = 0.6980997920036316
Iteration [14868]: Loss = 0.6978791952133179
Iteration [14869]: Loss = 0.6976505517959595
Iteration [14870]: Loss = 0.6974144577980042
Iteration [14871]: Loss = 0.6971720457077026
Iteration [14872]: Loss = 0.6969236731529236
Iteration [14873]: Loss = 4.963357925415039
Iteration [14874]: Loss = 0.6966001987457275
Iteration [14875]: Loss = 0.6965075135231018
Iteration [14876]: Loss = 0.6963939666748047
Iteration [14877]: Loss = 0.6962617039680481
Iteration [14878]: Loss = 0.6961125135421753
Iteration [14879]: Loss = 0.6959482431411743
Iteration [14880]: Loss = 4.968102931976318
Iteration [14881]: Loss = 0.6957688331604004
Iteration [14882]: Loss = 0.6957374811172485
Iteration [14883]: Loss = 4.968583583831787
Iteration [14884]: Loss = 0.6957851648330688
Iteration [14885]: Loss = 0.6958504319190979
Iteration [14886]: Loss = 0.695879340171814
Iteration [14887]: Loss = 0.6958752870559692
Iteration [14888]: Loss = 4.96772575378418
Iteration [14889]: Loss = 0.6959696412086487
Iteration [14890]: Loss = 4.96660041809082
Iteration [14891]: Loss = 0.6962894797325134
Iteration [14892]: Loss = 0.6964709162712097
Iteration [14893]: Loss = 0.6966041326522827
Iteration [14894]: Loss = 0.6966941952705383
Iteration [14895]: Loss = 0.6967451572418213
Iteration [14896]: Loss = 0.6967610716819763
Iteration [14897]: Loss = 0.6967452764511108
Iteration [14898]: Loss = 0.696700930595398
Iteration [14899]: Loss = 0.6966310739517212
Iteration [14900]: Loss = 0.696537971496582
Iteration [14901]: Loss = 0.6964240074157715
Iteration [14902]: Loss = 0.6962913870811462
Iteration [14903]: Loss = 0.6961418986320496
Iteration [14904]: Loss = 0.6959772706031799
Iteration [14905]: Loss = 0.6957988739013672
Iteration [14906]: Loss = 4.968959331512451
Iteration [14907]: Loss = 0.6955956220626831
Iteration [14908]: Loss = 0.6955541968345642
Iteration [14909]: Loss = 0.6954869031906128
Iteration [14910]: Loss = 4.970078945159912
Iteration [14911]: Loss = 0.695473313331604
Iteration [14912]: Loss = 0.6955128312110901
Iteration [14913]: Loss = 9.243350982666016
Iteration [14914]: Loss = 0.6958673000335693
Iteration [14915]: Loss = 0.6961519718170166
Iteration [14916]: Loss = 4.9648942947387695
Iteration [14917]: Loss = 0.6967390775680542
Iteration [14918]: Loss = 0.6970340609550476
Iteration [14919]: Loss = 9.223130226135254
Iteration [14920]: Loss = 0.6978210806846619
Iteration [14921]: Loss = 0.6982879042625427
Iteration [14922]: Loss = 0.6986788511276245
Iteration [14923]: Loss = 4.951108455657959
Iteration [14924]: Loss = 0.6994465589523315
Iteration [14925]: Loss = 0.6998180150985718
Iteration [14926]: Loss = 0.7001228928565979
Iteration [14927]: Loss = 0.7003675699234009
Iteration [14928]: Loss = 0.7005581855773926
Iteration [14929]: Loss = 0.7006999254226685
Iteration [14930]: Loss = 4.941714763641357
Iteration [14931]: Loss = 0.7010412812232971
Iteration [14932]: Loss = 0.7012307643890381
Iteration [14933]: Loss = 0.7013715505599976
Iteration [14934]: Loss = 0.7014683485031128
Iteration [14935]: Loss = 0.7015256285667419
Iteration [14936]: Loss = 0.7015472650527954
Iteration [14937]: Loss = 0.7015368342399597
Iteration [14938]: Loss = 4.9380669593811035
Iteration [14939]: Loss = 0.701617956161499
Iteration [14940]: Loss = 0.7016964554786682
Iteration [14941]: Loss = 0.701737105846405
Iteration [14942]: Loss = 0.7017438411712646
Iteration [14943]: Loss = 0.7017199397087097
Iteration [14944]: Loss = 4.93717622756958
Iteration [14945]: Loss = 0.701777994632721
Iteration [14946]: Loss = 0.7018467783927917
Iteration [14947]: Loss = 0.7018787860870361
Iteration [14948]: Loss = 0.7018774747848511
Iteration [14949]: Loss = 0.7018463015556335
Iteration [14950]: Loss = 0.7017883062362671
Iteration [14951]: Loss = 0.7017059922218323
Iteration [14952]: Loss = 0.7016018629074097
Iteration [14953]: Loss = 0.7014781832695007
Iteration [14954]: Loss = 0.701336681842804
Iteration [14955]: Loss = 0.7011793851852417
Iteration [14956]: Loss = 0.7010076642036438
Iteration [14957]: Loss = 0.7008230090141296
Iteration [14958]: Loss = 0.7006267309188843
Iteration [14959]: Loss = 0.700420081615448
Iteration [14960]: Loss = 0.7002040147781372
Iteration [14961]: Loss = 0.6999794840812683
Iteration [14962]: Loss = 0.6997473835945129
Iteration [14963]: Loss = 0.6995083689689636
Iteration [14964]: Loss = 0.6992631554603577
Iteration [14965]: Loss = 0.6990125179290771
Iteration [14966]: Loss = 4.952389717102051
Iteration [14967]: Loss = 4.952771186828613
Iteration [14968]: Loss = 4.9522905349731445
Iteration [14969]: Loss = 0.6990145444869995
Iteration [14970]: Loss = 0.6991997361183167
Iteration [14971]: Loss = 0.699336588382721
Iteration [14972]: Loss = 4.948863506317139
Iteration [14973]: Loss = 0.6996701955795288
Iteration [14974]: Loss = 0.6998568177223206
Iteration [14975]: Loss = 0.699994683265686
Iteration [14976]: Loss = 0.700089156627655
Iteration [14977]: Loss = 0.7001440525054932
Iteration [14978]: Loss = 0.7001635432243347
Iteration [14979]: Loss = 4.945091247558594
Iteration [14980]: Loss = 4.944332122802734
Iteration [14981]: Loss = 0.7005835175514221
Iteration [14982]: Loss = 0.7008119821548462
Iteration [14983]: Loss = 0.7009878158569336
Iteration [14984]: Loss = 0.701116144657135
Iteration [14985]: Loss = 0.7012017369270325
Iteration [14986]: Loss = 0.7012487053871155
Iteration [14987]: Loss = 0.7012608647346497
Iteration [14988]: Loss = 0.7012418508529663
Iteration [14989]: Loss = 0.7011946439743042
Iteration [14990]: Loss = 0.7011219263076782
Iteration [14991]: Loss = 0.7010263800621033
Iteration [14992]: Loss = 0.7009103298187256
Iteration [14993]: Loss = 0.700775682926178
Iteration [14994]: Loss = 0.7006243467330933
Iteration [14995]: Loss = 0.7004579901695251
Iteration [14996]: Loss = 0.7002782821655273
Iteration [14997]: Loss = 0.7000861763954163
Iteration [14998]: Loss = 0.6998833417892456
Iteration [14999]: Loss = 0.6996703147888184
Iteration [15000]: Loss = 0.6994487047195435
Iteration [15001]: Loss = 0.6992190480232239
Iteration [15002]: Loss = 0.6989821791648865
Iteration [15003]: Loss = 0.6987388730049133
Iteration [15004]: Loss = 0.6984897255897522
Iteration [15005]: Loss = 0.6982354521751404
Iteration [15006]: Loss = 0.6979764103889465
Iteration [15007]: Loss = 0.6977131962776184
Iteration [15008]: Loss = 4.9592719078063965
Iteration [15009]: Loss = 0.6973641514778137
Iteration [15010]: Loss = 0.6972603797912598
Iteration [15011]: Loss = 0.6971367001533508
Iteration [15012]: Loss = 0.6969954967498779
Iteration [15013]: Loss = 0.69683837890625
Iteration [15014]: Loss = 0.6966668367385864
Iteration [15015]: Loss = 0.6964823603630066
Iteration [15016]: Loss = 4.9653801918029785
Iteration [15017]: Loss = 0.6962682008743286
Iteration [15018]: Loss = 4.965719223022461
Iteration [15019]: Loss = 0.6963383555412292
Iteration [15020]: Loss = 0.6964130997657776
Iteration [15021]: Loss = 4.964513778686523
Iteration [15022]: Loss = 0.6966419219970703
Iteration [15023]: Loss = 0.6967843174934387
Iteration [15024]: Loss = 0.6968825459480286
Iteration [15025]: Loss = 0.6969409584999084
Iteration [15026]: Loss = 4.961811542510986
Iteration [15027]: Loss = 4.960874080657959
Iteration [15028]: Loss = 0.6974592208862305
Iteration [15029]: Loss = 0.6977152228355408
Iteration [15030]: Loss = 0.69791579246521
Iteration [15031]: Loss = 0.6980665326118469
Iteration [15032]: Loss = 0.6981720328330994
Iteration [15033]: Loss = 0.6982371211051941
Iteration [15034]: Loss = 0.6982656121253967
Iteration [15035]: Loss = 0.6982612013816833
Iteration [15036]: Loss = 0.6982271671295166
Iteration [15037]: Loss = 0.6981663703918457
Iteration [15038]: Loss = 0.6980814933776855
Iteration [15039]: Loss = 0.6979750990867615
Iteration [15040]: Loss = 0.6978490948677063
Iteration [15041]: Loss = 0.6977055072784424
Iteration [15042]: Loss = 0.697546124458313
Iteration [15043]: Loss = 0.697372555732727
Iteration [15044]: Loss = 0.6971861720085144
Iteration [15045]: Loss = 0.6969882249832153
Iteration [15046]: Loss = 0.6967799067497253
Iteration [15047]: Loss = 0.6965622901916504
Iteration [15048]: Loss = 4.965116500854492
Iteration [15049]: Loss = 0.6962917447090149
Iteration [15050]: Loss = 0.6962215304374695
Iteration [15051]: Loss = 0.6961283683776855
Iteration [15052]: Loss = 0.6960143446922302
Iteration [15053]: Loss = 0.6958815455436707
Iteration [15054]: Loss = 0.6957319974899292
Iteration [15055]: Loss = 0.6955671906471252
Iteration [15056]: Loss = 0.695388674736023
Iteration [15057]: Loss = 0.6951979994773865
Iteration [15058]: Loss = 4.972193241119385
Iteration [15059]: Loss = 4.972311973571777
Iteration [15060]: Loss = 0.6951123476028442
Iteration [15061]: Loss = 4.971078872680664
Iteration [15062]: Loss = 0.6954505443572998
Iteration [15063]: Loss = 0.6956398487091064
Iteration [15064]: Loss = 0.6957802772521973
Iteration [15065]: Loss = 0.6958767175674438
Iteration [15066]: Loss = 0.6959335803985596
Iteration [15067]: Loss = 0.6959546804428101
Iteration [15068]: Loss = 0.6959435939788818
Iteration [15069]: Loss = 0.6959034204483032
Iteration [15070]: Loss = 0.6958371996879578
Iteration [15071]: Loss = 0.6957475543022156
Iteration [15072]: Loss = 0.6956366896629333
Iteration [15073]: Loss = 0.6955066323280334
Iteration [15074]: Loss = 0.6953595280647278
Iteration [15075]: Loss = 0.6951970458030701
Iteration [15076]: Loss = 0.6950204968452454
Iteration [15077]: Loss = 4.97306489944458
Iteration [15078]: Loss = 0.6948208212852478
Iteration [15079]: Loss = 0.6947811841964722
Iteration [15080]: Loss = 0.6947154402732849
Iteration [15081]: Loss = 0.694625973701477
Iteration [15082]: Loss = 0.694515585899353
Iteration [15083]: Loss = 0.6943859457969666
Iteration [15084]: Loss = 0.6942390203475952
Iteration [15085]: Loss = 9.26004695892334
Iteration [15086]: Loss = 0.6930787563323975
Iteration [15087]: Loss = 4.981557846069336
Iteration [15088]: Loss = 0.6935229897499084
Iteration [15089]: Loss = 0.6937574744224548
Iteration [15090]: Loss = 4.97869348526001
Iteration [15091]: Loss = 0.6936509609222412
Iteration [15092]: Loss = 4.978862285614014
Iteration [15093]: Loss = 0.6944717764854431
Iteration [15094]: Loss = 0.6950216889381409
Iteration [15095]: Loss = 0.695302426815033
Iteration [15096]: Loss = 0.6955049633979797
Iteration [15097]: Loss = 0.6956576704978943
Iteration [15098]: Loss = 0.6957650780677795
Iteration [15099]: Loss = 0.6958321332931519
Iteration [15100]: Loss = 0.6958627700805664
Iteration [15101]: Loss = 0.6958601474761963
Iteration [15102]: Loss = 0.6958280801773071
Iteration [15103]: Loss = 0.695769190788269
Iteration [15104]: Loss = 0.6956863403320312
Iteration [15105]: Loss = 4.9690985679626465
Iteration [15106]: Loss = 4.976561069488525
Iteration [15107]: Loss = 0.69438636302948
Iteration [15108]: Loss = 0.6945502161979675
Iteration [15109]: Loss = 0.6946679949760437
Iteration [15110]: Loss = 0.6947442889213562
Iteration [15111]: Loss = 4.973320960998535
Iteration [15112]: Loss = 0.6949756145477295
Iteration [15113]: Loss = 0.6951192021369934
Iteration [15114]: Loss = 0.6952186822891235
Iteration [15115]: Loss = 0.6952782869338989
Iteration [15116]: Loss = 0.6953022480010986
Iteration [15117]: Loss = 0.6952938437461853
Iteration [15118]: Loss = 0.6952564120292664
Iteration [15119]: Loss = 0.6951928734779358
Iteration [15120]: Loss = 0.6951056718826294
Iteration [15121]: Loss = 0.6949973702430725
Iteration [15122]: Loss = 0.6948699355125427
Iteration [15123]: Loss = 0.6947252154350281
Iteration [15124]: Loss = 9.254386901855469
Iteration [15125]: Loss = 0.694765567779541
Iteration [15126]: Loss = 0.6949164867401123
Iteration [15127]: Loss = 0.6950227618217468
Iteration [15128]: Loss = 0.6950888633728027
Iteration [15129]: Loss = 4.971546649932861
Iteration [15130]: Loss = 0.6953020691871643
Iteration [15131]: Loss = 0.6954377889633179
Iteration [15132]: Loss = 0.6955300569534302
Iteration [15133]: Loss = 0.695583701133728
Iteration [15134]: Loss = 0.6949681043624878
Iteration [15135]: Loss = 4.972411632537842
Iteration [15136]: Loss = 0.6951000690460205
Iteration [15137]: Loss = 0.69520103931427
Iteration [15138]: Loss = 0.6952623128890991
Iteration [15139]: Loss = 0.6952877044677734
Iteration [15140]: Loss = 0.6952807903289795
Iteration [15141]: Loss = 0.6952449679374695
Iteration [15142]: Loss = 0.6951828598976135
Iteration [15143]: Loss = 0.6950970888137817
Iteration [15144]: Loss = 4.972225666046143
Iteration [15145]: Loss = 4.971902370452881
Iteration [15146]: Loss = 0.6952632665634155
Iteration [15147]: Loss = 0.6954243183135986
Iteration [15148]: Loss = 0.6955397129058838
Iteration [15149]: Loss = 4.968928813934326
Iteration [15150]: Loss = 0.6958373188972473
Iteration [15151]: Loss = 0.6960088610649109
Iteration [15152]: Loss = 0.6961336731910706
Iteration [15153]: Loss = 0.6962162852287292
Iteration [15154]: Loss = 4.965514659881592
Iteration [15155]: Loss = 0.6964576244354248
Iteration [15156]: Loss = 0.6966052055358887
Iteration [15157]: Loss = 0.6967083215713501
Iteration [15158]: Loss = 0.6967712640762329
Iteration [15159]: Loss = 0.6967982053756714
Iteration [15160]: Loss = 0.6967925429344177
Iteration [15161]: Loss = 0.6967577338218689
Iteration [15162]: Loss = 0.696696400642395
Iteration [15163]: Loss = 0.6966113448143005
Iteration [15164]: Loss = 0.6965048313140869
Iteration [15165]: Loss = 0.6963793039321899
Iteration [15166]: Loss = 0.696236252784729
Iteration [15167]: Loss = 0.6960775852203369
Iteration [15168]: Loss = 0.6959047317504883
Iteration [15169]: Loss = 0.6957194209098816
Iteration [15170]: Loss = 0.6955226063728333
Iteration [15171]: Loss = 0.6953156590461731
Iteration [15172]: Loss = 0.6950994729995728
Iteration [15173]: Loss = 0.6948749423027039
Iteration [15174]: Loss = 0.6946430206298828
Iteration [15175]: Loss = 0.6944043040275574
Iteration [15176]: Loss = 4.97662353515625
Iteration [15177]: Loss = 0.6940977573394775
Iteration [15178]: Loss = 0.6940122842788696
Iteration [15179]: Loss = 0.6939054131507874
Iteration [15180]: Loss = 0.6937794089317322
Iteration [15181]: Loss = 0.6936362981796265
Iteration [15182]: Loss = 0.6934774518013
Iteration [15183]: Loss = 0.6933046579360962
Iteration [15184]: Loss = 0.6931192874908447
Iteration [15185]: Loss = 0.6929226517677307
Iteration [15186]: Loss = 0.6927157044410706
Iteration [15187]: Loss = 4.985438346862793
Iteration [15188]: Loss = 0.6924639940261841
Iteration [15189]: Loss = 0.6924020051956177
Iteration [15190]: Loss = 0.6923165321350098
Iteration [15191]: Loss = 0.6922096014022827
Iteration [15192]: Loss = 0.6920836567878723
Iteration [15193]: Loss = 0.6919405460357666
Iteration [15194]: Loss = 0.6917818188667297
Iteration [15195]: Loss = 0.6916091442108154
Iteration [15196]: Loss = 0.6914238333702087
Iteration [15197]: Loss = 0.6912272572517395
Iteration [15198]: Loss = 0.6910206079483032
Iteration [15199]: Loss = 0.6908046007156372
Iteration [15200]: Loss = 0.6905804872512817
Iteration [15201]: Loss = 4.996910572052002
Iteration [15202]: Loss = 0.6902998089790344
Iteration [15203]: Loss = 0.6902259588241577
Iteration [15204]: Loss = 0.6901296377182007
Iteration [15205]: Loss = 4.9987053871154785
Iteration [15206]: Loss = 0.6900677680969238
Iteration [15207]: Loss = 4.998311996459961
Iteration [15208]: Loss = 0.6902629137039185
Iteration [15209]: Loss = 0.6903917789459229
Iteration [15210]: Loss = 4.996219635009766
Iteration [15211]: Loss = 0.6907142400741577
Iteration [15212]: Loss = 4.993980407714844
Iteration [15213]: Loss = 4.992255687713623
Iteration [15214]: Loss = 0.6916683316230774
Iteration [15215]: Loss = 0.6920425295829773
Iteration [15216]: Loss = 0.6923497915267944
Iteration [15217]: Loss = 9.277244567871094
Iteration [15218]: Loss = 0.6931599378585815
Iteration [15219]: Loss = 0.6936376094818115
Iteration [15220]: Loss = 4.97726583480835
Iteration [15221]: Loss = 0.6945553421974182
Iteration [15222]: Loss = 0.6949912905693054
Iteration [15223]: Loss = 0.6953545212745667
Iteration [15224]: Loss = 0.6956519484519958
Iteration [15225]: Loss = 4.967469692230225
Iteration [15226]: Loss = 4.965514183044434
Iteration [15227]: Loss = 0.6967502236366272
Iteration [15228]: Loss = 0.6971613764762878
Iteration [15229]: Loss = 0.697502076625824
Iteration [15230]: Loss = 0.6977791786193848
Iteration [15231]: Loss = 0.6979990601539612
Iteration [15232]: Loss = 0.6981671452522278
Iteration [15233]: Loss = 0.6982886791229248
Iteration [15234]: Loss = 0.6983684301376343
Iteration [15235]: Loss = 0.6984102725982666
Iteration [15236]: Loss = 0.6984180808067322
Iteration [15237]: Loss = 0.698395311832428
Iteration [15238]: Loss = 0.6983447074890137
Iteration [15239]: Loss = 0.6982693672180176
Iteration [15240]: Loss = 0.6981715559959412
Iteration [15241]: Loss = 0.6980537176132202
Iteration [15242]: Loss = 0.697917640209198
Iteration [15243]: Loss = 0.6977651715278625
Iteration [15244]: Loss = 0.6975979804992676
Iteration [15245]: Loss = 0.697417676448822
Iteration [15246]: Loss = 0.6972251534461975
Iteration [15247]: Loss = 0.6970221996307373
Iteration [15248]: Loss = 0.6968095302581787
Iteration [15249]: Loss = 0.6965880990028381
Iteration [15250]: Loss = 0.6963587999343872
Iteration [15251]: Loss = 4.966242790222168
Iteration [15252]: Loss = 0.6960678696632385
Iteration [15253]: Loss = 0.6959887742996216
Iteration [15254]: Loss = 0.6958876252174377
Iteration [15255]: Loss = 0.6957666873931885
Iteration [15256]: Loss = 0.6956280469894409
Iteration [15257]: Loss = 0.6954732537269592
Iteration [15258]: Loss = 0.6953040361404419
Iteration [15259]: Loss = 0.6951218247413635
Iteration [15260]: Loss = 0.694927990436554
Iteration [15261]: Loss = 0.6947234869003296
Iteration [15262]: Loss = 4.974769592285156
Iteration [15263]: Loss = 0.6944753527641296
Iteration [15264]: Loss = 0.6944145560264587
Iteration [15265]: Loss = 0.6943302154541016
Iteration [15266]: Loss = 0.6942243576049805
Iteration [15267]: Loss = 0.6940991878509521
Iteration [15268]: Loss = 0.6939565539360046
Iteration [15269]: Loss = 0.6937985420227051
Iteration [15270]: Loss = 0.6936261653900146
Iteration [15271]: Loss = 0.6934413313865662
Iteration [15272]: Loss = 0.6932449340820312
Iteration [15273]: Loss = 0.6930383443832397
Iteration [15274]: Loss = 0.6928225755691528
Iteration [15275]: Loss = 0.6925983428955078
Iteration [15276]: Loss = 4.98614501953125
Iteration [15277]: Loss = 4.986408233642578
Iteration [15278]: Loss = 0.6924311518669128
Iteration [15279]: Loss = 0.692503809928894
Iteration [15280]: Loss = 0.6925395131111145
Iteration [15281]: Loss = 0.6925418972969055
Iteration [15282]: Loss = 0.6925143003463745
Iteration [15283]: Loss = 0.6924595832824707
Iteration [15284]: Loss = 0.692380428314209
Iteration [15285]: Loss = 0.6922795176506042
Iteration [15286]: Loss = 4.987252712249756
Iteration [15287]: Loss = 0.6922086477279663
Iteration [15288]: Loss = 0.692223846912384
Iteration [15289]: Loss = 0.692207932472229
Iteration [15290]: Loss = 0.6921637058258057
Iteration [15291]: Loss = 0.6920939683914185
Iteration [15292]: Loss = 0.6920014023780823
Iteration [15293]: Loss = 4.988692283630371
Iteration [15294]: Loss = 0.6919451951980591
Iteration [15295]: Loss = 0.691966712474823
Iteration [15296]: Loss = 0.6919562816619873
Iteration [15297]: Loss = 0.6919170618057251
Iteration [15298]: Loss = 0.6918519735336304
Iteration [15299]: Loss = 0.6917636394500732
Iteration [15300]: Loss = 0.6916540861129761
Iteration [15301]: Loss = 0.6915255784988403
Iteration [15302]: Loss = 0.6913802027702332
Iteration [15303]: Loss = 0.6912194490432739
Iteration [15304]: Loss = 0.6910447478294373
Iteration [15305]: Loss = 0.6908577680587769
Iteration [15306]: Loss = 0.6906595230102539
Iteration [15307]: Loss = 0.6904513835906982
Iteration [15308]: Loss = 0.6902339458465576
Iteration [15309]: Loss = 0.6900084614753723
Iteration [15310]: Loss = 0.6897756457328796
Iteration [15311]: Loss = 9.31298542022705
Iteration [15312]: Loss = 0.6896690130233765
Iteration [15313]: Loss = 0.6897588968276978
Iteration [15314]: Loss = 0.6898102760314941
Iteration [15315]: Loss = 0.689827024936676
Iteration [15316]: Loss = 0.6898124814033508
Iteration [15317]: Loss = 0.6897698044776917
Iteration [15318]: Loss = 0.6897017359733582
Iteration [15319]: Loss = 0.6896108388900757
Iteration [15320]: Loss = 0.6894994378089905
Iteration [15321]: Loss = 0.6893694996833801
Iteration [15322]: Loss = 0.6892227530479431
Iteration [15323]: Loss = 0.6890610456466675
Iteration [15324]: Loss = 0.6888860464096069
Iteration [15325]: Loss = 0.6886986494064331
Iteration [15326]: Loss = 0.6885004639625549
Iteration [15327]: Loss = 0.6882923245429993
Iteration [15328]: Loss = 0.6880754232406616
Iteration [15329]: Loss = 0.6878504753112793
Iteration [15330]: Loss = 5.011559009552002
Iteration [15331]: Loss = 0.6875690221786499
Iteration [15332]: Loss = 0.6874949932098389
Iteration [15333]: Loss = 5.0127410888671875
Iteration [15334]: Loss = 5.012350082397461
Iteration [15335]: Loss = 0.6876953840255737
Iteration [15336]: Loss = 0.6878674030303955
Iteration [15337]: Loss = 0.6879928708076477
Iteration [15338]: Loss = 0.6880764961242676
Iteration [15339]: Loss = 0.688122034072876
Iteration [15340]: Loss = 0.6881335377693176
Iteration [15341]: Loss = 5.00889253616333
Iteration [15342]: Loss = 0.6882556676864624
Iteration [15343]: Loss = 0.6883535385131836
Iteration [15344]: Loss = 5.007291316986084
Iteration [15345]: Loss = 0.688623309135437
Iteration [15346]: Loss = 5.005294322967529
Iteration [15347]: Loss = 5.003668308258057
Iteration [15348]: Loss = 5.00136137008667
Iteration [15349]: Loss = 0.6900621056556702
Iteration [15350]: Loss = 0.6905235052108765
Iteration [15351]: Loss = 4.9939141273498535
Iteration [15352]: Loss = 0.6914141178131104
Iteration [15353]: Loss = 0.6918391585350037
Iteration [15354]: Loss = 0.6921924948692322
Iteration [15355]: Loss = 0.6924809813499451
Iteration [15356]: Loss = 0.6927111744880676
Iteration [15357]: Loss = 4.98336935043335
Iteration [15358]: Loss = 0.6932059526443481
Iteration [15359]: Loss = 0.6934621334075928
Iteration [15360]: Loss = 0.6936630010604858
Iteration [15361]: Loss = 0.6938142776489258
Iteration [15362]: Loss = 0.6939205527305603
Iteration [15363]: Loss = 0.6939865350723267
Iteration [15364]: Loss = 0.6940160989761353
Iteration [15365]: Loss = 0.6940128803253174
Iteration [15366]: Loss = 0.6939800977706909
Iteration [15367]: Loss = 0.6939207911491394
Iteration [15368]: Loss = 0.6938375234603882
Iteration [15369]: Loss = 0.6937326788902283
Iteration [15370]: Loss = 0.6936085224151611
Iteration [15371]: Loss = 4.9802985191345215
Iteration [15372]: Loss = 0.6934977173805237
Iteration [15373]: Loss = 0.6934958100318909
Iteration [15374]: Loss = 0.6934641599655151
Iteration [15375]: Loss = 0.6934059262275696
Iteration [15376]: Loss = 0.6933234930038452
Iteration [15377]: Loss = 0.6932194232940674
Iteration [15378]: Loss = 0.6930959224700928
Iteration [15379]: Loss = 0.6929548382759094
Iteration [15380]: Loss = 4.983851432800293
Iteration [15381]: Loss = 0.6928157210350037
Iteration [15382]: Loss = 0.6928016543388367
Iteration [15383]: Loss = 0.6927592754364014
Iteration [15384]: Loss = 0.6926911473274231
Iteration [15385]: Loss = 0.6926001310348511
Iteration [15386]: Loss = 0.6924881339073181
Iteration [15387]: Loss = 0.6923574805259705
Iteration [15388]: Loss = 0.6922100782394409
Iteration [15389]: Loss = 0.6920474767684937
Iteration [15390]: Loss = 0.691871166229248
Iteration [15391]: Loss = 0.6916825771331787
Iteration [15392]: Loss = 0.6914829015731812
Iteration [15393]: Loss = 0.6912733316421509
Iteration [15394]: Loss = 0.6910548806190491
Iteration [15395]: Loss = 0.6908283233642578
Iteration [15396]: Loss = 0.690594494342804
Iteration [15397]: Loss = 0.6903541088104248
Iteration [15398]: Loss = 0.6901079416275024
Iteration [15399]: Loss = 4.999545574188232
Iteration [15400]: Loss = 0.6897900700569153
Iteration [15401]: Loss = 0.6897004246711731
Iteration [15402]: Loss = 0.6895899772644043
Iteration [15403]: Loss = 0.6894607543945312
Iteration [15404]: Loss = 5.002448558807373
Iteration [15405]: Loss = 0.6893429160118103
Iteration [15406]: Loss = 0.6893383860588074
Iteration [15407]: Loss = 5.002501010894775
Iteration [15408]: Loss = 0.6894338726997375
Iteration [15409]: Loss = 5.001345634460449
Iteration [15410]: Loss = 0.6897571682929993
Iteration [15411]: Loss = 4.999093532562256
Iteration [15412]: Loss = 0.6902647018432617
Iteration [15413]: Loss = 0.6905268430709839
Iteration [15414]: Loss = 0.6907328963279724
Iteration [15415]: Loss = 4.994024276733398
Iteration [15416]: Loss = 0.6911879181861877
Iteration [15417]: Loss = 0.6914274096488953
Iteration [15418]: Loss = 0.6916134357452393
Iteration [15419]: Loss = 0.6917508244514465
Iteration [15420]: Loss = 0.6918449401855469
Iteration [15421]: Loss = 0.6918997168540955
Iteration [15422]: Loss = 4.988528251647949
Iteration [15423]: Loss = 0.6920957565307617
Iteration [15424]: Loss = 0.6922246813774109
Iteration [15425]: Loss = 0.69231116771698
Iteration [15426]: Loss = 0.6923589110374451
Iteration [15427]: Loss = 0.6923720240592957
Iteration [15428]: Loss = 0.6923539638519287
Iteration [15429]: Loss = 0.6923078298568726
Iteration [15430]: Loss = 9.281444549560547
Iteration [15431]: Loss = 4.985342025756836
Iteration [15432]: Loss = 0.69292813539505
Iteration [15433]: Loss = 0.6932682991027832
Iteration [15434]: Loss = 0.6935448050498962
Iteration [15435]: Loss = 0.6937643885612488
Iteration [15436]: Loss = 0.6939322352409363
Iteration [15437]: Loss = 0.6940537095069885
Iteration [15438]: Loss = 4.976762771606445
Iteration [15439]: Loss = 0.6943622827529907
Iteration [15440]: Loss = 0.694538950920105
Iteration [15441]: Loss = 0.6946681141853333
Iteration [15442]: Loss = 0.6947548389434814
Iteration [15443]: Loss = 0.6948028206825256
Iteration [15444]: Loss = 0.6948162913322449
Iteration [15445]: Loss = 0.6947986483573914
Iteration [15446]: Loss = 0.6947529315948486
Iteration [15447]: Loss = 0.6946817636489868
Iteration [15448]: Loss = 4.9743547439575195
Iteration [15449]: Loss = 4.973965644836426
Iteration [15450]: Loss = 0.6948850750923157
Iteration [15451]: Loss = 0.6950567364692688
Iteration [15452]: Loss = 0.6951815485954285
Iteration [15453]: Loss = 0.6952640414237976
Iteration [15454]: Loss = 0.6953085064888
Iteration [15455]: Loss = 0.6953185796737671
Iteration [15456]: Loss = 4.970599174499512
Iteration [15457]: Loss = 0.6954368352890015
Iteration [15458]: Loss = 4.969360828399658
Iteration [15459]: Loss = 0.6957755088806152
Iteration [15460]: Loss = 0.6959646940231323
Iteration [15461]: Loss = 0.6961051821708679
Iteration [15462]: Loss = 0.6962018609046936
Iteration [15463]: Loss = 4.965524196624756
Iteration [15464]: Loss = 0.6964678764343262
Iteration [15465]: Loss = 4.963589191436768
Iteration [15466]: Loss = 0.6969256401062012
Iteration [15467]: Loss = 9.224332809448242
Iteration [15468]: Loss = 0.6977205872535706
Iteration [15469]: Loss = 0.6981911063194275
Iteration [15470]: Loss = 0.6985852718353271
Iteration [15471]: Loss = 0.6989105939865112
Iteration [15472]: Loss = 0.6991738080978394
Iteration [15473]: Loss = 4.9491190910339355
Iteration [15474]: Loss = 0.6997232437133789
Iteration [15475]: Loss = 0.7000015377998352
Iteration [15476]: Loss = 4.944718837738037
Iteration [15477]: Loss = 0.7005767822265625
Iteration [15478]: Loss = 0.7008658647537231
Iteration [15479]: Loss = 0.7010967135429382
Iteration [15480]: Loss = 0.7012744545936584
Iteration [15481]: Loss = 0.7014045715332031
Iteration [15482]: Loss = 0.7014920115470886
Iteration [15483]: Loss = 0.7015405297279358
Iteration [15484]: Loss = 4.937770843505859
Iteration [15485]: Loss = 0.7017225623130798
Iteration [15486]: Loss = 4.936259746551514
Iteration [15487]: Loss = 0.7021093368530273
Iteration [15488]: Loss = 0.7023181319236755
Iteration [15489]: Loss = 0.7024762630462646
Iteration [15490]: Loss = 0.7025884985923767
Iteration [15491]: Loss = 0.7026596665382385
Iteration [15492]: Loss = 0.7026937007904053
Iteration [15493]: Loss = 0.7026941776275635
Iteration [15494]: Loss = 0.7026646733283997
Iteration [15495]: Loss = 0.7026079297065735
Iteration [15496]: Loss = 4.932711124420166
Iteration [15497]: Loss = 0.7026100754737854
Iteration [15498]: Loss = 0.7026548385620117
Iteration [15499]: Loss = 0.7026652097702026
Iteration [15500]: Loss = 0.7026443481445312
Iteration [15501]: Loss = 0.7025956511497498
Iteration [15502]: Loss = 0.7025216221809387
Iteration [15503]: Loss = 0.7024247646331787
Iteration [15504]: Loss = 0.7023075819015503
Iteration [15505]: Loss = 0.7021719813346863
Iteration [15506]: Loss = 0.7020196914672852
Iteration [15507]: Loss = 0.701852560043335
Iteration [15508]: Loss = 0.7016719579696655
Iteration [15509]: Loss = 0.7014792561531067
Iteration [15510]: Loss = 0.701275646686554
Iteration [15511]: Loss = 0.7010623216629028
Iteration [15512]: Loss = 0.700840175151825
Iteration [15513]: Loss = 0.7006100416183472
Iteration [15514]: Loss = 0.7003728747367859
Iteration [15515]: Loss = 0.7001291513442993
Iteration [15516]: Loss = 0.6998797059059143
Iteration [15517]: Loss = 0.6996251940727234
Iteration [15518]: Loss = 0.6993658542633057
Iteration [15519]: Loss = 0.6991024613380432
Iteration [15520]: Loss = 0.6988351941108704
Iteration [15521]: Loss = 0.6985646486282349
Iteration [15522]: Loss = 0.6982910633087158
Iteration [15523]: Loss = 0.6980146169662476
Iteration [15524]: Loss = 0.6977357864379883
Iteration [15525]: Loss = 0.6974547505378723
Iteration [15526]: Loss = 0.6971719264984131
Iteration [15527]: Loss = 4.962214469909668
Iteration [15528]: Loss = 0.6967891454696655
Iteration [15529]: Loss = 0.6966710090637207
Iteration [15530]: Loss = 0.6965347528457642
Iteration [15531]: Loss = 0.6963819265365601
Iteration [15532]: Loss = 0.696214497089386
Iteration [15533]: Loss = 0.6960337162017822
Iteration [15534]: Loss = 4.967729091644287
Iteration [15535]: Loss = 0.6958260536193848
Iteration [15536]: Loss = 0.6957824230194092
Iteration [15537]: Loss = 4.968404293060303
Iteration [15538]: Loss = 0.6958089470863342
Iteration [15539]: Loss = 0.695865273475647
Iteration [15540]: Loss = 0.695885956287384
Iteration [15541]: Loss = 0.6958746910095215
Iteration [15542]: Loss = 0.6958345770835876
Iteration [15543]: Loss = 0.6957685947418213
Iteration [15544]: Loss = 0.6956791877746582
Iteration [15545]: Loss = 0.6955686211585999
Iteration [15546]: Loss = 0.6954392194747925
Iteration [15547]: Loss = 0.6952926516532898
Iteration [15548]: Loss = 0.6951307654380798
Iteration [15549]: Loss = 4.972411155700684
Iteration [15550]: Loss = 0.6949555277824402
Iteration [15551]: Loss = 0.6949259638786316
Iteration [15552]: Loss = 0.6948694586753845
Iteration [15553]: Loss = 0.6947886347770691
Iteration [15554]: Loss = 0.6946858167648315
Iteration [15555]: Loss = 0.6945633888244629
Iteration [15556]: Loss = 4.975227355957031
Iteration [15557]: Loss = 0.694455623626709
Iteration [15558]: Loss = 0.6944549083709717
Iteration [15559]: Loss = 0.6944243907928467
Iteration [15560]: Loss = 0.6943668127059937
Iteration [15561]: Loss = 0.6942852139472961
Iteration [15562]: Loss = 0.6941816210746765
Iteration [15563]: Loss = 4.97715950012207
Iteration [15564]: Loss = 0.6941064596176147
Iteration [15565]: Loss = 0.6941196918487549
Iteration [15566]: Loss = 0.6941015720367432
Iteration [15567]: Loss = 0.6940553784370422
Iteration [15568]: Loss = 0.6939839124679565
Iteration [15569]: Loss = 0.6938895583152771
Iteration [15570]: Loss = 0.6937745213508606
Iteration [15571]: Loss = 0.6936410665512085
Iteration [15572]: Loss = 0.6934910416603088
Iteration [15573]: Loss = 0.6933258771896362
Iteration [15574]: Loss = 0.6931473016738892
Iteration [15575]: Loss = 0.6929565072059631
Iteration [15576]: Loss = 0.6927547454833984
Iteration [15577]: Loss = 0.6925432085990906
Iteration [15578]: Loss = 0.6923227906227112
Iteration [15579]: Loss = 0.6920944452285767
Iteration [15580]: Loss = 0.6918588876724243
Iteration [15581]: Loss = 0.691616952419281
Iteration [15582]: Loss = 0.6913690567016602
Iteration [15583]: Loss = 0.6911160945892334
Iteration [15584]: Loss = 4.994187355041504
Iteration [15585]: Loss = 4.994570732116699
Iteration [15586]: Loss = 0.6908813714981079
Iteration [15587]: Loss = 0.6909369826316833
Iteration [15588]: Loss = 0.6909571290016174
Iteration [15589]: Loss = 4.993722438812256
Iteration [15590]: Loss = 0.691094160079956
Iteration [15591]: Loss = 0.6911983489990234
Iteration [15592]: Loss = 0.6912621259689331
Iteration [15593]: Loss = 0.6912898421287537
Iteration [15594]: Loss = 0.691284716129303
Iteration [15595]: Loss = 0.6912502646446228
Iteration [15596]: Loss = 0.6911893486976624
Iteration [15597]: Loss = 0.6911044716835022
Iteration [15598]: Loss = 4.9934401512146
Iteration [15599]: Loss = 0.6910622715950012
Iteration [15600]: Loss = 0.6910901665687561
Iteration [15601]: Loss = 0.6910853385925293
Iteration [15602]: Loss = 0.6910509467124939
Iteration [15603]: Loss = 0.690990149974823
Iteration [15604]: Loss = 0.6909055113792419
Iteration [15605]: Loss = 0.6907991766929626
Iteration [15606]: Loss = 0.6906737089157104
Iteration [15607]: Loss = 4.995938301086426
Iteration [15608]: Loss = 0.6905620694160461
Iteration [15609]: Loss = 0.6905604004859924
Iteration [15610]: Loss = 0.6905289888381958
Iteration [15611]: Loss = 4.996258735656738
Iteration [15612]: Loss = 0.6905781030654907
Iteration [15613]: Loss = 0.6906449198722839
Iteration [15614]: Loss = 0.6906751394271851
Iteration [15615]: Loss = 0.6906725168228149
Iteration [15616]: Loss = 0.6906401515007019
Iteration [15617]: Loss = 4.995668888092041
Iteration [15618]: Loss = 0.6906877160072327
Iteration [15619]: Loss = 0.6907539963722229
Iteration [15620]: Loss = 0.6907835602760315
Iteration [15621]: Loss = 4.99460506439209
Iteration [15622]: Loss = 4.993767261505127
Iteration [15623]: Loss = 0.6912373304367065
Iteration [15624]: Loss = 0.69147789478302
Iteration [15625]: Loss = 0.6916646361351013
Iteration [15626]: Loss = 0.6918027997016907
Iteration [15627]: Loss = 0.6918973326683044
Iteration [15628]: Loss = 0.6919524669647217
Iteration [15629]: Loss = 0.6919721961021423
Iteration [15630]: Loss = 0.6919598579406738
Iteration [15631]: Loss = 0.6919187307357788
Iteration [15632]: Loss = 0.6918517351150513
Iteration [15633]: Loss = 0.6917613744735718
Iteration [15634]: Loss = 0.6916499733924866
Iteration [15635]: Loss = 0.6915196776390076
Iteration [15636]: Loss = 0.6913723349571228
Iteration [15637]: Loss = 0.6912097334861755
Iteration [15638]: Loss = 0.6910331845283508
Iteration [15639]: Loss = 0.6908441781997681
Iteration [15640]: Loss = 0.6906440854072571
Iteration [15641]: Loss = 0.6904338598251343
Iteration [15642]: Loss = 0.6902145743370056
Iteration [15643]: Loss = 0.6899872422218323
Iteration [15644]: Loss = 0.689752459526062
Iteration [15645]: Loss = 0.6895111799240112
Iteration [15646]: Loss = 5.002719879150391
Iteration [15647]: Loss = 5.003049373626709
Iteration [15648]: Loss = 0.6893075108528137
Iteration [15649]: Loss = 0.6893723607063293
Iteration [15650]: Loss = 0.6894006133079529
Iteration [15651]: Loss = 5.002009391784668
Iteration [15652]: Loss = 5.001171588897705
Iteration [15653]: Loss = 0.6898530721664429
Iteration [15654]: Loss = 0.6900936961174011
Iteration [15655]: Loss = 4.997274875640869
Iteration [15656]: Loss = 0.6906084418296814
Iteration [15657]: Loss = 0.6908737421035767
Iteration [15658]: Loss = 0.6910827159881592
Iteration [15659]: Loss = 9.293048858642578
Iteration [15660]: Loss = 0.6917282938957214
Iteration [15661]: Loss = 0.6921377182006836
Iteration [15662]: Loss = 0.692476749420166
Iteration [15663]: Loss = 4.984094619750977
Iteration [15664]: Loss = 0.6931580305099487
Iteration [15665]: Loss = 0.6934939026832581
Iteration [15666]: Loss = 0.6937665343284607
Iteration [15667]: Loss = 0.6939821243286133
Iteration [15668]: Loss = 0.6941463947296143
Iteration [15669]: Loss = 0.6942644119262695
Iteration [15670]: Loss = 0.6943409442901611
Iteration [15671]: Loss = 0.6943797469139099
Iteration [15672]: Loss = 4.975430488586426
Iteration [15673]: Loss = 0.6945476531982422
Iteration [15674]: Loss = 0.6946644186973572
Iteration [15675]: Loss = 0.6947396397590637
Iteration [15676]: Loss = 4.97335147857666
Iteration [15677]: Loss = 0.6949697732925415
Iteration [15678]: Loss = 0.695112943649292
Iteration [15679]: Loss = 0.6952121257781982
Iteration [15680]: Loss = 4.970739841461182
Iteration [15681]: Loss = 0.6954827308654785
Iteration [15682]: Loss = 0.6956430673599243
Iteration [15683]: Loss = 0.6957576274871826
Iteration [15684]: Loss = 0.6958307027816772
Iteration [15685]: Loss = 0.695866584777832
Iteration [15686]: Loss = 0.695868730545044
Iteration [15687]: Loss = 0.6958406567573547
Iteration [15688]: Loss = 0.6957851648330688
Iteration [15689]: Loss = 0.6957052946090698
Iteration [15690]: Loss = 0.6956031918525696
Iteration [15691]: Loss = 0.6954811811447144
Iteration [15692]: Loss = 0.6953413486480713
Iteration [15693]: Loss = 0.6951853632926941
Iteration [15694]: Loss = 0.6950146555900574
Iteration [15695]: Loss = 0.694831132888794
Iteration [15696]: Loss = 4.974101543426514
Iteration [15697]: Loss = 0.6946190595626831
Iteration [15698]: Loss = 0.6945741772651672
Iteration [15699]: Loss = 4.9748005867004395
Iteration [15700]: Loss = 0.6945991516113281
Iteration [15701]: Loss = 0.6946552395820618
Iteration [15702]: Loss = 0.6946756839752197
Iteration [15703]: Loss = 0.6946638226509094
Iteration [15704]: Loss = 0.6946232318878174
Iteration [15705]: Loss = 0.694556713104248
Iteration [15706]: Loss = 4.974997043609619
Iteration [15707]: Loss = 0.6945446729660034
Iteration [15708]: Loss = 4.97437047958374
Iteration [15709]: Loss = 0.6947799921035767
Iteration [15710]: Loss = 0.6949256062507629
Iteration [15711]: Loss = 0.6950267553329468
Iteration [15712]: Loss = 0.6950875520706177
Iteration [15713]: Loss = 0.6951124668121338
Iteration [15714]: Loss = 4.971620082855225
Iteration [15715]: Loss = 0.6952565312385559
Iteration [15716]: Loss = 0.6953632831573486
Iteration [15717]: Loss = 0.6954293251037598
Iteration [15718]: Loss = 4.969748497009277
Iteration [15719]: Loss = 0.6956437826156616
Iteration [15720]: Loss = 0.6957803964614868
Iteration [15721]: Loss = 0.6958733797073364
Iteration [15722]: Loss = 0.6959269642829895
Iteration [15723]: Loss = 0.695945143699646
Iteration [15724]: Loss = 0.6959312558174133
Iteration [15725]: Loss = 4.967478275299072
Iteration [15726]: Loss = 0.6960092782974243
Iteration [15727]: Loss = 0.6960877180099487
Iteration [15728]: Loss = 0.696128249168396
Iteration [15729]: Loss = 0.696134626865387
Iteration [15730]: Loss = 0.6961101293563843
Iteration [15731]: Loss = 0.6960579752922058
Iteration [15732]: Loss = 0.6959807276725769
Iteration [15733]: Loss = 0.6958810687065125
Iteration [15734]: Loss = 0.6957611441612244
Iteration [15735]: Loss = 0.695622980594635
Iteration [15736]: Loss = 0.6954683661460876
Iteration [15737]: Loss = 0.6952990889549255
Iteration [15738]: Loss = 0.6951163411140442
Iteration [15739]: Loss = 0.694921612739563
Iteration [15740]: Loss = 0.6947163939476013
Iteration [15741]: Loss = 0.6945011019706726
Iteration [15742]: Loss = 0.6942773461341858
Iteration [15743]: Loss = 0.6940456032752991
Iteration [15744]: Loss = 0.6938068866729736
Iteration [15745]: Loss = 0.6935617327690125
Iteration [15746]: Loss = 0.6933109760284424
Iteration [15747]: Loss = 0.6930550336837769
Iteration [15748]: Loss = 0.6927945017814636
Iteration [15749]: Loss = 0.6925297379493713
Iteration [15750]: Loss = 4.986706733703613
Iteration [15751]: Loss = 0.6921805143356323
Iteration [15752]: Loss = 4.987685203552246
Iteration [15753]: Loss = 0.6921451687812805
Iteration [15754]: Loss = 0.6921759843826294
Iteration [15755]: Loss = 4.987173080444336
Iteration [15756]: Loss = 4.986333847045898
Iteration [15757]: Loss = 0.692632794380188
Iteration [15758]: Loss = 4.983447074890137
Iteration [15759]: Loss = 0.6932505369186401
Iteration [15760]: Loss = 0.6935594081878662
Iteration [15761]: Loss = 0.6938077211380005
Iteration [15762]: Loss = 0.6940011978149414
Iteration [15763]: Loss = 0.6941452026367188
Iteration [15764]: Loss = 0.6942448616027832
Iteration [15765]: Loss = 0.6943045258522034
Iteration [15766]: Loss = 0.6943280696868896
Iteration [15767]: Loss = 0.6943188905715942
Iteration [15768]: Loss = 0.6942806839942932
Iteration [15769]: Loss = 0.6942160129547119
Iteration [15770]: Loss = 0.6941275596618652
Iteration [15771]: Loss = 0.6940176486968994
Iteration [15772]: Loss = 0.6938886046409607
Iteration [15773]: Loss = 4.978837013244629
Iteration [15774]: Loss = 0.6937705874443054
Iteration [15775]: Loss = 0.6937660574913025
Iteration [15776]: Loss = 0.6937317252159119
Iteration [15777]: Loss = 0.6936706304550171
Iteration [15778]: Loss = 0.6935855150222778
Iteration [15779]: Loss = 0.693478524684906
Iteration [15780]: Loss = 0.6933521032333374
Iteration [15781]: Loss = 0.6932080984115601
Iteration [15782]: Loss = 0.6930482387542725
Iteration [15783]: Loss = 0.6928740739822388
Iteration [15784]: Loss = 0.6926870346069336
Iteration [15785]: Loss = 4.985497951507568
Iteration [15786]: Loss = 0.6924705505371094
Iteration [15787]: Loss = 0.6924243569374084
Iteration [15788]: Loss = 0.6923525333404541
Iteration [15789]: Loss = 0.6922576427459717
Iteration [15790]: Loss = 0.6921420693397522
Iteration [15791]: Loss = 0.692007839679718
Iteration [15792]: Loss = 0.6918567419052124
Iteration [15793]: Loss = 0.6916905641555786
Iteration [15794]: Loss = 4.990706443786621
Iteration [15795]: Loss = 0.6915099024772644
Iteration [15796]: Loss = 0.6914790868759155
Iteration [15797]: Loss = 0.6914210915565491
Iteration [15798]: Loss = 0.6913387775421143
Iteration [15799]: Loss = 0.6912344098091125
Iteration [15800]: Loss = 4.992841720581055
Iteration [15801]: Loss = 0.691159725189209
Iteration [15802]: Loss = 0.6911739706993103
Iteration [15803]: Loss = 0.6911566257476807
Iteration [15804]: Loss = 0.6911109685897827
Iteration [15805]: Loss = 0.6910395622253418
Iteration [15806]: Loss = 0.6909453272819519
Iteration [15807]: Loss = 0.6908300518989563
Iteration [15808]: Loss = 0.6906961798667908
Iteration [15809]: Loss = 0.6905454993247986
Iteration [15810]: Loss = 0.6903796792030334
Iteration [15811]: Loss = 0.6902002096176147
Iteration [15812]: Loss = 0.6900084614753723
Iteration [15813]: Loss = 0.6898056864738464
Iteration [15814]: Loss = 0.6895927786827087
Iteration [15815]: Loss = 0.6893711686134338
Iteration [15816]: Loss = 5.0033769607543945
Iteration [15817]: Loss = 0.6890966892242432
Iteration [15818]: Loss = 0.6890261173248291
Iteration [15819]: Loss = 0.6889325380325317
Iteration [15820]: Loss = 0.688818097114563
Iteration [15821]: Loss = 0.6886849403381348
Iteration [15822]: Loss = 0.6885349154472351
Iteration [15823]: Loss = 0.6883698105812073
Iteration [15824]: Loss = 0.6881908178329468
Iteration [15825]: Loss = 0.6879997253417969
Iteration [15826]: Loss = 0.6877975463867188
Iteration [15827]: Loss = 0.6875854134559631
Iteration [15828]: Loss = 0.6873643398284912
Iteration [15829]: Loss = 0.6871351003646851
Iteration [15830]: Loss = 0.6868986487388611
Iteration [15831]: Loss = 0.6866556406021118
Iteration [15832]: Loss = 0.6864069104194641
Iteration [15833]: Loss = 5.019461631774902
Iteration [15834]: Loss = 5.019817352294922
Iteration [15835]: Loss = 5.019260883331299
Iteration [15836]: Loss = 0.6864439249038696
Iteration [15837]: Loss = 0.6866428256034851
Iteration [15838]: Loss = 0.6867920160293579
Iteration [15839]: Loss = 0.6868962049484253
Iteration [15840]: Loss = 0.686959981918335
Iteration [15841]: Loss = 5.014957904815674
Iteration [15842]: Loss = 0.6871739625930786
Iteration [15843]: Loss = 5.013210296630859
Iteration [15844]: Loss = 0.6875971555709839
Iteration [15845]: Loss = 0.687824010848999
Iteration [15846]: Loss = 0.6879984140396118
Iteration [15847]: Loss = 0.6881253123283386
Iteration [15848]: Loss = 0.6882096529006958
Iteration [15849]: Loss = 0.6882553100585938
Iteration [15850]: Loss = 0.6882665157318115
Iteration [15851]: Loss = 0.6882463097572327
Iteration [15852]: Loss = 0.688197910785675
Iteration [15853]: Loss = 0.6881242990493774
Iteration [15854]: Loss = 5.00935697555542
Iteration [15855]: Loss = 0.6881030201911926
Iteration [15856]: Loss = 5.0087504386901855
Iteration [15857]: Loss = 0.6883360147476196
Iteration [15858]: Loss = 0.6884819269180298
Iteration [15859]: Loss = 0.6885831356048584
Iteration [15860]: Loss = 0.6886442303657532
Iteration [15861]: Loss = 0.6886689066886902
Iteration [15862]: Loss = 0.6886612176895142
Iteration [15863]: Loss = 0.6886239647865295
Iteration [15864]: Loss = 0.6885603070259094
Iteration [15865]: Loss = 0.6884727478027344
Iteration [15866]: Loss = 0.6883636713027954
Iteration [15867]: Loss = 0.6882354021072388
Iteration [15868]: Loss = 0.6880896687507629
Iteration [15869]: Loss = 0.6879281401634216
Iteration [15870]: Loss = 0.6877526640892029
Iteration [15871]: Loss = 0.6875645518302917
Iteration [15872]: Loss = 5.0129241943359375
Iteration [15873]: Loss = 0.6873478889465332
Iteration [15874]: Loss = 0.6873025298118591
Iteration [15875]: Loss = 0.6872313022613525
Iteration [15876]: Loss = 0.6871371865272522
Iteration [15877]: Loss = 0.6870222091674805
Iteration [15878]: Loss = 0.686888575553894
Iteration [15879]: Loss = 5.016302108764648
Iteration [15880]: Loss = 0.6867653131484985
Iteration [15881]: Loss = 5.016185760498047
Iteration [15882]: Loss = 0.6869170069694519
Iteration [15883]: Loss = 0.6870285868644714
Iteration [15884]: Loss = 0.6870987415313721
Iteration [15885]: Loss = 0.6871317625045776
Iteration [15886]: Loss = 0.6871315836906433
Iteration [15887]: Loss = 0.6871011257171631
Iteration [15888]: Loss = 0.6870435476303101
Iteration [15889]: Loss = 0.6869614124298096
Iteration [15890]: Loss = 0.6868574023246765
Iteration [15891]: Loss = 5.016326904296875
Iteration [15892]: Loss = 5.016049861907959
Iteration [15893]: Loss = 0.6869929432868958
Iteration [15894]: Loss = 0.6871505379676819
Iteration [15895]: Loss = 0.6872621774673462
Iteration [15896]: Loss = 0.6873325109481812
Iteration [15897]: Loss = 0.6873657703399658
Iteration [15898]: Loss = 0.6873655319213867
Iteration [15899]: Loss = 0.6873350739479065
Iteration [15900]: Loss = 0.6872774958610535
Iteration [15901]: Loss = 0.687195360660553
Iteration [15902]: Loss = 0.6870912909507751
Iteration [15903]: Loss = 0.6869672536849976
Iteration [15904]: Loss = 0.6868254542350769
Iteration [15905]: Loss = 0.6866676211357117
Iteration [15906]: Loss = 5.017611503601074
Iteration [15907]: Loss = 0.6865032911300659
Iteration [15908]: Loss = 0.6864802837371826
Iteration [15909]: Loss = 0.6864292621612549
Iteration [15910]: Loss = 0.6863532662391663
Iteration [15911]: Loss = 0.6862546801567078
Iteration [15912]: Loss = 0.6861355900764465
Iteration [15913]: Loss = 0.6859982013702393
Iteration [15914]: Loss = 0.6858444213867188
Iteration [15915]: Loss = 0.6856756210327148
Iteration [15916]: Loss = 0.685493528842926
Iteration [15917]: Loss = 0.6852993965148926
Iteration [15918]: Loss = 0.6850942969322205
Iteration [15919]: Loss = 0.6848796010017395
Iteration [15920]: Loss = 0.6846559643745422
Iteration [15921]: Loss = 0.6844245791435242
Iteration [15922]: Loss = 0.6841861009597778
Iteration [15923]: Loss = 0.683941125869751
Iteration [15924]: Loss = 0.6836905479431152
Iteration [15925]: Loss = 0.6834347248077393
Iteration [15926]: Loss = 0.683174192905426
Iteration [15927]: Loss = 0.6829095482826233
Iteration [15928]: Loss = 0.6826412677764893
Iteration [15929]: Loss = 0.6823694705963135
Iteration [15930]: Loss = 0.6820946335792542
Iteration [15931]: Loss = 0.6818171739578247
Iteration [15932]: Loss = 0.6815372705459595
Iteration [15933]: Loss = 0.6812551617622375
Iteration [15934]: Loss = 0.6809710264205933
Iteration [15935]: Loss = 0.68068528175354
Iteration [15936]: Loss = 0.6803978085517883
Iteration [15937]: Loss = 0.6801090240478516
Iteration [15938]: Loss = 0.6798189878463745
Iteration [15939]: Loss = 0.6795276403427124
Iteration [15940]: Loss = 5.057128429412842
Iteration [15941]: Loss = 0.6791380047798157
Iteration [15942]: Loss = 0.67902010679245
Iteration [15943]: Loss = 0.6788840293884277
Iteration [15944]: Loss = 0.6787312626838684
Iteration [15945]: Loss = 0.6785640120506287
Iteration [15946]: Loss = 5.061811447143555
Iteration [15947]: Loss = 0.6783857345581055
Iteration [15948]: Loss = 5.061950206756592
Iteration [15949]: Loss = 0.678497850894928
Iteration [15950]: Loss = 9.442712783813477
Iteration [15951]: Loss = 5.058230400085449
Iteration [15952]: Loss = 0.6795934438705444
Iteration [15953]: Loss = 0.6800671815872192
Iteration [15954]: Loss = 0.6804642677307129
Iteration [15955]: Loss = 0.6807922720909119
Iteration [15956]: Loss = 0.6810577511787415
Iteration [15957]: Loss = 0.6812671422958374
Iteration [15958]: Loss = 5.045133113861084
Iteration [15959]: Loss = 0.681731104850769
Iteration [15960]: Loss = 5.0421295166015625
Iteration [15961]: Loss = 0.6823589205741882
Iteration [15962]: Loss = 0.6826736330986023
Iteration [15963]: Loss = 0.6829273700714111
Iteration [15964]: Loss = 0.6831259727478027
Iteration [15965]: Loss = 0.6832749843597412
Iteration [15966]: Loss = 0.6833792924880981
Iteration [15967]: Loss = 0.6834432482719421
Iteration [15968]: Loss = 0.6834708452224731
Iteration [15969]: Loss = 0.6834657192230225
Iteration [15970]: Loss = 0.6834312081336975
Iteration [15971]: Loss = 0.6833702325820923
Iteration [15972]: Loss = 0.6832852959632874
Iteration [15973]: Loss = 9.387981414794922
Iteration [15974]: Loss = 0.6834363341331482
Iteration [15975]: Loss = 0.6836385130882263
Iteration [15976]: Loss = 0.6837910413742065
Iteration [15977]: Loss = 0.6838985681533813
Iteration [15978]: Loss = 0.6839655637741089
Iteration [15979]: Loss = 0.6839962005615234
Iteration [15980]: Loss = 0.6839939951896667
Iteration [15981]: Loss = 0.6839621067047119
Iteration [15982]: Loss = 0.6839036345481873
Iteration [15983]: Loss = 0.6838213801383972
Iteration [15984]: Loss = 0.6837172508239746
Iteration [15985]: Loss = 0.6835938096046448
Iteration [15986]: Loss = 0.6834527850151062
Iteration [15987]: Loss = 0.6832960844039917
Iteration [15988]: Loss = 0.6831250190734863
Iteration [15989]: Loss = 0.6829412579536438
Iteration [15990]: Loss = 0.6827460527420044
Iteration [15991]: Loss = 0.6825404763221741
Iteration [15992]: Loss = 0.6823256015777588
Iteration [15993]: Loss = 0.6821024417877197
Iteration [15994]: Loss = 0.6818714737892151
Iteration [15995]: Loss = 0.6816339492797852
Iteration [15996]: Loss = 0.6813902258872986
Iteration [15997]: Loss = 0.6811411380767822
Iteration [15998]: Loss = 0.68088698387146
Iteration [15999]: Loss = 5.049493312835693
Iteration [16000]: Loss = 5.049872875213623
Iteration [16001]: Loss = 0.6806591153144836
Iteration [16002]: Loss = 0.6807194948196411
Iteration [16003]: Loss = 0.6807440519332886
Iteration [16004]: Loss = 0.6807366609573364
Iteration [16005]: Loss = 0.6807001829147339
Iteration [16006]: Loss = 0.6806374788284302
Iteration [16007]: Loss = 0.6805514097213745
Iteration [16008]: Loss = 0.6804440021514893
Iteration [16009]: Loss = 0.6803176999092102
Iteration [16010]: Loss = 0.6801741123199463
Iteration [16011]: Loss = 0.6800152063369751
Iteration [16012]: Loss = 5.053798198699951
Iteration [16013]: Loss = 0.6798499226570129
Iteration [16014]: Loss = 0.6798270344734192
Iteration [16015]: Loss = 0.6797766089439392
Iteration [16016]: Loss = 0.6797015070915222
Iteration [16017]: Loss = 0.6796042919158936
Iteration [16018]: Loss = 9.43200969696045
Iteration [16019]: Loss = 5.054388523101807
Iteration [16020]: Loss = 0.6801185607910156
Iteration [16021]: Loss = 0.6804348826408386
Iteration [16022]: Loss = 0.680690348148346
Iteration [16023]: Loss = 0.6808907985687256
Iteration [16024]: Loss = 0.6810420155525208
Iteration [16025]: Loss = 0.6811485290527344
Iteration [16026]: Loss = 0.6812149286270142
Iteration [16027]: Loss = 0.6812451481819153
Iteration [16028]: Loss = 0.6812427639961243
Iteration [16029]: Loss = 5.046307563781738
Iteration [16030]: Loss = 0.6813439726829529
Iteration [16031]: Loss = 0.681434154510498
Iteration [16032]: Loss = 0.6814857125282288
Iteration [16033]: Loss = 0.6815025210380554
Iteration [16034]: Loss = 0.681488037109375
Iteration [16035]: Loss = 0.6814454197883606
Iteration [16036]: Loss = 5.045397758483887
Iteration [16037]: Loss = 0.6814779043197632
Iteration [16038]: Loss = 0.6815387010574341
Iteration [16039]: Loss = 0.6815639734268188
Iteration [16040]: Loss = 0.6815570592880249
Iteration [16041]: Loss = 0.6815211176872253
Iteration [16042]: Loss = 0.6814591884613037
Iteration [16043]: Loss = 0.6813738346099854
Iteration [16044]: Loss = 5.045999526977539
Iteration [16045]: Loss = 0.6813332438468933
Iteration [16046]: Loss = 0.681363046169281
Iteration [16047]: Loss = 0.6813603043556213
Iteration [16048]: Loss = 0.6813280582427979
Iteration [16049]: Loss = 0.6812695264816284
Iteration [16050]: Loss = 0.6811871528625488
Iteration [16051]: Loss = 0.6810834407806396
Iteration [16052]: Loss = 0.6809602379798889
Iteration [16053]: Loss = 0.6808197498321533
Iteration [16054]: Loss = 0.6806635856628418
Iteration [16055]: Loss = 0.6804934144020081
Iteration [16056]: Loss = 0.6803103685379028
Iteration [16057]: Loss = 0.6801161766052246
Iteration [16058]: Loss = 5.05341911315918
Iteration [16059]: Loss = 0.681955099105835
Iteration [16060]: Loss = 0.6817294359207153
Iteration [16061]: Loss = 5.045620918273926
Iteration [16062]: Loss = 0.6817518472671509
Iteration [16063]: Loss = 0.6820083856582642
Iteration [16064]: Loss = 5.041322231292725
Iteration [16065]: Loss = 5.039539813995361
Iteration [16066]: Loss = 0.6827753186225891
Iteration [16067]: Loss = 0.683037519454956
Iteration [16068]: Loss = 0.6832439303398132
Iteration [16069]: Loss = 0.6834000945091248
Iteration [16070]: Loss = 0.6835108399391174
Iteration [16071]: Loss = 0.6835809350013733
Iteration [16072]: Loss = 0.6836143136024475
Iteration [16073]: Loss = 0.6836144328117371
Iteration [16074]: Loss = 0.6835848093032837
Iteration [16075]: Loss = 0.6835283041000366
Iteration [16076]: Loss = 0.6834474802017212
Iteration [16077]: Loss = 0.6833449602127075
Iteration [16078]: Loss = 0.6832229495048523
Iteration [16079]: Loss = 5.036100387573242
Iteration [16080]: Loss = 5.035902500152588
Iteration [16081]: Loss = 0.6833140850067139
Iteration [16082]: Loss = 0.6834595203399658
Iteration [16083]: Loss = 0.6830726861953735
Iteration [16084]: Loss = 0.6831338405609131
Iteration [16085]: Loss = 5.035686492919922
Iteration [16086]: Loss = 0.6833435297012329
Iteration [16087]: Loss = 0.6834796667098999
Iteration [16088]: Loss = 0.6835727095603943
Iteration [16089]: Loss = 5.033145427703857
Iteration [16090]: Loss = 0.6838366389274597
Iteration [16091]: Loss = 0.6839959621429443
Iteration [16092]: Loss = 0.6841096878051758
Iteration [16093]: Loss = 0.684182345867157
Iteration [16094]: Loss = 0.6842178702354431
Iteration [16095]: Loss = 0.6842200756072998
Iteration [16096]: Loss = 0.6841921210289001
Iteration [16097]: Loss = 0.6841371059417725
Iteration [16098]: Loss = 0.6840577721595764
Iteration [16099]: Loss = 0.6839564442634583
Iteration [16100]: Loss = 0.6838352680206299
Iteration [16101]: Loss = 0.6836963295936584
Iteration [16102]: Loss = 0.6835413575172424
Iteration [16103]: Loss = 0.6833719611167908
Iteration [16104]: Loss = 0.6831896305084229
Iteration [16105]: Loss = 0.6829955577850342
Iteration [16106]: Loss = 0.682790994644165
Iteration [16107]: Loss = 0.6825768947601318
Iteration [16108]: Loss = 9.397783279418945
Iteration [16109]: Loss = 0.6825078129768372
Iteration [16110]: Loss = 0.6826165914535522
Iteration [16111]: Loss = 0.6826848983764648
Iteration [16112]: Loss = 5.038094520568848
Iteration [16113]: Loss = 0.6829063296318054
Iteration [16114]: Loss = 0.6830475926399231
Iteration [16115]: Loss = 5.035763263702393
Iteration [16116]: Loss = 0.6833935379981995
Iteration [16117]: Loss = 0.6835875511169434
Iteration [16118]: Loss = 0.683732807636261
Iteration [16119]: Loss = 0.6838338971138
Iteration [16120]: Loss = 0.6838952898979187
Iteration [16121]: Loss = 0.6839210391044617
Iteration [16122]: Loss = 5.031582355499268
Iteration [16123]: Loss = 0.6840692162513733
Iteration [16124]: Loss = 5.030144691467285
Iteration [16125]: Loss = 5.028738498687744
Iteration [16126]: Loss = 5.026605606079102
Iteration [16127]: Loss = 0.6853457093238831
Iteration [16128]: Loss = 0.6857789158821106
Iteration [16129]: Loss = 0.6861395239830017
Iteration [16130]: Loss = 0.6864345669746399
Iteration [16131]: Loss = 5.016665935516357
Iteration [16132]: Loss = 0.6870428323745728
Iteration [16133]: Loss = 0.687348484992981
Iteration [16134]: Loss = 0.6875938177108765
Iteration [16135]: Loss = 5.010662078857422
Iteration [16136]: Loss = 0.6881169080734253
Iteration [16137]: Loss = 0.6883858442306519
Iteration [16138]: Loss = 0.6885983943939209
Iteration [16139]: Loss = 0.6887600421905518
Iteration [16140]: Loss = 0.6888757944107056
Iteration [16141]: Loss = 0.6889501810073853
Iteration [16142]: Loss = 0.688987135887146
Iteration [16143]: Loss = 5.004185676574707
Iteration [16144]: Loss = 5.003310203552246
Iteration [16145]: Loss = 0.689460277557373
Iteration [16146]: Loss = 0.6897062659263611
Iteration [16147]: Loss = 0.6898981928825378
Iteration [16148]: Loss = 0.6900410652160645
Iteration [16149]: Loss = 0.6901398301124573
Iteration [16150]: Loss = 0.6901987791061401
Iteration [16151]: Loss = 0.6902220249176025
Iteration [16152]: Loss = 0.6902127861976624
Iteration [16153]: Loss = 4.997841835021973
Iteration [16154]: Loss = 4.997169017791748
Iteration [16155]: Loss = 0.6905732154846191
Iteration [16156]: Loss = 0.690788984298706
Iteration [16157]: Loss = 0.6909531950950623
Iteration [16158]: Loss = 0.6910713315010071
Iteration [16159]: Loss = 0.6911476254463196
Iteration [16160]: Loss = 0.6911863684654236
Iteration [16161]: Loss = 0.6911911964416504
Iteration [16162]: Loss = 0.6911656260490417
Iteration [16163]: Loss = 0.6911126971244812
Iteration [16164]: Loss = 0.6910347938537598
Iteration [16165]: Loss = 9.296622276306152
Iteration [16166]: Loss = 0.6911927461624146
Iteration [16167]: Loss = 0.6913954019546509
Iteration [16168]: Loss = 0.6915481090545654
Iteration [16169]: Loss = 4.989933013916016
Iteration [16170]: Loss = 0.6919111609458923
Iteration [16171]: Loss = 0.6921113729476929
Iteration [16172]: Loss = 0.6922619342803955
Iteration [16173]: Loss = 0.6923674941062927
Iteration [16174]: Loss = 0.6924329400062561
Iteration [16175]: Loss = 0.6924618482589722
Iteration [16176]: Loss = 0.6924580335617065
Iteration [16177]: Loss = 0.6924247145652771
Iteration [16178]: Loss = 4.986155033111572
Iteration [16179]: Loss = 0.6924699544906616
Iteration [16180]: Loss = 0.6925345063209534
Iteration [16181]: Loss = 0.6925630569458008
Iteration [16182]: Loss = 0.6925587058067322
Iteration [16183]: Loss = 0.692524790763855
Iteration [16184]: Loss = 0.6924645900726318
Iteration [16185]: Loss = 0.6923803687095642
Iteration [16186]: Loss = 0.6922745108604431
Iteration [16187]: Loss = 0.6921493411064148
Iteration [16188]: Loss = 0.6920067667961121
Iteration [16189]: Loss = 0.6918483972549438
Iteration [16190]: Loss = 0.6916759014129639
Iteration [16191]: Loss = 0.6914907097816467
Iteration [16192]: Loss = 0.6912941336631775
Iteration [16193]: Loss = 0.6910871863365173
Iteration [16194]: Loss = 4.994121074676514
Iteration [16195]: Loss = 0.6908361911773682
Iteration [16196]: Loss = 0.6907750368118286
Iteration [16197]: Loss = 0.6906902194023132
Iteration [16198]: Loss = 0.6905838251113892
Iteration [16199]: Loss = 4.996325969696045
Iteration [16200]: Loss = 4.996077060699463
Iteration [16201]: Loss = 0.6907061338424683
Iteration [16202]: Loss = 0.6908575296401978
Iteration [16203]: Loss = 0.6909639835357666
Iteration [16204]: Loss = 13.59775161743164
Iteration [16205]: Loss = 0.6916131973266602
Iteration [16206]: Loss = 0.6921092867851257
Iteration [16207]: Loss = 0.6925268769264221
Iteration [16208]: Loss = 0.6928738355636597
Iteration [16209]: Loss = 0.6931569576263428
Iteration [16210]: Loss = 0.6933826208114624
Iteration [16211]: Loss = 0.6935564875602722
Iteration [16212]: Loss = 0.6936837434768677
Iteration [16213]: Loss = 0.6937689185142517
Iteration [16214]: Loss = 4.9784440994262695
Iteration [16215]: Loss = 4.977391719818115
Iteration [16216]: Loss = 0.6943484544754028
Iteration [16217]: Loss = 0.6946196556091309
Iteration [16218]: Loss = 0.6948347091674805
Iteration [16219]: Loss = 0.6949988007545471
Iteration [16220]: Loss = 0.6951170563697815
Iteration [16221]: Loss = 0.6951941847801208
Iteration [16222]: Loss = 0.6952341198921204
Iteration [16223]: Loss = 0.6952405571937561
Iteration [16224]: Loss = 0.6952167749404907
Iteration [16225]: Loss = 0.6951658725738525
Iteration [16226]: Loss = 0.6950905323028564
Iteration [16227]: Loss = 4.97221040725708
Iteration [16228]: Loss = 4.971848487854004
Iteration [16229]: Loss = 0.6952788829803467
Iteration [16230]: Loss = 0.6954450607299805
Iteration [16231]: Loss = 4.969185829162598
Iteration [16232]: Loss = 4.967792987823486
Iteration [16233]: Loss = 0.6962214112281799
Iteration [16234]: Loss = 0.696545422077179
Iteration [16235]: Loss = 0.6968077421188354
Iteration [16236]: Loss = 0.6970143914222717
Iteration [16237]: Loss = 0.6971710920333862
Iteration [16238]: Loss = 0.6972824931144714
Iteration [16239]: Loss = 0.6973532438278198
Iteration [16240]: Loss = 0.6973873972892761
Iteration [16241]: Loss = 0.6973883509635925
Iteration [16242]: Loss = 0.6973596215248108
Iteration [16243]: Loss = 4.960019111633301
Iteration [16244]: Loss = 0.697409987449646
Iteration [16245]: Loss = 0.6974756717681885
Iteration [16246]: Loss = 0.6975051760673523
Iteration [16247]: Loss = 0.697502076625824
Iteration [16248]: Loss = 0.6974695920944214
Iteration [16249]: Loss = 0.6974107027053833
Iteration [16250]: Loss = 4.959893226623535
Iteration [16251]: Loss = 4.9594645500183105
Iteration [16252]: Loss = 0.6976386904716492
Iteration [16253]: Loss = 4.957330703735352
Iteration [16254]: Loss = 0.6981295347213745
Iteration [16255]: Loss = 4.95435094833374
Iteration [16256]: Loss = 0.6987659931182861
Iteration [16257]: Loss = 0.6990813612937927
Iteration [16258]: Loss = 0.6993357539176941
Iteration [16259]: Loss = 0.6995352506637573
Iteration [16260]: Loss = 0.6996850967407227
Iteration [16261]: Loss = 0.6997902989387512
Iteration [16262]: Loss = 0.6998553276062012
Iteration [16263]: Loss = 0.6998841762542725
Iteration [16264]: Loss = 0.6998801231384277
Iteration [16265]: Loss = 0.6998469829559326
Iteration [16266]: Loss = 0.6997870802879333
Iteration [16267]: Loss = 0.6997034549713135
Iteration [16268]: Loss = 4.947982311248779
Iteration [16269]: Loss = 0.699659526348114
Iteration [16270]: Loss = 0.6996849775314331
Iteration [16271]: Loss = 0.6996780037879944
Iteration [16272]: Loss = 0.69964200258255
Iteration [16273]: Loss = 4.9480791091918945
Iteration [16274]: Loss = 0.6996795535087585
Iteration [16275]: Loss = 0.6997396945953369
Iteration [16276]: Loss = 4.947115898132324
Iteration [16277]: Loss = 0.6999415159225464
Iteration [16278]: Loss = 0.7000716328620911
Iteration [16279]: Loss = 0.7001588940620422
Iteration [16280]: Loss = 4.944795608520508
Iteration [16281]: Loss = 0.7004073262214661
Iteration [16282]: Loss = 0.7005571126937866
Iteration [16283]: Loss = 0.7006623148918152
Iteration [16284]: Loss = 0.700727105140686
Iteration [16285]: Loss = 0.7007554769515991
Iteration [16286]: Loss = 0.7007513046264648
Iteration [16287]: Loss = 0.7007176876068115
Iteration [16288]: Loss = 0.7006573677062988
Iteration [16289]: Loss = 4.942886829376221
Iteration [16290]: Loss = 0.7006534337997437
Iteration [16291]: Loss = 0.700695812702179
Iteration [16292]: Loss = 0.7007040977478027
Iteration [16293]: Loss = 4.942320823669434
Iteration [16294]: Loss = 0.700817346572876
Iteration [16295]: Loss = 0.7009096145629883
Iteration [16296]: Loss = 0.7009627819061279
Iteration [16297]: Loss = 0.7009808421134949
Iteration [16298]: Loss = 9.180695533752441
Iteration [16299]: Loss = 0.7012936472892761
Iteration [16300]: Loss = 4.937750339508057
Iteration [16301]: Loss = 0.7019504308700562
Iteration [16302]: Loss = 4.934024810791016
Iteration [16303]: Loss = 4.931711196899414
Iteration [16304]: Loss = 0.703273355960846
Iteration [16305]: Loss = 0.7037429809570312
Iteration [16306]: Loss = 0.704136312007904
Iteration [16307]: Loss = 0.704460859298706
Iteration [16308]: Loss = 0.7047233581542969
Iteration [16309]: Loss = 0.7049298286437988
Iteration [16310]: Loss = 0.7050860524177551
Iteration [16311]: Loss = 0.7051966786384583
Iteration [16312]: Loss = 0.7052664160728455
Iteration [16313]: Loss = 0.7052993774414062
Iteration [16314]: Loss = 4.918351173400879
Iteration [16315]: Loss = 0.705453097820282
Iteration [16316]: Loss = 0.7055619955062866
Iteration [16317]: Loss = 0.7056300640106201
Iteration [16318]: Loss = 0.7056612968444824
Iteration [16319]: Loss = 4.916489124298096
Iteration [16320]: Loss = 0.7058123350143433
Iteration [16321]: Loss = 0.7059200406074524
Iteration [16322]: Loss = 0.7059870362281799
Iteration [16323]: Loss = 0.7060173153877258
Iteration [16324]: Loss = 0.7060146927833557
Iteration [16325]: Loss = 0.7059822082519531
Iteration [16326]: Loss = 4.915131568908691
Iteration [16327]: Loss = 0.7060242295265198
Iteration [16328]: Loss = 4.914292335510254
Iteration [16329]: Loss = 0.7062950134277344
Iteration [16330]: Loss = 0.7064536213874817
Iteration [16331]: Loss = 0.706566333770752
Iteration [16332]: Loss = 4.911448955535889
Iteration [16333]: Loss = 0.7068565487861633
Iteration [16334]: Loss = 0.7070235013961792
Iteration [16335]: Loss = 0.7071437835693359
Iteration [16336]: Loss = 4.908443927764893
Iteration [16337]: Loss = 0.7074466347694397
Iteration [16338]: Loss = 0.7076188325881958
Iteration [16339]: Loss = 9.103781700134277
Iteration [16340]: Loss = 0.7081912159919739
Iteration [16341]: Loss = 0.7085644006729126
Iteration [16342]: Loss = 0.7088704705238342
Iteration [16343]: Loss = 0.7091164588928223
Iteration [16344]: Loss = 0.709307849407196
Iteration [16345]: Loss = 0.709450364112854
Iteration [16346]: Loss = 0.7095485925674438
Iteration [16347]: Loss = 0.7096071243286133
Iteration [16348]: Loss = 0.7096298336982727
Iteration [16349]: Loss = 0.7096201181411743
Iteration [16350]: Loss = 0.7095814347267151
Iteration [16351]: Loss = 0.7095165252685547
Iteration [16352]: Loss = 0.7094279527664185
Iteration [16353]: Loss = 0.7093181610107422
Iteration [16354]: Loss = 0.7091893553733826
Iteration [16355]: Loss = 0.7090432643890381
Iteration [16356]: Loss = 0.7088816165924072
Iteration [16357]: Loss = 0.7087060213088989
Iteration [16358]: Loss = 4.901793003082275
Iteration [16359]: Loss = 0.7085027694702148
Iteration [16360]: Loss = 0.7084590792655945
Iteration [16361]: Loss = 0.7083896994590759
Iteration [16362]: Loss = 0.7082971334457397
Iteration [16363]: Loss = 0.7081838250160217
Iteration [16364]: Loss = 0.7080516815185547
Iteration [16365]: Loss = 0.707902729511261
Iteration [16366]: Loss = 0.70773845911026
Iteration [16367]: Loss = 0.707560658454895
Iteration [16368]: Loss = 0.7073704600334167
Iteration [16369]: Loss = 0.7071691751480103
Iteration [16370]: Loss = 0.706957995891571
Iteration [16371]: Loss = 0.7067376971244812
Iteration [16372]: Loss = 0.7065094113349915
Iteration [16373]: Loss = 0.7062738537788391
Iteration [16374]: Loss = 0.7060317397117615
Iteration [16375]: Loss = 4.915849208831787
Iteration [16376]: Loss = 0.7057156562805176
Iteration [16377]: Loss = 0.7056244015693665
Iteration [16378]: Loss = 4.917250156402588
Iteration [16379]: Loss = 0.7055659294128418
Iteration [16380]: Loss = 0.7055844068527222
Iteration [16381]: Loss = 0.7055709958076477
Iteration [16382]: Loss = 4.917162895202637
Iteration [16383]: Loss = 0.7056456208229065
Iteration [16384]: Loss = 0.7057209014892578
Iteration [16385]: Loss = 0.7057585120201111
Iteration [16386]: Loss = 4.915958881378174
Iteration [16387]: Loss = 0.7059205174446106
Iteration [16388]: Loss = 0.7060328722000122
Iteration [16389]: Loss = 0.7061039209365845
Iteration [16390]: Loss = 0.7061381340026855
Iteration [16391]: Loss = 0.7061387300491333
Iteration [16392]: Loss = 0.7061092257499695
Iteration [16393]: Loss = 0.7060527205467224
Iteration [16394]: Loss = 0.7059717178344727
Iteration [16395]: Loss = 0.7058687210083008
Iteration [16396]: Loss = 0.7057459354400635
Iteration [16397]: Loss = 0.7056054472923279
Iteration [16398]: Loss = 0.7054487466812134
Iteration [16399]: Loss = 0.7052776217460632
Iteration [16400]: Loss = 0.705093502998352
Iteration [16401]: Loss = 0.7048978805541992
Iteration [16402]: Loss = 4.921489715576172
Iteration [16403]: Loss = 0.7046613693237305
Iteration [16404]: Loss = 0.7046040892601013
Iteration [16405]: Loss = 0.7045226097106934
Iteration [16406]: Loss = 0.7044192552566528
Iteration [16407]: Loss = 0.7042961716651917
Iteration [16408]: Loss = 4.924264430999756
Iteration [16409]: Loss = 4.924116134643555
Iteration [16410]: Loss = 4.923180103302002
Iteration [16411]: Loss = 0.7046819925308228
Iteration [16412]: Loss = 4.9202165603637695
Iteration [16413]: Loss = 0.7053223848342896
Iteration [16414]: Loss = 0.7056388854980469
Iteration [16415]: Loss = 0.7058939337730408
Iteration [16416]: Loss = 0.7060935497283936
Iteration [16417]: Loss = 0.7062433958053589
Iteration [16418]: Loss = 0.7063481211662292
Iteration [16419]: Loss = 0.7064125537872314
Iteration [16420]: Loss = 0.7064402103424072
Iteration [16421]: Loss = 0.7064351439476013
Iteration [16422]: Loss = 4.912671089172363
Iteration [16423]: Loss = 0.706524133682251
Iteration [16424]: Loss = 0.7066053748130798
Iteration [16425]: Loss = 0.7066484689712524
Iteration [16426]: Loss = 0.7066571712493896
Iteration [16427]: Loss = 0.7066347599029541
Iteration [16428]: Loss = 0.7065844535827637
Iteration [16429]: Loss = 0.7065089344978333
Iteration [16430]: Loss = 0.706410825252533
Iteration [16431]: Loss = 4.913227558135986
Iteration [16432]: Loss = 0.7063411474227905
Iteration [16433]: Loss = 0.7063547968864441
Iteration [16434]: Loss = 0.7063370943069458
Iteration [16435]: Loss = 0.7062909007072449
Iteration [16436]: Loss = 4.913604736328125
Iteration [16437]: Loss = 0.7063098549842834
Iteration [16438]: Loss = 4.912871837615967
Iteration [16439]: Loss = 0.7065628170967102
Iteration [16440]: Loss = 0.7067140340805054
Iteration [16441]: Loss = 0.7068200707435608
Iteration [16442]: Loss = 0.7068854570388794
Iteration [16443]: Loss = 0.7069140076637268
Iteration [16444]: Loss = 0.7069096565246582
Iteration [16445]: Loss = 0.7068753242492676
Iteration [16446]: Loss = 0.7068144083023071
Iteration [16447]: Loss = 0.7067291736602783
Iteration [16448]: Loss = 0.7066222429275513
Iteration [16449]: Loss = 4.912179946899414
Iteration [16450]: Loss = 4.911964416503906
Iteration [16451]: Loss = 0.7067304253578186
Iteration [16452]: Loss = 0.7068737149238586
Iteration [16453]: Loss = 0.7069727182388306
Iteration [16454]: Loss = 4.909422397613525
Iteration [16455]: Loss = 4.908352851867676
Iteration [16456]: Loss = 0.7075815796852112
Iteration [16457]: Loss = 0.707859456539154
Iteration [16458]: Loss = 0.7080795168876648
Iteration [16459]: Loss = 0.7082474231719971
Iteration [16460]: Loss = 0.7083684206008911
Iteration [16461]: Loss = 9.095864295959473
Iteration [16462]: Loss = 0.7088547348976135
Iteration [16463]: Loss = 0.7091920375823975
Iteration [16464]: Loss = 0.7094656229019165
Iteration [16465]: Loss = 0.7096819281578064
Iteration [16466]: Loss = 0.7098466157913208
Iteration [16467]: Loss = 0.7099648118019104
Iteration [16468]: Loss = 0.7100409865379333
Iteration [16469]: Loss = 0.710079550743103
Iteration [16470]: Loss = 0.7100839018821716
Iteration [16471]: Loss = 0.7100575566291809
Iteration [16472]: Loss = 0.7100036144256592
Iteration [16473]: Loss = 0.7099248170852661
Iteration [16474]: Loss = 0.709823727607727
Iteration [16475]: Loss = 4.895730495452881
Iteration [16476]: Loss = 4.8954997062683105
Iteration [16477]: Loss = 0.7099425196647644
Iteration [16478]: Loss = 0.7100878953933716
Iteration [16479]: Loss = 4.893248081207275
Iteration [16480]: Loss = 4.892000675201416
Iteration [16481]: Loss = 0.7108065485954285
Iteration [16482]: Loss = 0.711112916469574
Iteration [16483]: Loss = 0.7113586068153381
Iteration [16484]: Loss = 0.7115495800971985
Iteration [16485]: Loss = 0.7116913199424744
Iteration [16486]: Loss = 0.7117886543273926
Iteration [16487]: Loss = 4.88480281829834
Iteration [16488]: Loss = 0.7120515704154968
Iteration [16489]: Loss = 0.712206244468689
Iteration [16490]: Loss = 0.7123153805732727
Iteration [16491]: Loss = 4.882073402404785
Iteration [16492]: Loss = 0.7125980257987976
Iteration [16493]: Loss = 0.7127611637115479
Iteration [16494]: Loss = 4.8795623779296875
Iteration [16495]: Loss = 0.7131364345550537
Iteration [16496]: Loss = 0.7133390307426453
Iteration [16497]: Loss = 0.7134910821914673
Iteration [16498]: Loss = 0.7135975360870361
Iteration [16499]: Loss = 0.7136630415916443
Iteration [16500]: Loss = 0.7136915922164917
Iteration [16501]: Loss = 4.875462055206299
Iteration [16502]: Loss = 0.7138365507125854
Iteration [16503]: Loss = 0.7139408588409424
Iteration [16504]: Loss = 0.7140045166015625
Iteration [16505]: Loss = 0.7140311598777771
Iteration [16506]: Loss = 0.7140247225761414
Iteration [16507]: Loss = 0.7139886021614075
Iteration [16508]: Loss = 0.7139254212379456
Iteration [16509]: Loss = 0.7138380408287048
Iteration [16510]: Loss = 0.7137288451194763
Iteration [16511]: Loss = 0.7136000990867615
Iteration [16512]: Loss = 0.7134536504745483
Iteration [16513]: Loss = 0.7132912278175354
Iteration [16514]: Loss = 0.7131146192550659
Iteration [16515]: Loss = 0.7129249572753906
Iteration [16516]: Loss = 0.7127238512039185
Iteration [16517]: Loss = 0.7125121355056763
Iteration [16518]: Loss = 0.7122911810874939
Iteration [16519]: Loss = 0.7120617032051086
Iteration [16520]: Loss = 0.7118246555328369
Iteration [16521]: Loss = 0.7115808129310608
Iteration [16522]: Loss = 0.7113308310508728
Iteration [16523]: Loss = 0.7110751867294312
Iteration [16524]: Loss = 0.7108146548271179
Iteration [16525]: Loss = 0.7105497121810913
Iteration [16526]: Loss = 4.892776966094971
Iteration [16527]: Loss = 4.893218040466309
Iteration [16528]: Loss = 0.7102717161178589
Iteration [16529]: Loss = 0.7103109955787659
Iteration [16530]: Loss = 0.710316002368927
Iteration [16531]: Loss = 0.7102900147438049
Iteration [16532]: Loss = 0.7102361917495728
Iteration [16533]: Loss = 0.7101573944091797
Iteration [16534]: Loss = 0.7100560069084167
Iteration [16535]: Loss = 4.8945465087890625
Iteration [16536]: Loss = 0.7099801301956177
Iteration [16537]: Loss = 0.7099910378456116
Iteration [16538]: Loss = 4.894361972808838
Iteration [16539]: Loss = 0.7101069092750549
Iteration [16540]: Loss = 0.7101994156837463
Iteration [16541]: Loss = 0.7102524042129517
Iteration [16542]: Loss = 9.075398445129395
Iteration [16543]: Loss = 0.7106229662895203
Iteration [16544]: Loss = 0.710910975933075
Iteration [16545]: Loss = 0.7111401557922363
Iteration [16546]: Loss = 0.7113162279129028
Iteration [16547]: Loss = 0.7114447355270386
Iteration [16548]: Loss = 0.7115299105644226
Iteration [16549]: Loss = 0.7115765810012817
Iteration [16550]: Loss = 0.7115879654884338
Iteration [16551]: Loss = 0.7115681767463684
Iteration [16552]: Loss = 0.711519718170166
Iteration [16553]: Loss = 4.886837959289551
Iteration [16554]: Loss = 0.7115339636802673
Iteration [16555]: Loss = 0.7115827798843384
Iteration [16556]: Loss = 0.7115963697433472
Iteration [16557]: Loss = 0.711578369140625
Iteration [16558]: Loss = 0.7115316390991211
Iteration [16559]: Loss = 0.7114592790603638
Iteration [16560]: Loss = 0.7113637328147888
Iteration [16561]: Loss = 0.7112473249435425
Iteration [16562]: Loss = 0.7111122012138367
Iteration [16563]: Loss = 0.7109600305557251
Iteration [16564]: Loss = 0.7107928395271301
Iteration [16565]: Loss = 0.7106118202209473
Iteration [16566]: Loss = 0.7104184627532959
Iteration [16567]: Loss = 0.7102140188217163
Iteration [16568]: Loss = 4.894212245941162
Iteration [16569]: Loss = 0.7099619507789612
Iteration [16570]: Loss = 4.894733428955078
Iteration [16571]: Loss = 0.7099945545196533
Iteration [16572]: Loss = 0.7100515365600586
Iteration [16573]: Loss = 4.8938398361206055
Iteration [16574]: Loss = 0.7102461457252502
Iteration [16575]: Loss = 0.7103720307350159
Iteration [16576]: Loss = 0.710455060005188
Iteration [16577]: Loss = 0.7104994654655457
Iteration [16578]: Loss = 0.710509181022644
Iteration [16579]: Loss = 0.7104876041412354
Iteration [16580]: Loss = 0.7104375958442688
Iteration [16581]: Loss = 0.7103623151779175
Iteration [16582]: Loss = 0.7102640867233276
Iteration [16583]: Loss = 0.7101452350616455
Iteration [16584]: Loss = 0.7100078463554382
Iteration [16585]: Loss = 0.7098537683486938
Iteration [16586]: Loss = 0.7096847295761108
Iteration [16587]: Loss = 0.709502100944519
Iteration [16588]: Loss = 0.7093072533607483
Iteration [16589]: Loss = 0.7091014385223389
Iteration [16590]: Loss = 0.7088857293128967
Iteration [16591]: Loss = 0.7086611390113831
Iteration [16592]: Loss = 4.90225076675415
Iteration [16593]: Loss = 0.7083751559257507
Iteration [16594]: Loss = 4.902926921844482
Iteration [16595]: Loss = 0.708381712436676
Iteration [16596]: Loss = 0.7084278464317322
Iteration [16597]: Loss = 0.7084391117095947
Iteration [16598]: Loss = 0.7084189057350159
Iteration [16599]: Loss = 0.7083702087402344
Iteration [16600]: Loss = 4.902929306030273
Iteration [16601]: Loss = 0.7083849906921387
Iteration [16602]: Loss = 0.7084346413612366
Iteration [16603]: Loss = 0.7084490060806274
Iteration [16604]: Loss = 0.708431601524353
Iteration [16605]: Loss = 0.7083854675292969
Iteration [16606]: Loss = 0.7083135843276978
Iteration [16607]: Loss = 0.7082185745239258
Iteration [16608]: Loss = 0.7081025242805481
Iteration [16609]: Loss = 4.904613971710205
Iteration [16610]: Loss = 0.7080023288726807
Iteration [16611]: Loss = 0.708003044128418
Iteration [16612]: Loss = 4.904585361480713
Iteration [16613]: Loss = 0.708102285861969
Iteration [16614]: Loss = 0.7081880569458008
Iteration [16615]: Loss = 0.7082349061965942
Iteration [16616]: Loss = 0.7082467675209045
Iteration [16617]: Loss = 0.7082269191741943
Iteration [16618]: Loss = 0.7081787586212158
Iteration [16619]: Loss = 0.7081049680709839
Iteration [16620]: Loss = 0.7080081105232239
Iteration [16621]: Loss = 4.90501070022583
Iteration [16622]: Loss = 0.7079406380653381
Iteration [16623]: Loss = 0.7079553604125977
Iteration [16624]: Loss = 0.7079383134841919
Iteration [16625]: Loss = 0.7078925371170044
Iteration [16626]: Loss = 0.7078208327293396
Iteration [16627]: Loss = 0.7077258825302124
Iteration [16628]: Loss = 0.707610011100769
Iteration [16629]: Loss = 0.7074753046035767
Iteration [16630]: Loss = 0.7073235511779785
Iteration [16631]: Loss = 4.908781051635742
Iteration [16632]: Loss = 0.7071624994277954
Iteration [16633]: Loss = 4.908877372741699
Iteration [16634]: Loss = 0.7072713375091553
Iteration [16635]: Loss = 0.7073612809181213
Iteration [16636]: Loss = 0.7074119448661804
Iteration [16637]: Loss = 0.7074271440505981
Iteration [16638]: Loss = 0.7074103355407715
Iteration [16639]: Loss = 0.7073649168014526
Iteration [16640]: Loss = 0.7072934508323669
Iteration [16641]: Loss = 0.7071987986564636
Iteration [16642]: Loss = 0.7070830464363098
Iteration [16643]: Loss = 0.7069482803344727
Iteration [16644]: Loss = 0.7067966461181641
Iteration [16645]: Loss = 0.706629753112793
Iteration [16646]: Loss = 0.7064489126205444
Iteration [16647]: Loss = 0.7062556147575378
Iteration [16648]: Loss = 0.7060511708259583
Iteration [16649]: Loss = 0.705836832523346
Iteration [16650]: Loss = 4.917182445526123
Iteration [16651]: Loss = 0.7055690884590149
Iteration [16652]: Loss = 0.7054988741874695
Iteration [16653]: Loss = 4.917802333831787
Iteration [16654]: Loss = 0.7054778337478638
Iteration [16655]: Loss = 0.7055127620697021
Iteration [16656]: Loss = 0.7055138349533081
Iteration [16657]: Loss = 0.7054843902587891
Iteration [16658]: Loss = 0.7054275274276733
Iteration [16659]: Loss = 0.7053458094596863
Iteration [16660]: Loss = 0.7052419185638428
Iteration [16661]: Loss = 9.133451461791992
Iteration [16662]: Loss = 0.7053489685058594
Iteration [16663]: Loss = 0.7055267095565796
Iteration [16664]: Loss = 0.7056565880775452
Iteration [16665]: Loss = 0.7057434320449829
Iteration [16666]: Loss = 0.7057914733886719
Iteration [16667]: Loss = 0.7058043479919434
Iteration [16668]: Loss = 0.7057857513427734
Iteration [16669]: Loss = 0.7057386636734009
Iteration [16670]: Loss = 0.7056660652160645
Iteration [16671]: Loss = 4.91694974899292
Iteration [16672]: Loss = 0.7056405544281006
Iteration [16673]: Loss = 0.705673336982727
Iteration [16674]: Loss = 0.7056726813316345
Iteration [16675]: Loss = 0.7056416273117065
Iteration [16676]: Loss = 4.916882038116455
Iteration [16677]: Loss = 0.705687403678894
Iteration [16678]: Loss = 0.7057505249977112
Iteration [16679]: Loss = 4.915882587432861
Iteration [16680]: Loss = 0.7059569954872131
Iteration [16681]: Loss = 0.7060886025428772
Iteration [16682]: Loss = 0.7061769962310791
Iteration [16683]: Loss = 4.913568496704102
Iteration [16684]: Loss = 0.7064263224601746
Iteration [16685]: Loss = 0.7065761089324951
Iteration [16686]: Loss = 0.7066808938980103
Iteration [16687]: Loss = 0.7067447900772095
Iteration [16688]: Loss = 0.7067720890045166
Iteration [16689]: Loss = 0.7067662477493286
Iteration [16690]: Loss = 4.910970211029053
Iteration [16691]: Loss = 0.7068546414375305
Iteration [16692]: Loss = 0.7069360017776489
Iteration [16693]: Loss = 0.7069789171218872
Iteration [16694]: Loss = 0.7069870829582214
Iteration [16695]: Loss = 0.7069642543792725
Iteration [16696]: Loss = 0.7069131135940552
Iteration [16697]: Loss = 4.910425186157227
Iteration [16698]: Loss = 0.706924319267273
Iteration [16699]: Loss = 0.7069727182388306
Iteration [16700]: Loss = 0.7069859504699707
Iteration [16701]: Loss = 4.909752368927002
Iteration [16702]: Loss = 0.7071070075035095
Iteration [16703]: Loss = 0.707202136516571
Iteration [16704]: Loss = 9.109265327453613
Iteration [16705]: Loss = 0.7076463103294373
Iteration [16706]: Loss = 0.7079665064811707
Iteration [16707]: Loss = 0.7082245945930481
Iteration [16708]: Loss = 0.7084270119667053
Iteration [16709]: Loss = 4.901480197906494
Iteration [16710]: Loss = 0.7088702321052551
Iteration [16711]: Loss = 0.7091022729873657
Iteration [16712]: Loss = 0.7092812061309814
Iteration [16713]: Loss = 0.7094119191169739
Iteration [16714]: Loss = 0.7094994187355042
Iteration [16715]: Loss = 4.89652156829834
Iteration [16716]: Loss = 0.7097460031509399
Iteration [16717]: Loss = 0.7098942995071411
Iteration [16718]: Loss = 0.7099974155426025
Iteration [16719]: Loss = 0.7100600004196167
Iteration [16720]: Loss = 0.7100860476493835
Iteration [16721]: Loss = 4.893805980682373
Iteration [16722]: Loss = 0.7102276682853699
Iteration [16723]: Loss = 0.7103311419487
Iteration [16724]: Loss = 0.7103939652442932
Iteration [16725]: Loss = 0.7104201316833496
Iteration [16726]: Loss = 0.7104132175445557
Iteration [16727]: Loss = 0.7103767395019531
Iteration [16728]: Loss = 0.7103133201599121
Iteration [16729]: Loss = 4.893057346343994
Iteration [16730]: Loss = 0.7103022933006287
Iteration [16731]: Loss = 0.7103408575057983
Iteration [16732]: Loss = 4.892449378967285
Iteration [16733]: Loss = 0.7105036973953247
Iteration [16734]: Loss = 0.7106162905693054
Iteration [16735]: Loss = 0.7106872797012329
Iteration [16736]: Loss = 0.7107206583023071
Iteration [16737]: Loss = 0.7107203602790833
Iteration [16738]: Loss = 0.7106896638870239
Iteration [16739]: Loss = 0.7106316089630127
Iteration [16740]: Loss = 0.7105487585067749
Iteration [16741]: Loss = 4.891945838928223
Iteration [16742]: Loss = 0.7105045914649963
Iteration [16743]: Loss = 0.7105289697647095
Iteration [16744]: Loss = 0.710520327091217
Iteration [16745]: Loss = 0.7104822397232056
Iteration [16746]: Loss = 0.7104173898696899
Iteration [16747]: Loss = 0.7103284597396851
Iteration [16748]: Loss = 0.7102181315422058
Iteration [16749]: Loss = 0.7100881338119507
Iteration [16750]: Loss = 0.7099406123161316
Iteration [16751]: Loss = 0.7097774147987366
Iteration [16752]: Loss = 0.7095998525619507
Iteration [16753]: Loss = 0.7094096541404724
Iteration [16754]: Loss = 0.7092077732086182
Iteration [16755]: Loss = 0.7089956998825073
Iteration [16756]: Loss = 0.7087743282318115
Iteration [16757]: Loss = 0.7085444927215576
Iteration [16758]: Loss = 0.708307147026062
Iteration [16759]: Loss = 0.7080629467964172
Iteration [16760]: Loss = 4.905409812927246
Iteration [16761]: Loss = 4.905762195587158
Iteration [16762]: Loss = 0.7078382968902588
Iteration [16763]: Loss = 0.7078927159309387
Iteration [16764]: Loss = 0.7079113721847534
Iteration [16765]: Loss = 0.7078976631164551
Iteration [16766]: Loss = 0.7078549861907959
Iteration [16767]: Loss = 0.7077860236167908
Iteration [16768]: Loss = 0.7076934576034546
Iteration [16769]: Loss = 0.7075799107551575
Iteration [16770]: Loss = 0.7074469923973083
Iteration [16771]: Loss = 0.7072970867156982
Iteration [16772]: Loss = 4.908908843994141
Iteration [16773]: Loss = 0.7071390748023987
Iteration [16774]: Loss = 0.7071154713630676
Iteration [16775]: Loss = 0.7070638537406921
Iteration [16776]: Loss = 0.7069869637489319
Iteration [16777]: Loss = 0.7068872451782227
Iteration [16778]: Loss = 0.7067670226097107
Iteration [16779]: Loss = 4.911498069763184
Iteration [16780]: Loss = 0.7066602110862732
Iteration [16781]: Loss = 0.7066585421562195
Iteration [16782]: Loss = 0.7066265344619751
Iteration [16783]: Loss = 0.7065672874450684
Iteration [16784]: Loss = 0.7064835429191589
Iteration [16785]: Loss = 0.7063777446746826
Iteration [16786]: Loss = 4.913435459136963
Iteration [16787]: Loss = 0.7062956094741821
Iteration [16788]: Loss = 0.7063045501708984
Iteration [16789]: Loss = 0.7062820792198181
Iteration [16790]: Loss = 0.7062313556671143
Iteration [16791]: Loss = 0.7061553597450256
Iteration [16792]: Loss = 0.7060564756393433
Iteration [16793]: Loss = 0.7059370279312134
Iteration [16794]: Loss = 0.7057989239692688
Iteration [16795]: Loss = 0.7056441903114319
Iteration [16796]: Loss = 0.7054744958877563
Iteration [16797]: Loss = 0.7052912712097168
Iteration [16798]: Loss = 4.919400215148926
Iteration [16799]: Loss = 0.7050772309303284
Iteration [16800]: Loss = 0.705030083656311
Iteration [16801]: Loss = 0.7049573063850403
Iteration [16802]: Loss = 0.7048613429069519
Iteration [16803]: Loss = 0.7047444581985474
Iteration [16804]: Loss = 0.7046087980270386
Iteration [16805]: Loss = 0.7044562697410583
Iteration [16806]: Loss = 0.7042884230613708
Iteration [16807]: Loss = 0.7041070461273193
Iteration [16808]: Loss = 0.7039132714271545
Iteration [16809]: Loss = 0.703708291053772
Iteration [16810]: Loss = 0.7034934163093567
Iteration [16811]: Loss = 0.7032695412635803
Iteration [16812]: Loss = 0.7030376195907593
Iteration [16813]: Loss = 0.7027983069419861
Iteration [16814]: Loss = 4.932577610015869
Iteration [16815]: Loss = 4.932904243469238
Iteration [16816]: Loss = 0.7025905847549438
Iteration [16817]: Loss = 0.7026512026786804
Iteration [16818]: Loss = 4.931939125061035
Iteration [16819]: Loss = 0.7028545141220093
Iteration [16820]: Loss = 0.7029854655265808
Iteration [16821]: Loss = 4.929873466491699
Iteration [16822]: Loss = 0.7033091187477112
Iteration [16823]: Loss = 0.7034913897514343
Iteration [16824]: Loss = 4.927009582519531
Iteration [16825]: Loss = 0.703902542591095
Iteration [16826]: Loss = 0.704122006893158
Iteration [16827]: Loss = 0.7042893171310425
Iteration [16828]: Loss = 0.7044094800949097
Iteration [16829]: Loss = 0.7044873833656311
Iteration [16830]: Loss = 0.7045270204544067
Iteration [16831]: Loss = 0.7045322060585022
Iteration [16832]: Loss = 0.7045063972473145
Iteration [16833]: Loss = 4.92272424697876
Iteration [16834]: Loss = 0.7045621275901794
Iteration [16835]: Loss = 0.7046298980712891
Iteration [16836]: Loss = 0.7046606540679932
Iteration [16837]: Loss = 4.921664237976074
Iteration [16838]: Loss = 0.7048124670982361
Iteration [16839]: Loss = 0.7049213647842407
Iteration [16840]: Loss = 0.704988956451416
Iteration [16841]: Loss = 0.7050193548202515
Iteration [16842]: Loss = 0.7050161957740784
Iteration [16843]: Loss = 0.7049828767776489
Iteration [16844]: Loss = 0.7049223780632019
Iteration [16845]: Loss = 0.7048373222351074
Iteration [16846]: Loss = 4.921289443969727
Iteration [16847]: Loss = 0.7047916054725647
Iteration [16848]: Loss = 0.7048163414001465
Iteration [16849]: Loss = 0.704808235168457
Iteration [16850]: Loss = 0.7047702670097351
Iteration [16851]: Loss = 0.7047055959701538
Iteration [16852]: Loss = 0.7046168446540833
Iteration [16853]: Loss = 0.7045062780380249
Iteration [16854]: Loss = 0.7043763399124146
Iteration [16855]: Loss = 0.7042287588119507
Iteration [16856]: Loss = 0.7040653228759766
Iteration [16857]: Loss = 0.7038875818252563
Iteration [16858]: Loss = 0.7036972045898438
Iteration [16859]: Loss = 0.7034950852394104
Iteration [16860]: Loss = 0.7032827734947205
Iteration [16861]: Loss = 0.7030609846115112
Iteration [16862]: Loss = 0.7028307914733887
Iteration [16863]: Loss = 0.7025930881500244
Iteration [16864]: Loss = 0.7023484706878662
Iteration [16865]: Loss = 0.7020977735519409
Iteration [16866]: Loss = 4.936274528503418
Iteration [16867]: Loss = 0.7017701864242554
Iteration [16868]: Loss = 0.701675295829773
Iteration [16869]: Loss = 0.7015594244003296
Iteration [16870]: Loss = 0.7014246582984924
Iteration [16871]: Loss = 0.7012728452682495
Iteration [16872]: Loss = 0.7011055946350098
Iteration [16873]: Loss = 0.7009246349334717
Iteration [16874]: Loss = 0.7007312178611755
Iteration [16875]: Loss = 0.7005267143249512
Iteration [16876]: Loss = 0.7003120183944702
Iteration [16877]: Loss = 0.7000883221626282
Iteration [16878]: Loss = 4.946631908416748
Iteration [16879]: Loss = 0.6998072266578674
Iteration [16880]: Loss = 0.6997324824333191
Iteration [16881]: Loss = 0.6996347904205322
Iteration [16882]: Loss = 4.948410987854004
Iteration [16883]: Loss = 0.699569046497345
Iteration [16884]: Loss = 0.6995859742164612
Iteration [16885]: Loss = 0.699570894241333
Iteration [16886]: Loss = 0.6995269656181335
Iteration [16887]: Loss = 0.6994567513465881
Iteration [16888]: Loss = 9.199061393737793
Iteration [16889]: Loss = 0.6996256709098816
Iteration [16890]: Loss = 4.946761131286621
Iteration [16891]: Loss = 0.7001743912696838
Iteration [16892]: Loss = 0.7004531025886536
Iteration [16893]: Loss = 0.7006738185882568
Iteration [16894]: Loss = 0.7008423209190369
Iteration [16895]: Loss = 0.7009639143943787
Iteration [16896]: Loss = 0.7010430097579956
Iteration [16897]: Loss = 0.7010840773582458
Iteration [16898]: Loss = 0.7010906934738159
Iteration [16899]: Loss = 4.94031286239624
Iteration [16900]: Loss = 0.7012023329734802
Iteration [16901]: Loss = 0.7012943625450134
Iteration [16902]: Loss = 0.7013469934463501
Iteration [16903]: Loss = 0.7013641595840454
Iteration [16904]: Loss = 0.7013491988182068
Iteration [16905]: Loss = 0.7013054490089417
Iteration [16906]: Loss = 0.7012355923652649
Iteration [16907]: Loss = 0.7011424899101257
Iteration [16908]: Loss = 0.7010282278060913
Iteration [16909]: Loss = 0.7008949518203735
Iteration [16910]: Loss = 0.7007446885108948
Iteration [16911]: Loss = 0.700579047203064
Iteration [16912]: Loss = 0.7003995180130005
Iteration [16913]: Loss = 0.700207531452179
Iteration [16914]: Loss = 0.7000044584274292
Iteration [16915]: Loss = 0.6997911334037781
Iteration [16916]: Loss = 0.6995689272880554
Iteration [16917]: Loss = 0.6993383765220642
Iteration [16918]: Loss = 0.6991005539894104
Iteration [16919]: Loss = 0.6988560557365417
Iteration [16920]: Loss = 0.6986057162284851
Iteration [16921]: Loss = 0.6983500123023987
Iteration [16922]: Loss = 0.6980895400047302
Iteration [16923]: Loss = 0.6978246569633484
Iteration [16924]: Loss = 0.6975559592247009
Iteration [16925]: Loss = 0.6972836852073669
Iteration [16926]: Loss = 4.961575031280518
Iteration [16927]: Loss = 4.962038993835449
Iteration [16928]: Loss = 0.69700026512146
Iteration [16929]: Loss = 0.697041928768158
Iteration [16930]: Loss = 0.6970493793487549
Iteration [16931]: Loss = 0.6970256567001343
Iteration [16932]: Loss = 0.6969741582870483
Iteration [16933]: Loss = 0.6968975067138672
Iteration [16934]: Loss = 0.6967982053756714
Iteration [16935]: Loss = 0.6966785192489624
Iteration [16936]: Loss = 0.6965404748916626
Iteration [16937]: Loss = 0.6963859796524048
Iteration [16938]: Loss = 0.6962167024612427
Iteration [16939]: Loss = 0.6960339546203613
Iteration [16940]: Loss = 0.6958391070365906
Iteration [16941]: Loss = 4.968825340270996
Iteration [16942]: Loss = 0.6956084370613098
Iteration [16943]: Loss = 0.6955555081367493
Iteration [16944]: Loss = 0.6954777240753174
Iteration [16945]: Loss = 0.6953775882720947
Iteration [16946]: Loss = 0.6952568888664246
Iteration [16947]: Loss = 0.6951181292533875
Iteration [16948]: Loss = 0.6949629783630371
Iteration [16949]: Loss = 4.973268985748291
Iteration [16950]: Loss = 0.6948001384735107
Iteration [16951]: Loss = 0.6947762966156006
Iteration [16952]: Loss = 0.6947246789932251
Iteration [16953]: Loss = 0.6946479678153992
Iteration [16954]: Loss = 4.974562168121338
Iteration [16955]: Loss = 0.6946191787719727
Iteration [16956]: Loss = 0.6946526169776917
Iteration [16957]: Loss = 0.6946523785591125
Iteration [16958]: Loss = 4.9741740226745605
Iteration [16959]: Loss = 0.6947544813156128
Iteration [16960]: Loss = 0.6948434114456177
Iteration [16961]: Loss = 0.694893479347229
Iteration [16962]: Loss = 0.6949082612991333
Iteration [16963]: Loss = 0.6948913335800171
Iteration [16964]: Loss = 0.6948457956314087
Iteration [16965]: Loss = 0.6947746276855469
Iteration [16966]: Loss = 0.6946803331375122
Iteration [16967]: Loss = 4.974475860595703
Iteration [16968]: Loss = 0.6946214437484741
Iteration [16969]: Loss = 0.6946421265602112
Iteration [16970]: Loss = 0.6946302652359009
Iteration [16971]: Loss = 0.6945895552635193
Iteration [16972]: Loss = 4.974700450897217
Iteration [16973]: Loss = 4.974172115325928
Iteration [16974]: Loss = 0.6948716640472412
Iteration [16975]: Loss = 0.6950660347938538
Iteration [16976]: Loss = 0.6952109336853027
Iteration [16977]: Loss = 0.6953110098838806
Iteration [16978]: Loss = 0.6953709125518799
Iteration [16979]: Loss = 0.6953946352005005
Iteration [16980]: Loss = 0.6953856945037842
Iteration [16981]: Loss = 0.6953473687171936
Iteration [16982]: Loss = 0.6952824592590332
Iteration [16983]: Loss = 0.6951938271522522
Iteration [16984]: Loss = 0.6950835585594177
Iteration [16985]: Loss = 4.972415924072266
Iteration [16986]: Loss = 0.6949979662895203
Iteration [16987]: Loss = 0.6950070261955261
Iteration [16988]: Loss = 0.6949849128723145
Iteration [16989]: Loss = 0.6949347853660583
Iteration [16990]: Loss = 0.6948593258857727
Iteration [16991]: Loss = 4.973438262939453
Iteration [16992]: Loss = 0.6948329210281372
Iteration [16993]: Loss = 0.6948673129081726
Iteration [16994]: Loss = 0.6948680281639099
Iteration [16995]: Loss = 0.694838285446167
Iteration [16996]: Loss = 0.6947813034057617
Iteration [16997]: Loss = 0.6946996450424194
Iteration [16998]: Loss = 4.974312782287598
Iteration [16999]: Loss = 0.6946627497673035
Iteration [17000]: Loss = 0.6946927905082703
Iteration [17001]: Loss = 0.6946895122528076
Iteration [17002]: Loss = 4.973992347717285
Iteration [17003]: Loss = 4.973302841186523
Iteration [17004]: Loss = 0.6950636506080627
Iteration [17005]: Loss = 0.6952828168869019
Iteration [17006]: Loss = 0.695449948310852
Iteration [17007]: Loss = 0.695570170879364
Iteration [17008]: Loss = 0.6956480741500854
Iteration [17009]: Loss = 0.695688009262085
Iteration [17010]: Loss = 0.6956934928894043
Iteration [17011]: Loss = 0.6956681609153748
Iteration [17012]: Loss = 4.968924045562744
Iteration [17013]: Loss = 0.6957273483276367
Iteration [17014]: Loss = 0.6957980990409851
Iteration [17015]: Loss = 0.6958314180374146
Iteration [17016]: Loss = 0.6958310604095459
Iteration [17017]: Loss = 0.6958004832267761
Iteration [17018]: Loss = 4.968249320983887
Iteration [17019]: Loss = 0.6958505511283875
Iteration [17020]: Loss = 0.6959176063537598
Iteration [17021]: Loss = 0.695947527885437
Iteration [17022]: Loss = 0.69594407081604
Iteration [17023]: Loss = 0.6959105730056763
Iteration [17024]: Loss = 0.6958499550819397
Iteration [17025]: Loss = 0.69576495885849
Iteration [17026]: Loss = 0.6956581473350525
Iteration [17027]: Loss = 4.969364643096924
Iteration [17028]: Loss = 0.6955780982971191
Iteration [17029]: Loss = 0.6955896615982056
Iteration [17030]: Loss = 0.6955696940422058
Iteration [17031]: Loss = 0.6955214142799377
Iteration [17032]: Loss = 0.6954474449157715
Iteration [17033]: Loss = 0.6953504681587219
Iteration [17034]: Loss = 0.695232629776001
Iteration [17035]: Loss = 0.6950962543487549
Iteration [17036]: Loss = 0.6949428915977478
Iteration [17037]: Loss = 0.6947745084762573
Iteration [17038]: Loss = 0.6945924758911133
Iteration [17039]: Loss = 4.975358486175537
Iteration [17040]: Loss = 0.6943845152854919
Iteration [17041]: Loss = 0.694341778755188
Iteration [17042]: Loss = 0.694273054599762
Iteration [17043]: Loss = 0.6941806674003601
Iteration [17044]: Loss = 4.977114200592041
Iteration [17045]: Loss = 0.6941258907318115
Iteration [17046]: Loss = 4.976681709289551
Iteration [17047]: Loss = 0.6943296194076538
Iteration [17048]: Loss = 0.6944621801376343
Iteration [17049]: Loss = 4.974547863006592
Iteration [17050]: Loss = 0.6947919726371765
Iteration [17051]: Loss = 0.6949782371520996
Iteration [17052]: Loss = 0.6951156854629517
Iteration [17053]: Loss = 0.6952091455459595
Iteration [17054]: Loss = 0.6952626705169678
Iteration [17055]: Loss = 0.6952805519104004
Iteration [17056]: Loss = 0.6952663660049438
Iteration [17057]: Loss = 0.6952229738235474
Iteration [17058]: Loss = 4.971362113952637
Iteration [17059]: Loss = 0.6952517628669739
Iteration [17060]: Loss = 0.6953098177909851
Iteration [17061]: Loss = 0.6953318119049072
Iteration [17062]: Loss = 0.6953209638595581
Iteration [17063]: Loss = 0.695280909538269
Iteration [17064]: Loss = 0.6952142715454102
Iteration [17065]: Loss = 0.6951239705085754
Iteration [17066]: Loss = 0.6950119733810425
Iteration [17067]: Loss = 0.6948807835578918
Iteration [17068]: Loss = 0.694732129573822
Iteration [17069]: Loss = 0.694567859172821
Iteration [17070]: Loss = 4.975404739379883
Iteration [17071]: Loss = 0.6943904161453247
Iteration [17072]: Loss = 4.97555685043335
Iteration [17073]: Loss = 0.6944952011108398
Iteration [17074]: Loss = 0.6945858597755432
Iteration [17075]: Loss = 0.69463711977005
Iteration [17076]: Loss = 0.6946526169776917
Iteration [17077]: Loss = 0.694636344909668
Iteration [17078]: Loss = 9.254084587097168
Iteration [17079]: Loss = 0.6949002742767334
Iteration [17080]: Loss = 0.6951484680175781
Iteration [17081]: Loss = 0.6953417062759399
Iteration [17082]: Loss = 4.969606399536133
Iteration [17083]: Loss = 0.6957745552062988
Iteration [17084]: Loss = 0.6960043907165527
Iteration [17085]: Loss = 0.6961812376976013
Iteration [17086]: Loss = 0.6963101625442505
Iteration [17087]: Loss = 0.696395993232727
Iteration [17088]: Loss = 0.6964430212974548
Iteration [17089]: Loss = 0.6964548826217651
Iteration [17090]: Loss = 4.96459436416626
Iteration [17091]: Loss = 9.231114387512207
Iteration [17092]: Loss = 4.961355686187744
Iteration [17093]: Loss = 0.6976329684257507
Iteration [17094]: Loss = 0.6981281042098999
Iteration [17095]: Loss = 4.953505516052246
Iteration [17096]: Loss = 0.69907546043396
Iteration [17097]: Loss = 4.948369026184082
Iteration [17098]: Loss = 4.945436477661133
Iteration [17099]: Loss = 4.941981315612793
Iteration [17100]: Loss = 0.7014983296394348
Iteration [17101]: Loss = 4.934692859649658
Iteration [17102]: Loss = 0.702884316444397
Iteration [17103]: Loss = 0.7035197019577026
Iteration [17104]: Loss = 0.7040619850158691
Iteration [17105]: Loss = 4.922375679016113
Iteration [17106]: Loss = 4.919436454772949
Iteration [17107]: Loss = 0.705756425857544
Iteration [17108]: Loss = 0.7063276171684265
Iteration [17109]: Loss = 0.7068118453025818
Iteration [17110]: Loss = 0.7072176337242126
Iteration [17111]: Loss = 4.906744480133057
Iteration [17112]: Loss = 0.7080100774765015
Iteration [17113]: Loss = 0.7083917856216431
Iteration [17114]: Loss = 0.7087050676345825
Iteration [17115]: Loss = 0.7089565992355347
Iteration [17116]: Loss = 0.7091526985168457
Iteration [17117]: Loss = 0.7092984914779663
Iteration [17118]: Loss = 0.7093992233276367
Iteration [17119]: Loss = 0.7094593048095703
Iteration [17120]: Loss = 0.7094827890396118
Iteration [17121]: Loss = 0.7094731330871582
Iteration [17122]: Loss = 0.7094338536262512
Iteration [17123]: Loss = 0.7093678116798401
Iteration [17124]: Loss = 0.7092775702476501
Iteration [17125]: Loss = 0.709165632724762
Iteration [17126]: Loss = 0.7090342044830322
Iteration [17127]: Loss = 0.708885133266449
Iteration [17128]: Loss = 0.7087202072143555
Iteration [17129]: Loss = 0.7085410356521606
Iteration [17130]: Loss = 4.902657985687256
Iteration [17131]: Loss = 0.7083336710929871
Iteration [17132]: Loss = 0.7082892656326294
Iteration [17133]: Loss = 9.09843635559082
Iteration [17134]: Loss = 4.901896953582764
Iteration [17135]: Loss = 0.7089040279388428
Iteration [17136]: Loss = 0.7092395424842834
Iteration [17137]: Loss = 0.709511399269104
Iteration [17138]: Loss = 0.7097259163856506
Iteration [17139]: Loss = 4.89478063583374
Iteration [17140]: Loss = 0.7101902365684509
Iteration [17141]: Loss = 0.7104314565658569
Iteration [17142]: Loss = 0.7106181383132935
Iteration [17143]: Loss = 0.7107558250427246
Iteration [17144]: Loss = 0.7108492255210876
Iteration [17145]: Loss = 0.710902750492096
Iteration [17146]: Loss = 0.7109203338623047
Iteration [17147]: Loss = 0.7109055519104004
Iteration [17148]: Loss = 0.7108616232872009
Iteration [17149]: Loss = 0.7107913494110107
Iteration [17150]: Loss = 0.710697591304779
Iteration [17151]: Loss = 0.7105823159217834
Iteration [17152]: Loss = 0.7104480266571045
Iteration [17153]: Loss = 0.7102965712547302
Iteration [17154]: Loss = 0.7101294994354248
Iteration [17155]: Loss = 0.7099484801292419
Iteration [17156]: Loss = 0.7097547650337219
Iteration [17157]: Loss = 0.7095498442649841
Iteration [17158]: Loss = 0.7093346118927002
Iteration [17159]: Loss = 0.7091102600097656
Iteration [17160]: Loss = 0.7088777422904968
Iteration [17161]: Loss = 0.7086377739906311
Iteration [17162]: Loss = 0.7083910703659058
Iteration [17163]: Loss = 0.7081384658813477
Iteration [17164]: Loss = 0.7078803777694702
Iteration [17165]: Loss = 0.7076175212860107
Iteration [17166]: Loss = 0.7073502540588379
Iteration [17167]: Loss = 0.7070791125297546
Iteration [17168]: Loss = 0.7068043947219849
Iteration [17169]: Loss = 0.7065265774726868
Iteration [17170]: Loss = 0.7062458395957947
Iteration [17171]: Loss = 0.7059627771377563
Iteration [17172]: Loss = 0.7056772708892822
Iteration [17173]: Loss = 0.7053896188735962
Iteration [17174]: Loss = 0.7051002979278564
Iteration [17175]: Loss = 4.9208807945251465
Iteration [17176]: Loss = 0.7047054767608643
Iteration [17177]: Loss = 4.922058582305908
Iteration [17178]: Loss = 0.7046275734901428
Iteration [17179]: Loss = 0.7046386003494263
Iteration [17180]: Loss = 0.7046180963516235
Iteration [17181]: Loss = 0.7045691013336182
Iteration [17182]: Loss = 0.7044944763183594
Iteration [17183]: Loss = 0.7043968439102173
Iteration [17184]: Loss = 9.142972946166992
Iteration [17185]: Loss = 0.7045156955718994
Iteration [17186]: Loss = 4.921449661254883
Iteration [17187]: Loss = 0.7050201892852783
Iteration [17188]: Loss = 0.7052789926528931
Iteration [17189]: Loss = 0.7054818272590637
Iteration [17190]: Loss = 0.705634355545044
Iteration [17191]: Loss = 0.7057413458824158
Iteration [17192]: Loss = 0.7058073282241821
Iteration [17193]: Loss = 0.7058363556861877
Iteration [17194]: Loss = 0.7058322429656982
Iteration [17195]: Loss = 0.7057981491088867
Iteration [17196]: Loss = 0.7057369947433472
Iteration [17197]: Loss = 0.7056516408920288
Iteration [17198]: Loss = 0.7055444717407227
Iteration [17199]: Loss = 0.7054175138473511
Iteration [17200]: Loss = 0.7052727937698364
Iteration [17201]: Loss = 0.7051122188568115
Iteration [17202]: Loss = 0.7049371600151062
Iteration [17203]: Loss = 0.7047491669654846
Iteration [17204]: Loss = 0.7045496106147766
Iteration [17205]: Loss = 0.7043396830558777
Iteration [17206]: Loss = 0.7041200399398804
Iteration [17207]: Loss = 0.703892171382904
Iteration [17208]: Loss = 0.7036564946174622
Iteration [17209]: Loss = 0.7034140229225159
Iteration [17210]: Loss = 0.7031654715538025
Iteration [17211]: Loss = 0.7029112577438354
Iteration [17212]: Loss = 0.7026521563529968
Iteration [17213]: Loss = 4.933429718017578
Iteration [17214]: Loss = 0.702309250831604
Iteration [17215]: Loss = 4.934370994567871
Iteration [17216]: Loss = 0.7022735476493835
Iteration [17217]: Loss = 0.7023026347160339
Iteration [17218]: Loss = 0.7022985219955444
Iteration [17219]: Loss = 0.7022646069526672
Iteration [17220]: Loss = 0.7022037506103516
Iteration [17221]: Loss = 0.7021186351776123
Iteration [17222]: Loss = 0.70201176404953
Iteration [17223]: Loss = 0.7018850445747375
Iteration [17224]: Loss = 0.7017407417297363
Iteration [17225]: Loss = 0.7015805840492249
Iteration [17226]: Loss = 0.701405942440033
Iteration [17227]: Loss = 0.7012185454368591
Iteration [17228]: Loss = 0.701019287109375
Iteration [17229]: Loss = 0.7008097767829895
Iteration [17230]: Loss = 0.7005908489227295
Iteration [17231]: Loss = 0.7003633975982666
Iteration [17232]: Loss = 0.7001283168792725
Iteration [17233]: Loss = 4.946475028991699
Iteration [17234]: Loss = 0.6998273134231567
Iteration [17235]: Loss = 0.6997438669204712
Iteration [17236]: Loss = 4.94777250289917
Iteration [17237]: Loss = 0.7005372643470764
Iteration [17238]: Loss = 0.7005640268325806
Iteration [17239]: Loss = 0.7005578279495239
Iteration [17240]: Loss = 0.7005219459533691
Iteration [17241]: Loss = 0.7004591822624207
Iteration [17242]: Loss = 0.7003725171089172
Iteration [17243]: Loss = 4.944500923156738
Iteration [17244]: Loss = 0.7003248333930969
Iteration [17245]: Loss = 4.944055557250977
Iteration [17246]: Loss = 0.7005292177200317
Iteration [17247]: Loss = 0.7006610631942749
Iteration [17248]: Loss = 4.941967010498047
Iteration [17249]: Loss = 0.7009866237640381
Iteration [17250]: Loss = 0.7011699676513672
Iteration [17251]: Loss = 0.7013049125671387
Iteration [17252]: Loss = 4.938594341278076
Iteration [17253]: Loss = 0.7016356587409973
Iteration [17254]: Loss = 0.7018211483955383
Iteration [17255]: Loss = 4.935668468475342
Iteration [17256]: Loss = 0.7022385001182556
Iteration [17257]: Loss = 0.7024608254432678
Iteration [17258]: Loss = 0.7026306390762329
Iteration [17259]: Loss = 0.7027533054351807
Iteration [17260]: Loss = 0.7028332948684692
Iteration [17261]: Loss = 0.7028749585151672
Iteration [17262]: Loss = 0.7028820514678955
Iteration [17263]: Loss = 0.7028578519821167
Iteration [17264]: Loss = 0.7028058767318726
Iteration [17265]: Loss = 0.7027285099029541
Iteration [17266]: Loss = 4.932184219360352
Iteration [17267]: Loss = 0.7026962041854858
Iteration [17268]: Loss = 0.7027270197868347
Iteration [17269]: Loss = 0.7027243971824646
Iteration [17270]: Loss = 0.7026915550231934
Iteration [17271]: Loss = 4.9321675300598145
Iteration [17272]: Loss = 0.7027354836463928
Iteration [17273]: Loss = 0.7027986645698547
Iteration [17274]: Loss = 0.702825129032135
Iteration [17275]: Loss = 0.7028186321258545
Iteration [17276]: Loss = 0.702782154083252
Iteration [17277]: Loss = 0.7027188539505005
Iteration [17278]: Loss = 0.7026313543319702
Iteration [17279]: Loss = 0.7025222182273865
Iteration [17280]: Loss = 4.933404445648193
Iteration [17281]: Loss = 4.933183670043945
Iteration [17282]: Loss = 0.7026320695877075
Iteration [17283]: Loss = 0.7027783393859863
Iteration [17284]: Loss = 0.7028795480728149
Iteration [17285]: Loss = 0.7029403448104858
Iteration [17286]: Loss = 0.7029645442962646
Iteration [17287]: Loss = 0.7029557228088379
Iteration [17288]: Loss = 0.7029174566268921
Iteration [17289]: Loss = 0.7028524875640869
Iteration [17290]: Loss = 0.7027633786201477
Iteration [17291]: Loss = 0.7026526927947998
Iteration [17292]: Loss = 0.7025224566459656
Iteration [17293]: Loss = 4.933501243591309
Iteration [17294]: Loss = 0.7024004459381104
Iteration [17295]: Loss = 0.702393114566803
Iteration [17296]: Loss = 0.7023559212684631
Iteration [17297]: Loss = 0.7022920250892639
Iteration [17298]: Loss = 0.7022039890289307
Iteration [17299]: Loss = 0.7020941972732544
Iteration [17300]: Loss = 0.7019647359848022
Iteration [17301]: Loss = 0.7018176913261414
Iteration [17302]: Loss = 4.937247276306152
Iteration [17303]: Loss = 0.7016671299934387
Iteration [17304]: Loss = 0.7016477584838867
Iteration [17305]: Loss = 0.7015998363494873
Iteration [17306]: Loss = 0.7015261650085449
Iteration [17307]: Loss = 0.7014293670654297
Iteration [17308]: Loss = 0.7013117074966431
Iteration [17309]: Loss = 0.7011751532554626
Iteration [17310]: Loss = 0.7010217308998108
Iteration [17311]: Loss = 0.700853168964386
Iteration [17312]: Loss = 0.7006708383560181
Iteration [17313]: Loss = 4.943393230438232
Iteration [17314]: Loss = 0.7004603147506714
Iteration [17315]: Loss = 0.7004156112670898
Iteration [17316]: Loss = 0.7003449201583862
Iteration [17317]: Loss = 4.944570541381836
Iteration [17318]: Loss = 0.7003251910209656
Iteration [17319]: Loss = 0.7003618478775024
Iteration [17320]: Loss = 0.700364351272583
Iteration [17321]: Loss = 0.7003359794616699
Iteration [17322]: Loss = 9.188554763793945
Iteration [17323]: Loss = 4.942872524261475
Iteration [17324]: Loss = 0.7009992599487305
Iteration [17325]: Loss = 0.7013503909111023
Iteration [17326]: Loss = 4.937342643737793
Iteration [17327]: Loss = 0.7020508646965027
Iteration [17328]: Loss = 4.933401107788086
Iteration [17329]: Loss = 0.7028594613075256
Iteration [17330]: Loss = 4.9289631843566895
Iteration [17331]: Loss = 0.7037551999092102
Iteration [17332]: Loss = 0.704181432723999
Iteration [17333]: Loss = 0.7045348882675171
Iteration [17334]: Loss = 0.7048229575157166
Iteration [17335]: Loss = 0.7050520181655884
Iteration [17336]: Loss = 0.705227792263031
Iteration [17337]: Loss = 0.705355703830719
Iteration [17338]: Loss = 0.7054404616355896
Iteration [17339]: Loss = 0.7054861783981323
Iteration [17340]: Loss = 0.7054967880249023
Iteration [17341]: Loss = 0.705475926399231
Iteration [17342]: Loss = 0.7054266929626465
Iteration [17343]: Loss = 0.705351710319519
Iteration [17344]: Loss = 0.7052536606788635
Iteration [17345]: Loss = 0.705134928226471
Iteration [17346]: Loss = 0.7049973607063293
Iteration [17347]: Loss = 0.7048429846763611
Iteration [17348]: Loss = 0.7046734094619751
Iteration [17349]: Loss = 0.7044903635978699
Iteration [17350]: Loss = 0.7042949795722961
Iteration [17351]: Loss = 4.924609661102295
Iteration [17352]: Loss = 4.924752712249756
Iteration [17353]: Loss = 0.7041937112808228
Iteration [17354]: Loss = 0.7042828798294067
Iteration [17355]: Loss = 0.704332709312439
Iteration [17356]: Loss = 0.7043471336364746
Iteration [17357]: Loss = 0.7043295502662659
Iteration [17358]: Loss = 0.7042832374572754
Iteration [17359]: Loss = 0.7042108178138733
Iteration [17360]: Loss = 0.7041152119636536
Iteration [17361]: Loss = 0.7039986848831177
Iteration [17362]: Loss = 0.7038631439208984
Iteration [17363]: Loss = 4.926567554473877
Iteration [17364]: Loss = 0.7037314176559448
Iteration [17365]: Loss = 0.7037198543548584
Iteration [17366]: Loss = 0.7036789059638977
Iteration [17367]: Loss = 0.703611433506012
Iteration [17368]: Loss = 0.7035201191902161
Iteration [17369]: Loss = 0.7034075260162354
Iteration [17370]: Loss = 0.7032754421234131
Iteration [17371]: Loss = 4.929598808288574
Iteration [17372]: Loss = 0.70315021276474
Iteration [17373]: Loss = 0.7031412720680237
Iteration [17374]: Loss = 0.7031027674674988
Iteration [17375]: Loss = 9.15707778930664
Iteration [17376]: Loss = 0.7033236026763916
Iteration [17377]: Loss = 0.7035508751869202
Iteration [17378]: Loss = 0.703725278377533
Iteration [17379]: Loss = 0.7038519382476807
Iteration [17380]: Loss = 0.7039358019828796
Iteration [17381]: Loss = 0.7039808630943298
Iteration [17382]: Loss = 0.7039911150932312
Iteration [17383]: Loss = 0.7039700150489807
Iteration [17384]: Loss = 0.7039204835891724
Iteration [17385]: Loss = 0.7038456797599792
Iteration [17386]: Loss = 0.7037477493286133
Iteration [17387]: Loss = 0.7036292552947998
Iteration [17388]: Loss = 0.7034922242164612
Iteration [17389]: Loss = 0.7033383846282959
Iteration [17390]: Loss = 0.7031694650650024
Iteration [17391]: Loss = 0.7029869556427002
Iteration [17392]: Loss = 0.7111811637878418
Iteration [17393]: Loss = 0.7025817632675171
Iteration [17394]: Loss = 0.7023617029190063
Iteration [17395]: Loss = 0.7021332383155823
Iteration [17396]: Loss = 0.7018972635269165
Iteration [17397]: Loss = 0.7016543745994568
Iteration [17398]: Loss = 0.7014054656028748
Iteration [17399]: Loss = 0.7011508941650391
Iteration [17400]: Loss = 0.700891375541687
Iteration [17401]: Loss = 0.700627326965332
Iteration [17402]: Loss = 0.7003594040870667
Iteration [17403]: Loss = 9.190756797790527
Iteration [17404]: Loss = 0.7001901268959045
Iteration [17405]: Loss = 4.944562911987305
Iteration [17406]: Loss = 0.7004649639129639
Iteration [17407]: Loss = 0.7006263732910156
Iteration [17408]: Loss = 0.7007418274879456
Iteration [17409]: Loss = 0.7008155584335327
Iteration [17410]: Loss = 0.7008518576622009
Iteration [17411]: Loss = 4.94141960144043
Iteration [17412]: Loss = 0.7010136842727661
Iteration [17413]: Loss = 0.7011269927024841
Iteration [17414]: Loss = 4.93962287902832
Iteration [17415]: Loss = 0.7014203667640686
Iteration [17416]: Loss = 0.7015897035598755
Iteration [17417]: Loss = 0.7017120122909546
Iteration [17418]: Loss = 0.7017920613288879
Iteration [17419]: Loss = 0.7018339037895203
Iteration [17420]: Loss = 0.7018413543701172
Iteration [17421]: Loss = 0.7018179893493652
Iteration [17422]: Loss = 4.936664581298828
Iteration [17423]: Loss = 4.936087131500244
Iteration [17424]: Loss = 4.934752941131592
Iteration [17425]: Loss = 0.7025211453437805
Iteration [17426]: Loss = 0.702839732170105
Iteration [17427]: Loss = 0.7030963897705078
Iteration [17428]: Loss = 0.7032973170280457
Iteration [17429]: Loss = 0.7034481763839722
Iteration [17430]: Loss = 0.7035536766052246
Iteration [17431]: Loss = 0.703618586063385
Iteration [17432]: Loss = 0.7036466598510742
Iteration [17433]: Loss = 0.7036415934562683
Iteration [17434]: Loss = 0.7036066651344299
Iteration [17435]: Loss = 0.7035449743270874
Iteration [17436]: Loss = 0.7034592032432556
Iteration [17437]: Loss = 4.92842960357666
Iteration [17438]: Loss = 0.703411877155304
Iteration [17439]: Loss = 0.7034359574317932
Iteration [17440]: Loss = 0.703427255153656
Iteration [17441]: Loss = 0.7033891081809998
Iteration [17442]: Loss = 0.7033244371414185
Iteration [17443]: Loss = 0.703235924243927
Iteration [17444]: Loss = 0.7031259536743164
Iteration [17445]: Loss = 0.702996551990509
Iteration [17446]: Loss = 0.7028496861457825
Iteration [17447]: Loss = 0.7026870846748352
Iteration [17448]: Loss = 0.702510416507721
Iteration [17449]: Loss = 0.7023210525512695
Iteration [17450]: Loss = 0.7021201252937317
Iteration [17451]: Loss = 0.701909065246582
Iteration [17452]: Loss = 0.7016887068748474
Iteration [17453]: Loss = 0.7014600038528442
Iteration [17454]: Loss = 0.7012237310409546
Iteration [17455]: Loss = 0.7009807229042053
Iteration [17456]: Loss = 0.7007316946983337
Iteration [17457]: Loss = 0.7004772424697876
Iteration [17458]: Loss = 0.7002178430557251
Iteration [17459]: Loss = 0.6999540328979492
Iteration [17460]: Loss = 0.6996862888336182
Iteration [17461]: Loss = 0.6994149088859558
Iteration [17462]: Loss = 4.950379848480225
Iteration [17463]: Loss = 0.6990522146224976
Iteration [17464]: Loss = 0.6989424824714661
Iteration [17465]: Loss = 4.952093124389648
Iteration [17466]: Loss = 0.6988558769226074
Iteration [17467]: Loss = 0.6988638639450073
Iteration [17468]: Loss = 0.6988407969474792
Iteration [17469]: Loss = 0.6987898349761963
Iteration [17470]: Loss = 0.6987136602401733
Iteration [17471]: Loss = 0.6986149549484253
Iteration [17472]: Loss = 0.6984957456588745
Iteration [17473]: Loss = 0.6983581185340881
Iteration [17474]: Loss = 4.955289840698242
Iteration [17475]: Loss = 4.955183982849121
Iteration [17476]: Loss = 0.6984005570411682
Iteration [17477]: Loss = 0.6985291242599487
Iteration [17478]: Loss = 4.953135013580322
Iteration [17479]: Loss = 0.6988497972488403
Iteration [17480]: Loss = 0.6990313529968262
Iteration [17481]: Loss = 0.6991645693778992
Iteration [17482]: Loss = 0.6992543935775757
Iteration [17483]: Loss = 0.69930499792099
Iteration [17484]: Loss = 0.6993203163146973
Iteration [17485]: Loss = 0.6993038058280945
Iteration [17486]: Loss = 0.6992587447166443
Iteration [17487]: Loss = 4.950131893157959
Iteration [17488]: Loss = 0.6992823481559753
Iteration [17489]: Loss = 0.6993373036384583
Iteration [17490]: Loss = 0.6993564963340759
Iteration [17491]: Loss = 4.949315071105957
Iteration [17492]: Loss = 0.6994902491569519
Iteration [17493]: Loss = 0.6995919942855835
Iteration [17494]: Loss = 0.6996533870697021
Iteration [17495]: Loss = 0.699678361415863
Iteration [17496]: Loss = 0.6996705532073975
Iteration [17497]: Loss = 0.6996331214904785
Iteration [17498]: Loss = 0.6995692849159241
Iteration [17499]: Loss = 0.6994813680648804
Iteration [17500]: Loss = 0.6993718147277832
Iteration [17501]: Loss = 0.6992430090904236
Iteration [17502]: Loss = 0.6990965604782104
Iteration [17503]: Loss = 0.6989344358444214
Iteration [17504]: Loss = 4.952382564544678
Iteration [17505]: Loss = 0.698758602142334
Iteration [17506]: Loss = 0.6987286806106567
Iteration [17507]: Loss = 0.6986714601516724
Iteration [17508]: Loss = 0.698589563369751
Iteration [17509]: Loss = 0.6984855532646179
Iteration [17510]: Loss = 0.6983616352081299
Iteration [17511]: Loss = 4.955207824707031
Iteration [17512]: Loss = 0.6982510089874268
Iteration [17513]: Loss = 0.698249101638794
Iteration [17514]: Loss = 0.69821697473526
Iteration [17515]: Loss = 0.698157787322998
Iteration [17516]: Loss = 0.6980741620063782
Iteration [17517]: Loss = 0.6979684829711914
Iteration [17518]: Loss = 4.957185745239258
Iteration [17519]: Loss = 0.6978894472122192
Iteration [17520]: Loss = 0.6979009509086609
Iteration [17521]: Loss = 0.6978809833526611
Iteration [17522]: Loss = 4.957241058349609
Iteration [17523]: Loss = 0.6979482769966125
Iteration [17524]: Loss = 0.6980220675468445
Iteration [17525]: Loss = 0.6980582475662231
Iteration [17526]: Loss = 0.6980605125427246
Iteration [17527]: Loss = 0.6980322599411011
Iteration [17528]: Loss = 0.6979764103889465
Iteration [17529]: Loss = 0.6978958249092102
Iteration [17530]: Loss = 4.957448959350586
Iteration [17531]: Loss = 4.957098484039307
Iteration [17532]: Loss = 0.6980786323547363
Iteration [17533]: Loss = 0.6982454061508179
Iteration [17534]: Loss = 4.954442501068115
Iteration [17535]: Loss = 0.698632001876831
Iteration [17536]: Loss = 0.6988416910171509
Iteration [17537]: Loss = 0.6990002989768982
Iteration [17538]: Loss = 0.6991128921508789
Iteration [17539]: Loss = 0.6991837620735168
Iteration [17540]: Loss = 9.200737953186035
Iteration [17541]: Loss = 0.6995922327041626
Iteration [17542]: Loss = 4.946405410766602
Iteration [17543]: Loss = 0.7003335952758789
Iteration [17544]: Loss = 0.7006942629814148
Iteration [17545]: Loss = 0.7009888887405396
Iteration [17546]: Loss = 0.7012242078781128
Iteration [17547]: Loss = 0.7014057040214539
Iteration [17548]: Loss = 0.7015389800071716
Iteration [17549]: Loss = 0.7016286849975586
Iteration [17550]: Loss = 0.7016792893409729
Iteration [17551]: Loss = 0.7016945481300354
Iteration [17552]: Loss = 0.7016778588294983
Iteration [17553]: Loss = 0.7016326189041138
Iteration [17554]: Loss = 0.7015615701675415
Iteration [17555]: Loss = 0.7014672160148621
Iteration [17556]: Loss = 0.7013519406318665
Iteration [17557]: Loss = 4.939523696899414
Iteration [17558]: Loss = 0.701255202293396
Iteration [17559]: Loss = 0.7012585401535034
Iteration [17560]: Loss = 0.7012311816215515
Iteration [17561]: Loss = 4.939740180969238
Iteration [17562]: Loss = 0.7012848854064941
Iteration [17563]: Loss = 0.7013522982597351
Iteration [17564]: Loss = 0.7013826966285706
Iteration [17565]: Loss = 0.7013797163963318
Iteration [17566]: Loss = 0.701346755027771
Iteration [17567]: Loss = 0.7012866735458374
Iteration [17568]: Loss = 0.7012023329734802
Iteration [17569]: Loss = 0.7010959386825562
Iteration [17570]: Loss = 0.7009696960449219
Iteration [17571]: Loss = 0.7008258700370789
Iteration [17572]: Loss = 0.7006659507751465
Iteration [17573]: Loss = 0.7004916071891785
Iteration [17574]: Loss = 0.7003043293952942
Iteration [17575]: Loss = 0.7001053094863892
Iteration [17576]: Loss = 0.6998957991600037
Iteration [17577]: Loss = 0.6996768116950989
Iteration [17578]: Loss = 4.948761940002441
Iteration [17579]: Loss = 0.6994036436080933
Iteration [17580]: Loss = 0.6993322372436523
Iteration [17581]: Loss = 4.949871063232422
Iteration [17582]: Loss = 0.6993110179901123
Iteration [17583]: Loss = 0.6993468999862671
Iteration [17584]: Loss = 0.6993489265441895
Iteration [17585]: Loss = 0.699320375919342
Iteration [17586]: Loss = 0.6992643475532532
Iteration [17587]: Loss = 4.950153350830078
Iteration [17588]: Loss = 0.6992697715759277
Iteration [17589]: Loss = 4.949455738067627
Iteration [17590]: Loss = 4.948404312133789
Iteration [17591]: Loss = 0.6998562216758728
Iteration [17592]: Loss = 0.7001307010650635
Iteration [17593]: Loss = 0.700347900390625
Iteration [17594]: Loss = 0.7005131244659424
Iteration [17595]: Loss = 0.7006314992904663
Iteration [17596]: Loss = 0.7007077932357788
Iteration [17597]: Loss = 0.7007461190223694
Iteration [17598]: Loss = 4.941962718963623
Iteration [17599]: Loss = 0.7009124159812927
Iteration [17600]: Loss = 0.7010278701782227
Iteration [17601]: Loss = 0.7011014819145203
Iteration [17602]: Loss = 0.7011375427246094
Iteration [17603]: Loss = 4.939932346343994
Iteration [17604]: Loss = 0.7012995481491089
Iteration [17605]: Loss = 0.7014132738113403
Iteration [17606]: Loss = 0.701485276222229
Iteration [17607]: Loss = 4.937952041625977
Iteration [17608]: Loss = 0.7017087340354919
Iteration [17609]: Loss = 4.936238765716553
Iteration [17610]: Loss = 0.7021324038505554
Iteration [17611]: Loss = 0.7023574709892273
Iteration [17612]: Loss = 0.7025299072265625
Iteration [17613]: Loss = 0.7026547193527222
Iteration [17614]: Loss = 0.7027365565299988
Iteration [17615]: Loss = 0.7027798891067505
Iteration [17616]: Loss = 0.7027882933616638
Iteration [17617]: Loss = 4.931471347808838
Iteration [17618]: Loss = 0.702903151512146
Iteration [17619]: Loss = 0.702996551990509
Iteration [17620]: Loss = 0.7030502557754517
Iteration [17621]: Loss = 4.929900169372559
Iteration [17622]: Loss = 0.7032420635223389
Iteration [17623]: Loss = 0.7033683657646179
Iteration [17624]: Loss = 0.7034516334533691
Iteration [17625]: Loss = 0.7034959197044373
Iteration [17626]: Loss = 4.92763090133667
Iteration [17627]: Loss = 0.7036720514297485
Iteration [17628]: Loss = 0.7037915587425232
Iteration [17629]: Loss = 0.703868567943573
Iteration [17630]: Loss = 4.9255475997924805
Iteration [17631]: Loss = 0.7041003108024597
Iteration [17632]: Loss = 0.7042434811592102
Iteration [17633]: Loss = 0.7043418288230896
Iteration [17634]: Loss = 0.7043999433517456
Iteration [17635]: Loss = 0.7044216394424438
Iteration [17636]: Loss = 0.7044105529785156
Iteration [17637]: Loss = 0.7043699622154236
Iteration [17638]: Loss = 4.9235005378723145
Iteration [17639]: Loss = 0.7044005393981934
Iteration [17640]: Loss = 0.7044580578804016
Iteration [17641]: Loss = 0.7044792771339417
Iteration [17642]: Loss = 4.922646522521973
Iteration [17643]: Loss = 0.7046155333518982
Iteration [17644]: Loss = 0.7047180533409119
Iteration [17645]: Loss = 0.7047796845436096
Iteration [17646]: Loss = 0.7048046588897705
Iteration [17647]: Loss = 0.704796314239502
Iteration [17648]: Loss = 0.70475834608078
Iteration [17649]: Loss = 0.7046934366226196
Iteration [17650]: Loss = 0.7046042084693909
Iteration [17651]: Loss = 0.7044934034347534
Iteration [17652]: Loss = 0.7043628096580505
Iteration [17653]: Loss = 0.7042146921157837
Iteration [17654]: Loss = 0.7040506601333618
Iteration [17655]: Loss = 0.7038722634315491
Iteration [17656]: Loss = 0.7036811113357544
Iteration [17657]: Loss = 0.703478217124939
Iteration [17658]: Loss = 0.7032649517059326
Iteration [17659]: Loss = 0.7030422687530518
Iteration [17660]: Loss = 4.9312334060668945
Iteration [17661]: Loss = 4.931485652923584
Iteration [17662]: Loss = 0.7028775215148926
Iteration [17663]: Loss = 0.7029505968093872
Iteration [17664]: Loss = 0.7029857039451599
Iteration [17665]: Loss = 0.7029867172241211
Iteration [17666]: Loss = 0.7029570937156677
Iteration [17667]: Loss = 0.7028997540473938
Iteration [17668]: Loss = 0.7028173208236694
Iteration [17669]: Loss = 0.7027127146720886
Iteration [17670]: Loss = 4.932394981384277
Iteration [17671]: Loss = 0.7026343941688538
Iteration [17672]: Loss = 0.7026458978652954
Iteration [17673]: Loss = 0.7026256918907166
Iteration [17674]: Loss = 4.932451248168945
Iteration [17675]: Loss = 4.931854248046875
Iteration [17676]: Loss = 0.702953577041626
Iteration [17677]: Loss = 0.703158974647522
Iteration [17678]: Loss = 0.7033133506774902
Iteration [17679]: Loss = 0.7034216523170471
Iteration [17680]: Loss = 0.7034885883331299
Iteration [17681]: Loss = 0.7035182118415833
Iteration [17682]: Loss = 0.7035140991210938
Iteration [17683]: Loss = 0.7034799456596375
Iteration [17684]: Loss = 4.928082466125488
Iteration [17685]: Loss = 0.7035219669342041
Iteration [17686]: Loss = 0.703584611415863
Iteration [17687]: Loss = 0.7036102414131165
Iteration [17688]: Loss = 0.70360267162323
Iteration [17689]: Loss = 0.7035651803016663
Iteration [17690]: Loss = 0.7035007476806641
Iteration [17691]: Loss = 0.7034119963645935
Iteration [17692]: Loss = 0.7033014297485352
Iteration [17693]: Loss = 0.7031711339950562
Iteration [17694]: Loss = 0.7030230164527893
Iteration [17695]: Loss = 0.702859103679657
Iteration [17696]: Loss = 0.7026807069778442
Iteration [17697]: Loss = 0.7024893760681152
Iteration [17698]: Loss = 4.933959484100342
Iteration [17699]: Loss = 0.7022636532783508
Iteration [17700]: Loss = 0.702212393283844
Iteration [17701]: Loss = 9.167354583740234
Iteration [17702]: Loss = 4.933299541473389
Iteration [17703]: Loss = 0.7028211951255798
Iteration [17704]: Loss = 9.155709266662598
Iteration [17705]: Loss = 0.7038009166717529
Iteration [17706]: Loss = 4.92325496673584
Iteration [17707]: Loss = 0.7049999237060547
Iteration [17708]: Loss = 0.7055552005767822
Iteration [17709]: Loss = 0.7060251832008362
Iteration [17710]: Loss = 0.7064183354377747
Iteration [17711]: Loss = 0.706741988658905
Iteration [17712]: Loss = 0.7070031762123108
Iteration [17713]: Loss = 0.707207977771759
Iteration [17714]: Loss = 4.907724380493164
Iteration [17715]: Loss = 0.7076565623283386
Iteration [17716]: Loss = 0.7078915238380432
Iteration [17717]: Loss = 0.7080724835395813
Iteration [17718]: Loss = 0.7082052230834961
Iteration [17719]: Loss = 0.7082940936088562
Iteration [17720]: Loss = 0.7083435654640198
Iteration [17721]: Loss = 4.902614116668701
Iteration [17722]: Loss = 0.708526611328125
Iteration [17723]: Loss = 0.7086482644081116
Iteration [17724]: Loss = 0.708727240562439
Iteration [17725]: Loss = 0.7087677717208862
Iteration [17726]: Loss = 4.900482177734375
Iteration [17727]: Loss = 0.7089354991912842
Iteration [17728]: Loss = 0.7090505361557007
Iteration [17729]: Loss = 0.7091236114501953
Iteration [17730]: Loss = 0.709158718585968
Iteration [17731]: Loss = 0.709159791469574
Iteration [17732]: Loss = 0.7091301679611206
Iteration [17733]: Loss = 0.7090728282928467
Iteration [17734]: Loss = 0.708990752696991
Iteration [17735]: Loss = 0.7088859677314758
Iteration [17736]: Loss = 0.7087610960006714
Iteration [17737]: Loss = 0.7086179852485657
Iteration [17738]: Loss = 0.7084586024284363
Iteration [17739]: Loss = 0.7082843780517578
Iteration [17740]: Loss = 0.708096981048584
Iteration [17741]: Loss = 0.707897424697876
Iteration [17742]: Loss = 0.7076874375343323
Iteration [17743]: Loss = 0.7074675559997559
Iteration [17744]: Loss = 0.707239031791687
Iteration [17745]: Loss = 4.909571647644043
Iteration [17746]: Loss = 0.7069476842880249
Iteration [17747]: Loss = 0.7068675756454468
Iteration [17748]: Loss = 0.7067647576332092
Iteration [17749]: Loss = 0.7066417336463928
Iteration [17750]: Loss = 0.706500232219696
Iteration [17751]: Loss = 4.912970542907715
Iteration [17752]: Loss = 0.7063578367233276
Iteration [17753]: Loss = 0.7063411474227905
Iteration [17754]: Loss = 0.7062956094741821
Iteration [17755]: Loss = 0.7062239646911621
Iteration [17756]: Loss = 0.7061290740966797
Iteration [17757]: Loss = 0.7060127854347229
Iteration [17758]: Loss = 0.7058776617050171
Iteration [17759]: Loss = 0.7057253122329712
Iteration [17760]: Loss = 0.7055577635765076
Iteration [17761]: Loss = 0.7053760886192322
Iteration [17762]: Loss = 0.7051820755004883
Iteration [17763]: Loss = 0.7049768567085266
Iteration [17764]: Loss = 0.7047613263130188
Iteration [17765]: Loss = 0.7045369148254395
Iteration [17766]: Loss = 0.7043042182922363
Iteration [17767]: Loss = 0.704064130783081
Iteration [17768]: Loss = 0.70381760597229
Iteration [17769]: Loss = 4.9273223876953125
Iteration [17770]: Loss = 0.7034962773323059
Iteration [17771]: Loss = 0.703403890132904
Iteration [17772]: Loss = 0.7032902240753174
Iteration [17773]: Loss = 0.7031573057174683
Iteration [17774]: Loss = 0.7030072212219238
Iteration [17775]: Loss = 0.7028414011001587
Iteration [17776]: Loss = 0.7026616930961609
Iteration [17777]: Loss = 0.7024694085121155
Iteration [17778]: Loss = 0.7022656798362732
Iteration [17779]: Loss = 0.7020517587661743
Iteration [17780]: Loss = 4.936341285705566
Iteration [17781]: Loss = 0.7017868757247925
Iteration [17782]: Loss = 0.7017189264297485
Iteration [17783]: Loss = 0.7016271352767944
Iteration [17784]: Loss = 0.7015141248703003
Iteration [17785]: Loss = 0.7013817429542542
Iteration [17786]: Loss = 0.7012321352958679
Iteration [17787]: Loss = 4.940310478210449
Iteration [17788]: Loss = 4.9402570724487305
Iteration [17789]: Loss = 0.7012450098991394
Iteration [17790]: Loss = 4.938753604888916
Iteration [17791]: Loss = 0.7016324996948242
Iteration [17792]: Loss = 0.7018423080444336
Iteration [17793]: Loss = 0.7020009756088257
Iteration [17794]: Loss = 0.702113151550293
Iteration [17795]: Loss = 0.7021839022636414
Iteration [17796]: Loss = 0.7022169828414917
Iteration [17797]: Loss = 0.702216386795044
Iteration [17798]: Loss = 0.7021852135658264
Iteration [17799]: Loss = 0.7021265029907227
Iteration [17800]: Loss = 0.7020432949066162
Iteration [17801]: Loss = 0.7019377946853638
Iteration [17802]: Loss = 0.7018122673034668
Iteration [17803]: Loss = 4.9371747970581055
Iteration [17804]: Loss = 0.7016984224319458
Iteration [17805]: Loss = 0.701694905757904
Iteration [17806]: Loss = 0.7016609907150269
Iteration [17807]: Loss = 0.7015999555587769
Iteration [17808]: Loss = 0.7015146017074585
Iteration [17809]: Loss = 4.93853759765625
Iteration [17810]: Loss = 0.701469361782074
Iteration [17811]: Loss = 4.938079833984375
Iteration [17812]: Loss = 0.7016767859458923
Iteration [17813]: Loss = 0.7018098831176758
Iteration [17814]: Loss = 0.7018992304801941
Iteration [17815]: Loss = 0.7019492387771606
Iteration [17816]: Loss = 4.93563985824585
Iteration [17817]: Loss = 4.934746265411377
Iteration [17818]: Loss = 0.7024478316307068
Iteration [17819]: Loss = 0.7026990056037903
Iteration [17820]: Loss = 0.7028946876525879
Iteration [17821]: Loss = 0.703040361404419
Iteration [17822]: Loss = 0.703140914440155
Iteration [17823]: Loss = 0.7032008767127991
Iteration [17824]: Loss = 0.7032243609428406
Iteration [17825]: Loss = 9.155061721801758
Iteration [17826]: Loss = 0.7035512328147888
Iteration [17827]: Loss = 0.7038238644599915
Iteration [17828]: Loss = 0.7040390968322754
Iteration [17829]: Loss = 0.7042023539543152
Iteration [17830]: Loss = 0.7043189406394958
Iteration [17831]: Loss = 0.7043936848640442
Iteration [17832]: Loss = 0.704430341720581
Iteration [17833]: Loss = 0.7044329643249512
Iteration [17834]: Loss = 0.7044048309326172
Iteration [17835]: Loss = 0.7043489813804626
Iteration [17836]: Loss = 0.704268217086792
Iteration [17837]: Loss = 0.7041649222373962
Iteration [17838]: Loss = 0.7040413618087769
Iteration [17839]: Loss = 0.703899621963501
Iteration [17840]: Loss = 0.7037416696548462
Iteration [17841]: Loss = 0.7035688161849976
Iteration [17842]: Loss = 4.928267478942871
Iteration [17843]: Loss = 4.928315162658691
Iteration [17844]: Loss = 0.7035230398178101
Iteration [17845]: Loss = 0.7036272287368774
Iteration [17846]: Loss = 4.926670074462891
Iteration [17847]: Loss = 4.925558567047119
Iteration [17848]: Loss = 4.923744201660156
Iteration [17849]: Loss = 0.7047275900840759
Iteration [17850]: Loss = 0.7051223516464233
Iteration [17851]: Loss = 4.91758394241333
Iteration [17852]: Loss = 0.7058968544006348
Iteration [17853]: Loss = 0.706271231174469
Iteration [17854]: Loss = 4.9117584228515625
Iteration [17855]: Loss = 0.7070102095603943
Iteration [17856]: Loss = 0.707369327545166
Iteration [17857]: Loss = 0.7034331560134888
Iteration [17858]: Loss = 0.7036640048027039
Iteration [17859]: Loss = 0.7038414478302002
Iteration [17860]: Loss = 0.7039709687232971
Iteration [17861]: Loss = 4.924771785736084
Iteration [17862]: Loss = 0.704291820526123
Iteration [17863]: Loss = 4.92262077331543
Iteration [17864]: Loss = 0.704792320728302
Iteration [17865]: Loss = 0.7050497531890869
Iteration [17866]: Loss = 0.7052512168884277
Iteration [17867]: Loss = 0.7054023146629333
Iteration [17868]: Loss = 0.705507755279541
Iteration [17869]: Loss = 4.916940689086914
Iteration [17870]: Loss = 4.915830612182617
Iteration [17871]: Loss = 0.7061372399330139
Iteration [17872]: Loss = 0.7064222097396851
Iteration [17873]: Loss = 0.7066482305526733
Iteration [17874]: Loss = 0.7068213820457458
Iteration [17875]: Loss = 0.7069467306137085
Iteration [17876]: Loss = 0.7070290446281433
Iteration [17877]: Loss = 0.7070726156234741
Iteration [17878]: Loss = 0.7070813775062561
Iteration [17879]: Loss = 0.7070585489273071
Iteration [17880]: Loss = 0.7070075273513794
Iteration [17881]: Loss = 0.7069309949874878
Iteration [17882]: Loss = 4.910452842712402
Iteration [17883]: Loss = 0.7068991661071777
Iteration [17884]: Loss = 0.7069295644760132
Iteration [17885]: Loss = 0.7069264054298401
Iteration [17886]: Loss = 0.7068929672241211
Iteration [17887]: Loss = 0.7068321704864502
Iteration [17888]: Loss = 0.7067468166351318
Iteration [17889]: Loss = 0.7066395282745361
Iteration [17890]: Loss = 0.7065122127532959
Iteration [17891]: Loss = 0.706367015838623
Iteration [17892]: Loss = 0.7062054872512817
Iteration [17893]: Loss = 0.7060296535491943
Iteration [17894]: Loss = 0.7058407068252563
Iteration [17895]: Loss = 0.7056399583816528
Iteration [17896]: Loss = 0.7054286003112793
Iteration [17897]: Loss = 0.7052076458930969
Iteration [17898]: Loss = 0.704978346824646
Iteration [17899]: Loss = 4.9212327003479
Iteration [17900]: Loss = 0.7046861052513123
Iteration [17901]: Loss = 0.7046059966087341
Iteration [17902]: Loss = 4.922463417053223
Iteration [17903]: Loss = 0.7045688629150391
Iteration [17904]: Loss = 0.7045973539352417
Iteration [17905]: Loss = 0.7045925259590149
Iteration [17906]: Loss = 0.7045575380325317
Iteration [17907]: Loss = 0.7044954299926758
Iteration [17908]: Loss = 0.7044090032577515
Iteration [17909]: Loss = 0.7043006420135498
Iteration [17910]: Loss = 0.7041724920272827
Iteration [17911]: Loss = 0.7040265202522278
Iteration [17912]: Loss = 0.7038644552230835
Iteration [17913]: Loss = 0.7036880850791931
Iteration [17914]: Loss = 0.7034987211227417
Iteration [17915]: Loss = 0.7032974362373352
Iteration [17916]: Loss = 0.7030857801437378
Iteration [17917]: Loss = 0.7028647661209106
Iteration [17918]: Loss = 0.7026351690292358
Iteration [17919]: Loss = 0.7023979425430298
Iteration [17920]: Loss = 0.7021536827087402
Iteration [17921]: Loss = 4.935953140258789
Iteration [17922]: Loss = 0.7018373012542725
Iteration [17923]: Loss = 4.936765193939209
Iteration [17924]: Loss = 0.7018250226974487
Iteration [17925]: Loss = 0.7018646001815796
Iteration [17926]: Loss = 0.7018696069717407
Iteration [17927]: Loss = 0.701843798160553
Iteration [17928]: Loss = 0.7017897963523865
Iteration [17929]: Loss = 0.7017107605934143
Iteration [17930]: Loss = 0.701609194278717
Iteration [17931]: Loss = 0.7014870643615723
Iteration [17932]: Loss = 0.7013465166091919
Iteration [17933]: Loss = 0.7011895775794983
Iteration [17934]: Loss = 4.9405670166015625
Iteration [17935]: Loss = 0.7010223269462585
Iteration [17936]: Loss = 0.7009959816932678
Iteration [17937]: Loss = 0.7009416818618774
Iteration [17938]: Loss = 0.7008624076843262
Iteration [17939]: Loss = 0.7007604241371155
Iteration [17940]: Loss = 0.7006380558013916
Iteration [17941]: Loss = 0.7004973888397217
Iteration [17942]: Loss = 0.700340211391449
Iteration [17943]: Loss = 0.7001681923866272
Iteration [17944]: Loss = 0.6999828219413757
Iteration [17945]: Loss = 0.6997854113578796
Iteration [17946]: Loss = 0.6995770931243896
Iteration [17947]: Loss = 4.9492340087890625
Iteration [17948]: Loss = 0.6993227601051331
Iteration [17949]: Loss = 0.6992596983909607
Iteration [17950]: Loss = 4.9502129554748535
Iteration [17951]: Loss = 0.6992532014846802
Iteration [17952]: Loss = 0.6992956399917603
Iteration [17953]: Loss = 0.6993033289909363
Iteration [17954]: Loss = 0.6992798447608948
Iteration [17955]: Loss = 0.6992281675338745
Iteration [17956]: Loss = 0.6991511583328247
Iteration [17957]: Loss = 0.6990512609481812
Iteration [17958]: Loss = 0.6989308595657349
Iteration [17959]: Loss = 0.698792040348053
Iteration [17960]: Loss = 0.6986364126205444
Iteration [17961]: Loss = 0.698465883731842
Iteration [17962]: Loss = 0.6982818245887756
Iteration [17963]: Loss = 0.6980856657028198
Iteration [17964]: Loss = 0.6978784203529358
Iteration [17965]: Loss = 0.6976614594459534
Iteration [17966]: Loss = 4.959327220916748
Iteration [17967]: Loss = 0.6973928809165955
Iteration [17968]: Loss = 0.6973240375518799
Iteration [17969]: Loss = 0.6972315311431885
Iteration [17970]: Loss = 4.960999965667725
Iteration [17971]: Loss = 0.6971756219863892
Iteration [17972]: Loss = 0.6971971988677979
Iteration [17973]: Loss = 0.6971864104270935
Iteration [17974]: Loss = 4.960850715637207
Iteration [17975]: Loss = 0.6972697973251343
Iteration [17976]: Loss = 0.6973509788513184
Iteration [17977]: Loss = 0.6973934769630432
Iteration [17978]: Loss = 0.6974014043807983
Iteration [17979]: Loss = 0.6973779201507568
Iteration [17980]: Loss = 0.6973263025283813
Iteration [17981]: Loss = 0.6972495913505554
Iteration [17982]: Loss = 4.960831642150879
Iteration [17983]: Loss = 0.6972203850746155
Iteration [17984]: Loss = 9.22331714630127
Iteration [17985]: Loss = 4.958303451538086
Iteration [17986]: Loss = 0.6981276273727417
Iteration [17987]: Loss = 9.208452224731445
Iteration [17988]: Loss = 0.6992613673210144
Iteration [17989]: Loss = 0.6998764872550964
Iteration [17990]: Loss = 0.7004008293151855
Iteration [17991]: Loss = 0.7008429765701294
Iteration [17992]: Loss = 0.7012113332748413
Iteration [17993]: Loss = 0.7015127539634705
Iteration [17994]: Loss = 0.7017542123794556
Iteration [17995]: Loss = 0.7019415497779846
Iteration [17996]: Loss = 0.7020798325538635
Iteration [17997]: Loss = 0.702174186706543
Iteration [17998]: Loss = 0.7022289037704468
Iteration [17999]: Loss = 0.7022479176521301
Iteration [18000]: Loss = 0.7022347450256348
Iteration [18001]: Loss = 4.934448719024658
Iteration [18002]: Loss = 0.7023119926452637
Iteration [18003]: Loss = 0.702389121055603
Iteration [18004]: Loss = 0.7024284601211548
Iteration [18005]: Loss = 0.7024335861206055
Iteration [18006]: Loss = 0.7024077773094177
Iteration [18007]: Loss = 0.702354371547699
Iteration [18008]: Loss = 0.702275812625885
Iteration [18009]: Loss = 0.7021747827529907
Iteration [18010]: Loss = 0.7020534873008728
Iteration [18011]: Loss = 4.9358978271484375
Iteration [18012]: Loss = 0.7019463777542114
Iteration [18013]: Loss = 4.935735702514648
Iteration [18014]: Loss = 0.7021015286445618
Iteration [18015]: Loss = 0.7022119164466858
Iteration [18016]: Loss = 0.70228111743927
Iteration [18017]: Loss = 0.702313244342804
Iteration [18018]: Loss = 0.7023117542266846
Iteration [18019]: Loss = 0.7022800445556641
Iteration [18020]: Loss = 0.7022210955619812
Iteration [18021]: Loss = 0.7021377086639404
Iteration [18022]: Loss = 0.7020323276519775
Iteration [18023]: Loss = 0.7019069194793701
Iteration [18024]: Loss = 0.7017638087272644
Iteration [18025]: Loss = 0.7016044855117798
Iteration [18026]: Loss = 0.7014306783676147
Iteration [18027]: Loss = 4.939387798309326
Iteration [18028]: Loss = 0.7012341618537903
Iteration [18029]: Loss = 0.7011951208114624
Iteration [18030]: Loss = 0.7011294960975647
Iteration [18031]: Loss = 0.7010400891304016
Iteration [18032]: Loss = 0.7009293437004089
Iteration [18033]: Loss = 0.7007991671562195
Iteration [18034]: Loss = 0.7006515860557556
Iteration [18035]: Loss = 0.7004885077476501
Iteration [18036]: Loss = 0.7003111839294434
Iteration [18037]: Loss = 4.945247173309326
Iteration [18038]: Loss = 0.7001091241836548
Iteration [18039]: Loss = 0.7000676989555359
Iteration [18040]: Loss = 0.7000002264976501
Iteration [18041]: Loss = 0.6999090313911438
Iteration [18042]: Loss = 0.6997966766357422
Iteration [18043]: Loss = 0.6996651887893677
Iteration [18044]: Loss = 0.6995164155960083
Iteration [18045]: Loss = 0.6993521451950073
Iteration [18046]: Loss = 4.9502034187316895
Iteration [18047]: Loss = 4.950212001800537
Iteration [18048]: Loss = 0.6993296146392822
Iteration [18049]: Loss = 0.6994407176971436
Iteration [18050]: Loss = 0.6995105147361755
Iteration [18051]: Loss = 0.6995431184768677
Iteration [18052]: Loss = 0.6995422840118408
Iteration [18053]: Loss = 4.94843864440918
Iteration [18054]: Loss = 0.6996414661407471
Iteration [18055]: Loss = 0.6997286677360535
Iteration [18056]: Loss = 4.947048664093018
Iteration [18057]: Loss = 0.6999782919883728
Iteration [18058]: Loss = 0.700129508972168
Iteration [18059]: Loss = 0.7002354860305786
Iteration [18060]: Loss = 0.7003004550933838
Iteration [18061]: Loss = 0.7003285884857178
Iteration [18062]: Loss = 0.7003236413002014
Iteration [18063]: Loss = 0.7002888321876526
Iteration [18064]: Loss = 4.9446940422058105
Iteration [18065]: Loss = 0.7003300189971924
Iteration [18066]: Loss = 4.943830966949463
Iteration [18067]: Loss = 0.7006067037582397
Iteration [18068]: Loss = 0.7007694244384766
Iteration [18069]: Loss = 9.181626319885254
Iteration [18070]: Loss = 4.938923358917236
Iteration [18071]: Loss = 0.7018917798995972
Iteration [18072]: Loss = 0.7023651003837585
Iteration [18073]: Loss = 0.7027613520622253
Iteration [18074]: Loss = 0.7030879259109497
Iteration [18075]: Loss = 0.7033520936965942
Iteration [18076]: Loss = 0.7035596370697021
Iteration [18077]: Loss = 0.7037162780761719
Iteration [18078]: Loss = 4.925963401794434
Iteration [18079]: Loss = 0.7040833830833435
Iteration [18080]: Loss = 0.7042838931083679
Iteration [18081]: Loss = 4.922820568084717
Iteration [18082]: Loss = 0.7047258615493774
Iteration [18083]: Loss = 0.7049582004547119
Iteration [18084]: Loss = 0.705137312412262
Iteration [18085]: Loss = 0.7052680253982544
Iteration [18086]: Loss = 0.7053554654121399
Iteration [18087]: Loss = 0.705403745174408
Iteration [18088]: Loss = 0.7054167985916138
Iteration [18089]: Loss = 0.7053982019424438
Iteration [18090]: Loss = 0.7053509950637817
Iteration [18091]: Loss = 0.7052780985832214
Iteration [18092]: Loss = 0.7051819562911987
Iteration [18093]: Loss = 4.919559478759766
Iteration [18094]: Loss = 0.7051169276237488
Iteration [18095]: Loss = 0.7051331996917725
Iteration [18096]: Loss = 0.7051175236701965
Iteration [18097]: Loss = 4.91951847076416
Iteration [18098]: Loss = 0.7051899433135986
Iteration [18099]: Loss = 4.918527603149414
Iteration [18100]: Loss = 0.705488920211792
Iteration [18101]: Loss = 0.705660343170166
Iteration [18102]: Loss = 0.7057843208312988
Iteration [18103]: Loss = 0.7058655619621277
Iteration [18104]: Loss = 0.7059081792831421
Iteration [18105]: Loss = 4.915167331695557
Iteration [18106]: Loss = 0.7060800194740295
Iteration [18107]: Loss = 0.7061972618103027
Iteration [18108]: Loss = 0.7062724232673645
Iteration [18109]: Loss = 0.7063095569610596
Iteration [18110]: Loss = 0.7063124179840088
Iteration [18111]: Loss = 0.7062845826148987
Iteration [18112]: Loss = 0.706229031085968
Iteration [18113]: Loss = 0.7061483860015869
Iteration [18114]: Loss = 4.914501190185547
Iteration [18115]: Loss = 0.7061097025871277
Iteration [18116]: Loss = 0.7061372399330139
Iteration [18117]: Loss = 0.7061315774917603
Iteration [18118]: Loss = 0.7060959339141846
Iteration [18119]: Loss = 0.7060333490371704
Iteration [18120]: Loss = 0.7059464454650879
Iteration [18121]: Loss = 0.7058375477790833
Iteration [18122]: Loss = 0.7057089805603027
Iteration [18123]: Loss = 0.7055628299713135
Iteration [18124]: Loss = 0.7054004669189453
Iteration [18125]: Loss = 0.7052239179611206
Iteration [18126]: Loss = 4.919717311859131
Iteration [18127]: Loss = 0.7050216197967529
Iteration [18128]: Loss = 0.7049797773361206
Iteration [18129]: Loss = 0.704911470413208
Iteration [18130]: Loss = 0.7048194408416748
Iteration [18131]: Loss = 0.704706072807312
Iteration [18132]: Loss = 0.7045735716819763
Iteration [18133]: Loss = 0.7044236063957214
Iteration [18134]: Loss = 0.7042580842971802
Iteration [18135]: Loss = 0.7040786147117615
Iteration [18136]: Loss = 0.7038863897323608
Iteration [18137]: Loss = 0.7036828994750977
Iteration [18138]: Loss = 0.7034691572189331
Iteration [18139]: Loss = 0.7032461762428284
Iteration [18140]: Loss = 4.93017578125
Iteration [18141]: Loss = 0.7029653787612915
Iteration [18142]: Loss = 0.7028903961181641
Iteration [18143]: Loss = 4.931331634521484
Iteration [18144]: Loss = 0.7028622031211853
Iteration [18145]: Loss = 0.7028946876525879
Iteration [18146]: Loss = 0.7028935551643372
Iteration [18147]: Loss = 0.7028620839118958
Iteration [18148]: Loss = 0.7028031349182129
Iteration [18149]: Loss = 0.7027195692062378
Iteration [18150]: Loss = 0.702613890171051
Iteration [18151]: Loss = 0.7024883031845093
Iteration [18152]: Loss = 0.7023445963859558
Iteration [18153]: Loss = 0.7021848559379578
Iteration [18154]: Loss = 0.7020103931427002
Iteration [18155]: Loss = 4.936371326446533
Iteration [18156]: Loss = 0.7018129825592041
Iteration [18157]: Loss = 0.7017736434936523
Iteration [18158]: Loss = 0.701707661151886
Iteration [18159]: Loss = 0.7016178369522095
Iteration [18160]: Loss = 0.7015065550804138
Iteration [18161]: Loss = 0.7013757228851318
Iteration [18162]: Loss = 0.7012274265289307
Iteration [18163]: Loss = 4.940328598022461
Iteration [18164]: Loss = 4.940268516540527
Iteration [18165]: Loss = 0.7012437582015991
Iteration [18166]: Loss = 0.7013653516769409
Iteration [18167]: Loss = 0.7014445066452026
Iteration [18168]: Loss = 0.701485276222229
Iteration [18169]: Loss = 0.7014913558959961
Iteration [18170]: Loss = 0.7014665007591248
Iteration [18171]: Loss = 0.7014135122299194
Iteration [18172]: Loss = 0.7013353705406189
Iteration [18173]: Loss = 4.939436435699463
Iteration [18174]: Loss = 0.7013026475906372
Iteration [18175]: Loss = 0.7013335824012756
Iteration [18176]: Loss = 0.7013309001922607
Iteration [18177]: Loss = 0.7012979984283447
Iteration [18178]: Loss = 0.7012377977371216
Iteration [18179]: Loss = 0.7011531591415405
Iteration [18180]: Loss = 4.940418243408203
Iteration [18181]: Loss = 0.7011092901229858
Iteration [18182]: Loss = 0.7011356353759766
Iteration [18183]: Loss = 4.939987659454346
Iteration [18184]: Loss = 0.7012813091278076
Iteration [18185]: Loss = 0.7013881206512451
Iteration [18186]: Loss = 0.7014539241790771
Iteration [18187]: Loss = 0.7014825940132141
Iteration [18188]: Loss = 0.7014780640602112
Iteration [18189]: Loss = 0.7014433145523071
Iteration [18190]: Loss = 4.938670635223389
Iteration [18191]: Loss = 0.7014849185943604
Iteration [18192]: Loss = 4.937807083129883
Iteration [18193]: Loss = 0.7017622590065002
Iteration [18194]: Loss = 4.935839653015137
Iteration [18195]: Loss = 0.7022302150726318
Iteration [18196]: Loss = 4.932983875274658
Iteration [18197]: Loss = 0.7028520107269287
Iteration [18198]: Loss = 0.7031617164611816
Iteration [18199]: Loss = 0.7034102082252502
Iteration [18200]: Loss = 0.7036033868789673
Iteration [18201]: Loss = 0.7037467360496521
Iteration [18202]: Loss = 0.7038453221321106
Iteration [18203]: Loss = 0.7039033770561218
Iteration [18204]: Loss = 0.7039251923561096
Iteration [18205]: Loss = 0.7039141058921814
Iteration [18206]: Loss = 4.925723075866699
Iteration [18207]: Loss = 0.7039954662322998
Iteration [18208]: Loss = 0.7040747404098511
Iteration [18209]: Loss = 0.7041153311729431
Iteration [18210]: Loss = 0.7041214108467102
Iteration [18211]: Loss = 0.7040961980819702
Iteration [18212]: Loss = 0.7040426731109619
Iteration [18213]: Loss = 0.7039639949798584
Iteration [18214]: Loss = 0.7038624286651611
Iteration [18215]: Loss = 0.7037402391433716
Iteration [18216]: Loss = 0.7035995125770569
Iteration [18217]: Loss = 0.7034420967102051
Iteration [18218]: Loss = 0.7032697796821594
Iteration [18219]: Loss = 0.703083872795105
Iteration [18220]: Loss = 0.7028858065605164
Iteration [18221]: Loss = 4.9319305419921875
Iteration [18222]: Loss = 0.702648401260376
Iteration [18223]: Loss = 4.932372093200684
Iteration [18224]: Loss = 0.7027004361152649
Iteration [18225]: Loss = 0.7027673721313477
Iteration [18226]: Loss = 0.702796995639801
Iteration [18227]: Loss = 0.7027931213378906
Iteration [18228]: Loss = 4.931504726409912
Iteration [18229]: Loss = 4.930839538574219
Iteration [18230]: Loss = 0.7031611204147339
Iteration [18231]: Loss = 4.928296089172363
Iteration [18232]: Loss = 0.7037299871444702
Iteration [18233]: Loss = 0.7040172815322876
Iteration [18234]: Loss = 0.7042452096939087
Iteration [18235]: Loss = 0.7044198513031006
Iteration [18236]: Loss = 4.922239303588867
Iteration [18237]: Loss = 0.704818844795227
Iteration [18238]: Loss = 4.919723033905029
Iteration [18239]: Loss = 0.7053844928741455
Iteration [18240]: Loss = 0.7056701183319092
Iteration [18241]: Loss = 0.7058964967727661
Iteration [18242]: Loss = 0.7060697674751282
Iteration [18243]: Loss = 0.7061951160430908
Iteration [18244]: Loss = 0.7062771320343018
Iteration [18245]: Loss = 4.913084030151367
Iteration [18246]: Loss = 0.7065172791481018
Iteration [18247]: Loss = 0.706663966178894
Iteration [18248]: Loss = 0.706765353679657
Iteration [18249]: Loss = 0.7068256139755249
Iteration [18250]: Loss = 4.910360336303711
Iteration [18251]: Loss = 4.9094367027282715
Iteration [18252]: Loss = 0.7073483467102051
Iteration [18253]: Loss = 0.7076053023338318
Iteration [18254]: Loss = 0.7078059911727905
Iteration [18255]: Loss = 0.7079557776451111
Iteration [18256]: Loss = 0.7080599069595337
Iteration [18257]: Loss = 0.708122730255127
Iteration [18258]: Loss = 0.7081482410430908
Iteration [18259]: Loss = 0.7081406116485596
Iteration [18260]: Loss = 0.7081025242805481
Iteration [18261]: Loss = 0.7080375552177429
Iteration [18262]: Loss = 4.904715538024902
Iteration [18263]: Loss = 0.7080260515213013
Iteration [18264]: Loss = 0.7080652713775635
Iteration [18265]: Loss = 0.7080698609352112
Iteration [18266]: Loss = 4.9042277336120605
Iteration [18267]: Loss = 0.7081773281097412
Iteration [18268]: Loss = 0.708267331123352
Iteration [18269]: Loss = 0.7083174586296082
Iteration [18270]: Loss = 0.7083317041397095
Iteration [18271]: Loss = 0.7083134651184082
Iteration [18272]: Loss = 0.7082662582397461
Iteration [18273]: Loss = 0.7081926465034485
Iteration [18274]: Loss = 0.7080954909324646
Iteration [18275]: Loss = 0.7079769372940063
Iteration [18276]: Loss = 0.7078392505645752
Iteration [18277]: Loss = 0.7076842784881592
Iteration [18278]: Loss = 0.7075139880180359
Iteration [18279]: Loss = 4.907891273498535
Iteration [18280]: Loss = 0.7073227167129517
Iteration [18281]: Loss = 0.7072857022285461
Iteration [18282]: Loss = 4.908446311950684
Iteration [18283]: Loss = 0.7073225975036621
Iteration [18284]: Loss = 0.7073826789855957
Iteration [18285]: Loss = 4.907498836517334
Iteration [18286]: Loss = 0.707585334777832
Iteration [18287]: Loss = 0.7077161073684692
Iteration [18288]: Loss = 0.707802951335907
Iteration [18289]: Loss = 0.7078501582145691
Iteration [18290]: Loss = 0.7078617215156555
Iteration [18291]: Loss = 0.707841157913208
Iteration [18292]: Loss = 0.7077915668487549
Iteration [18293]: Loss = 0.7077161073684692
Iteration [18294]: Loss = 9.105212211608887
Iteration [18295]: Loss = 4.905091285705566
Iteration [18296]: Loss = 0.7082636952400208
Iteration [18297]: Loss = 0.7085835337638855
Iteration [18298]: Loss = 0.7088407278060913
Iteration [18299]: Loss = 0.7090415954589844
Iteration [18300]: Loss = 0.7091917991638184
Iteration [18301]: Loss = 4.89780855178833
Iteration [18302]: Loss = 0.7095472812652588
Iteration [18303]: Loss = 0.7097427845001221
Iteration [18304]: Loss = 0.7098879814147949
Iteration [18305]: Loss = 0.7099878787994385
Iteration [18306]: Loss = 0.7100468873977661
Iteration [18307]: Loss = 0.7100692391395569
Iteration [18308]: Loss = 4.893912315368652
Iteration [18309]: Loss = 0.7102062106132507
Iteration [18310]: Loss = 4.892635345458984
Iteration [18311]: Loss = 0.7105576992034912
Iteration [18312]: Loss = 0.7107512950897217
Iteration [18313]: Loss = 0.7108948230743408
Iteration [18314]: Loss = 0.7109930515289307
Iteration [18315]: Loss = 0.7110506892204285
Iteration [18316]: Loss = 0.7110715508460999
Iteration [18317]: Loss = 0.7110593914985657
Iteration [18318]: Loss = 0.7110174298286438
Iteration [18319]: Loss = 0.710948646068573
Iteration [18320]: Loss = 0.7108557820320129
Iteration [18321]: Loss = 0.7107411623001099
Iteration [18322]: Loss = 0.7106069326400757
Iteration [18323]: Loss = 0.7104552388191223
Iteration [18324]: Loss = 0.7102874517440796
Iteration [18325]: Loss = 0.7101055979728699
Iteration [18326]: Loss = 0.7099107503890991
Iteration [18327]: Loss = 0.7097044587135315
Iteration [18328]: Loss = 0.7094876766204834
Iteration [18329]: Loss = 0.7092615962028503
Iteration [18330]: Loss = 0.7090270519256592
Iteration [18331]: Loss = 0.7087849974632263
Iteration [18332]: Loss = 0.7085360288619995
Iteration [18333]: Loss = 0.7082809209823608
Iteration [18334]: Loss = 0.7080203890800476
Iteration [18335]: Loss = 0.707754909992218
Iteration [18336]: Loss = 0.7074849605560303
Iteration [18337]: Loss = 0.7072110772132874
Iteration [18338]: Loss = 0.7069334387779236
Iteration [18339]: Loss = 0.7066527009010315
Iteration [18340]: Loss = 0.7063690423965454
Iteration [18341]: Loss = 4.914307594299316
Iteration [18342]: Loss = 0.7059847712516785
Iteration [18343]: Loss = 0.7058656811714172
Iteration [18344]: Loss = 0.7057274580001831
Iteration [18345]: Loss = 0.705572247505188
Iteration [18346]: Loss = 4.917820930480957
Iteration [18347]: Loss = 0.7054075002670288
Iteration [18348]: Loss = 0.7053819298744202
Iteration [18349]: Loss = 0.7053279876708984
Iteration [18350]: Loss = 0.7052487134933472
Iteration [18351]: Loss = 4.919139862060547
Iteration [18352]: Loss = 4.918792247772217
Iteration [18353]: Loss = 0.7054327130317688
Iteration [18354]: Loss = 0.7055993676185608
Iteration [18355]: Loss = 0.7057186365127563
Iteration [18356]: Loss = 0.705795168876648
Iteration [18357]: Loss = 0.7058331966400146
Iteration [18358]: Loss = 0.7058367133140564
Iteration [18359]: Loss = 0.7058088183403015
Iteration [18360]: Loss = 0.7057530283927917
Iteration [18361]: Loss = 0.7056717872619629
Iteration [18362]: Loss = 0.7055677771568298
Iteration [18363]: Loss = 0.7054432034492493
Iteration [18364]: Loss = 0.7053000926971436
Iteration [18365]: Loss = 0.7051404714584351
Iteration [18366]: Loss = 0.7049658298492432
Iteration [18367]: Loss = 0.704777717590332
Iteration [18368]: Loss = 0.7045774459838867
Iteration [18369]: Loss = 0.7043662071228027
Iteration [18370]: Loss = 4.924315929412842
Iteration [18371]: Loss = 0.704106330871582
Iteration [18372]: Loss = 0.70404052734375
Iteration [18373]: Loss = 0.7039504051208496
Iteration [18374]: Loss = 0.7038384079933167
Iteration [18375]: Loss = 0.7037066221237183
Iteration [18376]: Loss = 0.7035571336746216
Iteration [18377]: Loss = 0.7033918499946594
Iteration [18378]: Loss = 0.7032120823860168
Iteration [18379]: Loss = 0.7030193209648132
Iteration [18380]: Loss = 4.931214332580566
Iteration [18381]: Loss = 0.7027913331985474
Iteration [18382]: Loss = 0.7027392983436584
Iteration [18383]: Loss = 4.932009696960449
Iteration [18384]: Loss = 0.7027516961097717
Iteration [18385]: Loss = 0.7028021216392517
Iteration [18386]: Loss = 0.7028166055679321
Iteration [18387]: Loss = 0.7027989029884338
Iteration [18388]: Loss = 0.7027520537376404
Iteration [18389]: Loss = 0.7026790380477905
Iteration [18390]: Loss = 0.7025824785232544
Iteration [18391]: Loss = 0.7024646997451782
Iteration [18392]: Loss = 0.7023277878761292
Iteration [18393]: Loss = 0.70217365026474
Iteration [18394]: Loss = 0.702004075050354
Iteration [18395]: Loss = 4.9363837242126465
Iteration [18396]: Loss = 0.7018160223960876
Iteration [18397]: Loss = 0.701781153678894
Iteration [18398]: Loss = 0.7017188668251038
Iteration [18399]: Loss = 0.701632022857666
Iteration [18400]: Loss = 0.7015230059623718
Iteration [18401]: Loss = 0.7013939023017883
Iteration [18402]: Loss = 0.7012470364570618
Iteration [18403]: Loss = 0.7010838389396667
Iteration [18404]: Loss = 0.7009060382843018
Iteration [18405]: Loss = 4.942145824432373
Iteration [18406]: Loss = 0.7007044553756714
Iteration [18407]: Loss = 0.7006639242172241
Iteration [18408]: Loss = 4.942763805389404
Iteration [18409]: Loss = 0.7006967663764954
Iteration [18410]: Loss = 0.7007560729980469
Iteration [18411]: Loss = 4.9418134689331055
Iteration [18412]: Loss = 0.7009596228599548
Iteration [18413]: Loss = 0.7010916471481323
Iteration [18414]: Loss = 0.7011797428131104
Iteration [18415]: Loss = 0.7012282609939575
Iteration [18416]: Loss = 0.701241135597229
Iteration [18417]: Loss = 4.939502716064453
Iteration [18418]: Loss = 0.701365053653717
Iteration [18419]: Loss = 0.7014631628990173
Iteration [18420]: Loss = 0.7015206217765808
Iteration [18421]: Loss = 0.701541543006897
Iteration [18422]: Loss = 4.937899589538574
Iteration [18423]: Loss = 0.7016792893409729
Iteration [18424]: Loss = 0.701783299446106
Iteration [18425]: Loss = 0.7018460631370544
Iteration [18426]: Loss = 0.7018717527389526
Iteration [18427]: Loss = 0.7018638849258423
Iteration [18428]: Loss = 0.7018260955810547
Iteration [18429]: Loss = 4.936694145202637
Iteration [18430]: Loss = 0.7018631100654602
Iteration [18431]: Loss = 0.7019243240356445
Iteration [18432]: Loss = 4.935718059539795
Iteration [18433]: Loss = 0.7021306157112122
Iteration [18434]: Loss = 0.7022637724876404
Iteration [18435]: Loss = 0.7023528218269348
Iteration [18436]: Loss = 0.7024019956588745
Iteration [18437]: Loss = 0.7024154663085938
Iteration [18438]: Loss = 0.702396810054779
Iteration [18439]: Loss = 0.7023489475250244
Iteration [18440]: Loss = 0.7022749781608582
Iteration [18441]: Loss = 0.7021774053573608
Iteration [18442]: Loss = 0.7020585536956787
Iteration [18443]: Loss = 0.701920747756958
Iteration [18444]: Loss = 0.7017655968666077
Iteration [18445]: Loss = 0.70159512758255
Iteration [18446]: Loss = 0.7014104723930359
Iteration [18447]: Loss = 0.7012135982513428
Iteration [18448]: Loss = 0.7010052800178528
Iteration [18449]: Loss = 4.9417724609375
Iteration [18450]: Loss = 0.7007516622543335
Iteration [18451]: Loss = 0.7006891965866089
Iteration [18452]: Loss = 0.7006019949913025
Iteration [18453]: Loss = 0.7004927396774292
Iteration [18454]: Loss = 0.7003633975982666
Iteration [18455]: Loss = 0.7002159357070923
Iteration [18456]: Loss = 0.7000524401664734
Iteration [18457]: Loss = 0.699874222278595
Iteration [18458]: Loss = 0.6996829509735107
Iteration [18459]: Loss = 0.6994796991348267
Iteration [18460]: Loss = 0.6992658972740173
Iteration [18461]: Loss = 0.6990424990653992
Iteration [18462]: Loss = 0.6988106369972229
Iteration [18463]: Loss = 0.6985708475112915
Iteration [18464]: Loss = 0.6983242034912109
Iteration [18465]: Loss = 0.6980711817741394
Iteration [18466]: Loss = 4.957345962524414
Iteration [18467]: Loss = 4.957714557647705
Iteration [18468]: Loss = 0.6978409290313721
Iteration [18469]: Loss = 0.6978989243507385
Iteration [18470]: Loss = 0.6979202628135681
Iteration [18471]: Loss = 0.6979087591171265
Iteration [18472]: Loss = 0.6978675127029419
Iteration [18473]: Loss = 0.6977995038032532
Iteration [18474]: Loss = 0.6977075338363647
Iteration [18475]: Loss = 0.6975938081741333
Iteration [18476]: Loss = 0.6974606513977051
Iteration [18477]: Loss = 0.6973097920417786
Iteration [18478]: Loss = 0.6971431970596313
Iteration [18479]: Loss = 0.6969623565673828
Iteration [18480]: Loss = 0.6967686414718628
Iteration [18481]: Loss = 0.6965634822845459
Iteration [18482]: Loss = 0.6963478326797485
Iteration [18483]: Loss = 0.6961230039596558
Iteration [18484]: Loss = 0.6958896517753601
Iteration [18485]: Loss = 0.6956487894058228
Iteration [18486]: Loss = 0.695401132106781
Iteration [18487]: Loss = 0.6951473951339722
Iteration [18488]: Loss = 0.6948880553245544
Iteration [18489]: Loss = 0.6946238279342651
Iteration [18490]: Loss = 0.6943552494049072
Iteration [18491]: Loss = 0.6940825581550598
Iteration [18492]: Loss = 0.6938064098358154
Iteration [18493]: Loss = 0.6935269236564636
Iteration [18494]: Loss = 4.981478214263916
Iteration [18495]: Loss = 4.981957912445068
Iteration [18496]: Loss = 4.981523036956787
Iteration [18497]: Loss = 0.6934722065925598
Iteration [18498]: Loss = 4.97930383682251
Iteration [18499]: Loss = 0.6939802169799805
Iteration [18500]: Loss = 0.6942431926727295
Iteration [18501]: Loss = 4.975088119506836
Iteration [18502]: Loss = 4.973248481750488
Iteration [18503]: Loss = 0.6952711343765259
Iteration [18504]: Loss = 0.695667564868927
Iteration [18505]: Loss = 4.966921329498291
Iteration [18506]: Loss = 0.6964492797851562
Iteration [18507]: Loss = 0.6968286037445068
Iteration [18508]: Loss = 0.6971396207809448
Iteration [18509]: Loss = 0.6973889470100403
Iteration [18510]: Loss = 4.958554267883301
Iteration [18511]: Loss = 0.6979183554649353
Iteration [18512]: Loss = 4.955364227294922
Iteration [18513]: Loss = 0.6985954642295837
Iteration [18514]: Loss = 0.698930025100708
Iteration [18515]: Loss = 0.6992005109786987
Iteration [18516]: Loss = 0.6994132399559021
Iteration [18517]: Loss = 0.6995738744735718
Iteration [18518]: Loss = 9.195342063903809
Iteration [18519]: Loss = 4.945150852203369
Iteration [18520]: Loss = 4.942193984985352
Iteration [18521]: Loss = 0.7013745307922363
Iteration [18522]: Loss = 9.169512748718262
Iteration [18523]: Loss = 0.7028024196624756
Iteration [18524]: Loss = 0.7035435438156128
Iteration [18525]: Loss = 0.7041807770729065
Iteration [18526]: Loss = 0.7047244310379028
Iteration [18527]: Loss = 0.7051836252212524
Iteration [18528]: Loss = 0.70556640625
Iteration [18529]: Loss = 0.7058807611465454
Iteration [18530]: Loss = 4.914047718048096
Iteration [18531]: Loss = 0.7065179944038391
Iteration [18532]: Loss = 0.7068339586257935
Iteration [18533]: Loss = 0.7070878148078918
Iteration [18534]: Loss = 0.7072855830192566
Iteration [18535]: Loss = 0.7074329853057861
Iteration [18536]: Loss = 0.707534909248352
Iteration [18537]: Loss = 0.7075957655906677
Iteration [18538]: Loss = 4.906400203704834
Iteration [18539]: Loss = 0.7077994346618652
Iteration [18540]: Loss = 0.7079304456710815
Iteration [18541]: Loss = 0.7080177068710327
Iteration [18542]: Loss = 4.90411376953125
Iteration [18543]: Loss = 0.7082661390304565
Iteration [18544]: Loss = 4.902314186096191
Iteration [18545]: Loss = 0.7087090611457825
Iteration [18546]: Loss = 0.7089420557022095
Iteration [18547]: Loss = 9.088290214538574
Iteration [18548]: Loss = 0.7096239924430847
Iteration [18549]: Loss = 0.710046648979187
Iteration [18550]: Loss = 0.7103966474533081
Iteration [18551]: Loss = 0.7106812000274658
Iteration [18552]: Loss = 0.7109067440032959
Iteration [18553]: Loss = 0.7110790610313416
Iteration [18554]: Loss = 0.7112035155296326
Iteration [18555]: Loss = 0.7112846970558167
Iteration [18556]: Loss = 4.887444019317627
Iteration [18557]: Loss = 0.7115216851234436
Iteration [18558]: Loss = 0.7116662859916687
Iteration [18559]: Loss = 0.7117656469345093
Iteration [18560]: Loss = 0.7118241786956787
Iteration [18561]: Loss = 0.7118460536003113
Iteration [18562]: Loss = 0.7118349671363831
Iteration [18563]: Loss = 0.7117939591407776
Iteration [18564]: Loss = 0.711726188659668
Iteration [18565]: Loss = 0.7116342186927795
Iteration [18566]: Loss = 0.7115206122398376
Iteration [18567]: Loss = 0.7113871574401855
Iteration [18568]: Loss = 0.7112362384796143
Iteration [18569]: Loss = 0.7110693454742432
Iteration [18570]: Loss = 0.7108883261680603
Iteration [18571]: Loss = 0.710694432258606
Iteration [18572]: Loss = 4.891714572906494
Iteration [18573]: Loss = 4.8918538093566895
Iteration [18574]: Loss = 0.7105945944786072
Iteration [18575]: Loss = 0.7106834053993225
Iteration [18576]: Loss = 0.7107324004173279
Iteration [18577]: Loss = 0.7107457518577576
Iteration [18578]: Loss = 0.7107268571853638
Iteration [18579]: Loss = 0.7106788754463196
Iteration [18580]: Loss = 0.7106049060821533
Iteration [18581]: Loss = 4.891621112823486
Iteration [18582]: Loss = 0.7105770111083984
Iteration [18583]: Loss = 0.7106090188026428
Iteration [18584]: Loss = 4.89111328125
Iteration [18585]: Loss = 0.7107622623443604
Iteration [18586]: Loss = 0.7108712196350098
Iteration [18587]: Loss = 0.710938572883606
Iteration [18588]: Loss = 0.7109682559967041
Iteration [18589]: Loss = 0.7109641432762146
Iteration [18590]: Loss = 0.7109294533729553
Iteration [18591]: Loss = 0.7108672261238098
Iteration [18592]: Loss = 0.7107803225517273
Iteration [18593]: Loss = 0.7106710076332092
Iteration [18594]: Loss = 0.710541844367981
Iteration [18595]: Loss = 4.892197608947754
Iteration [18596]: Loss = 0.7104196548461914
Iteration [18597]: Loss = 0.710411548614502
Iteration [18598]: Loss = 4.892303943634033
Iteration [18599]: Loss = 0.7104965448379517
Iteration [18600]: Loss = 0.7105766534805298
Iteration [18601]: Loss = 0.7106177806854248
Iteration [18602]: Loss = 0.7106238007545471
Iteration [18603]: Loss = 0.710598349571228
Iteration [18604]: Loss = 0.7105444669723511
Iteration [18605]: Loss = 4.891837120056152
Iteration [18606]: Loss = 0.710551381111145
Iteration [18607]: Loss = 0.7105982303619385
Iteration [18608]: Loss = 0.7106093764305115
Iteration [18609]: Loss = 0.7105885148048401
Iteration [18610]: Loss = 0.7105386853218079
Iteration [18611]: Loss = 0.7104628682136536
Iteration [18612]: Loss = 0.7103636264801025
Iteration [18613]: Loss = 0.7102432250976562
Iteration [18614]: Loss = 0.7101038694381714
Iteration [18615]: Loss = 0.7099474668502808
Iteration [18616]: Loss = 0.7097756266593933
Iteration [18617]: Loss = 0.709589958190918
Iteration [18618]: Loss = 0.7093919515609741
Iteration [18619]: Loss = 4.89838981628418
Iteration [18620]: Loss = 0.7091526985168457
Iteration [18621]: Loss = 0.7090948820114136
Iteration [18622]: Loss = 0.7090119123458862
Iteration [18623]: Loss = 0.7089062929153442
Iteration [18624]: Loss = 0.7087802290916443
Iteration [18625]: Loss = 0.7086358070373535
Iteration [18626]: Loss = 0.7084746956825256
Iteration [18627]: Loss = 0.7082986831665039
Iteration [18628]: Loss = 0.708109438419342
Iteration [18629]: Loss = 0.7079079747200012
Iteration [18630]: Loss = 0.7076956629753113
Iteration [18631]: Loss = 0.7074735164642334
Iteration [18632]: Loss = 9.109432220458984
Iteration [18633]: Loss = 0.7073827981948853
Iteration [18634]: Loss = 0.7074782252311707
Iteration [18635]: Loss = 0.7075334787368774
Iteration [18636]: Loss = 0.707552433013916
Iteration [18637]: Loss = 0.707538902759552
Iteration [18638]: Loss = 0.7074959874153137
Iteration [18639]: Loss = 0.7074264883995056
Iteration [18640]: Loss = 0.7073332071304321
Iteration [18641]: Loss = 0.7072184681892395
Iteration [18642]: Loss = 0.7070845365524292
Iteration [18643]: Loss = 0.7069330811500549
Iteration [18644]: Loss = 0.7067659497261047
Iteration [18645]: Loss = 0.7065848112106323
Iteration [18646]: Loss = 0.706390917301178
Iteration [18647]: Loss = 0.7061856985092163
Iteration [18648]: Loss = 0.7059701085090637
Iteration [18649]: Loss = 0.7057452201843262
Iteration [18650]: Loss = 0.7055121660232544
Iteration [18651]: Loss = 0.7052716016769409
Iteration [18652]: Loss = 4.919769763946533
Iteration [18653]: Loss = 0.7049607038497925
Iteration [18654]: Loss = 0.704872727394104
Iteration [18655]: Loss = 0.7047627568244934
Iteration [18656]: Loss = 0.7046331167221069
Iteration [18657]: Loss = 0.7044856548309326
Iteration [18658]: Loss = 0.704322338104248
Iteration [18659]: Loss = 4.924319744110107
Iteration [18660]: Loss = 0.7041434645652771
Iteration [18661]: Loss = 0.7041118741035461
Iteration [18662]: Loss = 0.7040525674819946
Iteration [18663]: Loss = 0.7039687037467957
Iteration [18664]: Loss = 0.7038624286651611
Iteration [18665]: Loss = 0.7037361264228821
Iteration [18666]: Loss = 0.7035915851593018
Iteration [18667]: Loss = 0.7034308910369873
Iteration [18668]: Loss = 0.7032555341720581
Iteration [18669]: Loss = 0.703066885471344
Iteration [18670]: Loss = 0.7028664350509644
Iteration [18671]: Loss = 0.7026553153991699
Iteration [18672]: Loss = 4.93319034576416
Iteration [18673]: Loss = 0.7023953795433044
Iteration [18674]: Loss = 0.7023295760154724
Iteration [18675]: Loss = 0.7022396922111511
Iteration [18676]: Loss = 0.7021281123161316
Iteration [18677]: Loss = 9.16893482208252
Iteration [18678]: Loss = 0.7022262811660767
Iteration [18679]: Loss = 4.933356761932373
Iteration [18680]: Loss = 0.7027184963226318
Iteration [18681]: Loss = 4.930393695831299
Iteration [18682]: Loss = 0.7033588886260986
Iteration [18683]: Loss = 0.7036764025688171
Iteration [18684]: Loss = 0.7039316892623901
Iteration [18685]: Loss = 0.7041313648223877
Iteration [18686]: Loss = 0.7042807340621948
Iteration [18687]: Loss = 0.7043846249580383
Iteration [18688]: Loss = 0.7044476866722107
Iteration [18689]: Loss = 0.7044739723205566
Iteration [18690]: Loss = 4.922650337219238
Iteration [18691]: Loss = 0.7046186923980713
Iteration [18692]: Loss = 0.7047246694564819
Iteration [18693]: Loss = 0.7047895789146423
Iteration [18694]: Loss = 0.7048174142837524
Iteration [18695]: Loss = 0.7048119306564331
Iteration [18696]: Loss = 0.7047765254974365
Iteration [18697]: Loss = 0.7047139406204224
Iteration [18698]: Loss = 0.7046269774436951
Iteration [18699]: Loss = 0.7045181393623352
Iteration [18700]: Loss = 0.7043895721435547
Iteration [18701]: Loss = 4.923809051513672
Iteration [18702]: Loss = 0.7042697668075562
Iteration [18703]: Loss = 0.7042632699012756
Iteration [18704]: Loss = 0.7042267322540283
Iteration [18705]: Loss = 0.7041633129119873
Iteration [18706]: Loss = 4.92467737197876
Iteration [18707]: Loss = 0.7041547894477844
Iteration [18708]: Loss = 0.7041957378387451
Iteration [18709]: Loss = 0.704201877117157
Iteration [18710]: Loss = 0.7041769623756409
Iteration [18711]: Loss = 0.7041239142417908
Iteration [18712]: Loss = 0.7040454745292664
Iteration [18713]: Loss = 4.925357341766357
Iteration [18714]: Loss = 0.7040117383003235
Iteration [18715]: Loss = 0.704041600227356
Iteration [18716]: Loss = 0.7040382027626038
Iteration [18717]: Loss = 0.7040044665336609
Iteration [18718]: Loss = 4.925361156463623
Iteration [18719]: Loss = 0.704046905040741
Iteration [18720]: Loss = 4.924500942230225
Iteration [18721]: Loss = 0.7043237686157227
Iteration [18722]: Loss = 0.7044862508773804
Iteration [18723]: Loss = 0.7046018838882446
Iteration [18724]: Loss = 0.7046756148338318
Iteration [18725]: Loss = 0.7047111392021179
Iteration [18726]: Loss = 0.7047127485275269
Iteration [18727]: Loss = 0.7046833038330078
Iteration [18728]: Loss = 0.7046262621879578
Iteration [18729]: Loss = 0.7045443058013916
Iteration [18730]: Loss = 0.7044397592544556
Iteration [18731]: Loss = 0.7043149471282959
Iteration [18732]: Loss = 0.704171895980835
Iteration [18733]: Loss = 0.7040125727653503
Iteration [18734]: Loss = 0.7038384079933167
Iteration [18735]: Loss = 0.7036508321762085
Iteration [18736]: Loss = 0.70345139503479
Iteration [18737]: Loss = 0.703241229057312
Iteration [18738]: Loss = 0.703021228313446
Iteration [18739]: Loss = 0.7027926445007324
Iteration [18740]: Loss = 0.7025561332702637
Iteration [18741]: Loss = 0.7023126482963562
Iteration [18742]: Loss = 0.7020627856254578
Iteration [18743]: Loss = 0.7018070816993713
Iteration [18744]: Loss = 4.937812328338623
Iteration [18745]: Loss = 0.7014715671539307
Iteration [18746]: Loss = 0.7013734579086304
Iteration [18747]: Loss = 0.7012547254562378
Iteration [18748]: Loss = 0.7011170983314514
Iteration [18749]: Loss = 4.940855026245117
Iteration [18750]: Loss = 0.7009832859039307
Iteration [18751]: Loss = 0.700971245765686
Iteration [18752]: Loss = 0.7009298205375671
Iteration [18753]: Loss = 0.700861930847168
Iteration [18754]: Loss = 0.7007702589035034
Iteration [18755]: Loss = 0.7006571292877197
Iteration [18756]: Loss = 4.943140029907227
Iteration [18757]: Loss = 0.7005650997161865
Iteration [18758]: Loss = 0.7005711197853088
Iteration [18759]: Loss = 0.7005456686019897
Iteration [18760]: Loss = 0.7004924416542053
Iteration [18761]: Loss = 0.7004138231277466
Iteration [18762]: Loss = 0.7003124952316284
Iteration [18763]: Loss = 0.7001906037330627
Iteration [18764]: Loss = 0.7000502943992615
Iteration [18765]: Loss = 0.6998934149742126
Iteration [18766]: Loss = 4.947338581085205
Iteration [18767]: Loss = 0.699726939201355
Iteration [18768]: Loss = 0.6997013092041016
Iteration [18769]: Loss = 0.6996475458145142
Iteration [18770]: Loss = 0.6995686888694763
Iteration [18771]: Loss = 0.6994669437408447
Iteration [18772]: Loss = 0.6993448734283447
Iteration [18773]: Loss = 0.6992043852806091
Iteration [18774]: Loss = 0.6990472674369812
Iteration [18775]: Loss = 0.6988752484321594
Iteration [18776]: Loss = 0.6986897587776184
Iteration [18777]: Loss = 4.95377779006958
Iteration [18778]: Loss = 0.6984750032424927
Iteration [18779]: Loss = 0.6984289884567261
Iteration [18780]: Loss = 0.6983568072319031
Iteration [18781]: Loss = 0.6982614398002625
Iteration [18782]: Loss = 4.955600261688232
Iteration [18783]: Loss = 0.6982004642486572
Iteration [18784]: Loss = 0.6982200145721436
Iteration [18785]: Loss = 0.6982070207595825
Iteration [18786]: Loss = 0.6981647610664368
Iteration [18787]: Loss = 0.6980960965156555
Iteration [18788]: Loss = 0.698003888130188
Iteration [18789]: Loss = 4.956938743591309
Iteration [18790]: Loss = 4.9566330909729
Iteration [18791]: Loss = 0.6981606483459473
Iteration [18792]: Loss = 0.6983213424682617
Iteration [18793]: Loss = 0.6984355449676514
Iteration [18794]: Loss = 4.953695297241211
Iteration [18795]: Loss = 0.6987327933311462
Iteration [18796]: Loss = 0.6989048719406128
Iteration [18797]: Loss = 0.6990293264389038
Iteration [18798]: Loss = 0.699110746383667
Iteration [18799]: Loss = 0.6991535425186157
Iteration [18800]: Loss = 0.6991614699363708
Iteration [18801]: Loss = 4.950393199920654
Iteration [18802]: Loss = 4.949665069580078
Iteration [18803]: Loss = 0.6995614767074585
Iteration [18804]: Loss = 0.6997873783111572
Iteration [18805]: Loss = 0.6999601125717163
Iteration [18806]: Loss = 0.7000852227210999
Iteration [18807]: Loss = 4.94500732421875
Iteration [18808]: Loss = 0.7004005312919617
Iteration [18809]: Loss = 0.7005801200866699
Iteration [18810]: Loss = 0.7007112503051758
Iteration [18811]: Loss = 0.700798749923706
Iteration [18812]: Loss = 0.700846791267395
Iteration [18813]: Loss = 4.941393852233887
Iteration [18814]: Loss = 0.7010303735733032
Iteration [18815]: Loss = 4.9398579597473145
Iteration [18816]: Loss = 0.7014243006706238
Iteration [18817]: Loss = 0.701637327671051
Iteration [18818]: Loss = 0.7017984390258789
Iteration [18819]: Loss = 0.7019128203392029
Iteration [18820]: Loss = 0.7019851803779602
Iteration [18821]: Loss = 0.7020195722579956
Iteration [18822]: Loss = 0.7020198106765747
Iteration [18823]: Loss = 0.7019892930984497
Iteration [18824]: Loss = 0.7019310593605042
Iteration [18825]: Loss = 4.936242580413818
Iteration [18826]: Loss = 0.7019329071044922
Iteration [18827]: Loss = 0.7019788026809692
Iteration [18828]: Loss = 0.7019892930984497
Iteration [18829]: Loss = 0.7019681334495544
Iteration [18830]: Loss = 0.7019181847572327
Iteration [18831]: Loss = 0.7018424272537231
Iteration [18832]: Loss = 0.701743483543396
Iteration [18833]: Loss = 4.937408447265625
Iteration [18834]: Loss = 0.7016761302947998
Iteration [18835]: Loss = 0.701692521572113
Iteration [18836]: Loss = 0.7016765475273132
Iteration [18837]: Loss = 0.7016314268112183
Iteration [18838]: Loss = 0.7015599012374878
Iteration [18839]: Loss = 0.701464831829071
Iteration [18840]: Loss = 0.7013483643531799
Iteration [18841]: Loss = 9.177886962890625
Iteration [18842]: Loss = 0.701440155506134
Iteration [18843]: Loss = 0.7016146183013916
Iteration [18844]: Loss = 4.936798095703125
Iteration [18845]: Loss = 0.7020134329795837
Iteration [18846]: Loss = 4.934262752532959
Iteration [18847]: Loss = 0.7025799751281738
Iteration [18848]: Loss = 0.7028661966323853
Iteration [18849]: Loss = 0.7030933499336243
Iteration [18850]: Loss = 0.7032674551010132
Iteration [18851]: Loss = 0.7033934593200684
Iteration [18852]: Loss = 4.927781105041504
Iteration [18853]: Loss = 0.7037095427513123
Iteration [18854]: Loss = 9.147398948669434
Iteration [18855]: Loss = 9.141671180725098
Iteration [18856]: Loss = 4.918942451477051
Iteration [18857]: Loss = 0.7060511112213135
Iteration [18858]: Loss = 0.7068021893501282
Iteration [18859]: Loss = 0.7074488401412964
Iteration [18860]: Loss = 0.7080010175704956
Iteration [18861]: Loss = 0.7084682583808899
Iteration [18862]: Loss = 0.7088587284088135
Iteration [18863]: Loss = 0.7091801762580872
Iteration [18864]: Loss = 0.709439218044281
Iteration [18865]: Loss = 0.7096419334411621
Iteration [18866]: Loss = 0.7097941637039185
Iteration [18867]: Loss = 0.7099006772041321
Iteration [18868]: Loss = 0.7099660634994507
Iteration [18869]: Loss = 0.7099944353103638
Iteration [18870]: Loss = 0.7099893093109131
Iteration [18871]: Loss = 0.7099542617797852
Iteration [18872]: Loss = 0.7098920941352844
Iteration [18873]: Loss = 0.7098055481910706
Iteration [18874]: Loss = 0.7096969485282898
Iteration [18875]: Loss = 0.7095687389373779
Iteration [18876]: Loss = 0.7094227075576782
Iteration [18877]: Loss = 0.7092604637145996
Iteration [18878]: Loss = 0.7090839743614197
Iteration [18879]: Loss = 0.7088944315910339
Iteration [18880]: Loss = 0.7086933255195618
Iteration [18881]: Loss = 0.7084815502166748
Iteration [18882]: Loss = 0.7082602977752686
Iteration [18883]: Loss = 0.708030641078949
Iteration [18884]: Loss = 0.7077933549880981
Iteration [18885]: Loss = 0.7075492143630981
Iteration [18886]: Loss = 4.908049583435059
Iteration [18887]: Loss = 0.7072305679321289
Iteration [18888]: Loss = 4.908872127532959
Iteration [18889]: Loss = 0.7072129249572754
Iteration [18890]: Loss = 0.7072491645812988
Iteration [18891]: Loss = 0.7072513699531555
Iteration [18892]: Loss = 0.7072227001190186
Iteration [18893]: Loss = 0.7071664929389954
Iteration [18894]: Loss = 4.909145832061768
Iteration [18895]: Loss = 4.90871524810791
Iteration [18896]: Loss = 0.707400918006897
Iteration [18897]: Loss = 0.7075791954994202
Iteration [18898]: Loss = 0.7077093124389648
Iteration [18899]: Loss = 9.103196144104004
Iteration [18900]: Loss = 0.708213746547699
Iteration [18901]: Loss = 4.901577472686768
Iteration [18902]: Loss = 0.7090260982513428
Iteration [18903]: Loss = 4.8971967697143555
Iteration [18904]: Loss = 0.7099208235740662
Iteration [18905]: Loss = 0.7103455662727356
Iteration [18906]: Loss = 0.7106978297233582
Iteration [18907]: Loss = 0.7109845280647278
Iteration [18908]: Loss = 0.7112124562263489
Iteration [18909]: Loss = 0.7113872766494751
Iteration [18910]: Loss = 0.7115142941474915
Iteration [18911]: Loss = 4.886064529418945
Iteration [18912]: Loss = 0.7118282914161682
Iteration [18913]: Loss = 0.7120053172111511
Iteration [18914]: Loss = 0.712134063243866
Iteration [18915]: Loss = 0.7122194766998291
Iteration [18916]: Loss = 0.7122659087181091
Iteration [18917]: Loss = 0.7122770547866821
Iteration [18918]: Loss = 0.712256669998169
Iteration [18919]: Loss = 4.882965087890625
Iteration [18920]: Loss = 4.882400989532471
Iteration [18921]: Loss = 4.881106853485107
Iteration [18922]: Loss = 0.7129572629928589
Iteration [18923]: Loss = 0.7132725119590759
Iteration [18924]: Loss = 9.03902816772461
Iteration [18925]: Loss = 0.7140889763832092
Iteration [18926]: Loss = 0.7145660519599915
Iteration [18927]: Loss = 0.7149653434753418
Iteration [18928]: Loss = 0.715294599533081
Iteration [18929]: Loss = 0.7155607342720032
Iteration [18930]: Loss = 0.7157698273658752
Iteration [18931]: Loss = 0.7159277200698853
Iteration [18932]: Loss = 0.7160393595695496
Iteration [18933]: Loss = 0.7161092162132263
Iteration [18934]: Loss = 0.7161415815353394
Iteration [18935]: Loss = 0.7161402106285095
Iteration [18936]: Loss = 0.7161082625389099
Iteration [18937]: Loss = 0.7160489559173584
Iteration [18938]: Loss = 0.7159649133682251
Iteration [18939]: Loss = 0.7158586978912354
Iteration [18940]: Loss = 4.865128993988037
Iteration [18941]: Loss = 0.7157729864120483
Iteration [18942]: Loss = 0.7157789468765259
Iteration [18943]: Loss = 0.7157537341117859
Iteration [18944]: Loss = 0.7157004475593567
Iteration [18945]: Loss = 0.715621829032898
Iteration [18946]: Loss = 0.7155203819274902
Iteration [18947]: Loss = 0.7153984308242798
Iteration [18948]: Loss = 0.7152579426765442
Iteration [18949]: Loss = 0.715100884437561
Iteration [18950]: Loss = 0.7149288058280945
Iteration [18951]: Loss = 0.7147432565689087
Iteration [18952]: Loss = 0.7145456075668335
Iteration [18953]: Loss = 0.7143371105194092
Iteration [18954]: Loss = 0.7141187191009521
Iteration [18955]: Loss = 0.7138914465904236
Iteration [18956]: Loss = 0.7136563062667847
Iteration [18957]: Loss = 0.7134139537811279
Iteration [18958]: Loss = 0.7131652235984802
Iteration [18959]: Loss = 0.7129105925559998
Iteration [18960]: Loss = 0.7126508951187134
Iteration [18961]: Loss = 0.7123865485191345
Iteration [18962]: Loss = 4.883420944213867
Iteration [18963]: Loss = 0.712031900882721
Iteration [18964]: Loss = 0.7119238972663879
Iteration [18965]: Loss = 0.7117959856987
Iteration [18966]: Loss = 0.7116503715515137
Iteration [18967]: Loss = 0.711488664150238
Iteration [18968]: Loss = 0.7113125920295715
Iteration [18969]: Loss = 0.711123526096344
Iteration [18970]: Loss = 0.7109227776527405
Iteration [18971]: Loss = 0.7107114195823669
Iteration [18972]: Loss = 0.7104907631874084
Iteration [18973]: Loss = 4.8928751945495605
Iteration [18974]: Loss = 0.7102110981941223
Iteration [18975]: Loss = 9.076904296875
Iteration [18976]: Loss = 0.7104064226150513
Iteration [18977]: Loss = 0.7106204032897949
Iteration [18978]: Loss = 4.890215873718262
Iteration [18979]: Loss = 0.7110831141471863
Iteration [18980]: Loss = 0.711323082447052
Iteration [18981]: Loss = 0.7115090489387512
Iteration [18982]: Loss = 4.8858208656311035
Iteration [18983]: Loss = 0.7119234204292297
Iteration [18984]: Loss = 0.712142825126648
Iteration [18985]: Loss = 0.7123101353645325
Iteration [18986]: Loss = 0.7124303579330444
Iteration [18987]: Loss = 0.7125083208084106
Iteration [18988]: Loss = 0.7125479578971863
Iteration [18989]: Loss = 0.7125534415245056
Iteration [18990]: Loss = 0.7125278115272522
Iteration [18991]: Loss = 0.7124741673469543
Iteration [18992]: Loss = 0.7123955488204956
Iteration [18993]: Loss = 0.712294340133667
Iteration [18994]: Loss = 0.7121726870536804
Iteration [18995]: Loss = 0.7120327353477478
Iteration [18996]: Loss = 0.7118761539459229
Iteration [18997]: Loss = 4.885520935058594
Iteration [18998]: Loss = 0.7117056250572205
Iteration [18999]: Loss = 4.88566780090332
Iteration [19000]: Loss = 0.7118039131164551
Iteration [19001]: Loss = 0.7118885517120361
Iteration [19002]: Loss = 0.7119344472885132
Iteration [19003]: Loss = 0.7119452953338623
Iteration [19004]: Loss = 0.7119246125221252
Iteration [19005]: Loss = 0.7118755578994751
Iteration [19006]: Loss = 0.7118009924888611
Iteration [19007]: Loss = 0.7117033004760742
Iteration [19008]: Loss = 0.7115848064422607
Iteration [19009]: Loss = 0.7114477157592773
Iteration [19010]: Loss = 0.7112938165664673
Iteration [19011]: Loss = 4.888473987579346
Iteration [19012]: Loss = 0.7111278772354126
Iteration [19013]: Loss = 9.066097259521484
Iteration [19014]: Loss = 0.7114131450653076
Iteration [19015]: Loss = 0.7116648554801941
Iteration [19016]: Loss = 0.711861252784729
Iteration [19017]: Loss = 0.7120078206062317
Iteration [19018]: Loss = 0.7121095061302185
Iteration [19019]: Loss = 0.7121708989143372
Iteration [19020]: Loss = 0.7121958136558533
Iteration [19021]: Loss = 0.7121878862380981
Iteration [19022]: Loss = 0.7121503353118896
Iteration [19023]: Loss = 0.7120862007141113
Iteration [19024]: Loss = 0.7119981646537781
Iteration [19025]: Loss = 0.7118885517120361
Iteration [19026]: Loss = 0.7117594480514526
Iteration [19027]: Loss = 0.71161288022995
Iteration [19028]: Loss = 0.7114505171775818
Iteration [19029]: Loss = 0.7112740278244019
Iteration [19030]: Loss = 0.71108478307724
Iteration [19031]: Loss = 0.7108840942382812
Iteration [19032]: Loss = 0.7106729745864868
Iteration [19033]: Loss = 0.7104525566101074
Iteration [19034]: Loss = 0.7102237939834595
Iteration [19035]: Loss = 0.7099875211715698
Iteration [19036]: Loss = 0.7097444534301758
Iteration [19037]: Loss = 0.7094953060150146
Iteration [19038]: Loss = 0.709240734577179
Iteration [19039]: Loss = 0.7089812755584717
Iteration [19040]: Loss = 0.7087172865867615
Iteration [19041]: Loss = 0.7084493637084961
Iteration [19042]: Loss = 0.7081778049468994
Iteration [19043]: Loss = 0.7079031467437744
Iteration [19044]: Loss = 0.7076256275177002
Iteration [19045]: Loss = 0.7073454260826111
Iteration [19046]: Loss = 0.7070629000663757
Iteration [19047]: Loss = 0.7067782878875732
Iteration [19048]: Loss = 0.7064918875694275
Iteration [19049]: Loss = 4.9136834144592285
Iteration [19050]: Loss = 0.7061006426811218
Iteration [19051]: Loss = 0.7059776186943054
Iteration [19052]: Loss = 4.915576457977295
Iteration [19053]: Loss = 0.7058655619621277
Iteration [19054]: Loss = 0.7058614492416382
Iteration [19055]: Loss = 0.705827534198761
Iteration [19056]: Loss = 0.7057667970657349
Iteration [19057]: Loss = 0.7056819796562195
Iteration [19058]: Loss = 0.7055752277374268
Iteration [19059]: Loss = 0.7054489850997925
Iteration [19060]: Loss = 0.7053050398826599
Iteration [19061]: Loss = 0.7051451802253723
Iteration [19062]: Loss = 0.704971194267273
Iteration [19063]: Loss = 4.921010494232178
Iteration [19064]: Loss = 0.7047722339630127
Iteration [19065]: Loss = 0.704731285572052
Iteration [19066]: Loss = 4.921631336212158
Iteration [19067]: Loss = 0.7047598958015442
Iteration [19068]: Loss = 0.7048158645629883
Iteration [19069]: Loss = 0.7048360109329224
Iteration [19070]: Loss = 0.7048240303993225
Iteration [19071]: Loss = 0.704783022403717
Iteration [19072]: Loss = 0.7047158479690552
Iteration [19073]: Loss = 0.704625129699707
Iteration [19074]: Loss = 0.7045131921768188
Iteration [19075]: Loss = 0.7043822407722473
Iteration [19076]: Loss = 0.7042340636253357
Iteration [19077]: Loss = 0.7040703892707825
Iteration [19078]: Loss = 4.925622940063477
Iteration [19079]: Loss = 0.7038898468017578
Iteration [19080]: Loss = 0.7038567662239075
Iteration [19081]: Loss = 0.7037968635559082
Iteration [19082]: Loss = 0.7037127614021301
Iteration [19083]: Loss = 0.7036067843437195
Iteration [19084]: Loss = 0.703481137752533
Iteration [19085]: Loss = 0.7033376693725586
Iteration [19086]: Loss = 0.703178346157074
Iteration [19087]: Loss = 0.7030047178268433
Iteration [19088]: Loss = 4.931197166442871
Iteration [19089]: Loss = 0.7028073072433472
Iteration [19090]: Loss = 0.7027673721313477
Iteration [19091]: Loss = 4.93180513381958
Iteration [19092]: Loss = 0.7027983069419861
Iteration [19093]: Loss = 0.7028557062149048
Iteration [19094]: Loss = 0.7028771638870239
Iteration [19095]: Loss = 0.7028661966323853
Iteration [19096]: Loss = 0.7028260827064514
Iteration [19097]: Loss = 0.7027598023414612
Iteration [19098]: Loss = 0.7026698589324951
Iteration [19099]: Loss = 0.7025588154792786
Iteration [19100]: Loss = 0.7024284601211548
Iteration [19101]: Loss = 0.7022809982299805
Iteration [19102]: Loss = 0.7021178603172302
Iteration [19103]: Loss = 0.7019408345222473
Iteration [19104]: Loss = 0.701751172542572
Iteration [19105]: Loss = 0.701550304889679
Iteration [19106]: Loss = 4.938891887664795
Iteration [19107]: Loss = 0.7013066411018372
Iteration [19108]: Loss = 0.7012473940849304
Iteration [19109]: Loss = 0.7011637687683105
Iteration [19110]: Loss = 0.7010582685470581
Iteration [19111]: Loss = 0.7009330987930298
Iteration [19112]: Loss = 4.941754341125488
Iteration [19113]: Loss = 0.7008191347122192
Iteration [19114]: Loss = 0.7008150815963745
Iteration [19115]: Loss = 0.7007812261581421
Iteration [19116]: Loss = 0.7007205486297607
Iteration [19117]: Loss = 0.7006356120109558
Iteration [19118]: Loss = 0.7005290985107422
Iteration [19119]: Loss = 0.7004029154777527
Iteration [19120]: Loss = 0.7002590298652649
Iteration [19121]: Loss = 0.7000994086265564
Iteration [19122]: Loss = 0.6999254822731018
Iteration [19123]: Loss = 4.9472479820251465
Iteration [19124]: Loss = 0.6997285485267639
Iteration [19125]: Loss = 4.947505950927734
Iteration [19126]: Loss = 0.6998116970062256
Iteration [19127]: Loss = 0.6998916268348694
Iteration [19128]: Loss = 0.6999334692955017
Iteration [19129]: Loss = 0.6999410390853882
Iteration [19130]: Loss = 0.6999176740646362
Iteration [19131]: Loss = 4.946580410003662
Iteration [19132]: Loss = 4.94599723815918
Iteration [19133]: Loss = 0.7002357840538025
Iteration [19134]: Loss = 0.700437605381012
Iteration [19135]: Loss = 0.7005892395973206
Iteration [19136]: Loss = 0.7006956934928894
Iteration [19137]: Loss = 0.7007613778114319
Iteration [19138]: Loss = 0.7007902264595032
Iteration [19139]: Loss = 0.7007859945297241
Iteration [19140]: Loss = 9.183156967163086
Iteration [19141]: Loss = 0.7010641098022461
Iteration [19142]: Loss = 0.7013152837753296
Iteration [19143]: Loss = 0.701511561870575
Iteration [19144]: Loss = 0.7016581296920776
Iteration [19145]: Loss = 0.7017602324485779
Iteration [19146]: Loss = 0.7018219828605652
Iteration [19147]: Loss = 0.701847493648529
Iteration [19148]: Loss = 0.7018404006958008
Iteration [19149]: Loss = 4.936471462249756
Iteration [19150]: Loss = 4.935827255249023
Iteration [19151]: Loss = 4.93443489074707
Iteration [19152]: Loss = 0.7025915384292603
Iteration [19153]: Loss = 0.702918529510498
Iteration [19154]: Loss = 0.7031830549240112
Iteration [19155]: Loss = 0.7033911943435669
Iteration [19156]: Loss = 0.7035484313964844
Iteration [19157]: Loss = 0.7036598920822144
Iteration [19158]: Loss = 4.92646598815918
Iteration [19159]: Loss = 0.7039493918418884
Iteration [19160]: Loss = 0.704116702079773
Iteration [19161]: Loss = 0.7042371034622192
Iteration [19162]: Loss = 0.7043154239654541
Iteration [19163]: Loss = 0.7043557167053223
Iteration [19164]: Loss = 0.7043617367744446
Iteration [19165]: Loss = 4.923324108123779
Iteration [19166]: Loss = 0.7044708728790283
Iteration [19167]: Loss = 0.7045612931251526
Iteration [19168]: Loss = 0.7046123743057251
Iteration [19169]: Loss = 0.7046283483505249
Iteration [19170]: Loss = 0.7046122550964355
Iteration [19171]: Loss = 0.704567551612854
Iteration [19172]: Loss = 0.7044971585273743
Iteration [19173]: Loss = 0.7044032216072083
Iteration [19174]: Loss = 0.7042885422706604
Iteration [19175]: Loss = 4.924265384674072
Iteration [19176]: Loss = 0.7041915655136108
Iteration [19177]: Loss = 9.143930435180664
Iteration [19178]: Loss = 0.7045369148254395
Iteration [19179]: Loss = 0.7048155069351196
Iteration [19180]: Loss = 0.705036461353302
Iteration [19181]: Loss = 0.7052053213119507
Iteration [19182]: Loss = 0.7053273320198059
Iteration [19183]: Loss = 0.7054070234298706
Iteration [19184]: Loss = 4.917577743530273
Iteration [19185]: Loss = 0.7056413888931274
Iteration [19186]: Loss = 0.7057849168777466
Iteration [19187]: Loss = 4.915332317352295
Iteration [19188]: Loss = 0.7061280608177185
Iteration [19189]: Loss = 0.7063178420066833
Iteration [19190]: Loss = 0.7064586877822876
Iteration [19191]: Loss = 0.706555187702179
Iteration [19192]: Loss = 0.7066119909286499
Iteration [19193]: Loss = 0.7066329121589661
Iteration [19194]: Loss = 0.706621527671814
Iteration [19195]: Loss = 4.911741256713867
Iteration [19196]: Loss = 0.7067000865936279
Iteration [19197]: Loss = 0.706777036190033
Iteration [19198]: Loss = 0.7068160772323608
Iteration [19199]: Loss = 0.7068210244178772
Iteration [19200]: Loss = 0.7067952752113342
Iteration [19201]: Loss = 0.7067418694496155
Iteration [19202]: Loss = 0.7066634893417358
Iteration [19203]: Loss = 0.7065626978874207
Iteration [19204]: Loss = 0.7064415216445923
Iteration [19205]: Loss = 0.7063022255897522
Iteration [19206]: Loss = 0.7061466574668884
Iteration [19207]: Loss = 0.7059763073921204
Iteration [19208]: Loss = 0.7057926654815674
Iteration [19209]: Loss = 0.7055969834327698
Iteration [19210]: Loss = 0.7053906917572021
Iteration [19211]: Loss = 0.7051746249198914
Iteration [19212]: Loss = 4.920153617858887
Iteration [19213]: Loss = 0.7049041390419006
Iteration [19214]: Loss = 0.7048327326774597
Iteration [19215]: Loss = 0.7047381401062012
Iteration [19216]: Loss = 0.704622745513916
Iteration [19217]: Loss = 0.7044886946678162
Iteration [19218]: Loss = 0.7043377757072449
Iteration [19219]: Loss = 0.7041715383529663
Iteration [19220]: Loss = 0.703991711139679
Iteration [19221]: Loss = 0.7037997245788574
Iteration [19222]: Loss = 0.7035965323448181
Iteration [19223]: Loss = 9.153142929077148
Iteration [19224]: Loss = 4.927483081817627
Iteration [19225]: Loss = 0.7038243412971497
Iteration [19226]: Loss = 0.7040560841560364
Iteration [19227]: Loss = 0.7042346596717834
Iteration [19228]: Loss = 0.7043654918670654
Iteration [19229]: Loss = 0.7044533491134644
Iteration [19230]: Loss = 0.7045025825500488
Iteration [19231]: Loss = 0.7045165300369263
Iteration [19232]: Loss = 0.7044992446899414
Iteration [19233]: Loss = 0.7044535875320435
Iteration [19234]: Loss = 0.7043824791908264
Iteration [19235]: Loss = 0.7042881846427917
Iteration [19236]: Loss = 0.7041733264923096
Iteration [19237]: Loss = 0.7040398120880127
Iteration [19238]: Loss = 0.7038895487785339
Iteration [19239]: Loss = 0.7037240266799927
Iteration [19240]: Loss = 0.703545093536377
Iteration [19241]: Loss = 0.7033538222312927
Iteration [19242]: Loss = 0.7031516432762146
Iteration [19243]: Loss = 0.7029393911361694
Iteration [19244]: Loss = 0.7027183771133423
Iteration [19245]: Loss = 0.7024892568588257
Iteration [19246]: Loss = 0.7022529244422913
Iteration [19247]: Loss = 0.7020100951194763
Iteration [19248]: Loss = 0.7017614245414734
Iteration [19249]: Loss = 0.701507568359375
Iteration [19250]: Loss = 0.7012489438056946
Iteration [19251]: Loss = 0.7009860277175903
Iteration [19252]: Loss = 0.7007193565368652
Iteration [19253]: Loss = 0.7004492282867432
Iteration [19254]: Loss = 0.7001760601997375
Iteration [19255]: Loss = 0.6999001502990723
Iteration [19256]: Loss = 0.6996217370033264
Iteration [19257]: Loss = 0.6993409991264343
Iteration [19258]: Loss = 0.699058473110199
Iteration [19259]: Loss = 4.95229959487915
Iteration [19260]: Loss = 0.6986756324768066
Iteration [19261]: Loss = 0.6985569596290588
Iteration [19262]: Loss = 0.6984203457832336
Iteration [19263]: Loss = 0.6982672214508057
Iteration [19264]: Loss = 0.6980994343757629
Iteration [19265]: Loss = 0.6979184746742249
Iteration [19266]: Loss = 0.6977255344390869
Iteration [19267]: Loss = 0.6975219249725342
Iteration [19268]: Loss = 0.6973086595535278
Iteration [19269]: Loss = 0.6970866918563843
Iteration [19270]: Loss = 0.6968569159507751
Iteration [19271]: Loss = 4.963621139526367
Iteration [19272]: Loss = 0.6965649127960205
Iteration [19273]: Loss = 0.6964853405952454
Iteration [19274]: Loss = 0.6963838338851929
Iteration [19275]: Loss = 0.696262538433075
Iteration [19276]: Loss = 0.6961233615875244
Iteration [19277]: Loss = 0.6959680914878845
Iteration [19278]: Loss = 0.6957984566688538
Iteration [19279]: Loss = 0.6956157684326172
Iteration [19280]: Loss = 0.6954213380813599
Iteration [19281]: Loss = 0.6952164173126221
Iteration [19282]: Loss = 0.6950021386146545
Iteration [19283]: Loss = 0.6947790384292603
Iteration [19284]: Loss = 4.974563121795654
Iteration [19285]: Loss = 0.6944994330406189
Iteration [19286]: Loss = 4.97521448135376
Iteration [19287]: Loss = 4.974730014801025
Iteration [19288]: Loss = 0.6947569847106934
Iteration [19289]: Loss = 0.6949432492256165
Iteration [19290]: Loss = 0.6950810551643372
Iteration [19291]: Loss = 0.6951754093170166
Iteration [19292]: Loss = 0.6952304840087891
Iteration [19293]: Loss = 0.6952502131462097
Iteration [19294]: Loss = 0.6952380537986755
Iteration [19295]: Loss = 0.6951971650123596
Iteration [19296]: Loss = 0.695130467414856
Iteration [19297]: Loss = 9.248878479003906
Iteration [19298]: Loss = 0.6953032612800598
Iteration [19299]: Loss = 0.6955104470252991
Iteration [19300]: Loss = 4.968647003173828
Iteration [19301]: Loss = 0.6959646344184875
Iteration [19302]: Loss = 0.6962028741836548
Iteration [19303]: Loss = 4.964845657348633
Iteration [19304]: Loss = 0.6967102289199829
Iteration [19305]: Loss = 0.6969709396362305
Iteration [19306]: Loss = 0.6971760988235474
Iteration [19307]: Loss = 0.6973311305046082
Iteration [19308]: Loss = 0.6974408626556396
Iteration [19309]: Loss = 4.95893669128418
Iteration [19310]: Loss = 0.6977285146713257
Iteration [19311]: Loss = 0.6978954672813416
Iteration [19312]: Loss = 0.6980161070823669
Iteration [19313]: Loss = 4.9558634757995605
Iteration [19314]: Loss = 0.6983219385147095
Iteration [19315]: Loss = 0.6984968185424805
Iteration [19316]: Loss = 0.698624312877655
Iteration [19317]: Loss = 0.6987094283103943
Iteration [19318]: Loss = 0.6987559199333191
Iteration [19319]: Loss = 0.6987681984901428
Iteration [19320]: Loss = 0.6987492442131042
Iteration [19321]: Loss = 0.698702335357666
Iteration [19322]: Loss = 0.6986299753189087
Iteration [19323]: Loss = 0.698535144329071
Iteration [19324]: Loss = 0.6984197497367859
Iteration [19325]: Loss = 0.6982859969139099
Iteration [19326]: Loss = 4.955648899078369
Iteration [19327]: Loss = 0.6981573104858398
Iteration [19328]: Loss = 0.6981470584869385
Iteration [19329]: Loss = 9.213482856750488
Iteration [19330]: Loss = 4.954190731048584
Iteration [19331]: Loss = 0.6988435983657837
Iteration [19332]: Loss = 0.6971814632415771
Iteration [19333]: Loss = 0.6974669694900513
Iteration [19334]: Loss = 0.6976944804191589
Iteration [19335]: Loss = 4.936359405517578
Iteration [19336]: Loss = 0.7021894454956055
Iteration [19337]: Loss = 0.7024409770965576
Iteration [19338]: Loss = 0.7026376128196716
Iteration [19339]: Loss = 0.7027849555015564
Iteration [19340]: Loss = 0.7028877139091492
Iteration [19341]: Loss = 0.7029502391815186
Iteration [19342]: Loss = 4.930374622344971
Iteration [19343]: Loss = 0.7031555771827698
Iteration [19344]: Loss = 0.7032867670059204
Iteration [19345]: Loss = 0.7033750414848328
Iteration [19346]: Loss = 0.7034244537353516
Iteration [19347]: Loss = 0.7034391164779663
Iteration [19348]: Loss = 0.7034221291542053
Iteration [19349]: Loss = 4.928297996520996
Iteration [19350]: Loss = 0.7034916281700134
Iteration [19351]: Loss = 4.927321434020996
Iteration [19352]: Loss = 0.7037861347198486
Iteration [19353]: Loss = 0.7039552927017212
Iteration [19354]: Loss = 4.924665451049805
Iteration [19355]: Loss = 0.7043428421020508
Iteration [19356]: Loss = 0.704551637172699
Iteration [19357]: Loss = 0.7047097086906433
Iteration [19358]: Loss = 0.7048218846321106
Iteration [19359]: Loss = 0.7048929333686829
Iteration [19360]: Loss = 4.9202728271484375
Iteration [19361]: Loss = 0.7051124572753906
Iteration [19362]: Loss = 4.918606281280518
Iteration [19363]: Loss = 0.7055278420448303
Iteration [19364]: Loss = 0.7057483196258545
Iteration [19365]: Loss = 0.7059168815612793
Iteration [19366]: Loss = 0.7060385942459106
Iteration [19367]: Loss = 0.7061179280281067
Iteration [19368]: Loss = 0.7061594724655151
Iteration [19369]: Loss = 0.7061666250228882
Iteration [19370]: Loss = 0.7061428427696228
Iteration [19371]: Loss = 4.91426420211792
Iteration [19372]: Loss = 0.7062003016471863
Iteration [19373]: Loss = 0.7062681913375854
Iteration [19374]: Loss = 0.7062992453575134
Iteration [19375]: Loss = 4.913203716278076
Iteration [19376]: Loss = 0.7064501047134399
Iteration [19377]: Loss = 0.7065578699111938
Iteration [19378]: Loss = 0.7066248059272766
Iteration [19379]: Loss = 0.7066549062728882
Iteration [19380]: Loss = 0.7066516280174255
Iteration [19381]: Loss = 0.7066186666488647
Iteration [19382]: Loss = 0.7065587043762207
Iteration [19383]: Loss = 0.7064744234085083
Iteration [19384]: Loss = 0.7063683271408081
Iteration [19385]: Loss = 0.7062426805496216
Iteration [19386]: Loss = 4.914222717285156
Iteration [19387]: Loss = 0.7061259150505066
Iteration [19388]: Loss = 0.7061197757720947
Iteration [19389]: Loss = 9.13229751586914
Iteration [19390]: Loss = 0.7057806849479675
Iteration [19391]: Loss = 0.7060269117355347
Iteration [19392]: Loss = 0.7062187790870667
Iteration [19393]: Loss = 0.7063615322113037
Iteration [19394]: Loss = 0.7064599990844727
Iteration [19395]: Loss = 0.706518828868866
Iteration [19396]: Loss = 0.7065417766571045
Iteration [19397]: Loss = 0.7065322399139404
Iteration [19398]: Loss = 0.7064938545227051
Iteration [19399]: Loss = 0.7064290642738342
Iteration [19400]: Loss = 0.7063406705856323
Iteration [19401]: Loss = 0.7062311172485352
Iteration [19402]: Loss = 4.914206027984619
Iteration [19403]: Loss = 0.7061413526535034
Iteration [19404]: Loss = 0.7061465382575989
Iteration [19405]: Loss = 0.7061210870742798
Iteration [19406]: Loss = 0.7060681581497192
Iteration [19407]: Loss = 0.7059904336929321
Iteration [19408]: Loss = 0.7058902978897095
Iteration [19409]: Loss = 0.7057702541351318
Iteration [19410]: Loss = 0.7039380073547363
Iteration [19411]: Loss = 0.703742265701294
Iteration [19412]: Loss = 0.7035737633705139
Iteration [19413]: Loss = 0.703391969203949
Iteration [19414]: Loss = 0.7031984925270081
Iteration [19415]: Loss = 0.7029942870140076
Iteration [19416]: Loss = 0.7027803659439087
Iteration [19417]: Loss = 0.7025579810142517
Iteration [19418]: Loss = 0.7023277878761292
Iteration [19419]: Loss = 0.7020905613899231
Iteration [19420]: Loss = 0.7018471360206604
Iteration [19421]: Loss = 0.7015979886054993
Iteration [19422]: Loss = 0.7013437747955322
Iteration [19423]: Loss = 0.7010850310325623
Iteration [19424]: Loss = 0.7008222937583923
Iteration [19425]: Loss = 0.700555682182312
Iteration [19426]: Loss = 0.700285792350769
Iteration [19427]: Loss = 0.7000131011009216
Iteration [19428]: Loss = 4.947253704071045
Iteration [19429]: Loss = 0.6996462345123291
Iteration [19430]: Loss = 0.6995341777801514
Iteration [19431]: Loss = 0.6994034051895142
Iteration [19432]: Loss = 0.6992558240890503
Iteration [19433]: Loss = 0.6990931034088135
Iteration [19434]: Loss = 0.6989167332649231
Iteration [19435]: Loss = 0.698728084564209
Iteration [19436]: Loss = 0.6985284090042114
Iteration [19437]: Loss = 0.6983188390731812
Iteration [19438]: Loss = 0.6981001496315002
Iteration [19439]: Loss = 0.6978735327720642
Iteration [19440]: Loss = 0.6976396441459656
Iteration [19441]: Loss = 0.6973991990089417
Iteration [19442]: Loss = 0.6971530914306641
Iteration [19443]: Loss = 0.6969014406204224
Iteration [19444]: Loss = 0.6966453194618225
Iteration [19445]: Loss = 0.6963846683502197
Iteration [19446]: Loss = 0.6961203813552856
Iteration [19447]: Loss = 4.967668533325195
Iteration [19448]: Loss = 0.695769190788269
Iteration [19449]: Loss = 9.241660118103027
Iteration [19450]: Loss = 0.6959118843078613
Iteration [19451]: Loss = 0.6961053013801575
Iteration [19452]: Loss = 0.6962500214576721
Iteration [19453]: Loss = 0.6963506937026978
Iteration [19454]: Loss = 0.6964117884635925
Iteration [19455]: Loss = 9.232732772827148
Iteration [19456]: Loss = 0.6967983245849609
Iteration [19457]: Loss = 0.6970941424369812
Iteration [19458]: Loss = 0.6973311901092529
Iteration [19459]: Loss = 0.6975152492523193
Iteration [19460]: Loss = 4.958191871643066
Iteration [19461]: Loss = 0.6979286074638367
Iteration [19462]: Loss = 0.6981488466262817
Iteration [19463]: Loss = 0.6983175277709961
Iteration [19464]: Loss = 0.6984401345252991
Iteration [19465]: Loss = 0.6985208988189697
Iteration [19466]: Loss = 0.6985641717910767
Iteration [19467]: Loss = 4.953351020812988
Iteration [19468]: Loss = 4.952495574951172
Iteration [19469]: Loss = 0.6990376710891724
Iteration [19470]: Loss = 0.699279248714447
Iteration [19471]: Loss = 4.948668003082275
Iteration [19472]: Loss = 0.6997905969619751
Iteration [19473]: Loss = 0.7000523209571838
Iteration [19474]: Loss = 0.7002584338188171
Iteration [19475]: Loss = 0.7004145979881287
Iteration [19476]: Loss = 4.943135738372803
Iteration [19477]: Loss = 4.941810131072998
Iteration [19478]: Loss = 0.7028929591178894
Iteration [19479]: Loss = 0.7032076120376587
Iteration [19480]: Loss = 4.927859306335449
Iteration [19481]: Loss = 0.7038431167602539
Iteration [19482]: Loss = 4.924252510070801
Iteration [19483]: Loss = 0.7045935988426208
Iteration [19484]: Loss = 0.7049567103385925
Iteration [19485]: Loss = 0.7052541375160217
Iteration [19486]: Loss = 0.7054920792579651
Iteration [19487]: Loss = 4.916400909423828
Iteration [19488]: Loss = 0.7059962153434753
Iteration [19489]: Loss = 0.7062541246414185
Iteration [19490]: Loss = 0.7064565420150757
Iteration [19491]: Loss = 0.7066090106964111
Iteration [19492]: Loss = 0.7067164182662964
Iteration [19493]: Loss = 0.7067833542823792
Iteration [19494]: Loss = 0.7068135738372803
Iteration [19495]: Loss = 0.7068108916282654
Iteration [19496]: Loss = 0.7067785263061523
Iteration [19497]: Loss = 0.7067192792892456
Iteration [19498]: Loss = 0.7066361308097839
Iteration [19499]: Loss = 0.706531286239624
Iteration [19500]: Loss = 4.912637233734131
Iteration [19501]: Loss = 0.7064493894577026
Iteration [19502]: Loss = 0.7064574956893921
Iteration [19503]: Loss = 0.7064350247383118
Iteration [19504]: Loss = 0.7063847780227661
Iteration [19505]: Loss = 0.7063094973564148
Iteration [19506]: Loss = 0.7062116861343384
Iteration [19507]: Loss = 0.7060937881469727
Iteration [19508]: Loss = 0.7059575915336609
Iteration [19509]: Loss = 0.7058049440383911
Iteration [19510]: Loss = 0.7056376338005066
Iteration [19511]: Loss = 0.7054569721221924
Iteration [19512]: Loss = 0.7052643895149231
Iteration [19513]: Loss = 0.7050610780715942
Iteration [19514]: Loss = 4.920680999755859
Iteration [19515]: Loss = 4.920870304107666
Iteration [19516]: Loss = 0.7049327492713928
Iteration [19517]: Loss = 0.7050122022628784
Iteration [19518]: Loss = 0.7050539255142212
Iteration [19519]: Loss = 0.7050615549087524
Iteration [19520]: Loss = 0.7050383687019348
Iteration [19521]: Loss = 0.7049875855445862
Iteration [19522]: Loss = 4.920350551605225
Iteration [19523]: Loss = 0.7049986124038696
Iteration [19524]: Loss = 0.7050465941429138
Iteration [19525]: Loss = 0.7050598859786987
Iteration [19526]: Loss = 0.7050418853759766
Iteration [19527]: Loss = 0.7049956917762756
Iteration [19528]: Loss = 0.7049242854118347
Iteration [19529]: Loss = 0.7048298120498657
Iteration [19530]: Loss = 4.9213690757751465
Iteration [19531]: Loss = 0.7047663927078247
Iteration [19532]: Loss = 0.7047827839851379
Iteration [19533]: Loss = 0.7047675848007202
Iteration [19534]: Loss = 0.7047239542007446
Iteration [19535]: Loss = 0.7046546339988708
Iteration [19536]: Loss = 9.139754295349121
Iteration [19537]: Loss = 0.7048169374465942
Iteration [19538]: Loss = 0.705016553401947
Iteration [19539]: Loss = 0.7051666378974915
Iteration [19540]: Loss = 4.918490409851074
Iteration [19541]: Loss = 0.7055203318595886
Iteration [19542]: Loss = 0.7057141661643982
Iteration [19543]: Loss = 0.7058590650558472
Iteration [19544]: Loss = 0.7059594988822937
Iteration [19545]: Loss = 0.7060202360153198
Iteration [19546]: Loss = 0.7060450315475464
Iteration [19547]: Loss = 0.7060374021530151
Iteration [19548]: Loss = 0.7060006856918335
Iteration [19549]: Loss = 0.7059378027915955
Iteration [19550]: Loss = 4.915501594543457
Iteration [19551]: Loss = 0.7059273719787598
Iteration [19552]: Loss = 0.705966055393219
Iteration [19553]: Loss = 4.914883136749268
Iteration [19554]: Loss = 0.7061293125152588
Iteration [19555]: Loss = 0.7062420845031738
Iteration [19556]: Loss = 0.7063136100769043
Iteration [19557]: Loss = 0.7063481211662292
Iteration [19558]: Loss = 0.7063493728637695
Iteration [19559]: Loss = 0.706320583820343
Iteration [19560]: Loss = 0.7062646746635437
Iteration [19561]: Loss = 0.7061843872070312
Iteration [19562]: Loss = 0.7060820460319519
Iteration [19563]: Loss = 0.7059600949287415
Iteration [19564]: Loss = 0.7058203220367432
Iteration [19565]: Loss = 0.7056644558906555
Iteration [19566]: Loss = 0.7054942846298218
Iteration [19567]: Loss = 4.9182891845703125
Iteration [19568]: Loss = 0.7032533884048462
Iteration [19569]: Loss = 0.7032144665718079
Iteration [19570]: Loss = 0.703149676322937
Iteration [19571]: Loss = 0.7030614614486694
Iteration [19572]: Loss = 0.7029521465301514
Iteration [19573]: Loss = 0.7028239965438843
Iteration [19574]: Loss = 0.7026787996292114
Iteration [19575]: Loss = 0.702518105506897
Iteration [19576]: Loss = 0.702343761920929
Iteration [19577]: Loss = 0.7021568417549133
Iteration [19578]: Loss = 0.7019587159156799
Iteration [19579]: Loss = 0.7017505764961243
Iteration [19580]: Loss = 0.7015334367752075
Iteration [19581]: Loss = 0.7013080716133118
Iteration [19582]: Loss = 0.7010754346847534
Iteration [19583]: Loss = 0.7008361220359802
Iteration [19584]: Loss = 0.700590968132019
Iteration [19585]: Loss = 0.7003403306007385
Iteration [19586]: Loss = 0.7000849843025208
Iteration [19587]: Loss = 4.9467949867248535
Iteration [19588]: Loss = 0.6997477412223816
Iteration [19589]: Loss = 0.6996480226516724
Iteration [19590]: Loss = 0.6995285153388977
Iteration [19591]: Loss = 0.6993911266326904
Iteration [19592]: Loss = 0.6992377042770386
Iteration [19593]: Loss = 4.950748920440674
Iteration [19594]: Loss = 4.950723648071289
Iteration [19595]: Loss = 0.6992344856262207
Iteration [19596]: Loss = 0.6993488073348999
Iteration [19597]: Loss = 0.6994218826293945
Iteration [19598]: Loss = 0.6994580626487732
Iteration [19599]: Loss = 0.6994608640670776
Iteration [19600]: Loss = 0.6994336247444153
Iteration [19601]: Loss = 0.6993792653083801
Iteration [19602]: Loss = 0.6993005871772766
Iteration [19603]: Loss = 0.6992000937461853
Iteration [19604]: Loss = 0.699079692363739
Iteration [19605]: Loss = 0.6989414691925049
Iteration [19606]: Loss = 0.6987873315811157
Iteration [19607]: Loss = 0.6986187696456909
Iteration [19608]: Loss = 0.6984370946884155
Iteration [19609]: Loss = 0.6982439756393433
Iteration [19610]: Loss = 4.956150531768799
Iteration [19611]: Loss = 0.6980133056640625
Iteration [19612]: Loss = 0.697959303855896
Iteration [19613]: Loss = 4.956985950469971
Iteration [19614]: Loss = 0.6979668140411377
Iteration [19615]: Loss = 0.6980142593383789
Iteration [19616]: Loss = 0.6980271935462952
Iteration [19617]: Loss = 0.6980091333389282
Iteration [19618]: Loss = 0.6979631185531616
Iteration [19619]: Loss = 0.6978920102119446
Iteration [19620]: Loss = 0.6977980732917786
Iteration [19621]: Loss = 0.6976836919784546
Iteration [19622]: Loss = 0.6975510120391846
Iteration [19623]: Loss = 0.6974018812179565
Iteration [19624]: Loss = 0.6972376108169556
Iteration [19625]: Loss = 0.6970599889755249
Iteration [19626]: Loss = 0.6968703269958496
Iteration [19627]: Loss = 0.6966698169708252
Iteration [19628]: Loss = 0.6964595317840576
Iteration [19629]: Loss = 0.6962404251098633
Iteration [19630]: Loss = 0.6960133910179138
Iteration [19631]: Loss = 0.6957792043685913
Iteration [19632]: Loss = 0.6955386400222778
Iteration [19633]: Loss = 0.6952922940254211
Iteration [19634]: Loss = 0.6950408220291138
Iteration [19635]: Loss = 0.6947846412658691
Iteration [19636]: Loss = 4.974691390991211
Iteration [19637]: Loss = 0.6944476366043091
Iteration [19638]: Loss = 0.6943490505218506
Iteration [19639]: Loss = 4.9762468338012695
Iteration [19640]: Loss = 0.694281280040741
Iteration [19641]: Loss = 0.6942972540855408
Iteration [19642]: Loss = 4.975975036621094
Iteration [19643]: Loss = 0.6944253444671631
Iteration [19644]: Loss = 9.254854202270508
Iteration [19645]: Loss = 0.6949538588523865
Iteration [19646]: Loss = 0.6953110098838806
Iteration [19647]: Loss = 0.6956031918525696
Iteration [19648]: Loss = 4.9677510261535645
Iteration [19649]: Loss = 0.6962025165557861
Iteration [19650]: Loss = 0.6965023279190063
Iteration [19651]: Loss = 4.9629740715026855
Iteration [19652]: Loss = 0.6971142292022705
Iteration [19653]: Loss = 0.6974193453788757
Iteration [19654]: Loss = 0.6976645588874817
Iteration [19655]: Loss = 0.6978558301925659
Iteration [19656]: Loss = 0.6979984641075134
Iteration [19657]: Loss = 0.698097288608551
Iteration [19658]: Loss = 0.698156476020813
Iteration [19659]: Loss = 0.6981801986694336
Iteration [19660]: Loss = 0.6981719732284546
Iteration [19661]: Loss = 0.6981347799301147
Iteration [19662]: Loss = 0.6980716586112976
Iteration [19663]: Loss = 4.95643949508667
Iteration [19664]: Loss = 0.6980630159378052
Iteration [19665]: Loss = 0.698103666305542
Iteration [19666]: Loss = 0.6981103420257568
Iteration [19667]: Loss = 0.6980868577957153
Iteration [19668]: Loss = 0.6980359554290771
Iteration [19669]: Loss = 4.956569671630859
Iteration [19670]: Loss = 4.9561076164245605
Iteration [19671]: Loss = 0.6982830166816711
Iteration [19672]: Loss = 0.6984646320343018
Iteration [19673]: Loss = 0.6985985636711121
Iteration [19674]: Loss = 0.698689341545105
Iteration [19675]: Loss = 0.6987415552139282
Iteration [19676]: Loss = 0.698758602142334
Iteration [19677]: Loss = 0.6987442970275879
Iteration [19678]: Loss = 4.952678203582764
Iteration [19679]: Loss = 0.6988192200660706
Iteration [19680]: Loss = 0.6988953948020935
Iteration [19681]: Loss = 4.951460838317871
Iteration [19682]: Loss = 0.6991246342658997
Iteration [19683]: Loss = 0.6992663741111755
Iteration [19684]: Loss = 0.699364423751831
Iteration [19685]: Loss = 0.6994228363037109
Iteration [19686]: Loss = 0.6994457244873047
Iteration [19687]: Loss = 0.6994364261627197
Iteration [19688]: Loss = 0.6993983387947083
Iteration [19689]: Loss = 0.6993341445922852
Iteration [19690]: Loss = 4.949823379516602
Iteration [19691]: Loss = 0.699323832988739
Iteration [19692]: Loss = 0.6993635892868042
Iteration [19693]: Loss = 0.6993696689605713
Iteration [19694]: Loss = 4.949306964874268
Iteration [19695]: Loss = 0.6994791030883789
Iteration [19696]: Loss = 0.6995698809623718
Iteration [19697]: Loss = 0.699621856212616
Iteration [19698]: Loss = 0.6996387839317322
Iteration [19699]: Loss = 0.699624240398407
Iteration [19700]: Loss = 0.6995813250541687
Iteration [19701]: Loss = 4.948429584503174
Iteration [19702]: Loss = 0.6996071934700012
Iteration [19703]: Loss = 0.6996622681617737
Iteration [19704]: Loss = 0.6996822357177734
Iteration [19705]: Loss = 4.947605609893799
Iteration [19706]: Loss = 9.193877220153809
Iteration [19707]: Loss = 0.7002832889556885
Iteration [19708]: Loss = 4.942355632781982
Iteration [19709]: Loss = 4.939712047576904
Iteration [19710]: Loss = 0.701790988445282
Iteration [19711]: Loss = 0.7023105621337891
Iteration [19712]: Loss = 0.7027488350868225
Iteration [19713]: Loss = 0.7031139731407166
Iteration [19714]: Loss = 0.703413188457489
Iteration [19715]: Loss = 0.7036529183387756
Iteration [19716]: Loss = 0.7038390636444092
Iteration [19717]: Loss = 4.925187587738037
Iteration [19718]: Loss = 0.7042548060417175
Iteration [19719]: Loss = 0.7044755220413208
Iteration [19720]: Loss = 0.7046442627906799
Iteration [19721]: Loss = 0.7047665119171143
Iteration [19722]: Loss = 0.7048467397689819
Iteration [19723]: Loss = 0.7048889398574829
Iteration [19724]: Loss = 0.7048971652984619
Iteration [19725]: Loss = 0.7048746943473816
Iteration [19726]: Loss = 0.7048245072364807
Iteration [19727]: Loss = 0.7047492861747742
Iteration [19728]: Loss = 0.7046518325805664
Iteration [19729]: Loss = 0.7045340538024902
Iteration [19730]: Loss = 0.7043981552124023
Iteration [19731]: Loss = 0.704245924949646
Iteration [19732]: Loss = 0.704078733921051
Iteration [19733]: Loss = 0.7038984298706055
Iteration [19734]: Loss = 4.9265899658203125
Iteration [19735]: Loss = 0.7036883234977722
Iteration [19736]: Loss = 4.926921367645264
Iteration [19737]: Loss = 0.7037556767463684
Iteration [19738]: Loss = 0.703827977180481
Iteration [19739]: Loss = 0.7038630843162537
Iteration [19740]: Loss = 0.7038648128509521
Iteration [19741]: Loss = 0.7038365006446838
Iteration [19742]: Loss = 0.7037810683250427
Iteration [19743]: Loss = 0.7037013173103333
Iteration [19744]: Loss = 0.7035995125770569
Iteration [19745]: Loss = 0.7034778594970703
Iteration [19746]: Loss = 0.7033383846282959
Iteration [19747]: Loss = 4.9293036460876465
Iteration [19748]: Loss = 4.92922306060791
Iteration [19749]: Loss = 0.703367292881012
Iteration [19750]: Loss = 4.927714824676514
Iteration [19751]: Loss = 0.7037538290023804
Iteration [19752]: Loss = 0.7039620876312256
Iteration [19753]: Loss = 0.7041198015213013
Iteration [19754]: Loss = 0.7042319178581238
Iteration [19755]: Loss = 4.923500061035156
Iteration [19756]: Loss = 0.7045214772224426
Iteration [19757]: Loss = 0.7046883702278137
Iteration [19758]: Loss = 0.7048087120056152
Iteration [19759]: Loss = 0.7048870325088501
Iteration [19760]: Loss = 0.7049276828765869
Iteration [19761]: Loss = 0.7049341797828674
Iteration [19762]: Loss = 0.704910159111023
Iteration [19763]: Loss = 0.7048585414886475
Iteration [19764]: Loss = 0.7047819495201111
Iteration [19765]: Loss = 4.921533584594727
Iteration [19766]: Loss = 0.7047490477561951
Iteration [19767]: Loss = 0.7047784328460693
Iteration [19768]: Loss = 0.7047750949859619
Iteration [19769]: Loss = 4.921228408813477
Iteration [19770]: Loss = 0.7048672437667847
Iteration [19771]: Loss = 0.7049498558044434
Iteration [19772]: Loss = 0.7049944996833801
Iteration [19773]: Loss = 0.7050045132637024
Iteration [19774]: Loss = 0.7049835324287415
Iteration [19775]: Loss = 0.7049345374107361
Iteration [19776]: Loss = 0.7048603296279907
Iteration [19777]: Loss = 0.704763650894165
Iteration [19778]: Loss = 0.7046462893486023
Iteration [19779]: Loss = 0.7045107483863831
Iteration [19780]: Loss = 0.7043584585189819
Iteration [19781]: Loss = 0.7041913866996765
Iteration [19782]: Loss = 0.7040108442306519
Iteration [19783]: Loss = 0.7038184404373169
Iteration [19784]: Loss = 0.7036149501800537
Iteration [19785]: Loss = 0.7034017443656921
Iteration [19786]: Loss = 0.7031798362731934
Iteration [19787]: Loss = 0.7029498219490051
Iteration [19788]: Loss = 0.7027128338813782
Iteration [19789]: Loss = 0.7024694085121155
Iteration [19790]: Loss = 4.934305191040039
Iteration [19791]: Loss = 0.7021522521972656
Iteration [19792]: Loss = 0.7020612359046936
Iteration [19793]: Loss = 0.7019493579864502
Iteration [19794]: Loss = 0.7018184065818787
Iteration [19795]: Loss = 0.7016705274581909
Iteration [19796]: Loss = 0.7015074491500854
Iteration [19797]: Loss = 0.7013305425643921
Iteration [19798]: Loss = 0.7011412978172302
Iteration [19799]: Loss = 0.7009408473968506
Iteration [19800]: Loss = 0.7007304430007935
Iteration [19801]: Loss = 0.7005109786987305
Iteration [19802]: Loss = 0.700283408164978
Iteration [19803]: Loss = 0.7000486254692078
Iteration [19804]: Loss = 0.6998071074485779
Iteration [19805]: Loss = 0.6995598077774048
Iteration [19806]: Loss = 4.949506759643555
Iteration [19807]: Loss = 0.6992368698120117
Iteration [19808]: Loss = 0.6991438269615173
Iteration [19809]: Loss = 0.6990300416946411
Iteration [19810]: Loss = 0.698897659778595
Iteration [19811]: Loss = 4.952433109283447
Iteration [19812]: Loss = 0.6987714171409607
Iteration [19813]: Loss = 0.698762059211731
Iteration [19814]: Loss = 0.698723554611206
Iteration [19815]: Loss = 0.6986590623855591
Iteration [19816]: Loss = 0.6985710859298706
Iteration [19817]: Loss = 0.6984618306159973
Iteration [19818]: Loss = 0.6983335614204407
Iteration [19819]: Loss = 0.6981881260871887
Iteration [19820]: Loss = 0.6980271935462952
Iteration [19821]: Loss = 0.6978523135185242
Iteration [19822]: Loss = 0.6976650357246399
Iteration [19823]: Loss = 0.6974663734436035
Iteration [19824]: Loss = 0.6972576379776001
Iteration [19825]: Loss = 0.6970396637916565
Iteration [19826]: Loss = 0.6968135237693787
Iteration [19827]: Loss = 0.6965799927711487
Iteration [19828]: Loss = 0.6963397860527039
Iteration [19829]: Loss = 0.6960936188697815
Iteration [19830]: Loss = 0.6958420872688293
Iteration [19831]: Loss = 0.6955857276916504
Iteration [19832]: Loss = 0.6953250169754028
Iteration [19833]: Loss = 0.6950604319572449
Iteration [19834]: Loss = 0.6947923302650452
Iteration [19835]: Loss = 0.6945210695266724
Iteration [19836]: Loss = 0.6942468881607056
Iteration [19837]: Loss = 0.6939703226089478
Iteration [19838]: Loss = 0.6936912536621094
Iteration [19839]: Loss = 0.693410336971283
Iteration [19840]: Loss = 0.6931275129318237
Iteration [19841]: Loss = 0.6928431391716003
Iteration [19842]: Loss = 0.692557156085968
Iteration [19843]: Loss = 0.6922697424888611
Iteration [19844]: Loss = 0.6919814348220825
Iteration [19845]: Loss = 0.6916919946670532
Iteration [19846]: Loss = 0.691401481628418
Iteration [19847]: Loss = 0.6911101937294006
Iteration [19848]: Loss = 0.6908181309700012
Iteration [19849]: Loss = 0.6905254125595093
Iteration [19850]: Loss = 0.6902320384979248
Iteration [19851]: Loss = 0.6899383068084717
Iteration [19852]: Loss = 0.6896439790725708
Iteration [19853]: Loss = 0.6893492341041565
Iteration [19854]: Loss = 0.6890541315078735
Iteration [19855]: Loss = 0.6887587308883667
Iteration [19856]: Loss = 0.6884629726409912
Iteration [19857]: Loss = 0.6881670951843262
Iteration [19858]: Loss = 5.0102009773254395
Iteration [19859]: Loss = 5.01077127456665
Iteration [19860]: Loss = 0.6878288984298706
Iteration [19861]: Loss = 0.6878570318222046
Iteration [19862]: Loss = 0.6878527998924255
Iteration [19863]: Loss = 0.6878191232681274
Iteration [19864]: Loss = 5.010801792144775
Iteration [19865]: Loss = 0.6878647208213806
Iteration [19866]: Loss = 0.6879302263259888
Iteration [19867]: Loss = 0.6879595518112183
Iteration [19868]: Loss = 0.6879561543464661
Iteration [19869]: Loss = 0.6879234313964844
Iteration [19870]: Loss = 0.6878643035888672
Iteration [19871]: Loss = 5.010683059692383
Iteration [19872]: Loss = 0.6878662705421448
Iteration [19873]: Loss = 5.009973049163818
Iteration [19874]: Loss = 0.6881147623062134
Iteration [19875]: Loss = 0.6882667541503906
Iteration [19876]: Loss = 0.6883737444877625
Iteration [19877]: Loss = 0.6884403824806213
Iteration [19878]: Loss = 0.688470721244812
Iteration [19879]: Loss = 0.6884683966636658
Iteration [19880]: Loss = 5.007160663604736
Iteration [19881]: Loss = 0.6885673403739929
Iteration [19882]: Loss = 0.6886553764343262
Iteration [19883]: Loss = 5.005719184875488
Iteration [19884]: Loss = 5.0046234130859375
Iteration [19885]: Loss = 0.689251184463501
Iteration [19886]: Loss = 0.689530074596405
Iteration [19887]: Loss = 5.000107765197754
Iteration [19888]: Loss = 0.690109133720398
Iteration [19889]: Loss = 0.690401554107666
Iteration [19890]: Loss = 0.6906353831291199
Iteration [19891]: Loss = 0.6908160448074341
Iteration [19892]: Loss = 0.6909490823745728
Iteration [19893]: Loss = 0.6910388469696045
Iteration [19894]: Loss = 0.6910900473594666
Iteration [19895]: Loss = 0.6911063194274902
Iteration [19896]: Loss = 0.6910909414291382
Iteration [19897]: Loss = 0.6910473704338074
Iteration [19898]: Loss = 0.6909781694412231
Iteration [19899]: Loss = 0.6908860802650452
Iteration [19900]: Loss = 0.6907731294631958
Iteration [19901]: Loss = 0.6906417012214661
Iteration [19902]: Loss = 0.6904934644699097
Iteration [19903]: Loss = 0.6903300881385803
Iteration [19904]: Loss = 0.6901530027389526
Iteration [19905]: Loss = 0.6899638175964355
Iteration [19906]: Loss = 0.6897633671760559
Iteration [19907]: Loss = 0.6895532608032227
Iteration [19908]: Loss = 0.6893341541290283
Iteration [19909]: Loss = 0.6891071200370789
Iteration [19910]: Loss = 0.6888726949691772
Iteration [19911]: Loss = 0.6886318922042847
Iteration [19912]: Loss = 0.6883851885795593
Iteration [19913]: Loss = 0.6881332993507385
Iteration [19914]: Loss = 5.010169506072998
Iteration [19915]: Loss = 0.6878066062927246
Iteration [19916]: Loss = 9.334380149841309
Iteration [19917]: Loss = 0.6879779100418091
Iteration [19918]: Loss = 0.6881864070892334
Iteration [19919]: Loss = 0.6883445382118225
Iteration [19920]: Loss = 5.007048606872559
Iteration [19921]: Loss = 0.6887175440788269
Iteration [19922]: Loss = 0.6889221668243408
Iteration [19923]: Loss = 0.689076840877533
Iteration [19924]: Loss = 0.6891866326332092
Iteration [19925]: Loss = 0.6892558932304382
Iteration [19926]: Loss = 5.002588272094727
Iteration [19927]: Loss = 0.6894765496253967
Iteration [19928]: Loss = 0.6896162033081055
Iteration [19929]: Loss = 0.689712405204773
Iteration [19930]: Loss = 0.6897693276405334
Iteration [19931]: Loss = 4.999897003173828
Iteration [19932]: Loss = 0.6899689435958862
Iteration [19933]: Loss = 4.99824333190918
Iteration [19934]: Loss = 0.6903755068778992
Iteration [19935]: Loss = 0.6905943751335144
Iteration [19936]: Loss = 4.99470329284668
Iteration [19937]: Loss = 0.6910704970359802
Iteration [19938]: Loss = 0.6913189888000488
Iteration [19939]: Loss = 4.99069356918335
Iteration [19940]: Loss = 0.6918455362319946
Iteration [19941]: Loss = 0.6921152472496033
Iteration [19942]: Loss = 0.6923285126686096
Iteration [19943]: Loss = 0.6924909949302673
Iteration [19944]: Loss = 0.6926073431968689
Iteration [19945]: Loss = 0.6926823854446411
Iteration [19946]: Loss = 4.984264850616455
Iteration [19947]: Loss = 0.6929122805595398
Iteration [19948]: Loss = 0.6930556297302246
Iteration [19949]: Loss = 0.6931548118591309
Iteration [19950]: Loss = 0.6932142972946167
Iteration [19951]: Loss = 0.6932381391525269
Iteration [19952]: Loss = 0.6932296752929688
Iteration [19953]: Loss = 4.98175573348999
Iteration [19954]: Loss = 4.981093883514404
Iteration [19955]: Loss = 4.9796600341796875
Iteration [19956]: Loss = 0.6939876079559326
Iteration [19957]: Loss = 0.6943185329437256
Iteration [19958]: Loss = 0.6945868134498596
Iteration [19959]: Loss = 0.6947987675666809
Iteration [19960]: Loss = 4.972386837005615
Iteration [19961]: Loss = 4.97078800201416
Iteration [19962]: Loss = 0.6956913471221924
Iteration [19963]: Loss = 0.6960482001304626
Iteration [19964]: Loss = 0.6963396668434143
Iteration [19965]: Loss = 0.6965723037719727
Iteration [19966]: Loss = 0.6967520117759705
Iteration [19967]: Loss = 0.6968837380409241
Iteration [19968]: Loss = 0.6969725489616394
Iteration [19969]: Loss = 0.6970223188400269
Iteration [19970]: Loss = 0.6970372796058655
Iteration [19971]: Loss = 4.96151065826416
Iteration [19972]: Loss = 0.6971635222434998
Iteration [19973]: Loss = 0.697262167930603
Iteration [19974]: Loss = 4.959929943084717
Iteration [19975]: Loss = 0.697531521320343
Iteration [19976]: Loss = 0.6976911425590515
Iteration [19977]: Loss = 0.6978046894073486
Iteration [19978]: Loss = 0.6978769898414612
Iteration [19979]: Loss = 0.6979122161865234
Iteration [19980]: Loss = 0.697913646697998
Iteration [19981]: Loss = 0.6978850364685059
Iteration [19982]: Loss = 0.6978291273117065
Iteration [19983]: Loss = 0.697748601436615
Iteration [19984]: Loss = 0.6976461410522461
Iteration [19985]: Loss = 0.6975237131118774
Iteration [19986]: Loss = 0.6973834037780762
Iteration [19987]: Loss = 4.960424900054932
Iteration [19988]: Loss = 0.6972447037696838
Iteration [19989]: Loss = 0.6972305774688721
Iteration [19990]: Loss = 0.697187602519989
Iteration [19991]: Loss = 0.697118878364563
Iteration [19992]: Loss = 0.6970269680023193
Iteration [19993]: Loss = 0.6969141364097595
Iteration [19994]: Loss = 0.6967824101448059
Iteration [19995]: Loss = 0.6966336965560913
Iteration [19996]: Loss = 0.6964698433876038
Iteration [19997]: Loss = 4.9653496742248535
Iteration [19998]: Loss = 0.6962909698486328
Iteration [19999]: Loss = 0.6962598562240601
Iteration [20000]: Loss = 0.6962018013000488
Iteration [20001]: Loss = 0.6961194276809692
Iteration [20002]: Loss = 4.96681022644043
Iteration [20003]: Loss = 0.6960799694061279
Iteration [20004]: Loss = 0.6961082816123962
Iteration [20005]: Loss = 0.6961036920547485
Iteration [20006]: Loss = 0.6960695385932922
Iteration [20007]: Loss = 0.6960086226463318
Iteration [20008]: Loss = 0.6959237456321716
Iteration [20009]: Loss = 0.695817232131958
Iteration [20010]: Loss = 0.6956912279129028
Iteration [20011]: Loss = 0.6955476999282837
Iteration [20012]: Loss = 0.6953883171081543
Iteration [20013]: Loss = 0.6952148675918579
Iteration [20014]: Loss = 0.69502854347229
Iteration [20015]: Loss = 0.6948306560516357
Iteration [20016]: Loss = 0.6946225166320801
Iteration [20017]: Loss = 0.6944049000740051
Iteration [20018]: Loss = 0.6941789984703064
Iteration [20019]: Loss = 0.693945586681366
Iteration [20020]: Loss = 0.6937053799629211
Iteration [20021]: Loss = 0.6934589743614197
Iteration [20022]: Loss = 0.6932072639465332
Iteration [20023]: Loss = 0.6929503679275513
Iteration [20024]: Loss = 0.6926892995834351
Iteration [20025]: Loss = 0.6924239993095398
Iteration [20026]: Loss = 4.987271308898926
Iteration [20027]: Loss = 4.987705707550049
Iteration [20028]: Loss = 0.6921596527099609
Iteration [20029]: Loss = 0.6922073364257812
Iteration [20030]: Loss = 0.6922202706336975
Iteration [20031]: Loss = 0.6922018527984619
Iteration [20032]: Loss = 0.6921553015708923
Iteration [20033]: Loss = 0.6920833587646484
Iteration [20034]: Loss = 0.6919885873794556
Iteration [20035]: Loss = 4.988773345947266
Iteration [20036]: Loss = 0.691929280757904
Iteration [20037]: Loss = 0.6919498443603516
Iteration [20038]: Loss = 0.6919382214546204
Iteration [20039]: Loss = 0.6918978095054626
Iteration [20040]: Loss = 4.988996505737305
Iteration [20041]: Loss = 0.691931426525116
Iteration [20042]: Loss = 4.9881439208984375
Iteration [20043]: Loss = 0.6922049522399902
Iteration [20044]: Loss = 0.6923672556877136
Iteration [20045]: Loss = 0.6924833655357361
Iteration [20046]: Loss = 0.6925578713417053
Iteration [20047]: Loss = 0.6925950050354004
Iteration [20048]: Loss = 0.6925984621047974
Iteration [20049]: Loss = 0.6925714612007141
Iteration [20050]: Loss = 0.6925171613693237
Iteration [20051]: Loss = 4.985764980316162
Iteration [20052]: Loss = 0.6925268769264221
Iteration [20053]: Loss = 0.6925766468048096
Iteration [20054]: Loss = 0.6925915479660034
Iteration [20055]: Loss = 0.6925749182701111
Iteration [20056]: Loss = 4.9852776527404785
Iteration [20057]: Loss = 0.6926490068435669
Iteration [20058]: Loss = 4.9842329025268555
Iteration [20059]: Loss = 0.6929550766944885
Iteration [20060]: Loss = 0.6931312084197998
Iteration [20061]: Loss = 4.9813971519470215
Iteration [20062]: Loss = 0.6935345530509949
Iteration [20063]: Loss = 0.693752110004425
Iteration [20064]: Loss = 4.977904319763184
Iteration [20065]: Loss = 0.6942261457443237
Iteration [20066]: Loss = 0.6944735646247864
Iteration [20067]: Loss = 4.973938941955566
Iteration [20068]: Loss = 4.9721808433532715
Iteration [20069]: Loss = 0.6954560875892639
Iteration [20070]: Loss = 0.6958379149436951
Iteration [20071]: Loss = 0.696151852607727
Iteration [20072]: Loss = 0.6964043974876404
Iteration [20073]: Loss = 0.6966017484664917
Iteration [20074]: Loss = 4.962939262390137
Iteration [20075]: Loss = 0.6970407366752625
Iteration [20076]: Loss = 0.6972729563713074
Iteration [20077]: Loss = 4.95924186706543
Iteration [20078]: Loss = 0.6977712512016296
Iteration [20079]: Loss = 0.6980286836624146
Iteration [20080]: Loss = 0.6982303857803345
Iteration [20081]: Loss = 0.6983817219734192
Iteration [20082]: Loss = 0.6984878182411194
Iteration [20083]: Loss = 0.6985530257225037
Iteration [20084]: Loss = 0.6985813975334167
Iteration [20085]: Loss = 0.6985767483711243
Iteration [20086]: Loss = 4.953516006469727
Iteration [20087]: Loss = 0.6986698508262634
Iteration [20088]: Loss = 0.6987545490264893
Iteration [20089]: Loss = 0.6988005638122559
Iteration [20090]: Loss = 0.6988117098808289
Iteration [20091]: Loss = 0.6987913250923157
Iteration [20092]: Loss = 0.6987426280975342
Iteration [20093]: Loss = 0.6986684203147888
Iteration [20094]: Loss = 0.6985712051391602
Iteration [20095]: Loss = 0.6984535455703735
Iteration [20096]: Loss = 0.6983170509338379
Iteration [20097]: Loss = 4.955501079559326
Iteration [20098]: Loss = 4.955387592315674
Iteration [20099]: Loss = 4.954452991485596
Iteration [20100]: Loss = 0.6986823678016663
Iteration [20101]: Loss = 0.6989392638206482
Iteration [20102]: Loss = 0.6991403698921204
Iteration [20103]: Loss = 0.6992911100387573
Iteration [20104]: Loss = 0.6993964910507202
Iteration [20105]: Loss = 0.6994609832763672
Iteration [20106]: Loss = 4.9485554695129395
Iteration [20107]: Loss = 0.6996724605560303
Iteration [20108]: Loss = 0.6998074650764465
Iteration [20109]: Loss = 0.6998987197875977
Iteration [20110]: Loss = 0.6999505162239075
Iteration [20111]: Loss = 0.6999667286872864
Iteration [20112]: Loss = 0.6999508738517761
Iteration [20113]: Loss = 0.6999062299728394
Iteration [20114]: Loss = 0.6998355388641357
Iteration [20115]: Loss = 0.6997414827346802
Iteration [20116]: Loss = 0.6996263861656189
Iteration [20117]: Loss = 0.6994922161102295
Iteration [20118]: Loss = 0.6985876560211182
Iteration [20119]: Loss = 4.954140663146973
Iteration [20120]: Loss = 0.6984343528747559
Iteration [20121]: Loss = 0.6984143257141113
Iteration [20122]: Loss = 0.6983658075332642
Iteration [20123]: Loss = 0.6982917785644531
Iteration [20124]: Loss = 0.698194682598114
Iteration [20125]: Loss = 0.6980768442153931
Iteration [20126]: Loss = 0.6979402303695679
Iteration [20127]: Loss = 0.697786808013916
Iteration [20128]: Loss = 9.219114303588867
Iteration [20129]: Loss = 0.6978152394294739
Iteration [20130]: Loss = 0.6979622840881348
Iteration [20131]: Loss = 0.6980644464492798
Iteration [20132]: Loss = 0.6981264352798462
Iteration [20133]: Loss = 0.6981519460678101
Iteration [20134]: Loss = 0.6981446146965027
Iteration [20135]: Loss = 0.6981078386306763
Iteration [20136]: Loss = 4.956127643585205
Iteration [20137]: Loss = 4.955593585968018
Iteration [20138]: Loss = 0.6983957886695862
Iteration [20139]: Loss = 4.9532623291015625
Iteration [20140]: Loss = 0.6989234089851379
Iteration [20141]: Loss = 0.6991932392120361
Iteration [20142]: Loss = 0.6994060277938843
Iteration [20143]: Loss = 4.948144435882568
Iteration [20144]: Loss = 0.6998703479766846
Iteration [20145]: Loss = 0.70011305809021
Iteration [20146]: Loss = 0.7003014087677002
Iteration [20147]: Loss = 0.7004407048225403
Iteration [20148]: Loss = 0.7005358338356018
Iteration [20149]: Loss = 0.7005912065505981
Iteration [20150]: Loss = 0.7006107568740845
Iteration [20151]: Loss = 0.7005979418754578
Iteration [20152]: Loss = 0.7005560994148254
Iteration [20153]: Loss = 0.7004879713058472
Iteration [20154]: Loss = 0.7003964185714722
Iteration [20155]: Loss = 4.944399833679199
Iteration [20156]: Loss = 0.7003404498100281
Iteration [20157]: Loss = 0.7003614902496338
Iteration [20158]: Loss = 0.7003499865531921
Iteration [20159]: Loss = 0.7003093361854553
Iteration [20160]: Loss = 0.7002422213554382
Iteration [20161]: Loss = 0.7001516222953796
Iteration [20162]: Loss = 0.7000395059585571
Iteration [20163]: Loss = 0.6999081969261169
Iteration [20164]: Loss = 0.6997596025466919
Iteration [20165]: Loss = 0.6995954513549805
Iteration [20166]: Loss = 0.6994174122810364
Iteration [20167]: Loss = 4.9499287605285645
Iteration [20168]: Loss = 0.6992140412330627
Iteration [20169]: Loss = 0.6991724967956543
Iteration [20170]: Loss = 0.6991046071052551
Iteration [20171]: Loss = 0.6990132331848145
Iteration [20172]: Loss = 0.6989006400108337
Iteration [20173]: Loss = 4.952327251434326
Iteration [20174]: Loss = 0.6988092660903931
Iteration [20175]: Loss = 0.6988154053688049
Iteration [20176]: Loss = 0.6987906694412231
Iteration [20177]: Loss = 0.6987379789352417
Iteration [20178]: Loss = 0.698660135269165
Iteration [20179]: Loss = 0.6985597014427185
Iteration [20180]: Loss = 0.6984388828277588
Iteration [20181]: Loss = 0.6982998847961426
Iteration [20182]: Loss = 0.698144257068634
Iteration [20183]: Loss = 0.6979737877845764
Iteration [20184]: Loss = 0.6977899670600891
Iteration [20185]: Loss = 4.958494186401367
Iteration [20186]: Loss = 4.958581447601318
Iteration [20187]: Loss = 0.6977217793464661
Iteration [20188]: Loss = 0.6978214383125305
Iteration [20189]: Loss = 0.6978808641433716
Iteration [20190]: Loss = 0.697904109954834
Iteration [20191]: Loss = 0.6978945136070251
Iteration [20192]: Loss = 0.6978555917739868
Iteration [20193]: Loss = 0.6977902054786682
Iteration [20194]: Loss = 0.6977009773254395
Iteration [20195]: Loss = 0.6975902915000916
Iteration [20196]: Loss = 0.6974602937698364
Iteration [20197]: Loss = 0.6973127722740173
Iteration [20198]: Loss = 0.6971496343612671
Iteration [20199]: Loss = 0.6969724297523499
Iteration [20200]: Loss = 0.6967824101448059
Iteration [20201]: Loss = 0.6965810656547546
Iteration [20202]: Loss = 0.696369469165802
Iteration [20203]: Loss = 4.966107368469238
Iteration [20204]: Loss = 4.966310024261475
Iteration [20205]: Loss = 0.6962350606918335
Iteration [20206]: Loss = 0.6963174343109131
Iteration [20207]: Loss = 0.6963613033294678
Iteration [20208]: Loss = 0.6963704228401184
Iteration [20209]: Loss = 0.6963483095169067
Iteration [20210]: Loss = 0.6962981820106506
Iteration [20211]: Loss = 0.6962225437164307
Iteration [20212]: Loss = 0.6961240768432617
Iteration [20213]: Loss = 0.69600510597229
Iteration [20214]: Loss = 0.6958677768707275
Iteration [20215]: Loss = 0.6957136392593384
Iteration [20216]: Loss = 0.6955444812774658
Iteration [20217]: Loss = 0.6953619122505188
Iteration [20218]: Loss = 4.97128963470459
Iteration [20219]: Loss = 0.6951525211334229
Iteration [20220]: Loss = 0.6951088905334473
Iteration [20221]: Loss = 0.6950393915176392
Iteration [20222]: Loss = 0.6949464678764343
Iteration [20223]: Loss = 0.694832444190979
Iteration [20224]: Loss = 0.6946994066238403
Iteration [20225]: Loss = 0.6945493221282959
Iteration [20226]: Loss = 4.97543478012085
Iteration [20227]: Loss = 4.975372314453125
Iteration [20228]: Loss = 0.694566547870636
Iteration [20229]: Loss = 0.6946901082992554
Iteration [20230]: Loss = 0.6947710514068604
Iteration [20231]: Loss = 0.6948136687278748
Iteration [20232]: Loss = 0.6948217153549194
Iteration [20233]: Loss = 0.6947986483573914
Iteration [20234]: Loss = 0.6947475075721741
Iteration [20235]: Loss = 0.694671094417572
Iteration [20236]: Loss = 4.9744391441345215
Iteration [20237]: Loss = 4.974060535430908
Iteration [20238]: Loss = 0.6948676705360413
Iteration [20239]: Loss = 0.6950393915176392
Iteration [20240]: Loss = 0.6951637268066406
Iteration [20241]: Loss = 4.970876693725586
Iteration [20242]: Loss = 0.6954787969589233
Iteration [20243]: Loss = 4.968692302703857
Iteration [20244]: Loss = 0.6959801316261292
Iteration [20245]: Loss = 0.6962393522262573
Iteration [20246]: Loss = 0.6964426636695862
Iteration [20247]: Loss = 0.6965951919555664
Iteration [20248]: Loss = 0.696702241897583
Iteration [20249]: Loss = 0.6967682838439941
Iteration [20250]: Loss = 0.696797251701355
Iteration [20251]: Loss = 4.962708950042725
Iteration [20252]: Loss = 0.6969490647315979
Iteration [20253]: Loss = 0.697059154510498
Iteration [20254]: Loss = 0.6971281170845032
Iteration [20255]: Loss = 4.960779666900635
Iteration [20256]: Loss = 0.69734787940979
Iteration [20257]: Loss = 0.6974869966506958
Iteration [20258]: Loss = 0.6975818276405334
Iteration [20259]: Loss = 4.958270072937012
Iteration [20260]: Loss = 0.6978458762168884
Iteration [20261]: Loss = 0.698003888130188
Iteration [20262]: Loss = 0.6981156468391418
Iteration [20263]: Loss = 0.6981858611106873
Iteration [20264]: Loss = 4.955214023590088
Iteration [20265]: Loss = 0.698407769203186
Iteration [20266]: Loss = 4.953486442565918
Iteration [20267]: Loss = 4.951990604400635
Iteration [20268]: Loss = 0.6992486715316772
Iteration [20269]: Loss = 0.6995925903320312
Iteration [20270]: Loss = 0.6998718976974487
Iteration [20271]: Loss = 0.700093150138855
Iteration [20272]: Loss = 0.7002618312835693
Iteration [20273]: Loss = 0.7003830671310425
Iteration [20274]: Loss = 0.700461745262146
Iteration [20275]: Loss = 0.7005020976066589
Iteration [20276]: Loss = 0.7005077004432678
Iteration [20277]: Loss = 4.943362236022949
Iteration [20278]: Loss = 0.7006186842918396
Iteration [20279]: Loss = 0.700711190700531
Iteration [20280]: Loss = 0.7007638812065125
Iteration [20281]: Loss = 0.7007806301116943
Iteration [20282]: Loss = 0.7007651329040527
Iteration [20283]: Loss = 0.7007205486297607
Iteration [20284]: Loss = 0.7006497979164124
Iteration [20285]: Loss = 0.7005553841590881
Iteration [20286]: Loss = 0.7004397511482239
Iteration [20287]: Loss = 0.7003050446510315
Iteration [20288]: Loss = 0.7001530528068542
Iteration [20289]: Loss = 0.6999854445457458
Iteration [20290]: Loss = 0.6998040080070496
Iteration [20291]: Loss = 0.6996099948883057
Iteration [20292]: Loss = 0.6994047164916992
Iteration [20293]: Loss = 0.699189305305481
Iteration [20294]: Loss = 0.6989646553993225
Iteration [20295]: Loss = 0.6987317204475403
Iteration [20296]: Loss = 0.6984913945198059
Iteration [20297]: Loss = 0.698244571685791
Iteration [20298]: Loss = 0.697991669178009
Iteration [20299]: Loss = 0.6977332830429077
Iteration [20300]: Loss = 0.6974701285362244
Iteration [20301]: Loss = 0.6972026824951172
Iteration [20302]: Loss = 4.961981296539307
Iteration [20303]: Loss = 0.696848452091217
Iteration [20304]: Loss = 0.6967432498931885
Iteration [20305]: Loss = 0.6966180205345154
Iteration [20306]: Loss = 0.6964747309684753
Iteration [20307]: Loss = 0.6963150501251221
Iteration [20308]: Loss = 0.6961408257484436
Iteration [20309]: Loss = 0.695953369140625
Iteration [20310]: Loss = 0.6957541108131409
Iteration [20311]: Loss = 4.969297885894775
Iteration [20312]: Loss = 0.6955166459083557
Iteration [20313]: Loss = 0.6954613327980042
Iteration [20314]: Loss = 0.6953811645507812
Iteration [20315]: Loss = 0.6952782869338989
Iteration [20316]: Loss = 0.6951552629470825
Iteration [20317]: Loss = 4.972099781036377
Iteration [20318]: Loss = 4.971919059753418
Iteration [20319]: Loss = 0.6952399611473083
Iteration [20320]: Loss = 0.6953821182250977
Iteration [20321]: Loss = 0.6954797506332397
Iteration [20322]: Loss = 0.6955370903015137
Iteration [20323]: Loss = 0.6955583691596985
Iteration [20324]: Loss = 0.6955467462539673
Iteration [20325]: Loss = 0.6955059170722961
Iteration [20326]: Loss = 0.6954385042190552
Iteration [20327]: Loss = 4.970337390899658
Iteration [20328]: Loss = 0.6954265832901001
Iteration [20329]: Loss = 0.6954674124717712
Iteration [20330]: Loss = 0.6954736113548279
Iteration [20331]: Loss = 0.6954487562179565
Iteration [20332]: Loss = 0.6953957080841064
Iteration [20333]: Loss = 0.6953173875808716
Iteration [20334]: Loss = 0.6952164173126221
Iteration [20335]: Loss = 0.6950949430465698
Iteration [20336]: Loss = 0.6949548125267029
Iteration [20337]: Loss = 4.973240852355957
Iteration [20338]: Loss = 4.973130226135254
Iteration [20339]: Loss = 0.6949991583824158
Iteration [20340]: Loss = 0.6951306462287903
Iteration [20341]: Loss = 0.695218563079834
Iteration [20342]: Loss = 0.6952673196792603
Iteration [20343]: Loss = 0.6952805519104004
Iteration [20344]: Loss = 0.6952618360519409
Iteration [20345]: Loss = 0.6952146291732788
Iteration [20346]: Loss = 0.6951413750648499
Iteration [20347]: Loss = 0.6950448751449585
Iteration [20348]: Loss = 0.6949273943901062
Iteration [20349]: Loss = 0.6947911381721497
Iteration [20350]: Loss = 0.6946378350257874
Iteration [20351]: Loss = 0.694469153881073
Iteration [20352]: Loss = 0.6942867636680603
Iteration [20353]: Loss = 0.6940918564796448
Iteration [20354]: Loss = 0.6938861012458801
Iteration [20355]: Loss = 0.6936699151992798
Iteration [20356]: Loss = 0.6934450268745422
Iteration [20357]: Loss = 0.6932117938995361
Iteration [20358]: Loss = 0.6929712891578674
Iteration [20359]: Loss = 0.6927242875099182
Iteration [20360]: Loss = 0.6924712657928467
Iteration [20361]: Loss = 0.6922130584716797
Iteration [20362]: Loss = 0.6919500827789307
Iteration [20363]: Loss = 0.6916826963424683
Iteration [20364]: Loss = 0.6914114952087402
Iteration [20365]: Loss = 4.992700576782227
Iteration [20366]: Loss = 0.6910528540611267
Iteration [20367]: Loss = 0.6909468173980713
Iteration [20368]: Loss = 0.6908208131790161
Iteration [20369]: Loss = 0.6906768083572388
Iteration [20370]: Loss = 0.6905168890953064
Iteration [20371]: Loss = 4.996945858001709
Iteration [20372]: Loss = 0.6902799606323242
Iteration [20373]: Loss = 0.6902547478675842
Iteration [20374]: Loss = 0.6902016997337341
Iteration [20375]: Loss = 0.6901234984397888
Iteration [20376]: Loss = 4.998655796051025
Iteration [20377]: Loss = 0.6900946497917175
Iteration [20378]: Loss = 0.6901291608810425
Iteration [20379]: Loss = 0.6901298761367798
Iteration [20380]: Loss = 4.998241424560547
Iteration [20381]: Loss = 0.6902357339859009
Iteration [20382]: Loss = 0.6903277039527893
Iteration [20383]: Loss = 0.6903799176216125
Iteration [20384]: Loss = 4.996654987335205
Iteration [20385]: Loss = 0.6905741691589355
Iteration [20386]: Loss = 0.6907035708427429
Iteration [20387]: Loss = 0.6907896399497986
Iteration [20388]: Loss = 0.6908367276191711
Iteration [20389]: Loss = 0.6908485293388367
Iteration [20390]: Loss = 4.994345664978027
Iteration [20391]: Loss = 0.6909735202789307
Iteration [20392]: Loss = 0.6910734176635742
Iteration [20393]: Loss = 0.6911330223083496
Iteration [20394]: Loss = 0.6911561489105225
Iteration [20395]: Loss = 0.6911464333534241
Iteration [20396]: Loss = 0.6911070942878723
Iteration [20397]: Loss = 0.6910412311553955
Iteration [20398]: Loss = 0.690951406955719
Iteration [20399]: Loss = 0.690839946269989
Iteration [20400]: Loss = 0.6907089948654175
Iteration [20401]: Loss = 0.6905606389045715
Iteration [20402]: Loss = 0.6903966665267944
Iteration [20403]: Loss = 0.6902182698249817
Iteration [20404]: Loss = 0.6900272369384766
Iteration [20405]: Loss = 0.6898247599601746
Iteration [20406]: Loss = 0.6896119117736816
Iteration [20407]: Loss = 5.002045154571533
Iteration [20408]: Loss = 0.6893534660339355
Iteration [20409]: Loss = 0.6892905235290527
Iteration [20410]: Loss = 0.6892032623291016
Iteration [20411]: Loss = 0.6890941858291626
Iteration [20412]: Loss = 5.00432014465332
Iteration [20413]: Loss = 0.6890133023262024
Iteration [20414]: Loss = 0.6890257596969604
Iteration [20415]: Loss = 0.6890064477920532
Iteration [20416]: Loss = 0.6889586448669434
Iteration [20417]: Loss = 0.6888852119445801
Iteration [20418]: Loss = 5.005270004272461
Iteration [20419]: Loss = 0.688865065574646
Iteration [20420]: Loss = 0.6889035701751709
Iteration [20421]: Loss = 5.004630088806152
Iteration [20422]: Loss = 0.6890747547149658
Iteration [20423]: Loss = 0.6891946196556091
Iteration [20424]: Loss = 0.6892721652984619
Iteration [20425]: Loss = 0.6893114447593689
Iteration [20426]: Loss = 0.6893162131309509
Iteration [20427]: Loss = 0.6892903447151184
Iteration [20428]: Loss = 0.6892362833023071
Iteration [20429]: Loss = 0.6891571879386902
Iteration [20430]: Loss = 0.6890554428100586
Iteration [20431]: Loss = 0.6889331936836243
Iteration [20432]: Loss = 0.6887927055358887
Iteration [20433]: Loss = 0.6886355876922607
Iteration [20434]: Loss = 5.00701379776001
Iteration [20435]: Loss = 0.6884730458259583
Iteration [20436]: Loss = 0.6884508728981018
Iteration [20437]: Loss = 5.007353782653809
Iteration [20438]: Loss = 0.6885187029838562
Iteration [20439]: Loss = 0.6885946393013
Iteration [20440]: Loss = 0.6886327266693115
Iteration [20441]: Loss = 0.6886363625526428
Iteration [20442]: Loss = 0.68860924243927
Iteration [20443]: Loss = 0.6885541677474976
Iteration [20444]: Loss = 5.006957530975342
Iteration [20445]: Loss = 0.6885659098625183
Iteration [20446]: Loss = 0.688618004322052
Iteration [20447]: Loss = 0.6886345148086548
Iteration [20448]: Loss = 0.6886187195777893
Iteration [20449]: Loss = 0.6885741949081421
Iteration [20450]: Loss = 9.325098991394043
Iteration [20451]: Loss = 5.005235195159912
Iteration [20452]: Loss = 0.6892189383506775
Iteration [20453]: Loss = 0.6895704865455627
Iteration [20454]: Loss = 0.6898571252822876
Iteration [20455]: Loss = 4.998323440551758
Iteration [20456]: Loss = 0.6904511451721191
Iteration [20457]: Loss = 0.6907508969306946
Iteration [20458]: Loss = 4.993481159210205
Iteration [20459]: Loss = 0.6913676261901855
Iteration [20460]: Loss = 0.6916768550872803
Iteration [20461]: Loss = 4.988496780395508
Iteration [20462]: Loss = 0.6923094987869263
Iteration [20463]: Loss = 4.984768390655518
Iteration [20464]: Loss = 0.6930705308914185
Iteration [20465]: Loss = 0.6934412121772766
Iteration [20466]: Loss = 4.978824615478516
Iteration [20467]: Loss = 0.6941782832145691
Iteration [20468]: Loss = 0.6945384740829468
Iteration [20469]: Loss = 0.6948325634002686
Iteration [20470]: Loss = 0.6950669884681702
Iteration [20471]: Loss = 0.6952475905418396
Iteration [20472]: Loss = 0.6953797340393066
Iteration [20473]: Loss = 4.969698905944824
Iteration [20474]: Loss = 0.695708692073822
Iteration [20475]: Loss = 0.6958947777748108
Iteration [20476]: Loss = 0.6960318088531494
Iteration [20477]: Loss = 0.6961246728897095
Iteration [20478]: Loss = 0.6961778998374939
Iteration [20479]: Loss = 0.6961948871612549
Iteration [20480]: Loss = 0.6961799263954163
Iteration [20481]: Loss = 0.6961355805397034
Iteration [20482]: Loss = 9.237029075622559
Iteration [20483]: Loss = 0.696352481842041
Iteration [20484]: Loss = 0.6965809464454651
Iteration [20485]: Loss = 4.9629034996032715
Iteration [20486]: Loss = 0.6970735192298889
Iteration [20487]: Loss = 0.6973289251327515
Iteration [20488]: Loss = 4.958837509155273
Iteration [20489]: Loss = 0.6978676915168762
Iteration [20490]: Loss = 0.6981425881385803
Iteration [20491]: Loss = 0.6983598470687866
Iteration [20492]: Loss = 4.953605651855469
Iteration [20493]: Loss = 0.6988329291343689
Iteration [20494]: Loss = 0.6990798115730286
Iteration [20495]: Loss = 0.6992716789245605
Iteration [20496]: Loss = 0.6994139552116394
Iteration [20497]: Loss = 4.948436260223389
Iteration [20498]: Loss = 0.699758768081665
Iteration [20499]: Loss = 0.6999508738517761
Iteration [20500]: Loss = 0.7000933885574341
Iteration [20501]: Loss = 0.700191080570221
Iteration [20502]: Loss = 0.7002487182617188
Iteration [20503]: Loss = 0.700269877910614
Iteration [20504]: Loss = 0.7002583146095276
Iteration [20505]: Loss = 0.7002173662185669
Iteration [20506]: Loss = 0.7001498937606812
Iteration [20507]: Loss = 0.7000585794448853
Iteration [20508]: Loss = 0.6999456882476807
Iteration [20509]: Loss = 0.6998133659362793
Iteration [20510]: Loss = 0.6996636986732483
Iteration [20511]: Loss = 9.197513580322266
Iteration [20512]: Loss = 0.6996986269950867
Iteration [20513]: Loss = 0.6998486518859863
Iteration [20514]: Loss = 0.6999534368515015
Iteration [20515]: Loss = 4.9457902908325195
Iteration [20516]: Loss = 0.7002333402633667
Iteration [20517]: Loss = 0.7003976106643677
Iteration [20518]: Loss = 0.7005150318145752
Iteration [20519]: Loss = 4.94279670715332
Iteration [20520]: Loss = 0.7008166313171387
Iteration [20521]: Loss = 0.7009900212287903
Iteration [20522]: Loss = 0.7011156678199768
Iteration [20523]: Loss = 0.7011984586715698
Iteration [20524]: Loss = 0.7012425661087036
Iteration [20525]: Loss = 0.7012518644332886
Iteration [20526]: Loss = 0.7012296319007874
Iteration [20527]: Loss = 0.7011792659759521
Iteration [20528]: Loss = 0.7011033296585083
Iteration [20529]: Loss = 0.7010044455528259
Iteration [20530]: Loss = 0.7008848786354065
Iteration [20531]: Loss = 0.7007467150688171
Iteration [20532]: Loss = 0.7005919218063354
Iteration [20533]: Loss = 0.7004220485687256
Iteration [20534]: Loss = 0.7002385258674622
Iteration [20535]: Loss = 0.7000428438186646
Iteration [20536]: Loss = 0.6998361349105835
Iteration [20537]: Loss = 4.947870254516602
Iteration [20538]: Loss = 0.699584424495697
Iteration [20539]: Loss = 0.6995223760604858
Iteration [20540]: Loss = 0.6994360089302063
Iteration [20541]: Loss = 0.6993277072906494
Iteration [20542]: Loss = 0.6991997361183167
Iteration [20543]: Loss = 0.6990540027618408
Iteration [20544]: Loss = 0.69889235496521
Iteration [20545]: Loss = 0.698716402053833
Iteration [20546]: Loss = 4.953592777252197
Iteration [20547]: Loss = 4.9536452293396
Iteration [20548]: Loss = 4.95285701751709
Iteration [20549]: Loss = 0.6989617943763733
Iteration [20550]: Loss = 0.6991963386535645
Iteration [20551]: Loss = 9.19890308380127
Iteration [20552]: Loss = 0.6998836994171143
Iteration [20553]: Loss = 0.700309693813324
Iteration [20554]: Loss = 0.7006633877754211
Iteration [20555]: Loss = 0.7009516954421997
Iteration [20556]: Loss = 4.939715385437012
Iteration [20557]: Loss = 0.7015447616577148
Iteration [20558]: Loss = 0.7018420696258545
Iteration [20559]: Loss = 4.935035228729248
Iteration [20560]: Loss = 0.7024506330490112
Iteration [20561]: Loss = 0.7027543783187866
Iteration [20562]: Loss = 0.702997624874115
Iteration [20563]: Loss = 0.7031864523887634
Iteration [20564]: Loss = 0.7033259868621826
Iteration [20565]: Loss = 0.7034213542938232
Iteration [20566]: Loss = 0.7034766674041748
Iteration [20567]: Loss = 0.7034961581230164
Iteration [20568]: Loss = 0.7034831643104553
Iteration [20569]: Loss = 0.7034410238265991
Iteration [20570]: Loss = 0.703372597694397
Iteration [20571]: Loss = 0.7032805681228638
Iteration [20572]: Loss = 0.7031671404838562
Iteration [20573]: Loss = 0.7030345797538757
Iteration [20574]: Loss = 0.7028847336769104
Iteration [20575]: Loss = 0.7027193307876587
Iteration [20576]: Loss = 0.7025400400161743
Iteration [20577]: Loss = 0.702347993850708
Iteration [20578]: Loss = 0.7021447420120239
Iteration [20579]: Loss = 0.7019312381744385
Iteration [20580]: Loss = 0.7017084956169128
Iteration [20581]: Loss = 0.7014777064323425
Iteration [20582]: Loss = 0.7012393474578857
Iteration [20583]: Loss = 0.7009943127632141
Iteration [20584]: Loss = 4.941999435424805
Iteration [20585]: Loss = 0.7006763219833374
Iteration [20586]: Loss = 0.7005857825279236
Iteration [20587]: Loss = 0.7004738450050354
Iteration [20588]: Loss = 0.7003427147865295
Iteration [20589]: Loss = 0.7001941204071045
Iteration [20590]: Loss = 0.7000298500061035
Iteration [20591]: Loss = 0.6998517513275146
Iteration [20592]: Loss = 0.6996608376502991
Iteration [20593]: Loss = 0.6994585394859314
Iteration [20594]: Loss = 0.6992459893226624
Iteration [20595]: Loss = 0.6990243196487427
Iteration [20596]: Loss = 0.698794424533844
Iteration [20597]: Loss = 0.6985568404197693
Iteration [20598]: Loss = 0.6983126997947693
Iteration [20599]: Loss = 0.698062539100647
Iteration [20600]: Loss = 0.6978068351745605
Iteration [20601]: Loss = 4.958745002746582
Iteration [20602]: Loss = 0.6974719762802124
Iteration [20603]: Loss = 0.6973745822906494
Iteration [20604]: Loss = 0.6972564458847046
Iteration [20605]: Loss = 0.6971198320388794
Iteration [20606]: Loss = 0.6969665288925171
Iteration [20607]: Loss = 4.962682247161865
Iteration [20608]: Loss = 0.6968064308166504
Iteration [20609]: Loss = 0.6967836022377014
Iteration [20610]: Loss = 4.963027000427246
Iteration [20611]: Loss = 0.6968465447425842
Iteration [20612]: Loss = 0.6969185471534729
Iteration [20613]: Loss = 0.696953296661377
Iteration [20614]: Loss = 0.6969541907310486
Iteration [20615]: Loss = 0.6969246864318848
Iteration [20616]: Loss = 0.6968676447868347
Iteration [20617]: Loss = 0.6967859864234924
Iteration [20618]: Loss = 0.6966822147369385
Iteration [20619]: Loss = 0.6965583562850952
Iteration [20620]: Loss = 0.6964164972305298
Iteration [20621]: Loss = 4.965527057647705
Iteration [20622]: Loss = 0.6962763071060181
Iteration [20623]: Loss = 0.696262001991272
Iteration [20624]: Loss = 0.6962188482284546
Iteration [20625]: Loss = 0.6961497068405151
Iteration [20626]: Loss = 0.6960570216178894
Iteration [20627]: Loss = 13.509684562683105
Iteration [20628]: Loss = 0.6963713765144348
Iteration [20629]: Loss = 0.6967273354530334
Iteration [20630]: Loss = 0.6970183849334717
Iteration [20631]: Loss = 0.6972506642341614
Iteration [20632]: Loss = 4.959356307983398
Iteration [20633]: Loss = 4.957686424255371
Iteration [20634]: Loss = 0.6981891989707947
Iteration [20635]: Loss = 0.6985570788383484
Iteration [20636]: Loss = 0.6988587975502014
Iteration [20637]: Loss = 0.6991006731987
Iteration [20638]: Loss = 4.9496026039123535
Iteration [20639]: Loss = 0.6996136903762817
Iteration [20640]: Loss = 0.6998764872550964
Iteration [20641]: Loss = 0.7000834345817566
Iteration [20642]: Loss = 0.7002398371696472
Iteration [20643]: Loss = 0.7003508806228638
Iteration [20644]: Loss = 0.7004207968711853
Iteration [20645]: Loss = 0.7004539370536804
Iteration [20646]: Loss = 4.94351053237915
Iteration [20647]: Loss = 4.942694664001465
Iteration [20648]: Loss = 0.7009060382843018
Iteration [20649]: Loss = 0.7011428475379944
Iteration [20650]: Loss = 0.7013261318206787
Iteration [20651]: Loss = 0.7014613151550293
Iteration [20652]: Loss = 0.7015530467033386
Iteration [20653]: Loss = 4.937502861022949
Iteration [20654]: Loss = 0.7018089294433594
Iteration [20655]: Loss = 0.7019619941711426
Iteration [20656]: Loss = 0.702069878578186
Iteration [20657]: Loss = 0.7021368741989136
Iteration [20658]: Loss = 0.702167272567749
Iteration [20659]: Loss = 4.934593677520752
Iteration [20660]: Loss = 0.7023182511329651
Iteration [20661]: Loss = 0.702426552772522
Iteration [20662]: Loss = 0.7024939656257629
Iteration [20663]: Loss = 0.702524721622467
Iteration [20664]: Loss = 9.162945747375488
Iteration [20665]: Loss = 0.7028594613075256
Iteration [20666]: Loss = 0.7031333446502686
Iteration [20667]: Loss = 0.7033501863479614
Iteration [20668]: Loss = 0.7035155892372131
Iteration [20669]: Loss = 4.926961421966553
Iteration [20670]: Loss = 0.7038964033126831
Iteration [20671]: Loss = 0.7041022181510925
Iteration [20672]: Loss = 0.7042577266693115
Iteration [20673]: Loss = 0.7043677568435669
Iteration [20674]: Loss = 0.7044368386268616
Iteration [20675]: Loss = 4.922638893127441
Iteration [20676]: Loss = 0.7046530246734619
Iteration [20677]: Loss = 4.920987129211426
Iteration [20678]: Loss = 0.7050653100013733
Iteration [20679]: Loss = 0.7052844166755676
Iteration [20680]: Loss = 4.917562961578369
Iteration [20681]: Loss = 0.705756664276123
Iteration [20682]: Loss = 0.7060014009475708
Iteration [20683]: Loss = 4.913746356964111
Iteration [20684]: Loss = 0.7065172791481018
Iteration [20685]: Loss = 0.7067805528640747
Iteration [20686]: Loss = 0.7069876194000244
Iteration [20687]: Loss = 0.7071439027786255
Iteration [20688]: Loss = 0.7072546482086182
Iteration [20689]: Loss = 4.907918453216553
Iteration [20690]: Loss = 0.7075413465499878
Iteration [20691]: Loss = 0.7077068090438843
Iteration [20692]: Loss = 0.7078254818916321
Iteration [20693]: Loss = 0.7079023718833923
Iteration [20694]: Loss = 0.707941472530365
Iteration [20695]: Loss = 0.7079464197158813
Iteration [20696]: Loss = 0.7079207897186279
Iteration [20697]: Loss = 0.707867443561554
Iteration [20698]: Loss = 4.905529499053955
Iteration [20699]: Loss = 0.7078738212585449
Iteration [20700]: Loss = 0.7079198360443115
Iteration [20701]: Loss = 4.90480375289917
Iteration [20702]: Loss = 0.7080956101417542
Iteration [20703]: Loss = 4.9033522605896
Iteration [20704]: Loss = 0.7084744572639465
Iteration [20705]: Loss = 0.7086789608001709
Iteration [20706]: Loss = 0.7088330388069153
Iteration [20707]: Loss = 0.7089415788650513
Iteration [20708]: Loss = 0.7090091109275818
Iteration [20709]: Loss = 0.7090396881103516
Iteration [20710]: Loss = 0.7090370059013367
Iteration [20711]: Loss = 0.7090041637420654
Iteration [20712]: Loss = 0.7089444398880005
Iteration [20713]: Loss = 0.7088603973388672
Iteration [20714]: Loss = 0.7087544798851013
Iteration [20715]: Loss = 0.70862877368927
Iteration [20716]: Loss = 9.095434188842773
Iteration [20717]: Loss = 0.7086949944496155
Iteration [20718]: Loss = 0.7088539004325867
Iteration [20719]: Loss = 0.708966851234436
Iteration [20720]: Loss = 4.8991265296936035
Iteration [20721]: Loss = 0.7065816521644592
Iteration [20722]: Loss = 0.7067473530769348
Iteration [20723]: Loss = 0.7068665027618408
Iteration [20724]: Loss = 0.7069440484046936
Iteration [20725]: Loss = 4.909669399261475
Iteration [20726]: Loss = 0.7071734070777893
Iteration [20727]: Loss = 0.7073142528533936
Iteration [20728]: Loss = 4.907472133636475
Iteration [20729]: Loss = 0.7076518535614014
Iteration [20730]: Loss = 0.7078388929367065
Iteration [20731]: Loss = 0.7079771757125854
Iteration [20732]: Loss = 0.708071768283844
Iteration [20733]: Loss = 0.7081268429756165
Iteration [20734]: Loss = 0.7081464529037476
Iteration [20735]: Loss = 0.708134114742279
Iteration [20736]: Loss = 0.7080928087234497
Iteration [20737]: Loss = 4.904316425323486
Iteration [20738]: Loss = 0.7081193327903748
Iteration [20739]: Loss = 0.7081735730171204
Iteration [20740]: Loss = 0.7081924080848694
Iteration [20741]: Loss = 0.7081793546676636
Iteration [20742]: Loss = 4.903743267059326
Iteration [20743]: Loss = 4.903146266937256
Iteration [20744]: Loss = 0.7085123062133789
Iteration [20745]: Loss = 0.7087151408195496
Iteration [20746]: Loss = 0.7088676691055298
Iteration [20747]: Loss = 0.7089749574661255
Iteration [20748]: Loss = 9.089179992675781
Iteration [20749]: Loss = 0.7094360589981079
Iteration [20750]: Loss = 0.7097615599632263
Iteration [20751]: Loss = 0.7100248336791992
Iteration [20752]: Loss = 0.7102319598197937
Iteration [20753]: Loss = 0.7103885412216187
Iteration [20754]: Loss = 0.7104997038841248
Iteration [20755]: Loss = 4.891303539276123
Iteration [20756]: Loss = 0.7107852697372437
Iteration [20757]: Loss = 0.7109495997428894
Iteration [20758]: Loss = 0.7110675573348999
Iteration [20759]: Loss = 0.7111437916755676
Iteration [20760]: Loss = 4.888180255889893
Iteration [20761]: Loss = 0.7113698124885559
Iteration [20762]: Loss = 4.886519908905029
Iteration [20763]: Loss = 0.7117860317230225
Iteration [20764]: Loss = 0.7120059132575989
Iteration [20765]: Loss = 0.7121739387512207
Iteration [20766]: Loss = 0.7122949361801147
Iteration [20767]: Loss = 0.7123739123344421
Iteration [20768]: Loss = 0.7124149799346924
Iteration [20769]: Loss = 0.7124218344688416
Iteration [20770]: Loss = 4.881999969482422
Iteration [20771]: Loss = 0.7125290036201477
Iteration [20772]: Loss = 0.7126170992851257
Iteration [20773]: Loss = 0.7126662135124207
Iteration [20774]: Loss = 4.8805646896362305
Iteration [20775]: Loss = 0.7128459215164185
Iteration [20776]: Loss = 0.7129648327827454
Iteration [20777]: Loss = 0.7130417823791504
Iteration [20778]: Loss = 0.7130808234214783
Iteration [20779]: Loss = 0.713085949420929
Iteration [20780]: Loss = 0.7130601406097412
Iteration [20781]: Loss = 4.878907680511475
Iteration [20782]: Loss = 0.7131119966506958
Iteration [20783]: Loss = 0.7131763100624084
Iteration [20784]: Loss = 0.7132041454315186
Iteration [20785]: Loss = 0.7131989002227783
Iteration [20786]: Loss = 0.7131641507148743
Iteration [20787]: Loss = 0.7131023406982422
Iteration [20788]: Loss = 0.7130166292190552
Iteration [20789]: Loss = 0.7129091620445251
Iteration [20790]: Loss = 0.7127822041511536
Iteration [20791]: Loss = 0.7126375436782837
Iteration [20792]: Loss = 0.7124770879745483
Iteration [20793]: Loss = 0.7123023271560669
Iteration [20794]: Loss = 0.7121148109436035
Iteration [20795]: Loss = 0.7119157910346985
Iteration [20796]: Loss = 0.711706280708313
Iteration [20797]: Loss = 0.7114874124526978
Iteration [20798]: Loss = 0.711260199546814
Iteration [20799]: Loss = 0.7110252976417542
Iteration [20800]: Loss = 0.7107837200164795
Iteration [20801]: Loss = 0.7105361223220825
Iteration [20802]: Loss = 4.89276647567749
Iteration [20803]: Loss = 0.7102093696594238
Iteration [20804]: Loss = 0.7101130485534668
Iteration [20805]: Loss = 0.7099961042404175
Iteration [20806]: Loss = 0.7098606824874878
Iteration [20807]: Loss = 0.709708571434021
Iteration [20808]: Loss = 0.7095414400100708
Iteration [20809]: Loss = 4.8974785804748535
Iteration [20810]: Loss = 4.897520065307617
Iteration [20811]: Loss = 4.896770477294922
Iteration [20812]: Loss = 0.709784746170044
Iteration [20813]: Loss = 0.7100118398666382
Iteration [20814]: Loss = 0.710186243057251
Iteration [20815]: Loss = 0.7103132009506226
Iteration [20816]: Loss = 0.7103972434997559
Iteration [20817]: Loss = 0.710442841053009
Iteration [20818]: Loss = 0.7104536294937134
Iteration [20819]: Loss = 4.8919997215271
Iteration [20820]: Loss = 0.7105686068534851
Iteration [20821]: Loss = 0.710660457611084
Iteration [20822]: Loss = 0.7107129693031311
Iteration [20823]: Loss = 0.7107299566268921
Iteration [20824]: Loss = 4.890562057495117
Iteration [20825]: Loss = 0.7108555436134338
Iteration [20826]: Loss = 0.7109520435333252
Iteration [20827]: Loss = 0.7110084295272827
Iteration [20828]: Loss = 0.7110291719436646
Iteration [20829]: Loss = 0.7110174298286438
Iteration [20830]: Loss = 0.7109766602516174
Iteration [20831]: Loss = 0.7109096646308899
Iteration [20832]: Loss = 0.7108190059661865
Iteration [20833]: Loss = 0.7107071876525879
Iteration [20834]: Loss = 0.710576057434082
Iteration [20835]: Loss = 0.7104278206825256
Iteration [20836]: Loss = 0.7102639675140381
Iteration [20837]: Loss = 0.7100861668586731
Iteration [20838]: Loss = 0.7098958492279053
Iteration [20839]: Loss = 0.7096941471099854
Iteration [20840]: Loss = 0.7094823122024536
Iteration [20841]: Loss = 0.7092613577842712
Iteration [20842]: Loss = 0.7090320587158203
Iteration [20843]: Loss = 0.7087953686714172
Iteration [20844]: Loss = 0.7085520625114441
Iteration [20845]: Loss = 0.7083027958869934
Iteration [20846]: Loss = 4.904201507568359
Iteration [20847]: Loss = 0.707974374294281
Iteration [20848]: Loss = 0.7078776955604553
Iteration [20849]: Loss = 0.7077604532241821
Iteration [20850]: Loss = 0.7076246738433838
Iteration [20851]: Loss = 0.7074721455574036
Iteration [20852]: Loss = 4.908019065856934
Iteration [20853]: Loss = 0.7073093056678772
Iteration [20854]: Loss = 0.7072832584381104
Iteration [20855]: Loss = 0.707229733467102
Iteration [20856]: Loss = 0.7071511149406433
Iteration [20857]: Loss = 0.7070502042770386
Iteration [20858]: Loss = 4.909949779510498
Iteration [20859]: Loss = 0.7069756388664246
Iteration [20860]: Loss = 0.7069871425628662
Iteration [20861]: Loss = 0.7069674134254456
Iteration [20862]: Loss = 0.7069194316864014
Iteration [20863]: Loss = 0.7068459391593933
Iteration [20864]: Loss = 0.7067496180534363
Iteration [20865]: Loss = 0.706632673740387
Iteration [20866]: Loss = 0.7064969539642334
Iteration [20867]: Loss = 0.7063447833061218
Iteration [20868]: Loss = 0.7061773538589478
Iteration [20869]: Loss = 4.91475248336792
Iteration [20870]: Loss = 0.7059895992279053
Iteration [20871]: Loss = 0.7059532403945923
Iteration [20872]: Loss = 0.7058901786804199
Iteration [20873]: Loss = 0.7058031558990479
Iteration [20874]: Loss = 0.7056947350502014
Iteration [20875]: Loss = 0.7055668234825134
Iteration [20876]: Loss = 0.7054213881492615
Iteration [20877]: Loss = 0.7052602767944336
Iteration [20878]: Loss = 0.7050849795341492
Iteration [20879]: Loss = 0.7048969268798828
Iteration [20880]: Loss = 0.7046974301338196
Iteration [20881]: Loss = 0.7044875621795654
Iteration [20882]: Loss = 0.7042684555053711
Iteration [20883]: Loss = 4.924856185913086
Iteration [20884]: Loss = 0.7039927840232849
Iteration [20885]: Loss = 0.7039192914962769
Iteration [20886]: Loss = 0.703822910785675
Iteration [20887]: Loss = 4.926591873168945
Iteration [20888]: Loss = 0.703757107257843
Iteration [20889]: Loss = 0.703773021697998
Iteration [20890]: Loss = 0.7037572264671326
Iteration [20891]: Loss = 4.926556587219238
Iteration [20892]: Loss = 0.7038289308547974
Iteration [20893]: Loss = 4.925568103790283
Iteration [20894]: Loss = 0.7041262984275818
Iteration [20895]: Loss = 0.7042970061302185
Iteration [20896]: Loss = 0.7044204473495483
Iteration [20897]: Loss = 0.7045014500617981
Iteration [20898]: Loss = 0.7045443058013916
Iteration [20899]: Loss = 9.139863014221191
Iteration [20900]: Loss = 0.7048995494842529
Iteration [20901]: Loss = 0.7051820755004883
Iteration [20902]: Loss = 0.7054065465927124
Iteration [20903]: Loss = 4.916906833648682
Iteration [20904]: Loss = 0.7058882713317871
Iteration [20905]: Loss = 0.7061368823051453
Iteration [20906]: Loss = 0.7063308954238892
Iteration [20907]: Loss = 0.7064754962921143
Iteration [20908]: Loss = 0.7065755128860474
Iteration [20909]: Loss = 4.9114603996276855
Iteration [20910]: Loss = 0.7068442702293396
Iteration [20911]: Loss = 0.7070022225379944
Iteration [20912]: Loss = 0.7071142792701721
Iteration [20913]: Loss = 4.908634185791016
Iteration [20914]: Loss = 0.7074032425880432
Iteration [20915]: Loss = 0.7075698971748352
Iteration [20916]: Loss = 0.707689642906189
Iteration [20917]: Loss = 4.905642986297607
Iteration [20918]: Loss = 0.707991898059845
Iteration [20919]: Loss = 0.7081639766693115
Iteration [20920]: Loss = 4.902968406677246
Iteration [20921]: Loss = 0.7085554003715515
Iteration [20922]: Loss = 0.7087655067443848
Iteration [20923]: Loss = 4.899709701538086
Iteration [20924]: Loss = 0.7092218399047852
Iteration [20925]: Loss = 4.896973133087158
Iteration [20926]: Loss = 0.7098273038864136
Iteration [20927]: Loss = 4.8935546875
Iteration [20928]: Loss = 0.7105533480644226
Iteration [20929]: Loss = 0.710905909538269
Iteration [20930]: Loss = 0.7111930251121521
Iteration [20931]: Loss = 0.7114214897155762
Iteration [20932]: Loss = 0.7115968465805054
Iteration [20933]: Loss = 0.7117243409156799
Iteration [20934]: Loss = 0.7118088603019714
Iteration [20935]: Loss = 0.7118545770645142
Iteration [20936]: Loss = 0.711865246295929
Iteration [20937]: Loss = 0.7118444442749023
Iteration [20938]: Loss = 0.7117953896522522
Iteration [20939]: Loss = 0.7117207050323486
Iteration [20940]: Loss = 0.7116230726242065
Iteration [20941]: Loss = 0.7115046977996826
Iteration [20942]: Loss = 0.7113677263259888
Iteration [20943]: Loss = 0.7112139463424683
Iteration [20944]: Loss = 0.71104496717453
Iteration [20945]: Loss = 0.7108624577522278
Iteration [20946]: Loss = 0.710667610168457
Iteration [20947]: Loss = 0.7104618549346924
Iteration [20948]: Loss = 0.7102462649345398
Iteration [20949]: Loss = 0.7100215554237366
Iteration [20950]: Loss = 0.7097889184951782
Iteration [20951]: Loss = 0.7095491886138916
Iteration [20952]: Loss = 0.7093027830123901
Iteration [20953]: Loss = 0.7090505361557007
Iteration [20954]: Loss = 0.7087932229042053
Iteration [20955]: Loss = 0.7085310816764832
Iteration [20956]: Loss = 4.9030914306640625
Iteration [20957]: Loss = 0.7081810235977173
Iteration [20958]: Loss = 0.7080754041671753
Iteration [20959]: Loss = 0.7079498767852783
Iteration [20960]: Loss = 0.7078065872192383
Iteration [20961]: Loss = 0.7076471447944641
Iteration [20962]: Loss = 0.7074732184410095
Iteration [20963]: Loss = 0.7072862982749939
Iteration [20964]: Loss = 0.7070876955986023
Iteration [20965]: Loss = 0.7068784236907959
Iteration [20966]: Loss = 0.7066598534584045
Iteration [20967]: Loss = 0.706432580947876
Iteration [20968]: Loss = 4.913715362548828
Iteration [20969]: Loss = 0.7061428427696228
Iteration [20970]: Loss = 0.7060630917549133
Iteration [20971]: Loss = 0.7059609889984131
Iteration [20972]: Loss = 0.7058387994766235
Iteration [20973]: Loss = 0.7056983709335327
Iteration [20974]: Loss = 4.917098045349121
Iteration [20975]: Loss = 0.7055571675300598
Iteration [20976]: Loss = 0.7055408358573914
Iteration [20977]: Loss = 0.7054957151412964
Iteration [20978]: Loss = 0.7054248452186584
Iteration [20979]: Loss = 0.7053307294845581
Iteration [20980]: Loss = 0.7052156329154968
Iteration [20981]: Loss = 0.7050817012786865
Iteration [20982]: Loss = 0.7049307823181152
Iteration [20983]: Loss = 0.704764723777771
Iteration [20984]: Loss = 0.7045847773551941
Iteration [20985]: Loss = 0.7043924927711487
Iteration [20986]: Loss = 0.704189121723175
Iteration [20987]: Loss = 0.7039756774902344
Iteration [20988]: Loss = 0.7037531137466431
Iteration [20989]: Loss = 0.7035225629806519
Iteration [20990]: Loss = 0.7032846808433533
Iteration [20991]: Loss = 0.7030401229858398
Iteration [20992]: Loss = 0.702789843082428
Iteration [20993]: Loss = 0.7025341391563416
Iteration [20994]: Loss = 0.7022737860679626
Iteration [20995]: Loss = 0.7020090222358704
Iteration [20996]: Loss = 0.7017403841018677
Iteration [20997]: Loss = 0.7014684081077576
Iteration [20998]: Loss = 0.7011932134628296
Iteration [20999]: Loss = 0.7009152770042419
Iteration [21000]: Loss = 0.700634777545929
Iteration [21001]: Loss = 0.7003520727157593
Iteration [21002]: Loss = 0.7000674605369568
Iteration [21003]: Loss = 0.6997809410095215
Iteration [21004]: Loss = 0.699492871761322
Iteration [21005]: Loss = 0.6992031931877136
Iteration [21006]: Loss = 0.6989123821258545
Iteration [21007]: Loss = 0.6986203789710999
Iteration [21008]: Loss = 0.6983272433280945
Iteration [21009]: Loss = 0.6980332136154175
Iteration [21010]: Loss = 0.6977383494377136
Iteration [21011]: Loss = 4.959290504455566
Iteration [21012]: Loss = 0.6973357796669006
Iteration [21013]: Loss = 0.6972092390060425
Iteration [21014]: Loss = 0.6970652341842651
Iteration [21015]: Loss = 0.6969054937362671
Iteration [21016]: Loss = 0.696731448173523
Iteration [21017]: Loss = 0.6965447068214417
Iteration [21018]: Loss = 4.965063571929932
Iteration [21019]: Loss = 0.6963269114494324
Iteration [21020]: Loss = 4.965417385101318
Iteration [21021]: Loss = 0.6963948011398315
Iteration [21022]: Loss = 0.6964688301086426
Iteration [21023]: Loss = 0.6965054273605347
Iteration [21024]: Loss = 0.6965083479881287
Iteration [21025]: Loss = 0.6964808106422424
Iteration [21026]: Loss = 0.6964259147644043
Iteration [21027]: Loss = 0.6963462829589844
Iteration [21028]: Loss = 4.965599536895752
Iteration [21029]: Loss = 0.6963117122650146
Iteration [21030]: Loss = 0.6963422298431396
Iteration [21031]: Loss = 0.6963394284248352
Iteration [21032]: Loss = 0.6963069438934326
Iteration [21033]: Loss = 0.6962475180625916
Iteration [21034]: Loss = 0.6961637735366821
Iteration [21035]: Loss = 0.6960583329200745
Iteration [21036]: Loss = 0.6959332823753357
Iteration [21037]: Loss = 0.6957905888557434
Iteration [21038]: Loss = 0.6956319808959961
Iteration [21039]: Loss = 0.6954589486122131
Iteration [21040]: Loss = 0.6952731609344482
Iteration [21041]: Loss = 0.6950756907463074
Iteration [21042]: Loss = 4.972873210906982
Iteration [21043]: Loss = 0.6948401927947998
Iteration [21044]: Loss = 0.6947852373123169
Iteration [21045]: Loss = 0.6947057247161865
Iteration [21046]: Loss = 0.6946040391921997
Iteration [21047]: Loss = 4.974913120269775
Iteration [21048]: Loss = 4.974648952484131
Iteration [21049]: Loss = 0.6947359442710876
Iteration [21050]: Loss = 0.69488924741745
Iteration [21051]: Loss = 0.6949974894523621
Iteration [21052]: Loss = 0.6950647234916687
Iteration [21053]: Loss = 0.6950951814651489
Iteration [21054]: Loss = 0.6950925588607788
Iteration [21055]: Loss = 0.6950600743293762
Iteration [21056]: Loss = 4.972170352935791
Iteration [21057]: Loss = 4.971611976623535
Iteration [21058]: Loss = 0.6953601241111755
Iteration [21059]: Loss = 0.6955586075782776
Iteration [21060]: Loss = 0.6957072615623474
Iteration [21061]: Loss = 0.6958110332489014
Iteration [21062]: Loss = 4.967553615570068
Iteration [21063]: Loss = 0.6960901618003845
Iteration [21064]: Loss = 0.6962541937828064
Iteration [21065]: Loss = 4.96492862701416
Iteration [21066]: Loss = 0.6966361999511719
Iteration [21067]: Loss = 0.6968443989753723
Iteration [21068]: Loss = 0.6970014572143555
Iteration [21069]: Loss = 0.6971127986907959
Iteration [21070]: Loss = 4.96065616607666
Iteration [21071]: Loss = 0.6974045038223267
Iteration [21072]: Loss = 0.6975739002227783
Iteration [21073]: Loss = 0.6976962685585022
Iteration [21074]: Loss = 0.6977762579917908
Iteration [21075]: Loss = 0.6978181004524231
Iteration [21076]: Loss = 0.6978253722190857
Iteration [21077]: Loss = 0.6978017687797546
Iteration [21078]: Loss = 0.6977502703666687
Iteration [21079]: Loss = 0.6976735591888428
Iteration [21080]: Loss = 4.958598613739014
Iteration [21081]: Loss = 0.6976439356803894
Iteration [21082]: Loss = 0.6976765394210815
Iteration [21083]: Loss = 0.6976754665374756
Iteration [21084]: Loss = 0.6976442933082581
Iteration [21085]: Loss = 0.6975859999656677
Iteration [21086]: Loss = 0.6975031495094299
Iteration [21087]: Loss = 0.69739830493927
Iteration [21088]: Loss = 0.6972736716270447
Iteration [21089]: Loss = 4.9609293937683105
Iteration [21090]: Loss = 0.6971622109413147
Iteration [21091]: Loss = 4.9607768058776855
Iteration [21092]: Loss = 4.959951400756836
Iteration [21093]: Loss = 0.6976167559623718
Iteration [21094]: Loss = 0.6978565454483032
Iteration [21095]: Loss = 0.6980422735214233
Iteration [21096]: Loss = 0.6981792449951172
Iteration [21097]: Loss = 0.6982723474502563
Iteration [21098]: Loss = 0.6983258724212646
Iteration [21099]: Loss = 0.6983436346054077
Iteration [21100]: Loss = 4.954631328582764
Iteration [21101]: Loss = 0.6984755992889404
Iteration [21102]: Loss = 0.6985768675804138
Iteration [21103]: Loss = 0.6986377239227295
Iteration [21104]: Loss = 0.6986622214317322
Iteration [21105]: Loss = 0.6986539363861084
Iteration [21106]: Loss = 0.6986160278320312
Iteration [21107]: Loss = 0.6985516548156738
Iteration [21108]: Loss = 0.6984633803367615
Iteration [21109]: Loss = 0.6983534097671509
Iteration [21110]: Loss = 9.21214485168457
Iteration [21111]: Loss = 0.6984546184539795
Iteration [21112]: Loss = 0.6986321210861206
Iteration [21113]: Loss = 0.6987619400024414
Iteration [21114]: Loss = 0.6988486051559448
Iteration [21115]: Loss = 0.6988964676856995
Iteration [21116]: Loss = 0.6989094018936157
Iteration [21117]: Loss = 0.6988909244537354
Iteration [21118]: Loss = 0.6988440752029419
Iteration [21119]: Loss = 4.952311992645264
Iteration [21120]: Loss = 0.6988646984100342
Iteration [21121]: Loss = 0.6989182829856873
Iteration [21122]: Loss = 0.698936402797699
Iteration [21123]: Loss = 4.951520919799805
Iteration [21124]: Loss = 0.6990680694580078
Iteration [21125]: Loss = 0.6991689205169678
Iteration [21126]: Loss = 4.949913024902344
Iteration [21127]: Loss = 0.6994417905807495
Iteration [21128]: Loss = 0.6996029019355774
Iteration [21129]: Loss = 0.6997177004814148
Iteration [21130]: Loss = 0.699790894985199
Iteration [21131]: Loss = 4.946788311004639
Iteration [21132]: Loss = 0.7000164985656738
Iteration [21133]: Loss = 0.7001573443412781
Iteration [21134]: Loss = 0.7002540230751038
Iteration [21135]: Loss = 0.7003106474876404
Iteration [21136]: Loss = 0.700331449508667
Iteration [21137]: Loss = 0.7003198266029358
Iteration [21138]: Loss = 0.7002792358398438
Iteration [21139]: Loss = 0.7002123594284058
Iteration [21140]: Loss = 0.7001215815544128
Iteration [21141]: Loss = 0.700009822845459
Iteration [21142]: Loss = 0.6998788714408875
Iteration [21143]: Loss = 0.6997305750846863
Iteration [21144]: Loss = 0.6995667815208435
Iteration [21145]: Loss = 0.6993889808654785
Iteration [21146]: Loss = 4.950074195861816
Iteration [21147]: Loss = 4.950139999389648
Iteration [21148]: Loss = 4.94936990737915
Iteration [21149]: Loss = 0.6996232867240906
Iteration [21150]: Loss = 0.6998544335365295
Iteration [21151]: Loss = 0.7000322937965393
Iteration [21152]: Loss = 0.7001622915267944
Iteration [21153]: Loss = 0.7002489566802979
Iteration [21154]: Loss = 0.7002968788146973
Iteration [21155]: Loss = 4.9442644119262695
Iteration [21156]: Loss = 0.7004790306091309
Iteration [21157]: Loss = 0.7006013989448547
Iteration [21158]: Loss = 0.7006812691688538
Iteration [21159]: Loss = 0.7007228136062622
Iteration [21160]: Loss = 0.70073002576828
Iteration [21161]: Loss = 0.7007061243057251
Iteration [21162]: Loss = 0.700654149055481
Iteration [21163]: Loss = 0.7005770206451416
Iteration [21164]: Loss = 0.7004772424697876
Iteration [21165]: Loss = 0.7003570199012756
Iteration [21166]: Loss = 0.7002183198928833
Iteration [21167]: Loss = 0.7000632286071777
Iteration [21168]: Loss = 0.6998931169509888
Iteration [21169]: Loss = 0.6997095346450806
Iteration [21170]: Loss = 0.6995139718055725
Iteration [21171]: Loss = 4.94950532913208
Iteration [21172]: Loss = 0.6992807984352112
Iteration [21173]: Loss = 0.699226438999176
Iteration [21174]: Loss = 0.6991471648216248
Iteration [21175]: Loss = 4.9508771896362305
Iteration [21176]: Loss = 4.950523853302002
Iteration [21177]: Loss = 4.949377059936523
Iteration [21178]: Loss = 0.6996868848800659
Iteration [21179]: Loss = 0.6999764442443848
Iteration [21180]: Loss = 0.7002070546150208
Iteration [21181]: Loss = 0.7003843784332275
Iteration [21182]: Loss = 0.7005136013031006
Iteration [21183]: Loss = 4.942748069763184
Iteration [21184]: Loss = 0.7008352875709534
Iteration [21185]: Loss = 0.7010170221328735
Iteration [21186]: Loss = 0.7011505365371704
Iteration [21187]: Loss = 0.7012403011322021
Iteration [21188]: Loss = 0.7012905478477478
Iteration [21189]: Loss = 0.7013055682182312
Iteration [21190]: Loss = 0.701288640499115
Iteration [21191]: Loss = 0.7012428045272827
Iteration [21192]: Loss = 4.939767360687256
Iteration [21193]: Loss = 0.7012653946876526
Iteration [21194]: Loss = 0.7013197541236877
Iteration [21195]: Loss = 0.7013382315635681
Iteration [21196]: Loss = 0.7013244032859802
Iteration [21197]: Loss = 0.7012815475463867
Iteration [21198]: Loss = 0.7012124061584473
Iteration [21199]: Loss = 0.7011198997497559
Iteration [21200]: Loss = 0.7010058760643005
Iteration [21201]: Loss = 0.7008728384971619
Iteration [21202]: Loss = 0.7007225751876831
Iteration [21203]: Loss = 0.7005568146705627
Iteration [21204]: Loss = 0.7003770470619202
Iteration [21205]: Loss = 0.7001848816871643
Iteration [21206]: Loss = 0.6999812722206116
Iteration [21207]: Loss = 0.699767529964447
Iteration [21208]: Loss = 0.6995446085929871
Iteration [21209]: Loss = 0.6993135213851929
Iteration [21210]: Loss = 0.6990749835968018
Iteration [21211]: Loss = 4.952006816864014
Iteration [21212]: Loss = 4.952325820922852
Iteration [21213]: Loss = 0.6988735795021057
Iteration [21214]: Loss = 0.6989373564720154
Iteration [21215]: Loss = 4.9513020515441895
Iteration [21216]: Loss = 0.6991475224494934
Iteration [21217]: Loss = 9.199991226196289
Iteration [21218]: Loss = 0.6997475028038025
Iteration [21219]: Loss = 4.945168495178223
Iteration [21220]: Loss = 0.7006433010101318
Iteration [21221]: Loss = 0.7010697722434998
Iteration [21222]: Loss = 4.938450813293457
Iteration [21223]: Loss = 0.7018991112709045
Iteration [21224]: Loss = 0.7022972106933594
Iteration [21225]: Loss = 0.7026254534721375
Iteration [21226]: Loss = 0.7028908729553223
Iteration [21227]: Loss = 0.7030994892120361
Iteration [21228]: Loss = 0.703257143497467
Iteration [21229]: Loss = 0.7033687233924866
Iteration [21230]: Loss = 0.7034386992454529
Iteration [21231]: Loss = 0.7034714818000793
Iteration [21232]: Loss = 0.7034705281257629
Iteration [21233]: Loss = 0.7034393548965454
Iteration [21234]: Loss = 0.7033807039260864
Iteration [21235]: Loss = 0.7032974362373352
Iteration [21236]: Loss = 0.7031922340393066
Iteration [21237]: Loss = 0.703066885471344
Iteration [21238]: Loss = 0.702923595905304
Iteration [21239]: Loss = 0.7027642130851746
Iteration [21240]: Loss = 0.7023360729217529
Iteration [21241]: Loss = 0.7021505832672119
Iteration [21242]: Loss = 4.935694217681885
Iteration [21243]: Loss = 0.7019338607788086
Iteration [21244]: Loss = 0.7019222974777222
Iteration [21245]: Loss = 0.6992150545120239
Iteration [21246]: Loss = 4.936922550201416
Iteration [21247]: Loss = 0.7017892003059387
Iteration [21248]: Loss = 0.7018237113952637
Iteration [21249]: Loss = 0.7018243074417114
Iteration [21250]: Loss = 0.7017945647239685
Iteration [21251]: Loss = 0.7017373442649841
Iteration [21252]: Loss = 0.7016555070877075
Iteration [21253]: Loss = 0.7015513777732849
Iteration [21254]: Loss = 4.948575496673584
Iteration [21255]: Loss = 0.7011488676071167
Iteration [21256]: Loss = 0.7011614441871643
Iteration [21257]: Loss = 4.939916610717773
Iteration [21258]: Loss = 0.7022545337677002
Iteration [21259]: Loss = 0.7022948265075684
Iteration [21260]: Loss = 0.702275812625885
Iteration [21261]: Loss = 0.7022083401679993
Iteration [21262]: Loss = 0.7020992040634155
Iteration [21263]: Loss = 0.7019538283348083
Iteration [21264]: Loss = 0.7017766833305359
Iteration [21265]: Loss = 0.7015715837478638
Iteration [21266]: Loss = 4.938878059387207
Iteration [21267]: Loss = 0.7014005184173584
Iteration [21268]: Loss = 0.7014132738113403
Iteration [21269]: Loss = 0.7013847827911377
Iteration [21270]: Loss = 0.7013195157051086
Iteration [21271]: Loss = 0.7012212872505188
Iteration [21272]: Loss = 0.7010934352874756
Iteration [21273]: Loss = 0.7009389400482178
Iteration [21274]: Loss = 0.7007607817649841
Iteration [21275]: Loss = 0.7005610466003418
Iteration [21276]: Loss = 0.7003421187400818
Iteration [21277]: Loss = 0.7001059651374817
Iteration [21278]: Loss = 0.6998541951179504
Iteration [21279]: Loss = 0.6995884776115417
Iteration [21280]: Loss = 4.949490547180176
Iteration [21281]: Loss = 0.6992690563201904
Iteration [21282]: Loss = 0.6991946697235107
Iteration [21283]: Loss = 4.950642108917236
Iteration [21284]: Loss = 0.6991895437240601
Iteration [21285]: Loss = 0.6992424130439758
Iteration [21286]: Loss = 0.6992537975311279
Iteration [21287]: Loss = 0.6992276906967163
Iteration [21288]: Loss = 9.201300621032715
Iteration [21289]: Loss = 0.6995077729225159
Iteration [21290]: Loss = 0.6997795104980469
Iteration [21291]: Loss = 0.6999902725219727
Iteration [21292]: Loss = 0.7001458406448364
Iteration [21293]: Loss = 4.944564342498779
Iteration [21294]: Loss = 0.7005231976509094
Iteration [21295]: Loss = 0.7007336616516113
Iteration [21296]: Loss = 0.7008892297744751
Iteration [21297]: Loss = 0.7009953856468201
Iteration [21298]: Loss = 0.7010574340820312
Iteration [21299]: Loss = 0.701079249382019
Iteration [21300]: Loss = 0.7010651230812073
Iteration [21301]: Loss = 0.7010185718536377
Iteration [21302]: Loss = 0.7009427547454834
Iteration [21303]: Loss = 0.7008407711982727
Iteration [21304]: Loss = 0.7007150053977966
Iteration [21305]: Loss = 0.7005681395530701
Iteration [21306]: Loss = 4.943780899047852
Iteration [21307]: Loss = 0.7004289627075195
Iteration [21308]: Loss = 0.699384331703186
Iteration [21309]: Loss = 4.949321269989014
Iteration [21310]: Loss = 0.6994799375534058
Iteration [21311]: Loss = 0.6995701193809509
Iteration [21312]: Loss = 0.6996179819107056
Iteration [21313]: Loss = 0.6996276378631592
Iteration [21314]: Loss = 0.6996027827262878
Iteration [21315]: Loss = 0.6995471119880676
Iteration [21316]: Loss = 0.6994633674621582
Iteration [21317]: Loss = 0.6993546485900879
Iteration [21318]: Loss = 0.6992232203483582
Iteration [21319]: Loss = 0.6990715265274048
Iteration [21320]: Loss = 0.6989014744758606
Iteration [21321]: Loss = 0.6987148523330688
Iteration [21322]: Loss = 0.6985133290290833
Iteration [21323]: Loss = 0.6982985734939575
Iteration [21324]: Loss = 0.6980716586112976
Iteration [21325]: Loss = 0.6978340148925781
Iteration [21326]: Loss = 0.6975864768028259
Iteration [21327]: Loss = 0.6973302960395813
Iteration [21328]: Loss = 0.697066068649292
Iteration [21329]: Loss = 0.6967946887016296
Iteration [21330]: Loss = 0.6965169906616211
Iteration [21331]: Loss = 0.6962333917617798
Iteration [21332]: Loss = 0.6959446668624878
Iteration [21333]: Loss = 0.6956512331962585
Iteration [21334]: Loss = 0.695353627204895
Iteration [21335]: Loss = 4.971897602081299
Iteration [21336]: Loss = 0.6949586868286133
Iteration [21337]: Loss = 0.6948411464691162
Iteration [21338]: Loss = 0.6947020292282104
Iteration [21339]: Loss = 0.6945433616638184
Iteration [21340]: Loss = 0.6943671703338623
Iteration [21341]: Loss = 0.6941754221916199
Iteration [21342]: Loss = 0.6939692497253418
Iteration [21343]: Loss = 0.6937502026557922
Iteration [21344]: Loss = 4.980016708374023
Iteration [21345]: Loss = 0.6934897303581238
Iteration [21346]: Loss = 0.6934294104576111
Iteration [21347]: Loss = 0.693341851234436
Iteration [21348]: Loss = 4.981556415557861
Iteration [21349]: Loss = 0.6933051347732544
Iteration [21350]: Loss = 0.6933398246765137
Iteration [21351]: Loss = 0.6933379173278809
Iteration [21352]: Loss = 0.6933032274246216
Iteration [21353]: Loss = 4.981508255004883
Iteration [21354]: Loss = 0.6933561563491821
Iteration [21355]: Loss = 0.6934288144111633
Iteration [21356]: Loss = 4.980327606201172
Iteration [21357]: Loss = 0.6936646699905396
Iteration [21358]: Loss = 4.978450775146484
Iteration [21359]: Loss = 0.6941232681274414
Iteration [21360]: Loss = 0.6943680047988892
Iteration [21361]: Loss = 0.694555938243866
Iteration [21362]: Loss = 0.6946921348571777
Iteration [21363]: Loss = 0.6947818994522095
Iteration [21364]: Loss = 4.9730730056762695
Iteration [21365]: Loss = 0.6950461864471436
Iteration [21366]: Loss = 4.971073150634766
Iteration [21367]: Loss = 0.6955257058143616
Iteration [21368]: Loss = 0.6957790851593018
Iteration [21369]: Loss = 0.6959746479988098
Iteration [21370]: Loss = 0.6961179971694946
Iteration [21371]: Loss = 0.6962142586708069
Iteration [21372]: Loss = 4.9654741287231445
Iteration [21373]: Loss = 0.6964888572692871
Iteration [21374]: Loss = 0.6966546773910522
Iteration [21375]: Loss = 0.6967713832855225
Iteration [21376]: Loss = 0.6968438625335693
Iteration [21377]: Loss = 0.6968764066696167
Iteration [21378]: Loss = 4.962288856506348
Iteration [21379]: Loss = 4.961400985717773
Iteration [21380]: Loss = 0.6973637938499451
Iteration [21381]: Loss = 0.6976215839385986
Iteration [21382]: Loss = 0.6978210806846619
Iteration [21383]: Loss = 0.6979681849479675
Iteration [21384]: Loss = 0.6980680823326111
Iteration [21385]: Loss = 0.6981253623962402
Iteration [21386]: Loss = 0.698144257068634
Iteration [21387]: Loss = 0.6981288194656372
Iteration [21388]: Loss = 0.6980822086334229
Iteration [21389]: Loss = 0.6980075836181641
Iteration [21390]: Loss = 0.6979076862335205
Iteration [21391]: Loss = 0.6977851390838623
Iteration [21392]: Loss = 0.6976421475410461
Iteration [21393]: Loss = 4.959089756011963
Iteration [21394]: Loss = 4.958950042724609
Iteration [21395]: Loss = 0.6977018117904663
Iteration [21396]: Loss = 0.6978444457054138
Iteration [21397]: Loss = 0.6979403495788574
Iteration [21398]: Loss = 0.6979941725730896
Iteration [21399]: Loss = 0.6980100870132446
Iteration [21400]: Loss = 0.6979920268058777
Iteration [21401]: Loss = 0.6979430317878723
Iteration [21402]: Loss = 0.6978663802146912
Iteration [21403]: Loss = 0.6977646946907043
Iteration [21404]: Loss = 4.958248615264893
Iteration [21405]: Loss = 0.6977001428604126
Iteration [21406]: Loss = 4.957826137542725
Iteration [21407]: Loss = 0.6979105472564697
Iteration [21408]: Loss = 0.6980485320091248
Iteration [21409]: Loss = 0.6981403231620789
Iteration [21410]: Loss = 0.6981905102729797
Iteration [21411]: Loss = 0.6982032060623169
Iteration [21412]: Loss = 0.6981821060180664
Iteration [21413]: Loss = 0.6981306076049805
Iteration [21414]: Loss = 0.6980517506599426
Iteration [21415]: Loss = 4.9566330909729
Iteration [21416]: Loss = 0.698025643825531
Iteration [21417]: Loss = 4.956030368804932
Iteration [21418]: Loss = 0.6982664465904236
Iteration [21419]: Loss = 0.6984173655509949
Iteration [21420]: Loss = 0.6985207796096802
Iteration [21421]: Loss = 0.6985813975334167
Iteration [21422]: Loss = 0.6986035704612732
Iteration [21423]: Loss = 0.6985911130905151
Iteration [21424]: Loss = 4.953487873077393
Iteration [21425]: Loss = 0.6986780166625977
Iteration [21426]: Loss = 0.698763370513916
Iteration [21427]: Loss = 0.6988075971603394
Iteration [21428]: Loss = 0.6988150477409363
Iteration [21429]: Loss = 4.952219009399414
Iteration [21430]: Loss = 0.6989360451698303
Iteration [21431]: Loss = 0.69903564453125
Iteration [21432]: Loss = 0.6990929841995239
Iteration [21433]: Loss = 0.6991121768951416
Iteration [21434]: Loss = 0.6990969181060791
Iteration [21435]: Loss = 0.699050784111023
Iteration [21436]: Loss = 0.6989768743515015
Iteration [21437]: Loss = 0.69887775182724
Iteration [21438]: Loss = 0.6987560391426086
Iteration [21439]: Loss = 0.6986140012741089
Iteration [21440]: Loss = 0.6984536647796631
Iteration [21441]: Loss = 0.6982767581939697
Iteration [21442]: Loss = 0.6980851888656616
Iteration [21443]: Loss = 0.6978801488876343
Iteration [21444]: Loss = 0.6976630091667175
Iteration [21445]: Loss = 0.6974351406097412
Iteration [21446]: Loss = 0.6971974968910217
Iteration [21447]: Loss = 0.6969509720802307
Iteration [21448]: Loss = 0.6966967582702637
Iteration [21449]: Loss = 0.696435272693634
Iteration [21450]: Loss = 0.6961674690246582
Iteration [21451]: Loss = 0.6958938837051392
Iteration [21452]: Loss = 0.6956152319908142
Iteration [21453]: Loss = 0.6953318119049072
Iteration [21454]: Loss = 0.6950442790985107
Iteration [21455]: Loss = 0.6947529315948486
Iteration [21456]: Loss = 0.6944581270217896
Iteration [21457]: Loss = 0.694160521030426
Iteration [21458]: Loss = 0.6938599348068237
Iteration [21459]: Loss = 0.69355708360672
Iteration [21460]: Loss = 0.6932519674301147
Iteration [21461]: Loss = 4.983070373535156
Iteration [21462]: Loss = 0.6928412318229675
Iteration [21463]: Loss = 0.6927154660224915
Iteration [21464]: Loss = 0.6925700306892395
Iteration [21465]: Loss = 0.6924066543579102
Iteration [21466]: Loss = 4.9868879318237305
Iteration [21467]: Loss = 0.6922381520271301
Iteration [21468]: Loss = 0.6922155618667603
Iteration [21469]: Loss = 0.6921629309654236
Iteration [21470]: Loss = 0.6920832395553589
Iteration [21471]: Loss = 0.691979169845581
Iteration [21472]: Loss = 4.988880634307861
Iteration [21473]: Loss = 0.6919118762016296
Iteration [21474]: Loss = 4.988457679748535
Iteration [21475]: Loss = 0.6921223998069763
Iteration [21476]: Loss = 0.6922612190246582
Iteration [21477]: Loss = 0.6923539638519287
Iteration [21478]: Loss = 0.6924053430557251
Iteration [21479]: Loss = 0.6924192309379578
Iteration [21480]: Loss = 4.985971450805664
Iteration [21481]: Loss = 4.985153675079346
Iteration [21482]: Loss = 0.692861795425415
Iteration [21483]: Loss = 0.6931077241897583
Iteration [21484]: Loss = 0.6932969093322754
Iteration [21485]: Loss = 0.6934352517127991
Iteration [21486]: Loss = 0.6935274004936218
Iteration [21487]: Loss = 0.6935783624649048
Iteration [21488]: Loss = 0.6935919523239136
Iteration [21489]: Loss = 0.693571925163269
Iteration [21490]: Loss = 0.6935214400291443
Iteration [21491]: Loss = 0.6934439539909363
Iteration [21492]: Loss = 0.6933417320251465
Iteration [21493]: Loss = 0.6932175159454346
Iteration [21494]: Loss = 0.6930735111236572
Iteration [21495]: Loss = 0.6929114460945129
Iteration [21496]: Loss = 0.6927332878112793
Iteration [21497]: Loss = 0.6925404667854309
Iteration [21498]: Loss = 0.6923347115516663
Iteration [21499]: Loss = 4.987473964691162
Iteration [21500]: Loss = 0.6920934915542603
Iteration [21501]: Loss = 4.987884998321533
Iteration [21502]: Loss = 0.6921629905700684
Iteration [21503]: Loss = 0.6922417283058167
Iteration [21504]: Loss = 0.6922804713249207
Iteration [21505]: Loss = 0.6922830939292908
Iteration [21506]: Loss = 0.6922532320022583
Iteration [21507]: Loss = 0.6921941637992859
Iteration [21508]: Loss = 0.692108690738678
Iteration [21509]: Loss = 0.6919994950294495
Iteration [21510]: Loss = 0.6918690800666809
Iteration [21511]: Loss = 0.6917192339897156
Iteration [21512]: Loss = 0.6915522813796997
Iteration [21513]: Loss = 0.6913697719573975
Iteration [21514]: Loss = 0.6911730170249939
Iteration [21515]: Loss = 0.6909637451171875
Iteration [21516]: Loss = 0.690743088722229
Iteration [21517]: Loss = 0.6905121207237244
Iteration [21518]: Loss = 0.6902719736099243
Iteration [21519]: Loss = 0.6900236010551453
Iteration [21520]: Loss = 0.6897677779197693
Iteration [21521]: Loss = 0.6895051598548889
Iteration [21522]: Loss = 5.002866268157959
Iteration [21523]: Loss = 0.6891679167747498
Iteration [21524]: Loss = 0.689073920249939
Iteration [21525]: Loss = 0.6889572143554688
Iteration [21526]: Loss = 0.6888197660446167
Iteration [21527]: Loss = 5.005938529968262
Iteration [21528]: Loss = 0.6886964440345764
Iteration [21529]: Loss = 0.6886937022209167
Iteration [21530]: Loss = 0.6886588335037231
Iteration [21531]: Loss = 0.6885955929756165
Iteration [21532]: Loss = 0.6885062456130981
Iteration [21533]: Loss = 0.6883938908576965
Iteration [21534]: Loss = 0.6882604360580444
Iteration [21535]: Loss = 0.6881081461906433
Iteration [21536]: Loss = 0.687938928604126
Iteration [21537]: Loss = 0.6877542734146118
Iteration [21538]: Loss = 0.6875560879707336
Iteration [21539]: Loss = 0.6873453855514526
Iteration [21540]: Loss = 0.6871235966682434
Iteration [21541]: Loss = 0.6868916749954224
Iteration [21542]: Loss = 5.016773223876953
Iteration [21543]: Loss = 0.6866076588630676
Iteration [21544]: Loss = 0.6865366697311401
Iteration [21545]: Loss = 5.017906665802002
Iteration [21546]: Loss = 0.6865273118019104
Iteration [21547]: Loss = 0.6865733861923218
Iteration [21548]: Loss = 0.6865827441215515
Iteration [21549]: Loss = 0.6865591406822205
Iteration [21550]: Loss = 0.6865058541297913
Iteration [21551]: Loss = 0.6864256858825684
Iteration [21552]: Loss = 0.686321496963501
Iteration [21553]: Loss = 0.686195433139801
Iteration [21554]: Loss = 0.6860499978065491
Iteration [21555]: Loss = 0.6858868598937988
Iteration [21556]: Loss = 0.6857079863548279
Iteration [21557]: Loss = 0.6855148077011108
Iteration [21558]: Loss = 0.6853088140487671
Iteration [21559]: Loss = 5.025200843811035
Iteration [21560]: Loss = 0.6850694417953491
Iteration [21561]: Loss = 0.6850175857543945
Iteration [21562]: Loss = 0.684938907623291
Iteration [21563]: Loss = 0.6848360896110535
Iteration [21564]: Loss = 0.6847115159034729
Iteration [21565]: Loss = 0.6845672130584717
Iteration [21566]: Loss = 0.6844050884246826
Iteration [21567]: Loss = 0.6842272281646729
Iteration [21568]: Loss = 0.6840351819992065
Iteration [21569]: Loss = 0.6838299036026001
Iteration [21570]: Loss = 0.6836131811141968
Iteration [21571]: Loss = 0.6833858489990234
Iteration [21572]: Loss = 0.6831493377685547
Iteration [21573]: Loss = 0.6829042434692383
Iteration [21574]: Loss = 0.6826515793800354
Iteration [21575]: Loss = 0.6823919415473938
Iteration [21576]: Loss = 5.041311740875244
Iteration [21577]: Loss = 0.6820623278617859
Iteration [21578]: Loss = 0.6819726228713989
Iteration [21579]: Loss = 0.6818598508834839
Iteration [21580]: Loss = 0.6817262768745422
Iteration [21581]: Loss = 0.6815741062164307
Iteration [21582]: Loss = 0.6814050674438477
Iteration [21583]: Loss = 0.6812208890914917
Iteration [21584]: Loss = 0.6810229420661926
Iteration [21585]: Loss = 0.6808128356933594
Iteration [21586]: Loss = 0.6805916428565979
Iteration [21587]: Loss = 0.6803605556488037
Iteration [21588]: Loss = 0.6801204085350037
Iteration [21589]: Loss = 0.6798721551895142
Iteration [21590]: Loss = 0.6796167492866516
Iteration [21591]: Loss = 0.6821582317352295
Iteration [21592]: Loss = 0.6818901300430298
Iteration [21593]: Loss = 0.6816166043281555
Iteration [21594]: Loss = 5.045612812042236
Iteration [21595]: Loss = 0.6812634468078613
Iteration [21596]: Loss = 0.6811643242835999
Iteration [21597]: Loss = 0.6810427904129028
Iteration [21598]: Loss = 0.6809014081954956
Iteration [21599]: Loss = 0.6807418465614319
Iteration [21600]: Loss = 0.680566132068634
Iteration [21601]: Loss = 0.6803759336471558
Iteration [21602]: Loss = 0.6801725029945374
Iteration [21603]: Loss = 0.6799570918083191
Iteration [21604]: Loss = 0.6797313094139099
Iteration [21605]: Loss = 5.055698871612549
Iteration [21606]: Loss = 0.6794601678848267
Iteration [21607]: Loss = 0.6793961524963379
Iteration [21608]: Loss = 0.6793064475059509
Iteration [21609]: Loss = 0.6791935563087463
Iteration [21610]: Loss = 0.6790598630905151
Iteration [21611]: Loss = 5.058929443359375
Iteration [21612]: Loss = 0.6789464950561523
Iteration [21613]: Loss = 0.6789495348930359
Iteration [21614]: Loss = 0.6789202094078064
Iteration [21615]: Loss = 5.05918025970459
Iteration [21616]: Loss = 0.6789848804473877
Iteration [21617]: Loss = 5.058070659637451
Iteration [21618]: Loss = 0.6793097853660583
Iteration [21619]: Loss = 0.6794992685317993
Iteration [21620]: Loss = 0.679638147354126
Iteration [21621]: Loss = 5.054409027099609
Iteration [21622]: Loss = 0.6799894571304321
Iteration [21623]: Loss = 0.6801900267601013
Iteration [21624]: Loss = 0.6803387403488159
Iteration [21625]: Loss = 5.0505194664001465
Iteration [21626]: Loss = 5.0490641593933105
Iteration [21627]: Loss = 0.6811199188232422
Iteration [21628]: Loss = 0.6814600229263306
Iteration [21629]: Loss = 0.6817345023155212
Iteration [21630]: Loss = 0.6819497346878052
Iteration [21631]: Loss = 0.6821116209030151
Iteration [21632]: Loss = 0.6822253465652466
Iteration [21633]: Loss = 0.6822959184646606
Iteration [21634]: Loss = 0.6823275685310364
Iteration [21635]: Loss = 0.6823238730430603
Iteration [21636]: Loss = 0.6822885870933533
Iteration [21637]: Loss = 5.040773868560791
Iteration [21638]: Loss = 0.6823417544364929
Iteration [21639]: Loss = 0.6824150681495667
Iteration [21640]: Loss = 0.6824489831924438
Iteration [21641]: Loss = 0.6824475526809692
Iteration [21642]: Loss = 0.6824143528938293
Iteration [21643]: Loss = 0.6823524832725525
Iteration [21644]: Loss = 0.6822646856307983
Iteration [21645]: Loss = 0.6821536421775818
Iteration [21646]: Loss = 0.6820217370986938
Iteration [21647]: Loss = 0.6818707585334778
Iteration [21648]: Loss = 0.6817029714584351
Iteration [21649]: Loss = 5.044620513916016
Iteration [21650]: Loss = 0.6815299391746521
Iteration [21651]: Loss = 0.6815069913864136
Iteration [21652]: Loss = 0.6814543604850769
Iteration [21653]: Loss = 0.6813750267028809
Iteration [21654]: Loss = 0.6812716126441956
Iteration [21655]: Loss = 0.6811463832855225
Iteration [21656]: Loss = 5.047451019287109
Iteration [21657]: Loss = 0.6810464859008789
Iteration [21658]: Loss = 0.6810548305511475
Iteration [21659]: Loss = 0.6810303330421448
Iteration [21660]: Loss = 0.6809763312339783
Iteration [21661]: Loss = 0.6808956265449524
Iteration [21662]: Loss = 0.6807911396026611
Iteration [21663]: Loss = 0.6806650161743164
Iteration [21664]: Loss = 0.6805195212364197
Iteration [21665]: Loss = 5.050981044769287
Iteration [21666]: Loss = 0.6803849935531616
Iteration [21667]: Loss = 0.6803786754608154
Iteration [21668]: Loss = 0.6803410649299622
Iteration [21669]: Loss = 0.6802751421928406
Iteration [21670]: Loss = 0.680184006690979
Iteration [21671]: Loss = 0.6800698637962341
Iteration [21672]: Loss = 0.6799351572990417
Iteration [21673]: Loss = 5.0541300773620605
Iteration [21674]: Loss = 0.6798192262649536
Iteration [21675]: Loss = 0.6798208355903625
Iteration [21676]: Loss = 0.6797903776168823
Iteration [21677]: Loss = 0.6797310709953308
Iteration [21678]: Loss = 0.6796457171440125
Iteration [21679]: Loss = 0.6795369982719421
Iteration [21680]: Loss = 0.6794070601463318
Iteration [21681]: Loss = 0.6792582273483276
Iteration [21682]: Loss = 0.679092288017273
Iteration [21683]: Loss = 0.6789109110832214
Iteration [21684]: Loss = 5.059983730316162
Iteration [21685]: Loss = 0.6787155270576477
Iteration [21686]: Loss = 0.6786836981773376
Iteration [21687]: Loss = 0.6786230802536011
Iteration [21688]: Loss = 0.6785365343093872
Iteration [21689]: Loss = 0.6784267425537109
Iteration [21690]: Loss = 0.6782959699630737
Iteration [21691]: Loss = 5.063115119934082
Iteration [21692]: Loss = 0.6781873106956482
Iteration [21693]: Loss = 5.062862873077393
Iteration [21694]: Loss = 5.061875343322754
Iteration [21695]: Loss = 0.6787073612213135
Iteration [21696]: Loss = 5.0585432052612305
Iteration [21697]: Loss = 0.6793948411941528
Iteration [21698]: Loss = 5.0543670654296875
Iteration [21699]: Loss = 5.051722049713135
Iteration [21700]: Loss = 0.6808280944824219
Iteration [21701]: Loss = 0.6813430190086365
Iteration [21702]: Loss = 0.6817751526832581
Iteration [21703]: Loss = 0.6821324825286865
Iteration [21704]: Loss = 5.02843713760376
Iteration [21705]: Loss = 0.687035083770752
Iteration [21706]: Loss = 0.6877459287643433
Iteration [21707]: Loss = 0.6733546257019043
Iteration [21708]: Loss = 0.6863905787467957
Iteration [21709]: Loss = 0.6610062718391418
Iteration [21710]: Loss = 0.6623490452766418
Iteration [21711]: Loss = 5.210555076599121
Iteration [21712]: Loss = 0.6767000555992126
Iteration [21713]: Loss = 0.6202012300491333
Iteration [21714]: Loss = 0.6202957630157471
Iteration [21715]: Loss = 0.6326460838317871
Iteration [21716]: Loss = 0.6326040029525757
Iteration [21717]: Loss = 0.63953697681427
Iteration [21718]: Loss = 0.6449199914932251
Iteration [21719]: Loss = 0.6315018534660339
Iteration [21720]: Loss = 5.242173671722412
Iteration [21721]: Loss = 0.6523423194885254
Iteration [21722]: Loss = 0.6634472608566284
Iteration [21723]: Loss = 0.6518272161483765
Iteration [21724]: Loss = 5.273959159851074
Iteration [21725]: Loss = 0.6342675089836121
Iteration [21726]: Loss = 5.24519157409668
Iteration [21727]: Loss = 0.6576224565505981
Iteration [21728]: Loss = 0.6543964147567749
Iteration [21729]: Loss = 0.6579988598823547
Iteration [21730]: Loss = 0.657998263835907
Iteration [21731]: Loss = 0.6433099508285522
Iteration [21732]: Loss = 0.6441071033477783
Iteration [21733]: Loss = 0.645979106426239
Iteration [21734]: Loss = 0.6449086666107178
Iteration [21735]: Loss = 0.6444559097290039
Iteration [21736]: Loss = 0.6410731077194214
Iteration [21737]: Loss = 5.2962775230407715
Iteration [21738]: Loss = 0.6429620981216431
Iteration [21739]: Loss = 0.643343448638916
Iteration [21740]: Loss = 0.6437517404556274
Iteration [21741]: Loss = 0.6471664309501648
Iteration [21742]: Loss = 0.6465363502502441
Iteration [21743]: Loss = 0.6456009149551392
Iteration [21744]: Loss = 0.6444012522697449
Iteration [21745]: Loss = 0.6429678201675415
Iteration [21746]: Loss = 0.6413277387619019
Iteration [21747]: Loss = 5.283832550048828
Iteration [21748]: Loss = 0.6448278427124023
Iteration [21749]: Loss = 0.6431912779808044
Iteration [21750]: Loss = 0.6500641107559204
Iteration [21751]: Loss = 0.6470101475715637
Iteration [21752]: Loss = 0.6453938484191895
Iteration [21753]: Loss = 0.6431974172592163
Iteration [21754]: Loss = 0.6481788158416748
Iteration [21755]: Loss = 9.836538314819336
Iteration [21756]: Loss = 0.6491029262542725
Iteration [21757]: Loss = 0.6500804424285889
Iteration [21758]: Loss = 0.6544677019119263
Iteration [21759]: Loss = 0.6548835635185242
Iteration [21760]: Loss = 5.221994400024414
Iteration [21761]: Loss = 0.653357207775116
Iteration [21762]: Loss = 0.6556820869445801
Iteration [21763]: Loss = 0.6564220190048218
Iteration [21764]: Loss = 0.6542957425117493
Iteration [21765]: Loss = 0.6493769884109497
Iteration [21766]: Loss = 0.6499767899513245
Iteration [21767]: Loss = 0.649116039276123
Iteration [21768]: Loss = 5.229740142822266
Iteration [21769]: Loss = 0.649524450302124
Iteration [21770]: Loss = 0.6499364972114563
Iteration [21771]: Loss = 0.650176465511322
Iteration [21772]: Loss = 0.6504439115524292
Iteration [21773]: Loss = 0.6503893733024597
Iteration [21774]: Loss = 0.6502096652984619
Iteration [21775]: Loss = 0.6499176025390625
Iteration [21776]: Loss = 0.6495245099067688
Iteration [21777]: Loss = 0.6514362692832947
Iteration [21778]: Loss = 0.6471147537231445
Iteration [21779]: Loss = 5.244167804718018
Iteration [21780]: Loss = 0.6466777920722961
Iteration [21781]: Loss = 5.242729187011719
Iteration [21782]: Loss = 0.6474858522415161
Iteration [21783]: Loss = 5.238849639892578
Iteration [21784]: Loss = 0.649232804775238
Iteration [21785]: Loss = 0.6501819491386414
Iteration [21786]: Loss = 5.217970371246338
Iteration [21787]: Loss = 0.6507741212844849
Iteration [21788]: Loss = 0.6518246531486511
Iteration [21789]: Loss = 0.6526303887367249
Iteration [21790]: Loss = 5.204281806945801
Iteration [21791]: Loss = 0.6544788479804993
Iteration [21792]: Loss = 0.655468761920929
Iteration [21793]: Loss = 0.6562477946281433
Iteration [21794]: Loss = 5.183446407318115
Iteration [21795]: Loss = 0.6579574346542358
Iteration [21796]: Loss = 0.658713161945343
Iteration [21797]: Loss = 5.169198036193848
Iteration [21798]: Loss = 0.6620662808418274
Iteration [21799]: Loss = 0.6630199551582336
Iteration [21800]: Loss = 0.6637663245201111
Iteration [21801]: Loss = 0.6643257737159729
Iteration [21802]: Loss = 0.6647167205810547
Iteration [21803]: Loss = 5.136874198913574
Iteration [21804]: Loss = 0.6657909154891968
Iteration [21805]: Loss = 0.6663443446159363
Iteration [21806]: Loss = 0.6667523384094238
Iteration [21807]: Loss = 0.6670293211936951
Iteration [21808]: Loss = 0.6671883463859558
Iteration [21809]: Loss = 0.6672409772872925
Iteration [21810]: Loss = 0.6671980619430542
Iteration [21811]: Loss = 5.1249003410339355
Iteration [21812]: Loss = 0.6674554347991943
Iteration [21813]: Loss = 0.6677144765853882
Iteration [21814]: Loss = 0.6678592562675476
Iteration [21815]: Loss = 5.120203018188477
Iteration [21816]: Loss = 0.6684280633926392
Iteration [21817]: Loss = 0.6681215763092041
Iteration [21818]: Loss = 0.6683774590492249
Iteration [21819]: Loss = 0.6685237288475037
Iteration [21820]: Loss = 0.6685715913772583
Iteration [21821]: Loss = 0.6685307025909424
Iteration [21822]: Loss = 0.6684101819992065
Iteration [21823]: Loss = 0.6682178974151611
Iteration [21824]: Loss = 0.6679611206054688
Iteration [21825]: Loss = 0.6676464676856995
Iteration [21826]: Loss = 0.6672797799110413
Iteration [21827]: Loss = 0.6668664813041687
Iteration [21828]: Loss = 5.128620147705078
Iteration [21829]: Loss = 0.6664724349975586
Iteration [21830]: Loss = 0.6664457321166992
Iteration [21831]: Loss = 5.129024982452393
Iteration [21832]: Loss = 0.6667009592056274
Iteration [21833]: Loss = 0.66694575548172
Iteration [21834]: Loss = 0.6670854687690735
Iteration [21835]: Loss = 0.6671310663223267
Iteration [21836]: Loss = 0.6670915484428406
Iteration [21837]: Loss = 0.6669756174087524
Iteration [21838]: Loss = 0.6667910814285278
Iteration [21839]: Loss = 5.127866268157959
Iteration [21840]: Loss = 5.12657356262207
Iteration [21841]: Loss = 0.6674145460128784
Iteration [21842]: Loss = 9.57234001159668
Iteration [21843]: Loss = 0.6692208051681519
Iteration [21844]: Loss = 0.6703255772590637
Iteration [21845]: Loss = 0.6712484359741211
Iteration [21846]: Loss = 0.6720069646835327
Iteration [21847]: Loss = 0.6726171970367432
Iteration [21848]: Loss = 5.091094493865967
Iteration [21849]: Loss = 5.08650016784668
Iteration [21850]: Loss = 0.6750501990318298
Iteration [21851]: Loss = 0.6759976744651794
Iteration [21852]: Loss = 5.070650577545166
Iteration [21853]: Loss = 0.6778669953346252
Iteration [21854]: Loss = 0.6787757873535156
Iteration [21855]: Loss = 0.6795231699943542
Iteration [21856]: Loss = 0.6801249980926514
Iteration [21857]: Loss = 0.6805955171585083
Iteration [21858]: Loss = 5.0477471351623535
Iteration [21859]: Loss = 0.6816478371620178
Iteration [21860]: Loss = 0.6822075843811035
Iteration [21861]: Loss = 0.6826406121253967
Iteration [21862]: Loss = 0.6829596161842346
Iteration [21863]: Loss = 0.6831756234169006
Iteration [21864]: Loss = 0.6832989454269409
Iteration [21865]: Loss = 0.6833388805389404
Iteration [21866]: Loss = 0.6833035945892334
Iteration [21867]: Loss = 0.6832005977630615
Iteration [21868]: Loss = 0.6830366849899292
Iteration [21869]: Loss = 0.6828182339668274
Iteration [21870]: Loss = 0.6825504899024963
Iteration [21871]: Loss = 0.6822385787963867
Iteration [21872]: Loss = 0.6818869113922119
Iteration [21873]: Loss = 0.6814996004104614
Iteration [21874]: Loss = 0.6810802817344666
Iteration [21875]: Loss = 0.6806322336196899
Iteration [21876]: Loss = 0.6801584959030151
Iteration [21877]: Loss = 0.6796616911888123
Iteration [21878]: Loss = 0.6791440844535828
Iteration [21879]: Loss = 0.6786080598831177
Iteration [21880]: Loss = 0.678055465221405
Iteration [21881]: Loss = 0.6774882078170776
Iteration [21882]: Loss = 0.6769077777862549
Iteration [21883]: Loss = 5.073215484619141
Iteration [21884]: Loss = 0.6761716604232788
Iteration [21885]: Loss = 0.675973117351532
Iteration [21886]: Loss = 5.076479434967041
Iteration [21887]: Loss = 0.6758833527565002
Iteration [21888]: Loss = 5.075196266174316
Iteration [21889]: Loss = 0.6763968467712402
Iteration [21890]: Loss = 5.070950508117676
Iteration [21891]: Loss = 5.067295551300049
Iteration [21892]: Loss = 0.6783437132835388
Iteration [21893]: Loss = 0.679138720035553
Iteration [21894]: Loss = 0.67978835105896
Iteration [21895]: Loss = 0.6803064346313477
Iteration [21896]: Loss = 5.049066543579102
Iteration [21897]: Loss = 0.6814249157905579
Iteration [21898]: Loss = 0.6820060610771179
Iteration [21899]: Loss = 0.6824628114700317
Iteration [21900]: Loss = 0.6828077435493469
Iteration [21901]: Loss = 0.6830517649650574
Iteration [21902]: Loss = 0.6832048892974854
Iteration [21903]: Loss = 0.6832760572433472
Iteration [21904]: Loss = 0.6832735538482666
Iteration [21905]: Loss = 5.0354390144348145
Iteration [21906]: Loss = 0.6835018396377563
Iteration [21907]: Loss = 0.683703601360321
Iteration [21908]: Loss = 0.6838191151618958
Iteration [21909]: Loss = 5.031893730163574
Iteration [21910]: Loss = 0.6842460632324219
Iteration [21911]: Loss = 0.6845309734344482
Iteration [21912]: Loss = 0.6847219467163086
Iteration [21913]: Loss = 5.026626110076904
Iteration [21914]: Loss = 0.6852748990058899
Iteration [21915]: Loss = 0.6856122016906738
Iteration [21916]: Loss = 5.021093368530273
Iteration [21917]: Loss = 0.6864122152328491
Iteration [21918]: Loss = 0.686853289604187
Iteration [21919]: Loss = 0.6871858835220337
Iteration [21920]: Loss = 0.6874205470085144
Iteration [21921]: Loss = 0.6875671148300171
Iteration [21922]: Loss = 0.6876341700553894
Iteration [21923]: Loss = 0.6876296997070312
Iteration [21924]: Loss = 0.6875609159469604
Iteration [21925]: Loss = 0.687434196472168
Iteration [21926]: Loss = 0.687255322933197
Iteration [21927]: Loss = 0.6870295405387878
Iteration [21928]: Loss = 0.6867616176605225
Iteration [21929]: Loss = 0.6864557862281799
Iteration [21930]: Loss = 0.6861160397529602
Iteration [21931]: Loss = 0.6857455968856812
Iteration [21932]: Loss = 0.6853476166725159
Iteration [21933]: Loss = 0.6849250793457031
Iteration [21934]: Loss = 0.6844803094863892
Iteration [21935]: Loss = 0.6840159296989441
Iteration [21936]: Loss = 0.6835336089134216
Iteration [21937]: Loss = 0.6830356121063232
Iteration [21938]: Loss = 0.6825230717658997
Iteration [21939]: Loss = 0.6819980144500732
Iteration [21940]: Loss = 0.6814615726470947
Iteration [21941]: Loss = 0.6809148192405701
Iteration [21942]: Loss = 0.6803591847419739
Iteration [21943]: Loss = 0.6797952651977539
Iteration [21944]: Loss = 0.67922443151474
Iteration [21945]: Loss = 0.6786469221115112
Iteration [21946]: Loss = 0.6780639290809631
Iteration [21947]: Loss = 5.066808223724365
Iteration [21948]: Loss = 0.6772988438606262
Iteration [21949]: Loss = 0.677076518535614
Iteration [21950]: Loss = 0.6768136024475098
Iteration [21951]: Loss = 0.6765142679214478
Iteration [21952]: Loss = 0.6761820912361145
Iteration [21953]: Loss = 0.6758204102516174
Iteration [21954]: Loss = 0.6754322648048401
Iteration [21955]: Loss = 5.080386161804199
Iteration [21956]: Loss = 0.6749971508979797
Iteration [21957]: Loss = 9.487032890319824
Iteration [21958]: Loss = 0.6755609512329102
Iteration [21959]: Loss = 0.6760839223861694
Iteration [21960]: Loss = 0.6764953136444092
Iteration [21961]: Loss = 0.6768063306808472
Iteration [21962]: Loss = 0.6770265102386475
Iteration [21963]: Loss = 0.6771652698516846
Iteration [21964]: Loss = 0.6772304773330688
Iteration [21965]: Loss = 0.6772293448448181
Iteration [21966]: Loss = 0.6771686673164368
Iteration [21967]: Loss = 0.6770541667938232
Iteration [21968]: Loss = 0.6768916845321655
Iteration [21969]: Loss = 5.071170806884766
Iteration [21970]: Loss = 0.6768285632133484
Iteration [21971]: Loss = 0.6768980026245117
Iteration [21972]: Loss = 0.6769014000892639
Iteration [21973]: Loss = 0.6768451929092407
Iteration [21974]: Loss = 0.6767353415489197
Iteration [21975]: Loss = 0.6765772700309753
Iteration [21976]: Loss = 0.6763755679130554
Iteration [21977]: Loss = 5.074212551116943
Iteration [21978]: Loss = 0.6762449145317078
Iteration [21979]: Loss = 0.6762851476669312
Iteration [21980]: Loss = 0.6762627363204956
Iteration [21981]: Loss = 0.6761837005615234
Iteration [21982]: Loss = 9.47326946258545
Iteration [21983]: Loss = 0.6766229271888733
Iteration [21984]: Loss = 0.6770789623260498
Iteration [21985]: Loss = 0.6774331331253052
Iteration [21986]: Loss = 0.6776953935623169
Iteration [21987]: Loss = 0.6778746247291565
Iteration [21988]: Loss = 0.6779792308807373
Iteration [21989]: Loss = 0.6780167818069458
Iteration [21990]: Loss = 0.6779935359954834
Iteration [21991]: Loss = 0.6779159307479858
Iteration [21992]: Loss = 0.6777892708778381
Iteration [21993]: Loss = 0.6776183247566223
Iteration [21994]: Loss = 0.6774076819419861
Iteration [21995]: Loss = 0.6771613955497742
Iteration [21996]: Loss = 0.6768829226493835
Iteration [21997]: Loss = 0.6765755414962769
Iteration [21998]: Loss = 0.6762422323226929
Iteration [21999]: Loss = 0.6758855581283569
Iteration [22000]: Loss = 0.6755079030990601
Iteration [22001]: Loss = 0.6751115918159485
Iteration [22002]: Loss = 0.6746983528137207
Iteration [22003]: Loss = 0.6742699146270752
Iteration [22004]: Loss = 5.08700704574585
Iteration [22005]: Loss = 0.6737449169158936
Iteration [22006]: Loss = 0.6736142635345459
Iteration [22007]: Loss = 0.6734405159950256
Iteration [22008]: Loss = 0.6732280850410461
Iteration [22009]: Loss = 9.51046371459961
Iteration [22010]: Loss = 0.6741300821304321
Iteration [22011]: Loss = 0.6716319918632507
Iteration [22012]: Loss = 0.6718573570251465
Iteration [22013]: Loss = 0.6713403463363647
Iteration [22014]: Loss = 0.6713788509368896
Iteration [22015]: Loss = 0.6713369488716125
Iteration [22016]: Loss = 0.6712222695350647
Iteration [22017]: Loss = 5.105072021484375
Iteration [22018]: Loss = 0.6708580851554871
Iteration [22019]: Loss = 0.671021580696106
Iteration [22020]: Loss = 0.6710931658744812
Iteration [22021]: Loss = 0.6710817813873291
Iteration [22022]: Loss = 0.6709956526756287
Iteration [22023]: Loss = 0.6708424687385559
Iteration [22024]: Loss = 0.6706286668777466
Iteration [22025]: Loss = 0.6703605651855469
Iteration [22026]: Loss = 0.6700435876846313
Iteration [22027]: Loss = 0.6696828603744507
Iteration [22028]: Loss = 0.6692824363708496
Iteration [22029]: Loss = 5.114872932434082
Iteration [22030]: Loss = 0.6688796281814575
Iteration [22031]: Loss = 0.6688346266746521
Iteration [22032]: Loss = 0.668719470500946
Iteration [22033]: Loss = 0.6685413122177124
Iteration [22034]: Loss = 0.6683064699172974
Iteration [22035]: Loss = 0.6680206656455994
Iteration [22036]: Loss = 0.6676888465881348
Iteration [22037]: Loss = 0.6673159003257751
Iteration [22038]: Loss = 0.6669061183929443
Iteration [22039]: Loss = 0.6664629578590393
Iteration [22040]: Loss = 0.6659899950027466
Iteration [22041]: Loss = 0.6654902696609497
Iteration [22042]: Loss = 0.6649666428565979
Iteration [22043]: Loss = 0.664421558380127
Iteration [22044]: Loss = 5.14312219619751
Iteration [22045]: Loss = 0.662658154964447
Iteration [22046]: Loss = 0.6625083684921265
Iteration [22047]: Loss = 0.6646155118942261
Iteration [22048]: Loss = 0.6643304824829102
Iteration [22049]: Loss = 0.6639697551727295
Iteration [22050]: Loss = 0.6635408997535706
Iteration [22051]: Loss = 0.6625794172286987
Iteration [22052]: Loss = 0.6620360612869263
Iteration [22053]: Loss = 0.6614437699317932
Iteration [22054]: Loss = 5.17241907119751
Iteration [22055]: Loss = 0.6551132202148438
Iteration [22056]: Loss = 0.6518966555595398
Iteration [22057]: Loss = 0.6469447612762451
Iteration [22058]: Loss = 0.646692156791687
Iteration [22059]: Loss = 0.6506555676460266
Iteration [22060]: Loss = 0.6507209539413452
Iteration [22061]: Loss = 0.649886429309845
Iteration [22062]: Loss = 0.6468991637229919
Iteration [22063]: Loss = 0.6400610208511353
Iteration [22064]: Loss = 0.6388864517211914
Iteration [22065]: Loss = 0.6414483785629272
Iteration [22066]: Loss = 0.6419506072998047
Iteration [22067]: Loss = 0.6555281281471252
Iteration [22068]: Loss = 0.6527669429779053
Iteration [22069]: Loss = 0.6523810625076294
Iteration [22070]: Loss = 5.224740028381348
Iteration [22071]: Loss = 0.6497195959091187
Iteration [22072]: Loss = 0.6495710611343384
Iteration [22073]: Loss = 0.652909517288208
Iteration [22074]: Loss = 0.6536008715629578
Iteration [22075]: Loss = 0.6523954272270203
Iteration [22076]: Loss = 0.6481163501739502
Iteration [22077]: Loss = 0.6495274305343628
Iteration [22078]: Loss = 5.248231887817383
Iteration [22079]: Loss = 0.645037055015564
Iteration [22080]: Loss = 0.6449398398399353
Iteration [22081]: Loss = 5.2543439865112305
Iteration [22082]: Loss = 5.252486705780029
Iteration [22083]: Loss = 0.643919825553894
Iteration [22084]: Loss = 0.6445004940032959
Iteration [22085]: Loss = 5.2644500732421875
Iteration [22086]: Loss = 0.6457958221435547
Iteration [22087]: Loss = 0.6464846134185791
Iteration [22088]: Loss = 0.6470663547515869
Iteration [22089]: Loss = 0.6457194089889526
Iteration [22090]: Loss = 0.6477775573730469
Iteration [22091]: Loss = 0.6479696035385132
Iteration [22092]: Loss = 0.6480666399002075
Iteration [22093]: Loss = 0.648078203201294
Iteration [22094]: Loss = 0.648012638092041
Iteration [22095]: Loss = 0.6478776931762695
Iteration [22096]: Loss = 0.6476805210113525
Iteration [22097]: Loss = 5.238576889038086
Iteration [22098]: Loss = 0.6442528963088989
Iteration [22099]: Loss = 9.869150161743164
Iteration [22100]: Loss = 0.6453976631164551
Iteration [22101]: Loss = 0.6462517976760864
Iteration [22102]: Loss = 0.6469495892524719
Iteration [22103]: Loss = 5.238108158111572
Iteration [22104]: Loss = 0.6484270095825195
Iteration [22105]: Loss = 0.649185299873352
Iteration [22106]: Loss = 0.6497965455055237
Iteration [22107]: Loss = 0.6502752304077148
Iteration [22108]: Loss = 5.22368860244751
Iteration [22109]: Loss = 0.650687575340271
Iteration [22110]: Loss = 5.202507019042969
Iteration [22111]: Loss = 0.6529189348220825
Iteration [22112]: Loss = 5.201674938201904
Iteration [22113]: Loss = 0.6548155546188354
Iteration [22114]: Loss = 5.189758777618408
Iteration [22115]: Loss = 0.6569938659667969
Iteration [22116]: Loss = 0.6580455303192139
Iteration [22117]: Loss = 0.6589221358299255
Iteration [22118]: Loss = 0.6596405506134033
Iteration [22119]: Loss = 0.6602164506912231
Iteration [22120]: Loss = 0.6606636643409729
Iteration [22121]: Loss = 0.6609947085380554
Iteration [22122]: Loss = 0.6612212061882019
Iteration [22123]: Loss = 0.6613535284996033
Iteration [22124]: Loss = 0.6614006757736206
Iteration [22125]: Loss = 0.6613714694976807
Iteration [22126]: Loss = 0.6612734198570251
Iteration [22127]: Loss = 0.6611133217811584
Iteration [22128]: Loss = 0.6608974933624268
Iteration [22129]: Loss = 0.6606314182281494
Iteration [22130]: Loss = 5.163352966308594
Iteration [22131]: Loss = 0.6604511737823486
Iteration [22132]: Loss = 5.170831680297852
Iteration [22133]: Loss = 0.6594811081886292
Iteration [22134]: Loss = 0.6598233580589294
Iteration [22135]: Loss = 0.6600589156150818
Iteration [22136]: Loss = 5.164053440093994
Iteration [22137]: Loss = 5.160951137542725
Iteration [22138]: Loss = 0.6615750193595886
Iteration [22139]: Loss = 0.6621619462966919
Iteration [22140]: Loss = 0.6626327633857727
Iteration [22141]: Loss = 0.6629993319511414
Iteration [22142]: Loss = 5.146459102630615
Iteration [22143]: Loss = 0.6638436913490295
Iteration [22144]: Loss = 0.664301335811615
Iteration [22145]: Loss = 0.6666425466537476
Iteration [22146]: Loss = 0.6669040322303772
Iteration [22147]: Loss = 5.12483024597168
Iteration [22148]: Loss = 5.122088432312012
Iteration [22149]: Loss = 5.117802619934082
Iteration [22150]: Loss = 0.6693315505981445
Iteration [22151]: Loss = 5.107385635375977
Iteration [22152]: Loss = 0.671261727809906
Iteration [22153]: Loss = 0.6721797585487366
Iteration [22154]: Loss = 5.0918989181518555
Iteration [22155]: Loss = 0.6739597916603088
Iteration [22156]: Loss = 5.081536769866943
Iteration [22157]: Loss = 0.6758967638015747
Iteration [22158]: Loss = 0.6768161058425903
Iteration [22159]: Loss = 0.6775869131088257
Iteration [22160]: Loss = 0.6782233715057373
Iteration [22161]: Loss = 0.6787388324737549
Iteration [22162]: Loss = 9.436105728149414
Iteration [22163]: Loss = 0.6801835298538208
Iteration [22164]: Loss = 0.6810626983642578
Iteration [22165]: Loss = 0.6817977428436279
Iteration [22166]: Loss = 0.6824028491973877
Iteration [22167]: Loss = 0.6828905940055847
Iteration [22168]: Loss = 0.6832726001739502
Iteration [22169]: Loss = 0.6835591793060303
Iteration [22170]: Loss = 0.6837597489356995
Iteration [22171]: Loss = 0.6838827729225159
Iteration [22172]: Loss = 0.6839361190795898
Iteration [22173]: Loss = 0.6839264631271362
Iteration [22174]: Loss = 0.683860182762146
Iteration [22175]: Loss = 5.032513618469238
Iteration [22176]: Loss = 0.6839494705200195
Iteration [22177]: Loss = 0.6840779185295105
Iteration [22178]: Loss = 0.6841362714767456
Iteration [22179]: Loss = 0.6841312646865845
Iteration [22180]: Loss = 0.6840692162513733
Iteration [22181]: Loss = 0.6839560866355896
Iteration [22182]: Loss = 0.6837965846061707
Iteration [22183]: Loss = 0.6835954189300537
Iteration [22184]: Loss = 0.6833570599555969
Iteration [22185]: Loss = 0.683085024356842
Iteration [22186]: Loss = 0.6827826499938965
Iteration [22187]: Loss = 5.039530277252197
Iteration [22188]: Loss = 0.6824692487716675
Iteration [22189]: Loss = 0.6824265718460083
Iteration [22190]: Loss = 0.6823310256004333
Iteration [22191]: Loss = 5.040976524353027
Iteration [22192]: Loss = 0.6823700070381165
Iteration [22193]: Loss = 5.03939962387085
Iteration [22194]: Loss = 0.6828824281692505
Iteration [22195]: Loss = 0.6831905245780945
Iteration [22196]: Loss = 0.6834113597869873
Iteration [22197]: Loss = 0.6835530400276184
Iteration [22198]: Loss = 5.033161163330078
Iteration [22199]: Loss = 0.6839954853057861
Iteration [22200]: Loss = 0.6842736005783081
Iteration [22201]: Loss = 0.684467077255249
Iteration [22202]: Loss = 0.684584379196167
Iteration [22203]: Loss = 0.6846329569816589
Iteration [22204]: Loss = 0.6846198439598083
Iteration [22205]: Loss = 0.684550940990448
Iteration [22206]: Loss = 0.6844319105148315
Iteration [22207]: Loss = 0.6842677593231201
Iteration [22208]: Loss = 0.6840629577636719
Iteration [22209]: Loss = 0.6838216185569763
Iteration [22210]: Loss = 0.6835474967956543
Iteration [22211]: Loss = 5.035226821899414
Iteration [22212]: Loss = 0.683279812335968
Iteration [22213]: Loss = 0.683255672454834
Iteration [22214]: Loss = 5.035588264465332
Iteration [22215]: Loss = 0.6834143400192261
Iteration [22216]: Loss = 5.033445358276367
Iteration [22217]: Loss = 0.6840184330940247
Iteration [22218]: Loss = 0.6843646764755249
Iteration [22219]: Loss = 0.6846200227737427
Iteration [22220]: Loss = 0.6847934722900391
Iteration [22221]: Loss = 0.6848929524421692
Iteration [22222]: Loss = 5.026096820831299
Iteration [22223]: Loss = 0.6852611303329468
Iteration [22224]: Loss = 0.6855064630508423
Iteration [22225]: Loss = 0.6856708526611328
Iteration [22226]: Loss = 0.6857624053955078
Iteration [22227]: Loss = 0.6857882142066956
Iteration [22228]: Loss = 5.02161169052124
Iteration [22229]: Loss = 0.6860296726226807
Iteration [22230]: Loss = 0.6862208247184753
Iteration [22231]: Loss = 5.018469333648682
Iteration [22232]: Loss = 0.6867440938949585
Iteration [22233]: Loss = 0.6870547533035278
Iteration [22234]: Loss = 0.6872782111167908
Iteration [22235]: Loss = 0.6874229311943054
Iteration [22236]: Loss = 0.6874967813491821
Iteration [22237]: Loss = 0.6875067353248596
Iteration [22238]: Loss = 0.6874591708183289
Iteration [22239]: Loss = 0.6873598098754883
Iteration [22240]: Loss = 0.6872137784957886
Iteration [22241]: Loss = 0.6870257258415222
Iteration [22242]: Loss = 0.6868001222610474
Iteration [22243]: Loss = 0.6865402460098267
Iteration [22244]: Loss = 0.6862499713897705
Iteration [22245]: Loss = 0.6859321594238281
Iteration [22246]: Loss = 0.685589611530304
Iteration [22247]: Loss = 0.6852250099182129
Iteration [22248]: Loss = 0.6848402619361877
Iteration [22249]: Loss = 0.6844376921653748
Iteration [22250]: Loss = 0.6840190291404724
Iteration [22251]: Loss = 0.6835858821868896
Iteration [22252]: Loss = 5.035791397094727
Iteration [22253]: Loss = 0.6830450296401978
Iteration [22254]: Loss = 0.682903528213501
Iteration [22255]: Loss = 0.6827200651168823
Iteration [22256]: Loss = 0.6824990510940552
Iteration [22257]: Loss = 0.682243824005127
Iteration [22258]: Loss = 5.042227745056152
Iteration [22259]: Loss = 0.6820065975189209
Iteration [22260]: Loss = 0.6819942593574524
Iteration [22261]: Loss = 0.6819273233413696
Iteration [22262]: Loss = 0.6818113327026367
Iteration [22263]: Loss = 0.6816508769989014
Iteration [22264]: Loss = 0.6814507246017456
Iteration [22265]: Loss = 5.0462870597839355
Iteration [22266]: Loss = 0.6813069581985474
Iteration [22267]: Loss = 0.681334376335144
Iteration [22268]: Loss = 0.6813034415245056
Iteration [22269]: Loss = 0.6812199950218201
Iteration [22270]: Loss = 0.6810891628265381
Iteration [22271]: Loss = 0.6809156537055969
Iteration [22272]: Loss = 0.6807037591934204
Iteration [22273]: Loss = 0.6804574131965637
Iteration [22274]: Loss = 0.6801801323890686
Iteration [22275]: Loss = 0.6798746585845947
Iteration [22276]: Loss = 5.0554327964782715
Iteration [22277]: Loss = 0.6795520782470703
Iteration [22278]: Loss = 0.6795036196708679
Iteration [22279]: Loss = 0.679404616355896
Iteration [22280]: Loss = 0.6792597770690918
Iteration [22281]: Loss = 0.679074227809906
Iteration [22282]: Loss = 0.6788517832756042
Iteration [22283]: Loss = 5.060640811920166
Iteration [22284]: Loss = 0.678670346736908
Iteration [22285]: Loss = 0.6786819696426392
Iteration [22286]: Loss = 0.6786372661590576
Iteration [22287]: Loss = 0.6785416603088379
Iteration [22288]: Loss = 0.6784005165100098
Iteration [22289]: Loss = 5.062719821929932
Iteration [22290]: Loss = 0.6783574223518372
Iteration [22291]: Loss = 0.6784276366233826
Iteration [22292]: Loss = 0.6784359216690063
Iteration [22293]: Loss = 5.061783790588379
Iteration [22294]: Loss = 0.678647518157959
Iteration [22295]: Loss = 0.6788260340690613
Iteration [22296]: Loss = 0.678931713104248
Iteration [22297]: Loss = 0.6789719462394714
Iteration [22298]: Loss = 0.6789530515670776
Iteration [22299]: Loss = 0.6788809895515442
Iteration [22300]: Loss = 0.6787611246109009
Iteration [22301]: Loss = 0.6785982847213745
Iteration [22302]: Loss = 0.6783966422080994
Iteration [22303]: Loss = 0.6781600713729858
Iteration [22304]: Loss = 0.6778919696807861
Iteration [22305]: Loss = 0.677595853805542
Iteration [22306]: Loss = 0.6772743463516235
Iteration [22307]: Loss = 0.6769298315048218
Iteration [22308]: Loss = 0.6765649914741516
Iteration [22309]: Loss = 0.6761816143989563
Iteration [22310]: Loss = 0.6757817268371582
Iteration [22311]: Loss = 0.675366997718811
Iteration [22312]: Loss = 0.6749388575553894
Iteration [22313]: Loss = 5.083280563354492
Iteration [22314]: Loss = 0.6744073033332825
Iteration [22315]: Loss = 0.6742704510688782
Iteration [22316]: Loss = 0.6740925312042236
Iteration [22317]: Loss = 0.6738780736923218
Iteration [22318]: Loss = 9.502583503723145
Iteration [22319]: Loss = 0.6740601658821106
Iteration [22320]: Loss = 0.674393892288208
Iteration [22321]: Loss = 0.6746408939361572
Iteration [22322]: Loss = 0.6748095154762268
Iteration [22323]: Loss = 0.6749078631401062
Iteration [22324]: Loss = 9.48669147491455
Iteration [22325]: Loss = 5.077115535736084
Iteration [22326]: Loss = 0.6765010952949524
Iteration [22327]: Loss = 0.6772511005401611
Iteration [22328]: Loss = 0.677873969078064
Iteration [22329]: Loss = 0.678382158279419
Iteration [22330]: Loss = 0.6787869334220886
Iteration [22331]: Loss = 0.6790985465049744
Iteration [22332]: Loss = 0.6793261170387268
Iteration [22333]: Loss = 5.055797100067139
Iteration [22334]: Loss = 0.6799046993255615
Iteration [22335]: Loss = 0.6802359819412231
Iteration [22336]: Loss = 0.6804814338684082
Iteration [22337]: Loss = 0.6806492209434509
Iteration [22338]: Loss = 0.6797143220901489
Iteration [22339]: Loss = 0.6797491908073425
Iteration [22340]: Loss = 0.6797274947166443
Iteration [22341]: Loss = 0.6796548366546631
Iteration [22342]: Loss = 0.6795362830162048
Iteration [22343]: Loss = 0.6793765425682068
Iteration [22344]: Loss = 0.6791796088218689
Iteration [22345]: Loss = 0.6789492964744568
Iteration [22346]: Loss = 0.6786887645721436
Iteration [22347]: Loss = 0.6784011721611023
Iteration [22348]: Loss = 0.6780893206596375
Iteration [22349]: Loss = 0.67775559425354
Iteration [22350]: Loss = 0.677402138710022
Iteration [22351]: Loss = 5.069262504577637
Iteration [22352]: Loss = 5.069490432739258
Iteration [22353]: Loss = 0.677243173122406
Iteration [22354]: Loss = 0.67741858959198
Iteration [22355]: Loss = 0.6775238513946533
Iteration [22356]: Loss = 0.6775659322738647
Iteration [22357]: Loss = 0.6775511503219604
Iteration [22358]: Loss = 0.6774850487709045
Iteration [22359]: Loss = 0.6773726940155029
Iteration [22360]: Loss = 0.6772189140319824
Iteration [22361]: Loss = 0.6770276427268982
Iteration [22362]: Loss = 0.6768024563789368
Iteration [22363]: Loss = 0.6757016777992249
Iteration [22364]: Loss = 0.676264762878418
Iteration [22365]: Loss = 0.6751136779785156
Iteration [22366]: Loss = 0.6756290793418884
Iteration [22367]: Loss = 0.6752804517745972
Iteration [22368]: Loss = 0.6749139428138733
Iteration [22369]: Loss = 5.083098411560059
Iteration [22370]: Loss = 5.083385467529297
Iteration [22371]: Loss = 0.6747236251831055
Iteration [22372]: Loss = 0.6728842854499817
Iteration [22373]: Loss = 0.6729820966720581
Iteration [22374]: Loss = 0.6730180978775024
Iteration [22375]: Loss = 0.6729983687400818
Iteration [22376]: Loss = 0.6729283928871155
Iteration [22377]: Loss = 0.6728131771087646
Iteration [22378]: Loss = 5.093526840209961
Iteration [22379]: Loss = 0.6728075742721558
Iteration [22380]: Loss = 0.6728907227516174
Iteration [22381]: Loss = 0.6729136109352112
Iteration [22382]: Loss = 0.6728819608688354
Iteration [22383]: Loss = 0.6728015542030334
Iteration [22384]: Loss = 0.6726769208908081
Iteration [22385]: Loss = 0.6725127696990967
Iteration [22386]: Loss = 5.0954484939575195
Iteration [22387]: Loss = 0.672423243522644
Iteration [22388]: Loss = 0.6724708080291748
Iteration [22389]: Loss = 0.6724615097045898
Iteration [22390]: Loss = 0.6724013090133667
Iteration [22391]: Loss = 0.6722949743270874
Iteration [22392]: Loss = 5.096372604370117
Iteration [22393]: Loss = 0.6723042726516724
Iteration [22394]: Loss = 0.6723936796188354
Iteration [22395]: Loss = 0.6724223494529724
Iteration [22396]: Loss = 0.6723962426185608
Iteration [22397]: Loss = 0.6723208427429199
Iteration [22398]: Loss = 0.6722009778022766
Iteration [22399]: Loss = 5.0969648361206055
Iteration [22400]: Loss = 13.94408130645752
Iteration [22401]: Loss = 0.6732429265975952
Iteration [22402]: Loss = 5.085245132446289
Iteration [22403]: Loss = 0.6752312779426575
Iteration [22404]: Loss = 0.676160454750061
Iteration [22405]: Loss = 0.6769479513168335
Iteration [22406]: Loss = 0.6776072978973389
Iteration [22407]: Loss = 0.6781514286994934
Iteration [22408]: Loss = 0.6785913109779358
Iteration [22409]: Loss = 0.6789371967315674
Iteration [22410]: Loss = 0.6791985630989075
Iteration [22411]: Loss = 0.6793835163116455
Iteration [22412]: Loss = 0.679499626159668
Iteration [22413]: Loss = 0.6795536875724792
Iteration [22414]: Loss = 0.6795520782470703
Iteration [22415]: Loss = 0.6794999241828918
Iteration [22416]: Loss = 0.6794027090072632
Iteration [22417]: Loss = 0.6792646050453186
Iteration [22418]: Loss = 0.6790897846221924
Iteration [22419]: Loss = 0.6788820624351501
Iteration [22420]: Loss = 0.6786445379257202
Iteration [22421]: Loss = 0.6783801913261414
Iteration [22422]: Loss = 0.6780919432640076
Iteration [22423]: Loss = 0.6777819991111755
Iteration [22424]: Loss = 0.6774525046348572
Iteration [22425]: Loss = 0.6771056056022644
Iteration [22426]: Loss = 0.6767430901527405
Iteration [22427]: Loss = 5.072934150695801
Iteration [22428]: Loss = 0.6763057708740234
Iteration [22429]: Loss = 0.6762011647224426
Iteration [22430]: Loss = 0.6760567426681519
Iteration [22431]: Loss = 0.6758765578269958
Iteration [22432]: Loss = 0.6756641268730164
Iteration [22433]: Loss = 0.6754227876663208
Iteration [22434]: Loss = 13.888605117797852
Iteration [22435]: Loss = 0.675822913646698
Iteration [22436]: Loss = 9.469382286071777
Iteration [22437]: Loss = 0.6774417161941528
Iteration [22438]: Loss = 0.6783543229103088
Iteration [22439]: Loss = 0.6791288256645203
Iteration [22440]: Loss = 0.6797786951065063
Iteration [22441]: Loss = 0.6803160309791565
Iteration [22442]: Loss = 5.048818111419678
Iteration [22443]: Loss = 5.045239448547363
Iteration [22444]: Loss = 9.398944854736328
Iteration [22445]: Loss = 0.6835148334503174
Iteration [22446]: Loss = 5.028064250946045
Iteration [22447]: Loss = 0.6870168447494507
Iteration [22448]: Loss = 0.6881101727485657
Iteration [22449]: Loss = 5.004045486450195
Iteration [22450]: Loss = 0.6900373697280884
Iteration [22451]: Loss = 0.6909133195877075
Iteration [22452]: Loss = 4.989919185638428
Iteration [22453]: Loss = 0.6925631165504456
Iteration [22454]: Loss = 0.6933342218399048
Iteration [22455]: Loss = 0.6939847469329834
Iteration [22456]: Loss = 0.6945263147354126
Iteration [22457]: Loss = 0.6949697732925415
Iteration [22458]: Loss = 0.6953246593475342
Iteration [22459]: Loss = 0.6955995559692383
Iteration [22460]: Loss = 0.695802628993988
Iteration [22461]: Loss = 0.6959407925605774
Iteration [22462]: Loss = 0.6960205435752869
Iteration [22463]: Loss = 0.6960475444793701
Iteration [22464]: Loss = 0.6960271596908569
Iteration [22465]: Loss = 0.6959641575813293
Iteration [22466]: Loss = 4.967615127563477
Iteration [22467]: Loss = 0.6960070729255676
Iteration [22468]: Loss = 0.696092426776886
Iteration [22469]: Loss = 0.6961246728897095
Iteration [22470]: Loss = 0.6961089372634888
Iteration [22471]: Loss = 0.6960501074790955
Iteration [22472]: Loss = 4.967141628265381
Iteration [22473]: Loss = 0.6961001753807068
Iteration [22474]: Loss = 0.6961885690689087
Iteration [22475]: Loss = 0.6962234377861023
Iteration [22476]: Loss = 0.6962102055549622
Iteration [22477]: Loss = 0.6961535215377808
Iteration [22478]: Loss = 0.6960578560829163
Iteration [22479]: Loss = 0.6959268450737
Iteration [22480]: Loss = 4.968133926391602
Iteration [22481]: Loss = 0.6958538889884949
Iteration [22482]: Loss = 4.967471122741699
Iteration [22483]: Loss = 9.235962867736816
Iteration [22484]: Loss = 0.6969027519226074
Iteration [22485]: Loss = 0.6975303292274475
Iteration [22486]: Loss = 0.6980515122413635
Iteration [22487]: Loss = 0.6984769105911255
Iteration [22488]: Loss = 0.6988158226013184
Iteration [22489]: Loss = 0.6990766525268555
Iteration [22490]: Loss = 0.6992672681808472
Iteration [22491]: Loss = 0.6993945240974426
Iteration [22492]: Loss = 0.6994647979736328
Iteration [22493]: Loss = 0.6994836330413818
Iteration [22494]: Loss = 0.6994561553001404
Iteration [22495]: Loss = 0.6993869543075562
Iteration [22496]: Loss = 0.6992802023887634
Iteration [22497]: Loss = 0.6991396546363831
Iteration [22498]: Loss = 0.6989685297012329
Iteration [22499]: Loss = 0.6987701058387756
Iteration [22500]: Loss = 0.6985470056533813
Iteration [22501]: Loss = 0.6983018517494202
Iteration [22502]: Loss = 0.6980365514755249
Iteration [22503]: Loss = 4.9576568603515625
Iteration [22504]: Loss = 4.95776891708374
Iteration [22505]: Loss = 0.6979454159736633
Iteration [22506]: Loss = 4.95587158203125
Iteration [22507]: Loss = 0.6984578371047974
Iteration [22508]: Loss = 0.698742151260376
Iteration [22509]: Loss = 0.6989537477493286
Iteration [22510]: Loss = 0.6991001963615417
Iteration [22511]: Loss = 4.950132369995117
Iteration [22512]: Loss = 0.6994978189468384
Iteration [22513]: Loss = 0.6997329592704773
Iteration [22514]: Loss = 0.6999003887176514
Iteration [22515]: Loss = 0.7000067234039307
Iteration [22516]: Loss = 0.7000582218170166
Iteration [22517]: Loss = 0.7000601291656494
Iteration [22518]: Loss = 0.700017511844635
Iteration [22519]: Loss = 0.6999346017837524
Iteration [22520]: Loss = 0.6998156309127808
Iteration [22521]: Loss = 4.947638511657715
Iteration [22522]: Loss = 0.699759840965271
Iteration [22523]: Loss = 0.6998017430305481
Iteration [22524]: Loss = 0.699795126914978
Iteration [22525]: Loss = 0.699744701385498
Iteration [22526]: Loss = 0.6996551156044006
Iteration [22527]: Loss = 0.6995298266410828
Iteration [22528]: Loss = 0.6993727684020996
Iteration [22529]: Loss = 0.6991868615150452
Iteration [22530]: Loss = 0.6989752054214478
Iteration [22531]: Loss = 0.6987403631210327
Iteration [22532]: Loss = 4.9538187980651855
Iteration [22533]: Loss = 0.6984870433807373
Iteration [22534]: Loss = 0.6984450221061707
Iteration [22535]: Loss = 0.6972436308860779
Iteration [22536]: Loss = 0.6971257328987122
Iteration [22537]: Loss = 0.6969754099845886
Iteration [22538]: Loss = 0.6967958211898804
Iteration [22539]: Loss = 4.963779449462891
Iteration [22540]: Loss = 0.6966373920440674
Iteration [22541]: Loss = 0.6966361999511719
Iteration [22542]: Loss = 0.6965909600257874
Iteration [22543]: Loss = 0.6965060830116272
Iteration [22544]: Loss = 0.696385383605957
Iteration [22545]: Loss = 4.965662956237793
Iteration [22546]: Loss = 0.696327805519104
Iteration [22547]: Loss = 0.6963695287704468
Iteration [22548]: Loss = 0.6963629126548767
Iteration [22549]: Loss = 0.6963127851486206
Iteration [22550]: Loss = 0.6962235569953918
Iteration [22551]: Loss = 0.6960992217063904
Iteration [22552]: Loss = 0.6959431171417236
Iteration [22553]: Loss = 4.968166351318359
Iteration [22554]: Loss = 0.6958249807357788
Iteration [22555]: Loss = 4.967730522155762
Iteration [22556]: Loss = 0.696087121963501
Iteration [22557]: Loss = 0.696264922618866
Iteration [22558]: Loss = 0.6963810920715332
Iteration [22559]: Loss = 0.6975590586662292
Iteration [22560]: Loss = 0.6975693106651306
Iteration [22561]: Loss = 0.6975343823432922
Iteration [22562]: Loss = 0.6974587440490723
Iteration [22563]: Loss = 9.222247123718262
Iteration [22564]: Loss = 4.963558197021484
Iteration [22565]: Loss = 0.6983397006988525
Iteration [22566]: Loss = 0.6988281011581421
Iteration [22567]: Loss = 0.6992242932319641
Iteration [22568]: Loss = 0.6995375156402588
Iteration [22569]: Loss = 0.6997758150100708
Iteration [22570]: Loss = 0.6999465823173523
Iteration [22571]: Loss = 0.7000564336776733
Iteration [22572]: Loss = 0.7001115083694458
Iteration [22573]: Loss = 0.700117290019989
Iteration [22574]: Loss = 0.7000784873962402
Iteration [22575]: Loss = 0.6999997496604919
Iteration [22576]: Loss = 0.6998847723007202
Iteration [22577]: Loss = 0.6997374296188354
Iteration [22578]: Loss = 0.6995607614517212
Iteration [22579]: Loss = 0.699357807636261
Iteration [22580]: Loss = 0.6991312503814697
Iteration [22581]: Loss = 0.6988832354545593
Iteration [22582]: Loss = 0.6986161470413208
Iteration [22583]: Loss = 0.698331892490387
Iteration [22584]: Loss = 0.698032021522522
Iteration [22585]: Loss = 0.6977183222770691
Iteration [22586]: Loss = 0.6973920464515686
Iteration [22587]: Loss = 0.6970545053482056
Iteration [22588]: Loss = 0.6967068910598755
Iteration [22589]: Loss = 0.69635009765625
Iteration [22590]: Loss = 0.6959851980209351
Iteration [22591]: Loss = 0.6956129670143127
Iteration [22592]: Loss = 0.6952341198921204
Iteration [22593]: Loss = 0.6948494911193848
Iteration [22594]: Loss = 4.975034713745117
Iteration [22595]: Loss = 4.975665092468262
Iteration [22596]: Loss = 0.6944642663002014
Iteration [22597]: Loss = 4.9746503829956055
Iteration [22598]: Loss = 0.6948229074478149
Iteration [22599]: Loss = 0.6950414180755615
Iteration [22600]: Loss = 0.6951947808265686
Iteration [22601]: Loss = 4.970644950866699
Iteration [22602]: Loss = 0.6956039071083069
Iteration [22603]: Loss = 0.6958437561988831
Iteration [22604]: Loss = 0.6960161328315735
Iteration [22605]: Loss = 0.6961277723312378
Iteration [22606]: Loss = 0.6961846947669983
Iteration [22607]: Loss = 0.6961923837661743
Iteration [22608]: Loss = 0.6961556673049927
Iteration [22609]: Loss = 0.696078896522522
Iteration [22610]: Loss = 0.6959661841392517
Iteration [22611]: Loss = 0.6958209276199341
Iteration [22612]: Loss = 0.6956465244293213
Iteration [22613]: Loss = 0.6954458951950073
Iteration [22614]: Loss = 0.6952216625213623
Iteration [22615]: Loss = 0.6949760913848877
Iteration [22616]: Loss = 0.6947113871574402
Iteration [22617]: Loss = 0.6944295167922974
Iteration [22618]: Loss = 0.6941320896148682
Iteration [22619]: Loss = 0.6938208341598511
Iteration [22620]: Loss = 0.6934970021247864
Iteration [22621]: Loss = 0.6931619644165039
Iteration [22622]: Loss = 0.6928169131278992
Iteration [22623]: Loss = 4.985634803771973
Iteration [22624]: Loss = 0.6923758387565613
Iteration [22625]: Loss = 0.6922543048858643
Iteration [22626]: Loss = 0.6921014189720154
Iteration [22627]: Loss = 0.691920280456543
Iteration [22628]: Loss = 0.691713809967041
Iteration [22629]: Loss = 0.6914844512939453
Iteration [22630]: Loss = 4.992178916931152
Iteration [22631]: Loss = 0.691241443157196
Iteration [22632]: Loss = 0.6912044286727905
Iteration [22633]: Loss = 0.691127598285675
Iteration [22634]: Loss = 4.993350028991699
Iteration [22635]: Loss = 0.6911451816558838
Iteration [22636]: Loss = 0.6912189722061157
Iteration [22637]: Loss = 0.6912419199943542
Iteration [22638]: Loss = 0.6912194490432739
Iteration [22639]: Loss = 0.6911559104919434
Iteration [22640]: Loss = 0.6910552382469177
Iteration [22641]: Loss = 0.6909212470054626
Iteration [22642]: Loss = 0.6907572746276855
Iteration [22643]: Loss = 0.6905663013458252
Iteration [22644]: Loss = 0.6903510093688965
Iteration [22645]: Loss = 0.6901137828826904
Iteration [22646]: Loss = 0.689857006072998
Iteration [22647]: Loss = 0.6895824670791626
Iteration [22648]: Loss = 0.6892919540405273
Iteration [22649]: Loss = 0.6889873743057251
Iteration [22650]: Loss = 5.0059075355529785
Iteration [22651]: Loss = 0.6886165142059326
Iteration [22652]: Loss = 0.688525378704071
Iteration [22653]: Loss = 0.6884002089500427
Iteration [22654]: Loss = 0.6882441639900208
Iteration [22655]: Loss = 0.6880606412887573
Iteration [22656]: Loss = 0.6878520846366882
Iteration [22657]: Loss = 0.6876212954521179
Iteration [22658]: Loss = 0.6873701810836792
Iteration [22659]: Loss = 5.014345645904541
Iteration [22660]: Loss = 0.6870915293693542
Iteration [22661]: Loss = 0.6870400309562683
Iteration [22662]: Loss = 0.6869503855705261
Iteration [22663]: Loss = 0.6868266463279724
Iteration [22664]: Loss = 0.6866720914840698
Iteration [22665]: Loss = 0.686489999294281
Iteration [22666]: Loss = 0.686282753944397
Iteration [22667]: Loss = 0.6860530972480774
Iteration [22668]: Loss = 5.0213494300842285
Iteration [22669]: Loss = 0.6858115792274475
Iteration [22670]: Loss = 0.685775876045227
Iteration [22671]: Loss = 5.021903991699219
Iteration [22672]: Loss = 0.6858652234077454
Iteration [22673]: Loss = 0.6859705448150635
Iteration [22674]: Loss = 0.6860222816467285
Iteration [22675]: Loss = 0.6860259175300598
Iteration [22676]: Loss = 0.6859862804412842
Iteration [22677]: Loss = 5.020786762237549
Iteration [22678]: Loss = 0.6860686540603638
Iteration [22679]: Loss = 0.6861708760261536
Iteration [22680]: Loss = 0.6862198710441589
Iteration [22681]: Loss = 0.6862210035324097
Iteration [22682]: Loss = 0.6861790418624878
Iteration [22683]: Loss = 0.6860982775688171
Iteration [22684]: Loss = 0.6859825849533081
Iteration [22685]: Loss = 0.6858353614807129
Iteration [22686]: Loss = 0.6856597661972046
Iteration [22687]: Loss = 0.6854586601257324
Iteration [22688]: Loss = 5.024425506591797
Iteration [22689]: Loss = 0.6852657198905945
Iteration [22690]: Loss = 0.6852507591247559
Iteration [22691]: Loss = 0.6851944923400879
Iteration [22692]: Loss = 0.6851008534431458
Iteration [22693]: Loss = 0.684973418712616
Iteration [22694]: Loss = 5.0266923904418945
Iteration [22695]: Loss = 0.684906542301178
Iteration [22696]: Loss = 0.6849454045295715
Iteration [22697]: Loss = 0.6849375367164612
Iteration [22698]: Loss = 0.6848872900009155
Iteration [22699]: Loss = 0.6847993731498718
Iteration [22700]: Loss = 0.6846771240234375
Iteration [22701]: Loss = 0.6845242381095886
Iteration [22702]: Loss = 0.6843436360359192
Iteration [22703]: Loss = 0.6841381788253784
Iteration [22704]: Loss = 0.6839101314544678
Iteration [22705]: Loss = 0.6836621165275574
Iteration [22706]: Loss = 0.6833958029747009
Iteration [22707]: Loss = 0.6831132769584656
Iteration [22708]: Loss = 0.6828159093856812
Iteration [22709]: Loss = 5.039244651794434
Iteration [22710]: Loss = 0.6824599504470825
Iteration [22711]: Loss = 0.6823760271072388
Iteration [22712]: Loss = 0.6822576522827148
Iteration [22713]: Loss = 0.6821084022521973
Iteration [22714]: Loss = 5.042374610900879
Iteration [22715]: Loss = 0.682004988193512
Iteration [22716]: Loss = 0.6820286512374878
Iteration [22717]: Loss = 0.6820074319839478
Iteration [22718]: Loss = 0.6819454431533813
Iteration [22719]: Loss = 0.6818467974662781
Iteration [22720]: Loss = 0.6817153692245483
Iteration [22721]: Loss = 0.6815543174743652
Iteration [22722]: Loss = 0.681366503238678
Iteration [22723]: Loss = 5.046615123748779
Iteration [22724]: Loss = 0.6811977028846741
Iteration [22725]: Loss = 0.6811935305595398
Iteration [22726]: Loss = 0.6811473369598389
Iteration [22727]: Loss = 0.6810628175735474
Iteration [22728]: Loss = 0.6809441447257996
Iteration [22729]: Loss = 0.6807945966720581
Iteration [22730]: Loss = 0.6806173324584961
Iteration [22731]: Loss = 0.680415153503418
Iteration [22732]: Loss = 9.423595428466797
Iteration [22733]: Loss = 0.6804940700531006
Iteration [22734]: Loss = 0.6807256937026978
Iteration [22735]: Loss = 0.6808919906616211
Iteration [22736]: Loss = 0.6809995174407959
Iteration [22737]: Loss = 0.6810539960861206
Iteration [22738]: Loss = 0.6810608506202698
Iteration [22739]: Loss = 0.6810247898101807
Iteration [22740]: Loss = 0.6809501051902771
Iteration [22741]: Loss = 0.6808404326438904
Iteration [22742]: Loss = 0.6806995272636414
Iteration [22743]: Loss = 0.6805301904678345
Iteration [22744]: Loss = 0.6803355813026428
Iteration [22745]: Loss = 0.6801179647445679
Iteration [22746]: Loss = 0.679879903793335
Iteration [22747]: Loss = 0.6796232461929321
Iteration [22748]: Loss = 0.6793498992919922
Iteration [22749]: Loss = 5.058082580566406
Iteration [22750]: Loss = 0.6790345311164856
Iteration [22751]: Loss = 0.6789678335189819
Iteration [22752]: Loss = 0.6788654923439026
Iteration [22753]: Loss = 0.6787312626838684
Iteration [22754]: Loss = 0.6785683631896973
Iteration [22755]: Loss = 0.6783793568611145
Iteration [22756]: Loss = 0.6781671047210693
Iteration [22757]: Loss = 0.6779338717460632
Iteration [22758]: Loss = 0.6776817440986633
Iteration [22759]: Loss = 0.6774125099182129
Iteration [22760]: Loss = 0.6771280169487
Iteration [22761]: Loss = 0.676829993724823
Iteration [22762]: Loss = 0.6765192747116089
Iteration [22763]: Loss = 0.6761976480484009
Iteration [22764]: Loss = 0.6758660078048706
Iteration [22765]: Loss = 0.6755253672599792
Iteration [22766]: Loss = 0.6751765608787537
Iteration [22767]: Loss = 0.6748207807540894
Iteration [22768]: Loss = 0.6744583249092102
Iteration [22769]: Loss = 0.6740900278091431
Iteration [22770]: Loss = 0.6737165451049805
Iteration [22771]: Loss = 0.6733382344245911
Iteration [22772]: Loss = 0.6729559898376465
Iteration [22773]: Loss = 0.6725698709487915
Iteration [22774]: Loss = 0.6721804738044739
Iteration [22775]: Loss = 0.6717878580093384
Iteration [22776]: Loss = 0.6713926792144775
Iteration [22777]: Loss = 0.6709950566291809
Iteration [22778]: Loss = 0.6705952882766724
Iteration [22779]: Loss = 0.6701936721801758
Iteration [22780]: Loss = 0.6697902679443359
Iteration [22781]: Loss = 0.669402003288269
Iteration [22782]: Loss = 0.6690149903297424
Iteration [22783]: Loss = 0.6686266660690308
Iteration [22784]: Loss = 0.668237566947937
Iteration [22785]: Loss = 0.6678473353385925
Iteration [22786]: Loss = 5.122710704803467
Iteration [22787]: Loss = 0.6673297882080078
Iteration [22788]: Loss = 0.6671758890151978
Iteration [22789]: Loss = 0.6669977307319641
Iteration [22790]: Loss = 5.126434326171875
Iteration [22791]: Loss = 0.666841983795166
Iteration [22792]: Loss = 0.6668421030044556
Iteration [22793]: Loss = 0.6668026447296143
Iteration [22794]: Loss = 0.6667276620864868
Iteration [22795]: Loss = 0.6666204929351807
Iteration [22796]: Loss = 0.6664842963218689
Iteration [22797]: Loss = 0.6663221716880798
Iteration [22798]: Loss = 5.130175590515137
Iteration [22799]: Loss = 0.6661937832832336
Iteration [22800]: Loss = 0.6662057638168335
Iteration [22801]: Loss = 0.666176974773407
Iteration [22802]: Loss = 0.6661115884780884
Iteration [22803]: Loss = 5.130875587463379
Iteration [22804]: Loss = 0.6661482453346252
Iteration [22805]: Loss = 0.6662303805351257
Iteration [22806]: Loss = 0.6662648320198059
Iteration [22807]: Loss = 0.6662564873695374
Iteration [22808]: Loss = 0.6662093997001648
Iteration [22809]: Loss = 0.6661273837089539
Iteration [22810]: Loss = 0.6660141348838806
Iteration [22811]: Loss = 0.6658724546432495
Iteration [22812]: Loss = 0.6657055020332336
Iteration [22813]: Loss = 0.6655154824256897
Iteration [22814]: Loss = 0.6653050184249878
Iteration [22815]: Loss = 0.6650760173797607
Iteration [22816]: Loss = 0.664830207824707
Iteration [22817]: Loss = 0.664569616317749
Iteration [22818]: Loss = 0.6642954349517822
Iteration [22819]: Loss = 5.142258167266846
Iteration [22820]: Loss = 0.6639764308929443
Iteration [22821]: Loss = 5.14283561706543
Iteration [22822]: Loss = 0.6640698313713074
Iteration [22823]: Loss = 0.6641764640808105
Iteration [22824]: Loss = 0.6642330884933472
Iteration [22825]: Loss = 5.140916347503662
Iteration [22826]: Loss = 0.6644787192344666
Iteration [22827]: Loss = 0.6646500825881958
Iteration [22828]: Loss = 0.6647650599479675
Iteration [22829]: Loss = 0.6648291945457458
Iteration [22830]: Loss = 0.6648476719856262
Iteration [22831]: Loss = 0.6648247241973877
Iteration [22832]: Loss = 0.6647648215293884
Iteration [22833]: Loss = 0.6646713018417358
Iteration [22834]: Loss = 0.6645478010177612
Iteration [22835]: Loss = 0.6643971800804138
Iteration [22836]: Loss = 9.617868423461914
Iteration [22837]: Loss = 0.6645480394363403
Iteration [22838]: Loss = 0.6648026704788208
Iteration [22839]: Loss = 0.6649929285049438
Iteration [22840]: Loss = 0.6651254892349243
Iteration [22841]: Loss = 0.665205717086792
Iteration [22842]: Loss = 5.135265827178955
Iteration [22843]: Loss = 5.133842468261719
Iteration [22844]: Loss = 0.6659353375434875
Iteration [22845]: Loss = 5.129262447357178
Iteration [22846]: Loss = 0.6668431758880615
Iteration [22847]: Loss = 0.6672956347465515
Iteration [22848]: Loss = 0.6676642298698425
Iteration [22849]: Loss = 0.6679573059082031
Iteration [22850]: Loss = 0.6681820750236511
Iteration [22851]: Loss = 0.6683455109596252
Iteration [22852]: Loss = 0.668453574180603
Iteration [22853]: Loss = 0.6685118675231934
Iteration [22854]: Loss = 0.668525218963623
Iteration [22855]: Loss = 5.116837501525879
Iteration [22856]: Loss = 0.668693482875824
Iteration [22857]: Loss = 0.6688305735588074
Iteration [22858]: Loss = 0.6689146757125854
Iteration [22859]: Loss = 0.6689514517784119
Iteration [22860]: Loss = 5.11431884765625
Iteration [22861]: Loss = 9.557066917419434
Iteration [22862]: Loss = 0.6698218584060669
Iteration [22863]: Loss = 0.6703797578811646
Iteration [22864]: Loss = 5.103662490844727
Iteration [22865]: Loss = 0.6714768409729004
Iteration [22866]: Loss = 0.6720083951950073
Iteration [22867]: Loss = 0.6724485158920288
Iteration [22868]: Loss = 0.6728062033653259
Iteration [22869]: Loss = 0.6730896234512329
Iteration [22870]: Loss = 0.6733059287071228
Iteration [22871]: Loss = 0.6734618544578552
Iteration [22872]: Loss = 0.6735633611679077
Iteration [22873]: Loss = 0.6736158728599548
Iteration [22874]: Loss = 0.6736240386962891
Iteration [22875]: Loss = 0.6735925078392029
Iteration [22876]: Loss = 0.6735250949859619
Iteration [22877]: Loss = 0.6734254956245422
Iteration [22878]: Loss = 0.6732967495918274
Iteration [22879]: Loss = 0.6731419563293457
Iteration [22880]: Loss = 0.6729633808135986
Iteration [22881]: Loss = 0.6727637648582458
Iteration [22882]: Loss = 0.6725450158119202
Iteration [22883]: Loss = 0.6723092198371887
Iteration [22884]: Loss = 0.6720578670501709
Iteration [22885]: Loss = 0.6717926263809204
Iteration [22886]: Loss = 5.0999064445495605
Iteration [22887]: Loss = 0.6714829802513123
Iteration [22888]: Loss = 0.6714155077934265
Iteration [22889]: Loss = 0.671315610408783
Iteration [22890]: Loss = 0.6711869239807129
Iteration [22891]: Loss = 0.6710320711135864
Iteration [22892]: Loss = 0.670853853225708
Iteration [22893]: Loss = 0.6706544756889343
Iteration [22894]: Loss = 0.6704362034797668
Iteration [22895]: Loss = 0.6702006459236145
Iteration [22896]: Loss = 5.108675003051758
Iteration [22897]: Loss = 0.6699423789978027
Iteration [22898]: Loss = 0.6698969006538391
Iteration [22899]: Loss = 0.6698170900344849
Iteration [22900]: Loss = 0.669706404209137
Iteration [22901]: Loss = 0.669567883014679
Iteration [22902]: Loss = 0.6694043874740601
Iteration [22903]: Loss = 0.6692184209823608
Iteration [22904]: Loss = 0.6690121293067932
Iteration [22905]: Loss = 0.6687875390052795
Iteration [22906]: Loss = 0.6685466766357422
Iteration [22907]: Loss = 0.6682910323143005
Iteration [22908]: Loss = 0.6680219769477844
Iteration [22909]: Loss = 0.6677411198616028
Iteration [22910]: Loss = 0.667449414730072
Iteration [22911]: Loss = 0.6671481728553772
Iteration [22912]: Loss = 0.6668381094932556
Iteration [22913]: Loss = 0.666520357131958
Iteration [22914]: Loss = 0.6661955714225769
Iteration [22915]: Loss = 0.6658644676208496
Iteration [22916]: Loss = 0.6655277013778687
Iteration [22917]: Loss = 0.665185809135437
Iteration [22918]: Loss = 5.137535572052002
Iteration [22919]: Loss = 5.138055324554443
Iteration [22920]: Loss = 0.6648844480514526
Iteration [22921]: Loss = 0.6649690866470337
Iteration [22922]: Loss = 0.6650064587593079
Iteration [22923]: Loss = 0.6650017499923706
Iteration [22924]: Loss = 0.6649588346481323
Iteration [22925]: Loss = 0.664881706237793
Iteration [22926]: Loss = 0.6647735834121704
Iteration [22927]: Loss = 0.6646376848220825
Iteration [22928]: Loss = 0.664476752281189
Iteration [22929]: Loss = 5.1406402587890625
Iteration [22930]: Loss = 0.6643475890159607
Iteration [22931]: Loss = 0.6643580794334412
Iteration [22932]: Loss = 0.6643288135528564
Iteration [22933]: Loss = 0.6642639636993408
Iteration [22934]: Loss = 0.6641671061515808
Iteration [22935]: Loss = 0.6640413403511047
Iteration [22936]: Loss = 0.663889467716217
Iteration [22937]: Loss = 0.6637142300605774
Iteration [22938]: Loss = 0.6635178923606873
Iteration [22939]: Loss = 0.6633026003837585
Iteration [22940]: Loss = 0.6630701422691345
Iteration [22941]: Loss = 0.6628226041793823
Iteration [22942]: Loss = 0.6625608801841736
Iteration [22943]: Loss = 0.6622870564460754
Iteration [22944]: Loss = 5.153712749481201
Iteration [22945]: Loss = 0.6619657874107361
Iteration [22946]: Loss = 5.154325485229492
Iteration [22947]: Loss = 0.6620506048202515
Iteration [22948]: Loss = 0.6621525287628174
Iteration [22949]: Loss = 0.6622058153152466
Iteration [22950]: Loss = 0.6622154712677002
Iteration [22951]: Loss = 0.6621856689453125
Iteration [22952]: Loss = 0.6621204018592834
Iteration [22953]: Loss = 0.6620231866836548
Iteration [22954]: Loss = 0.6618973016738892
Iteration [22955]: Loss = 0.6617454290390015
Iteration [22956]: Loss = 0.6615703105926514
Iteration [22957]: Loss = 5.157306671142578
Iteration [22958]: Loss = 0.6614179611206055
Iteration [22959]: Loss = 0.6614188551902771
Iteration [22960]: Loss = 0.6613813638687134
Iteration [22961]: Loss = 0.6613091826438904
Iteration [22962]: Loss = 0.6612058281898499
Iteration [22963]: Loss = 0.6610744595527649
Iteration [22964]: Loss = 0.6609175801277161
Iteration [22965]: Loss = 0.6607380509376526
Iteration [22966]: Loss = 0.6605380177497864
Iteration [22967]: Loss = 5.163356781005859
Iteration [22968]: Loss = 0.6603434681892395
Iteration [22969]: Loss = 0.6603267192840576
Iteration [22970]: Loss = 0.6602733731269836
Iteration [22971]: Loss = 0.660186767578125
Iteration [22972]: Loss = 0.6600705981254578
Iteration [22973]: Loss = 0.6599277257919312
Iteration [22974]: Loss = 0.659760594367981
Iteration [22975]: Loss = 0.6595718264579773
Iteration [22976]: Loss = 0.6593636274337769
Iteration [22977]: Loss = 0.6591378450393677
Iteration [22978]: Loss = 5.171546936035156
Iteration [22979]: Loss = 0.65889972448349
Iteration [22980]: Loss = 0.6588646173477173
Iteration [22981]: Loss = 0.6587948799133301
Iteration [22982]: Loss = 9.686735153198242
Iteration [22983]: Loss = 0.6590768098831177
Iteration [22984]: Loss = 0.6593842506408691
Iteration [22985]: Loss = 0.6596232652664185
Iteration [22986]: Loss = 0.6598007082939148
Iteration [22987]: Loss = 0.6599223613739014
Iteration [22988]: Loss = 0.6599943041801453
Iteration [22989]: Loss = 0.6600210666656494
Iteration [22990]: Loss = 9.670295715332031
Iteration [22991]: Loss = 0.6604626178741455
Iteration [22992]: Loss = 5.160396099090576
Iteration [22993]: Loss = 0.6613848209381104
Iteration [22994]: Loss = 0.6618422269821167
Iteration [22995]: Loss = 0.6622170209884644
Iteration [22996]: Loss = 5.150769233703613
Iteration [22997]: Loss = 0.6630004048347473
Iteration [22998]: Loss = 5.145737648010254
Iteration [22999]: Loss = 0.6639696955680847
Iteration [23000]: Loss = 0.6644468903541565
Iteration [23001]: Loss = 0.6648391485214233
Iteration [23002]: Loss = 0.6651545763015747
Iteration [23003]: Loss = 0.6654012203216553
Iteration [23004]: Loss = 0.6655855178833008
Iteration [23005]: Loss = 0.6657137274742126
Iteration [23006]: Loss = 0.6657914519309998
Iteration [23007]: Loss = 0.6658235788345337
Iteration [23008]: Loss = 0.6658146977424622
Iteration [23009]: Loss = 0.6657689213752747
Iteration [23010]: Loss = 0.6656897664070129
Iteration [23011]: Loss = 0.665580689907074
Iteration [23012]: Loss = 5.134099006652832
Iteration [23013]: Loss = 0.6655367016792297
Iteration [23014]: Loss = 0.6655818819999695
Iteration [23015]: Loss = 0.6655847430229187
Iteration [23016]: Loss = 0.6655494570732117
Iteration [23017]: Loss = 5.133898735046387
Iteration [23018]: Loss = 5.133039474487305
Iteration [23019]: Loss = 0.6659811735153198
Iteration [23020]: Loss = 0.6662584543228149
Iteration [23021]: Loss = 0.666470468044281
Iteration [23022]: Loss = 0.6666236519813538
Iteration [23023]: Loss = 0.6667237281799316
Iteration [23024]: Loss = 0.6667760610580444
Iteration [23025]: Loss = 5.126504421234131
Iteration [23026]: Loss = 0.6670070886611938
Iteration [23027]: Loss = 0.6671691536903381
Iteration [23028]: Loss = 5.12372350692749
Iteration [23029]: Loss = 0.6675873398780823
Iteration [23030]: Loss = 0.6678290367126465
Iteration [23031]: Loss = 0.6680087447166443
Iteration [23032]: Loss = 0.6681328415870667
Iteration [23033]: Loss = 0.6682066321372986
Iteration [23034]: Loss = 5.118318557739258
Iteration [23035]: Loss = 5.116973400115967
Iteration [23036]: Loss = 0.668900728225708
Iteration [23037]: Loss = 5.112619400024414
Iteration [23038]: Loss = 5.109677791595459
Iteration [23039]: Loss = 0.6704529523849487
Iteration [23040]: Loss = 0.6710296273231506
Iteration [23041]: Loss = 0.671511173248291
Iteration [23042]: Loss = 0.6719074249267578
Iteration [23043]: Loss = 0.672226071357727
Iteration [23044]: Loss = 0.6724753379821777
Iteration [23045]: Loss = 0.6726616621017456
Iteration [23046]: Loss = 0.6727917194366455
Iteration [23047]: Loss = 0.6728705763816833
Iteration [23048]: Loss = 0.6729037761688232
Iteration [23049]: Loss = 5.092199802398682
Iteration [23050]: Loss = 0.6730995178222656
Iteration [23051]: Loss = 0.6732454895973206
Iteration [23052]: Loss = 0.6733387112617493
Iteration [23053]: Loss = 0.6733847856521606
Iteration [23054]: Loss = 0.6733881235122681
Iteration [23055]: Loss = 0.6733530759811401
Iteration [23056]: Loss = 0.6732832789421082
Iteration [23057]: Loss = 0.6731824278831482
Iteration [23058]: Loss = 0.6730535626411438
Iteration [23059]: Loss = 0.6728992462158203
Iteration [23060]: Loss = 5.093163967132568
Iteration [23061]: Loss = 0.6727755069732666
Iteration [23062]: Loss = 0.6727854013442993
Iteration [23063]: Loss = 0.6727561950683594
Iteration [23064]: Loss = 0.6726917624473572
Iteration [23065]: Loss = 0.672595739364624
Iteration [23066]: Loss = 0.6724711656570435
Iteration [23067]: Loss = 0.6723209619522095
Iteration [23068]: Loss = 0.6721476912498474
Iteration [23069]: Loss = 0.6719534993171692
Iteration [23070]: Loss = 0.6717405319213867
Iteration [23071]: Loss = 0.6715108752250671
Iteration [23072]: Loss = 0.6712659597396851
Iteration [23073]: Loss = 5.1027445793151855
Iteration [23074]: Loss = 0.6709882020950317
Iteration [23075]: Loss = 0.6709326505661011
Iteration [23076]: Loss = 0.6708446741104126
Iteration [23077]: Loss = 0.670727550983429
Iteration [23078]: Loss = 0.6705840229988098
Iteration [23079]: Loss = 0.6704168319702148
Iteration [23080]: Loss = 0.6702281832695007
Iteration [23081]: Loss = 0.6700204014778137
Iteration [23082]: Loss = 0.6697953939437866
Iteration [23083]: Loss = 0.6695547699928284
Iteration [23084]: Loss = 0.6693001985549927
Iteration [23085]: Loss = 0.6690329909324646
Iteration [23086]: Loss = 0.6687545776367188
Iteration [23087]: Loss = 0.6684659123420715
Iteration [23088]: Loss = 0.6681679487228394
Iteration [23089]: Loss = 0.667862057685852
Iteration [23090]: Loss = 0.6675485372543335
Iteration [23091]: Loss = 0.6672284603118896
Iteration [23092]: Loss = 0.666902482509613
Iteration [23093]: Loss = 0.6665711402893066
Iteration [23094]: Loss = 0.6662349104881287
Iteration [23095]: Loss = 0.6658943295478821
Iteration [23096]: Loss = 0.6655498743057251
Iteration [23097]: Loss = 0.6652020812034607
Iteration [23098]: Loss = 5.137467861175537
Iteration [23099]: Loss = 0.6647506356239319
Iteration [23100]: Loss = 5.138767719268799
Iteration [23101]: Loss = 0.6647215485572815
Iteration [23102]: Loss = 0.664773166179657
Iteration [23103]: Loss = 9.610941886901855
Iteration [23104]: Loss = 0.6652499437332153
Iteration [23105]: Loss = 0.665634274482727
Iteration [23106]: Loss = 0.6659431457519531
Iteration [23107]: Loss = 0.6661839485168457
Iteration [23108]: Loss = 0.6663634777069092
Iteration [23109]: Loss = 0.6664875745773315
Iteration [23110]: Loss = 0.666562020778656
Iteration [23111]: Loss = 0.666591465473175
Iteration [23112]: Loss = 0.6665805578231812
Iteration [23113]: Loss = 0.6665332317352295
Iteration [23114]: Loss = 0.6664531230926514
Iteration [23115]: Loss = 0.6663434505462646
Iteration [23116]: Loss = 0.6662071943283081
Iteration [23117]: Loss = 0.6660470366477966
Iteration [23118]: Loss = 0.6658653616905212
Iteration [23119]: Loss = 0.6656641960144043
Iteration [23120]: Loss = 0.6654455661773682
Iteration [23121]: Loss = 5.135422706604004
Iteration [23122]: Loss = 0.6652134656906128
Iteration [23123]: Loss = 9.60604476928711
Iteration [23124]: Loss = 0.6656031608581543
Iteration [23125]: Loss = 0.6659489274024963
Iteration [23126]: Loss = 0.6662235856056213
Iteration [23127]: Loss = 0.666433572769165
Iteration [23128]: Loss = 0.6665856242179871
Iteration [23129]: Loss = 0.6666854619979858
Iteration [23130]: Loss = 0.6667382121086121
Iteration [23131]: Loss = 0.666748583316803
Iteration [23132]: Loss = 0.6667206287384033
Iteration [23133]: Loss = 0.6666581630706787
Iteration [23134]: Loss = 0.6665648221969604
Iteration [23135]: Loss = 0.6664436459541321
Iteration [23136]: Loss = 0.6662971377372742
Iteration [23137]: Loss = 5.130224227905273
Iteration [23138]: Loss = 0.6661866903305054
Iteration [23139]: Loss = 0.6662023067474365
Iteration [23140]: Loss = 0.6661791801452637
Iteration [23141]: Loss = 0.666121244430542
Iteration [23142]: Loss = 0.6660317778587341
Iteration [23143]: Loss = 0.6659140586853027
Iteration [23144]: Loss = 0.6657708883285522
Iteration [23145]: Loss = 0.6656047701835632
Iteration [23146]: Loss = 0.6654179692268372
Iteration [23147]: Loss = 5.135415077209473
Iteration [23148]: Loss = 0.6652390956878662
Iteration [23149]: Loss = 0.6652257442474365
Iteration [23150]: Loss = 0.665176510810852
Iteration [23151]: Loss = 0.6650949716567993
Iteration [23152]: Loss = 0.6649844646453857
Iteration [23153]: Loss = 5.137486934661865
Iteration [23154]: Loss = 5.136987686157227
Iteration [23155]: Loss = 5.1353440284729
Iteration [23156]: Loss = 0.6656946539878845
Iteration [23157]: Loss = 5.130492687225342
Iteration [23158]: Loss = 0.6666366457939148
Iteration [23159]: Loss = 0.6671006679534912
Iteration [23160]: Loss = 5.122570514678955
Iteration [23161]: Loss = 0.6680325865745544
Iteration [23162]: Loss = 0.6684918403625488
Iteration [23163]: Loss = 0.6688686013221741
Iteration [23164]: Loss = 0.6691707372665405
Iteration [23165]: Loss = 0.6694056987762451
Iteration [23166]: Loss = 0.6695799827575684
Iteration [23167]: Loss = 0.6696997284889221
Iteration [23168]: Loss = 0.6697702407836914
Iteration [23169]: Loss = 0.6697964668273926
Iteration [23170]: Loss = 0.6697827577590942
Iteration [23171]: Loss = 0.6697329878807068
Iteration [23172]: Loss = 0.6696511507034302
Iteration [23173]: Loss = 0.6695398688316345
Iteration [23174]: Loss = 0.6694023609161377
Iteration [23175]: Loss = 0.669241189956665
Iteration [23176]: Loss = 0.6690588593482971
Iteration [23177]: Loss = 5.114814758300781
Iteration [23178]: Loss = 0.668886125087738
Iteration [23179]: Loss = 0.6688746809959412
Iteration [23180]: Loss = 0.6688271164894104
Iteration [23181]: Loss = 0.6687469482421875
Iteration [23182]: Loss = 0.6686375737190247
Iteration [23183]: Loss = 0.6685017347335815
Iteration [23184]: Loss = 0.6683420538902283
Iteration [23185]: Loss = 0.6681610941886902
Iteration [23186]: Loss = 0.6679607629776001
Iteration [23187]: Loss = 5.121092319488525
Iteration [23188]: Loss = 0.6677579283714294
Iteration [23189]: Loss = 0.667733907699585
Iteration [23190]: Loss = 0.6676750183105469
Iteration [23191]: Loss = 0.6675847768783569
Iteration [23192]: Loss = 0.6674661636352539
Iteration [23193]: Loss = 0.6673222780227661
Iteration [23194]: Loss = 0.6671553254127502
Iteration [23195]: Loss = 0.6669679880142212
Iteration [23196]: Loss = 5.126636981964111
Iteration [23197]: Loss = 0.6667870283126831
Iteration [23198]: Loss = 0.6667725443840027
Iteration [23199]: Loss = 0.666722297668457
Iteration [23200]: Loss = 0.6666399836540222
Iteration [23201]: Loss = 5.127957344055176
Iteration [23202]: Loss = 0.6666386127471924
Iteration [23203]: Loss = 0.6667006015777588
Iteration [23204]: Loss = 5.126878261566162
Iteration [23205]: Loss = 0.66694575548172
Iteration [23206]: Loss = 0.6671126484870911
Iteration [23207]: Loss = 0.6672257781028748
Iteration [23208]: Loss = 0.6672905683517456
Iteration [23209]: Loss = 0.6673116087913513
Iteration [23210]: Loss = 0.6672934293746948
Iteration [23211]: Loss = 0.6672396659851074
Iteration [23212]: Loss = 0.66715407371521
Iteration [23213]: Loss = 0.6670398116111755
Iteration [23214]: Loss = 0.6668997406959534
Iteration [23215]: Loss = 0.6667362451553345
Iteration [23216]: Loss = 0.6665518879890442
Iteration [23217]: Loss = 5.128974914550781
Iteration [23218]: Loss = 5.128816604614258
Iteration [23219]: Loss = 5.127485752105713
Iteration [23220]: Loss = 0.6670322418212891
Iteration [23221]: Loss = 0.6673740148544312
Iteration [23222]: Loss = 0.6676446795463562
Iteration [23223]: Loss = 5.120482444763184
Iteration [23224]: Loss = 0.6682462096214294
Iteration [23225]: Loss = 0.6685646772384644
Iteration [23226]: Loss = 0.6688143610954285
Iteration [23227]: Loss = 0.6690019369125366
Iteration [23228]: Loss = 0.669133722782135
Iteration [23229]: Loss = 0.669215202331543
Iteration [23230]: Loss = 0.6692511439323425
Iteration [23231]: Loss = 0.6692463159561157
Iteration [23232]: Loss = 0.6692046523094177
Iteration [23233]: Loss = 0.6691297292709351
Iteration [23234]: Loss = 0.6690250039100647
Iteration [23235]: Loss = 0.6688933968544006
Iteration [23236]: Loss = 0.668737530708313
Iteration [23237]: Loss = 0.6685600280761719
Iteration [23238]: Loss = 0.6683629155158997
Iteration [23239]: Loss = 0.6681479811668396
Iteration [23240]: Loss = 0.6679171919822693
Iteration [23241]: Loss = 0.6676721572875977
Iteration [23242]: Loss = 0.6674143075942993
Iteration [23243]: Loss = 5.124472618103027
Iteration [23244]: Loss = 0.6671132445335388
Iteration [23245]: Loss = 0.6670475006103516
Iteration [23246]: Loss = 5.125566005706787
Iteration [23247]: Loss = 0.6670746803283691
Iteration [23248]: Loss = 0.6671487092971802
Iteration [23249]: Loss = 0.6671781539916992
Iteration [23250]: Loss = 0.6671674251556396
Iteration [23251]: Loss = 0.6671206951141357
Iteration [23252]: Loss = 0.6670412421226501
Iteration [23253]: Loss = 0.6669324636459351
Iteration [23254]: Loss = 0.6667973399162292
Iteration [23255]: Loss = 0.6666383743286133
Iteration [23256]: Loss = 0.6664580702781677
Iteration [23257]: Loss = 0.6662584543228149
Iteration [23258]: Loss = 5.130713939666748
Iteration [23259]: Loss = 0.6660573482513428
Iteration [23260]: Loss = 0.666034460067749
Iteration [23261]: Loss = 0.6659765243530273
Iteration [23262]: Loss = 5.131587982177734
Iteration [23263]: Loss = 0.6660174131393433
Iteration [23264]: Loss = 0.6660975217819214
Iteration [23265]: Loss = 9.594265937805176
Iteration [23266]: Loss = 0.6666158437728882
Iteration [23267]: Loss = 0.6670145988464355
Iteration [23268]: Loss = 0.6673370599746704
Iteration [23269]: Loss = 0.6675905585289001
Iteration [23270]: Loss = 0.6677820086479187
Iteration [23271]: Loss = 0.6679175496101379
Iteration [23272]: Loss = 0.6680026054382324
Iteration [23273]: Loss = 0.6680423021316528
Iteration [23274]: Loss = 0.6680411100387573
Iteration [23275]: Loss = 5.119627475738525
Iteration [23276]: Loss = 0.6681767702102661
Iteration [23277]: Loss = 0.6682964563369751
Iteration [23278]: Loss = 0.668367326259613
Iteration [23279]: Loss = 0.6683940887451172
Iteration [23280]: Loss = 0.6683812141418457
Iteration [23281]: Loss = 0.668332576751709
Iteration [23282]: Loss = 5.118224143981934
Iteration [23283]: Loss = 0.6683874130249023
Iteration [23284]: Loss = 0.6684725880622864
Iteration [23285]: Loss = 0.668512225151062
Iteration [23286]: Loss = 5.116765022277832
Iteration [23287]: Loss = 5.115601062774658
Iteration [23288]: Loss = 0.6691107153892517
Iteration [23289]: Loss = 0.6694279313087463
Iteration [23290]: Loss = 0.6696766018867493
Iteration [23291]: Loss = 0.6698637008666992
Iteration [23292]: Loss = 0.669995129108429
Iteration [23293]: Loss = 0.6700764894485474
Iteration [23294]: Loss = 5.107760429382324
Iteration [23295]: Loss = 0.6703526377677917
Iteration [23296]: Loss = 0.6705316305160522
Iteration [23297]: Loss = 0.6706559062004089
Iteration [23298]: Loss = 0.6707307696342468
Iteration [23299]: Loss = 0.6707610487937927
Iteration [23300]: Loss = 0.67075115442276
Iteration [23301]: Loss = 0.670705258846283
Iteration [23302]: Loss = 0.6706268787384033
Iteration [23303]: Loss = 0.6705191731452942
Iteration [23304]: Loss = 0.6703850030899048
Iteration [23305]: Loss = 0.6702271699905396
Iteration [23306]: Loss = 0.6700479984283447
Iteration [23307]: Loss = 0.6698495745658875
Iteration [23308]: Loss = 0.6696336269378662
Iteration [23309]: Loss = 5.111749649047852
Iteration [23310]: Loss = 0.6694025993347168
Iteration [23311]: Loss = 0.6693660616874695
Iteration [23312]: Loss = 0.6692959666252136
Iteration [23313]: Loss = 0.6691957712173462
Iteration [23314]: Loss = 0.6690685153007507
Iteration [23315]: Loss = 0.6689168810844421
Iteration [23316]: Loss = 9.562170028686523
Iteration [23317]: Loss = 0.6690377593040466
Iteration [23318]: Loss = 0.6692664623260498
Iteration [23319]: Loss = 0.6694356799125671
Iteration [23320]: Loss = 0.6695511937141418
Iteration [23321]: Loss = 0.6696186661720276
Iteration [23322]: Loss = 0.6696425676345825
Iteration [23323]: Loss = 0.6696273684501648
Iteration [23324]: Loss = 0.66957688331604
Iteration [23325]: Loss = 0.6694946885108948
Iteration [23326]: Loss = 0.6693837642669678
Iteration [23327]: Loss = 0.6692472100257874
Iteration [23328]: Loss = 0.6690874099731445
Iteration [23329]: Loss = 0.6689066886901855
Iteration [23330]: Loss = 0.6687072515487671
Iteration [23331]: Loss = 0.6684908866882324
Iteration [23332]: Loss = 0.6682594418525696
Iteration [23333]: Loss = 0.6680140495300293
Iteration [23334]: Loss = 0.6677565574645996
Iteration [23335]: Loss = 0.6674878001213074
Iteration [23336]: Loss = 0.667209267616272
Iteration [23337]: Loss = 0.6669217348098755
Iteration [23338]: Loss = 0.6666260957717896
Iteration [23339]: Loss = 0.6663232445716858
Iteration [23340]: Loss = 0.6660138964653015
Iteration [23341]: Loss = 0.6656987071037292
Iteration [23342]: Loss = 0.6653783917427063
Iteration [23343]: Loss = 0.665053129196167
Iteration [23344]: Loss = 0.6647237539291382
Iteration [23345]: Loss = 0.6643906235694885
Iteration [23346]: Loss = 5.142001628875732
Iteration [23347]: Loss = 0.663960337638855
Iteration [23348]: Loss = 0.6638391017913818
Iteration [23349]: Loss = 0.6636935472488403
Iteration [23350]: Loss = 0.6635259389877319
Iteration [23351]: Loss = 0.6633383631706238
Iteration [23352]: Loss = 0.6631327867507935
Iteration [23353]: Loss = 0.6629112958908081
Iteration [23354]: Loss = 0.6626753211021423
Iteration [23355]: Loss = 0.662426233291626
Iteration [23356]: Loss = 5.152777671813965
Iteration [23357]: Loss = 0.6621400117874146
Iteration [23358]: Loss = 0.6620806455612183
Iteration [23359]: Loss = 5.153777122497559
Iteration [23360]: Loss = 0.6621183753013611
Iteration [23361]: Loss = 5.152597904205322
Iteration [23362]: Loss = 0.6624753475189209
Iteration [23363]: Loss = 0.6626898050308228
Iteration [23364]: Loss = 0.6628465056419373
Iteration [23365]: Loss = 0.6629509925842285
Iteration [23366]: Loss = 0.6630087494850159
Iteration [23367]: Loss = 0.6630241870880127
Iteration [23368]: Loss = 0.6630014181137085
Iteration [23369]: Loss = 0.6629445552825928
Iteration [23370]: Loss = 0.6628566980361938
Iteration [23371]: Loss = 0.6627411842346191
Iteration [23372]: Loss = 0.6626003980636597
Iteration [23373]: Loss = 5.151224136352539
Iteration [23374]: Loss = 0.6624991297721863
Iteration [23375]: Loss = 0.6625183820724487
Iteration [23376]: Loss = 5.150869369506836
Iteration [23377]: Loss = 0.662690281867981
Iteration [23378]: Loss = 0.662825882434845
Iteration [23379]: Loss = 0.6629114151000977
Iteration [23380]: Loss = 0.6629518866539001
Iteration [23381]: Loss = 0.6629518866539001
Iteration [23382]: Loss = 5.14849328994751
Iteration [23383]: Loss = 0.6630906462669373
Iteration [23384]: Loss = 0.6632120013237
Iteration [23385]: Loss = 0.6632846593856812
Iteration [23386]: Loss = 5.1462202072143555
Iteration [23387]: Loss = 5.144886493682861
Iteration [23388]: Loss = 0.6639653444290161
Iteration [23389]: Loss = 0.6643050312995911
Iteration [23390]: Loss = 5.139040470123291
Iteration [23391]: Loss = 0.6650236248970032
Iteration [23392]: Loss = 0.6653916835784912
Iteration [23393]: Loss = 0.6656869053840637
Iteration [23394]: Loss = 0.6659160256385803
Iteration [23395]: Loss = 0.6660858988761902
Iteration [23396]: Loss = 0.6662022471427917
Iteration [23397]: Loss = 0.6662703156471252
Iteration [23398]: Loss = 0.6662949323654175
Iteration [23399]: Loss = 0.6662804484367371
Iteration [23400]: Loss = 9.59305477142334
Iteration [23401]: Loss = 0.666633129119873
Iteration [23402]: Loss = 0.6669594645500183
Iteration [23403]: Loss = 0.667216956615448
Iteration [23404]: Loss = 0.667412519454956
Iteration [23405]: Loss = 0.6675522923469543
Iteration [23406]: Loss = 0.6676417589187622
Iteration [23407]: Loss = 0.667685866355896
Iteration [23408]: Loss = 0.6676890254020691
Iteration [23409]: Loss = 0.6676554083824158
Iteration [23410]: Loss = 0.6675888299942017
Iteration [23411]: Loss = 0.6674922108650208
Iteration [23412]: Loss = 0.6673687696456909
Iteration [23413]: Loss = 0.667221188545227
Iteration [23414]: Loss = 0.6670517921447754
Iteration [23415]: Loss = 0.666862964630127
Iteration [23416]: Loss = 0.6666563153266907
Iteration [23417]: Loss = 0.6664337515830994
Iteration [23418]: Loss = 0.6661970615386963
Iteration [23419]: Loss = 0.665947437286377
Iteration [23420]: Loss = 0.6656861901283264
Iteration [23421]: Loss = 0.6654147505760193
Iteration [23422]: Loss = 5.135862350463867
Iteration [23423]: Loss = 5.136122226715088
Iteration [23424]: Loss = 0.665253221988678
Iteration [23425]: Loss = 0.6653656363487244
Iteration [23426]: Loss = 5.134178638458252
Iteration [23427]: Loss = 5.132681369781494
Iteration [23428]: Loss = 0.6661372184753418
Iteration [23429]: Loss = 0.666499674320221
Iteration [23430]: Loss = 0.6667898297309875
Iteration [23431]: Loss = 0.6670148372650146
Iteration [23432]: Loss = 0.6671810746192932
Iteration [23433]: Loss = 0.6672942638397217
Iteration [23434]: Loss = 5.123257160186768
Iteration [23435]: Loss = 0.6676240563392639
Iteration [23436]: Loss = 0.6678256988525391
Iteration [23437]: Loss = 0.6679707169532776
Iteration [23438]: Loss = 5.119277477264404
Iteration [23439]: Loss = 0.6683548092842102
Iteration [23440]: Loss = 0.6685793399810791
Iteration [23441]: Loss = 5.1154465675354
Iteration [23442]: Loss = 0.6690987944602966
Iteration [23443]: Loss = 5.1118693351745605
Iteration [23444]: Loss = 0.6698390245437622
Iteration [23445]: Loss = 0.6702150702476501
Iteration [23446]: Loss = 0.6705173850059509
Iteration [23447]: Loss = 0.6707531213760376
Iteration [23448]: Loss = 0.6709288954734802
Iteration [23449]: Loss = 0.6710505485534668
Iteration [23450]: Loss = 0.671123743057251
Iteration [23451]: Loss = 0.6711527109146118
Iteration [23452]: Loss = 0.6711423397064209
Iteration [23453]: Loss = 0.6710962653160095
Iteration [23454]: Loss = 0.6710182428359985
Iteration [23455]: Loss = 0.6709113121032715
Iteration [23456]: Loss = 5.104028701782227
Iteration [23457]: Loss = 0.6708638072013855
Iteration [23458]: Loss = 0.6709043979644775
Iteration [23459]: Loss = 0.6709040403366089
Iteration [23460]: Loss = 0.6708671450614929
Iteration [23461]: Loss = 0.6707973480224609
Iteration [23462]: Loss = 0.6706978678703308
Iteration [23463]: Loss = 5.105186462402344
Iteration [23464]: Loss = 0.6706632971763611
Iteration [23465]: Loss = 0.6707091331481934
Iteration [23466]: Loss = 0.6707139015197754
Iteration [23467]: Loss = 0.6706814765930176
Iteration [23468]: Loss = 5.104940414428711
Iteration [23469]: Loss = 0.6707614660263062
Iteration [23470]: Loss = 5.103592395782471
Iteration [23471]: Loss = 0.6711457967758179
Iteration [23472]: Loss = 0.6713701486587524
Iteration [23473]: Loss = 0.6715354919433594
Iteration [23474]: Loss = 0.671647846698761
Iteration [23475]: Loss = 0.6717122793197632
Iteration [23476]: Loss = 0.6717337369918823
Iteration [23477]: Loss = 0.6717162728309631
Iteration [23478]: Loss = 0.6716638803482056
Iteration [23479]: Loss = 0.6715800762176514
Iteration [23480]: Loss = 0.6714679002761841
Iteration [23481]: Loss = 5.1009392738342285
Iteration [23482]: Loss = 0.6714114546775818
Iteration [23483]: Loss = 0.6714480519294739
Iteration [23484]: Loss = 0.6714442372322083
Iteration [23485]: Loss = 5.100526332855225
Iteration [23486]: Loss = 0.6715728640556335
Iteration [23487]: Loss = 0.6716881990432739
Iteration [23488]: Loss = 5.098562240600586
Iteration [23489]: Loss = 5.097082614898682
Iteration [23490]: Loss = 0.6724621057510376
Iteration [23491]: Loss = 0.6728236675262451
Iteration [23492]: Loss = 0.673112690448761
Iteration [23493]: Loss = 0.6733362674713135
Iteration [23494]: Loss = 0.6735009551048279
Iteration [23495]: Loss = 0.6736124753952026
Iteration [23496]: Loss = 0.6736763119697571
Iteration [23497]: Loss = 0.6736968755722046
Iteration [23498]: Loss = 0.6736786365509033
Iteration [23499]: Loss = 0.6736255288124084
Iteration [23500]: Loss = 0.6735408306121826
Iteration [23501]: Loss = 5.089234352111816
Iteration [23502]: Loss = 0.6735306978225708
Iteration [23503]: Loss = 0.6735866069793701
Iteration [23504]: Loss = 5.0882744789123535
Iteration [23505]: Loss = 0.6738165616989136
Iteration [23506]: Loss = 0.6755186319351196
Iteration [23507]: Loss = 5.090187072753906
Iteration [23508]: Loss = 0.6724801063537598
Iteration [23509]: Loss = 0.6777754426002502
Iteration [23510]: Loss = 0.6724870800971985
Iteration [23511]: Loss = 0.672684907913208
Iteration [23512]: Loss = 0.6727620959281921
Iteration [23513]: Loss = 0.6727309226989746
Iteration [23514]: Loss = 0.6726029515266418
Iteration [23515]: Loss = 5.079225540161133
Iteration [23516]: Loss = 0.6727321743965149
Iteration [23517]: Loss = 0.6746208071708679
Iteration [23518]: Loss = 0.6738216876983643
Iteration [23519]: Loss = 0.6734389066696167
Iteration [23520]: Loss = 0.674233615398407
Iteration [23521]: Loss = 0.6744243502616882
Iteration [23522]: Loss = 0.6748965978622437
Iteration [23523]: Loss = 0.6745086908340454
Iteration [23524]: Loss = 0.6752719879150391
Iteration [23525]: Loss = 5.075987339019775
Iteration [23526]: Loss = 0.6727880835533142
Iteration [23527]: Loss = 0.6726534366607666
Iteration [23528]: Loss = 0.6726561784744263
Iteration [23529]: Loss = 0.6725698709487915
Iteration [23530]: Loss = 5.100722312927246
Iteration [23531]: Loss = 0.670203447341919
Iteration [23532]: Loss = 0.6718817949295044
Iteration [23533]: Loss = 0.6720178723335266
Iteration [23534]: Loss = 0.6709616780281067
Iteration [23535]: Loss = 0.6709170937538147
Iteration [23536]: Loss = 0.6708404421806335
Iteration [23537]: Loss = 0.6685609817504883
Iteration [23538]: Loss = 0.668429970741272
Iteration [23539]: Loss = 0.6682755351066589
Iteration [23540]: Loss = 0.668100118637085
Iteration [23541]: Loss = 9.643942832946777
Iteration [23542]: Loss = 0.6724828481674194
Iteration [23543]: Loss = 0.6746383905410767
Iteration [23544]: Loss = 0.6745309829711914
Iteration [23545]: Loss = 0.6747837662696838
Iteration [23546]: Loss = 0.6753028631210327
Iteration [23547]: Loss = 0.6753644347190857
Iteration [23548]: Loss = 0.6753057241439819
Iteration [23549]: Loss = 5.079729080200195
Iteration [23550]: Loss = 0.679104208946228
Iteration [23551]: Loss = 0.6818735003471375
Iteration [23552]: Loss = 0.6935985684394836
Iteration [23553]: Loss = 0.6859121322631836
Iteration [23554]: Loss = 0.6831841468811035
Iteration [23555]: Loss = 0.6829957962036133
Iteration [23556]: Loss = 0.6827267408370972
Iteration [23557]: Loss = 0.6813248991966248
Iteration [23558]: Loss = 0.6739687919616699
Iteration [23559]: Loss = 0.6734873652458191
Iteration [23560]: Loss = 0.672930896282196
Iteration [23561]: Loss = 0.6723070740699768
Iteration [23562]: Loss = 9.517552375793457
Iteration [23563]: Loss = 0.6729750633239746
Iteration [23564]: Loss = 0.6734088063240051
Iteration [23565]: Loss = 5.087647914886475
Iteration [23566]: Loss = 0.674453616142273
Iteration [23567]: Loss = 0.6750357151031494
Iteration [23568]: Loss = 0.6754750609397888
Iteration [23569]: Loss = 0.6757853627204895
Iteration [23570]: Loss = 0.675979733467102
Iteration [23571]: Loss = 0.6760693788528442
Iteration [23572]: Loss = 0.6760647892951965
Iteration [23573]: Loss = 0.6759756803512573
Iteration [23574]: Loss = 5.0760087966918945
Iteration [23575]: Loss = 0.676127552986145
Iteration [23576]: Loss = 0.6763293147087097
Iteration [23577]: Loss = 0.6764270067214966
Iteration [23578]: Loss = 0.6764311790466309
Iteration [23579]: Loss = 0.6763510704040527
Iteration [23580]: Loss = 0.676194965839386
Iteration [23581]: Loss = 0.6759708523750305
Iteration [23582]: Loss = 5.0767011642456055
Iteration [23583]: Loss = 0.6758891940116882
Iteration [23584]: Loss = 0.6759899258613586
Iteration [23585]: Loss = 0.6759981513023376
Iteration [23586]: Loss = 0.6759229302406311
Iteration [23587]: Loss = 0.6757726669311523
Iteration [23588]: Loss = 0.6755549311637878
Iteration [23589]: Loss = 0.6752766370773315
Iteration [23590]: Loss = 5.080810546875
Iteration [23591]: Loss = 0.6750989556312561
Iteration [23592]: Loss = 0.6751574277877808
Iteration [23593]: Loss = 0.6751287579536438
Iteration [23594]: Loss = 0.6750215888023376
Iteration [23595]: Loss = 0.6748439073562622
Iteration [23596]: Loss = 0.6746025681495667
Iteration [23597]: Loss = 0.6743043065071106
Iteration [23598]: Loss = 0.6739548444747925
Iteration [23599]: Loss = 0.6735592484474182
Iteration [23600]: Loss = 5.090935707092285
Iteration [23601]: Loss = 0.6731796264648438
Iteration [23602]: Loss = 0.6731511354446411
Iteration [23603]: Loss = 0.6730455160140991
Iteration [23604]: Loss = 0.6728705763816833
Iteration [23605]: Loss = 5.093661308288574
Iteration [23606]: Loss = 0.6728624701499939
Iteration [23607]: Loss = 0.6729900240898132
Iteration [23608]: Loss = 0.6730257272720337
Iteration [23609]: Loss = 0.6729786992073059
Iteration [23610]: Loss = 0.6728573441505432
Iteration [23611]: Loss = 0.6726691126823425
Iteration [23612]: Loss = 0.6724207401275635
Iteration [23613]: Loss = 0.672118067741394
Iteration [23614]: Loss = 0.6717668771743774
Iteration [23615]: Loss = 5.100705623626709
Iteration [23616]: Loss = 0.6714568138122559
Iteration [23617]: Loss = 0.6714552044868469
Iteration [23618]: Loss = 0.6713757514953613
Iteration [23619]: Loss = 0.6712262034416199
Iteration [23620]: Loss = 0.671013593673706
Iteration [23621]: Loss = 5.104219436645508
Iteration [23622]: Loss = 0.6709365844726562
Iteration [23623]: Loss = 0.6710325479507446
Iteration [23624]: Loss = 0.6710416078567505
Iteration [23625]: Loss = 0.6709727644920349
Iteration [23626]: Loss = 0.6708335280418396
Iteration [23627]: Loss = 0.6706311106681824
Iteration [23628]: Loss = 0.6703717112541199
Iteration [23629]: Loss = 0.6700612902641296
Iteration [23630]: Loss = 0.669704794883728
Iteration [23631]: Loss = 0.6693070530891418
Iteration [23632]: Loss = 0.6689372658729553
Iteration [23633]: Loss = 0.6685530543327332
Iteration [23634]: Loss = 0.6681443452835083
Iteration [23635]: Loss = 0.6677135229110718
Iteration [23636]: Loss = 0.6674022674560547
Iteration [23637]: Loss = 0.6670863628387451
Iteration [23638]: Loss = 5.126648902893066
Iteration [23639]: Loss = 0.6667059063911438
Iteration [23640]: Loss = 0.6666151285171509
Iteration [23641]: Loss = 0.6664910316467285
Iteration [23642]: Loss = 5.129040241241455
Iteration [23643]: Loss = 0.6664377450942993
Iteration [23644]: Loss = 9.589908599853516
Iteration [23645]: Loss = 0.6670396327972412
Iteration [23646]: Loss = 0.6674968600273132
Iteration [23647]: Loss = 5.120393753051758
Iteration [23648]: Loss = 0.6684334874153137
Iteration [23649]: Loss = 0.6689022779464722
Iteration [23650]: Loss = 0.6692827939987183
Iteration [23651]: Loss = 0.6695838570594788
Iteration [23652]: Loss = 0.6698132753372192
Iteration [23653]: Loss = 0.6699782013893127
Iteration [23654]: Loss = 5.107916831970215
Iteration [23655]: Loss = 0.670414388179779
Iteration [23656]: Loss = 0.6706693768501282
Iteration [23657]: Loss = 0.6708573698997498
Iteration [23658]: Loss = 0.6709848642349243
Iteration [23659]: Loss = 0.671057939529419
Iteration [23660]: Loss = 0.6710817813873291
Iteration [23661]: Loss = 0.6710615158081055
Iteration [23662]: Loss = 0.6710015535354614
Iteration [23663]: Loss = 0.670905590057373
Iteration [23664]: Loss = 0.6707773804664612
Iteration [23665]: Loss = 0.6706199645996094
Iteration [23666]: Loss = 0.6704366207122803
Iteration [23667]: Loss = 0.6702297925949097
Iteration [23668]: Loss = 0.6700015068054199
Iteration [23669]: Loss = 0.6697542667388916
Iteration [23670]: Loss = 0.6694899201393127
Iteration [23671]: Loss = 9.556448936462402
Iteration [23672]: Loss = 0.6694663763046265
Iteration [23673]: Loss = 0.6696560382843018
Iteration [23674]: Loss = 0.6697853803634644
Iteration [23675]: Loss = 0.6698607802391052
Iteration [23676]: Loss = 0.669887363910675
Iteration [23677]: Loss = 0.6698698997497559
Iteration [23678]: Loss = 0.6698129177093506
Iteration [23679]: Loss = 5.1099629402160645
Iteration [23680]: Loss = 0.6698686480522156
Iteration [23681]: Loss = 0.6699608564376831
Iteration [23682]: Loss = 0.670002818107605
Iteration [23683]: Loss = 0.6699991822242737
Iteration [23684]: Loss = 0.6699545979499817
Iteration [23685]: Loss = 0.6698732376098633
Iteration [23686]: Loss = 0.669758677482605
Iteration [23687]: Loss = 0.6696142554283142
Iteration [23688]: Loss = 0.6694427728652954
Iteration [23689]: Loss = 0.6692472100257874
Iteration [23690]: Loss = 0.6690298318862915
Iteration [23691]: Loss = 0.6687929034233093
Iteration [23692]: Loss = 0.6685382127761841
Iteration [23693]: Loss = 5.118135452270508
Iteration [23694]: Loss = 0.6682569980621338
Iteration [23695]: Loss = 0.6682062149047852
Iteration [23696]: Loss = 0.6681192517280579
Iteration [23697]: Loss = 0.6679998636245728
Iteration [23698]: Loss = 0.6678509712219238
Iteration [23699]: Loss = 0.6676759123802185
Iteration [23700]: Loss = 0.6674769520759583
Iteration [23701]: Loss = 0.667256772518158
Iteration [23702]: Loss = 0.6670172810554504
Iteration [23703]: Loss = 0.6667605638504028
Iteration [23704]: Loss = 0.6664882302284241
Iteration [23705]: Loss = 5.129805564880371
Iteration [23706]: Loss = 0.6661776900291443
Iteration [23707]: Loss = 0.6661146879196167
Iteration [23708]: Loss = 0.6660167574882507
Iteration [23709]: Loss = 0.665887713432312
Iteration [23710]: Loss = 0.6657304167747498
Iteration [23711]: Loss = 0.6655476689338684
Iteration [23712]: Loss = 0.6653419733047485
Iteration [23713]: Loss = 0.6651158332824707
Iteration [23714]: Loss = 0.664871335029602
Iteration [23715]: Loss = 0.6646099090576172
Iteration [23716]: Loss = 5.140410423278809
Iteration [23717]: Loss = 0.6643185615539551
Iteration [23718]: Loss = 0.6642642021179199
Iteration [23719]: Loss = 5.141317844390869
Iteration [23720]: Loss = 0.664326012134552
Iteration [23721]: Loss = 0.6644216179847717
Iteration [23722]: Loss = 0.6644669771194458
Iteration [23723]: Loss = 5.139653205871582
Iteration [23724]: Loss = 0.6646988391876221
Iteration [23725]: Loss = 0.6648669242858887
Iteration [23726]: Loss = 5.136751651763916
Iteration [23727]: Loss = 0.6653080582618713
Iteration [23728]: Loss = 0.6655651330947876
Iteration [23729]: Loss = 0.6657557487487793
Iteration [23730]: Loss = 5.131591796875
Iteration [23731]: Loss = 0.6662351489067078
Iteration [23732]: Loss = 0.6665082573890686
Iteration [23733]: Loss = 0.6667133569717407
Iteration [23734]: Loss = 0.666857123374939
Iteration [23735]: Loss = 5.1255974769592285
Iteration [23736]: Loss = 0.6672559380531311
Iteration [23737]: Loss = 0.6674946546554565
Iteration [23738]: Loss = 9.575358390808105
Iteration [23739]: Loss = 0.668318510055542
Iteration [23740]: Loss = 0.6678371429443359
Iteration [23741]: Loss = 0.6682863831520081
Iteration [23742]: Loss = 0.6686505675315857
Iteration [23743]: Loss = 0.6689381003379822
Iteration [23744]: Loss = 5.113131046295166
Iteration [23745]: Loss = 0.6695802211761475
Iteration [23746]: Loss = 0.6699210405349731
Iteration [23747]: Loss = 0.670187771320343
Iteration [23748]: Loss = 0.6703872680664062
Iteration [23749]: Loss = 0.670526385307312
Iteration [23750]: Loss = 0.6706111431121826
Iteration [23751]: Loss = 0.670646607875824
Iteration [23752]: Loss = 5.1048150062561035
Iteration [23753]: Loss = 0.6708573698997498
Iteration [23754]: Loss = 0.6710144877433777
Iteration [23755]: Loss = 0.6711153984069824
Iteration [23756]: Loss = 0.6711655259132385
Iteration [23757]: Loss = 0.6711699962615967
Iteration [23758]: Loss = 5.102040767669678
Iteration [23759]: Loss = 0.6713275909423828
Iteration [23760]: Loss = 0.6714618802070618
Iteration [23761]: Loss = 0.671542227268219
Iteration [23762]: Loss = 0.67157381772995
Iteration [23763]: Loss = 0.6715616583824158
Iteration [23764]: Loss = 5.09993314743042
Iteration [23765]: Loss = 0.6716906428337097
Iteration [23766]: Loss = 5.09824275970459
Iteration [23767]: Loss = 0.672148585319519
Iteration [23768]: Loss = 0.6724106669425964
Iteration [23769]: Loss = 5.095076560974121
Iteration [23770]: Loss = 5.092167854309082
Iteration [23771]: Loss = 0.6737099289894104
Iteration [23772]: Loss = 0.6743770241737366
Iteration [23773]: Loss = 5.080962657928467
Iteration [23774]: Loss = 0.6757373809814453
Iteration [23775]: Loss = 5.072659492492676
Iteration [23776]: Loss = 0.6773581504821777
Iteration [23777]: Loss = 0.6781461238861084
Iteration [23778]: Loss = 0.6787951588630676
Iteration [23779]: Loss = 0.679318368434906
Iteration [23780]: Loss = 0.6797285676002502
Iteration [23781]: Loss = 5.052735328674316
Iteration [23782]: Loss = 0.6806449890136719
Iteration [23783]: Loss = 9.412344932556152
Iteration [23784]: Loss = 0.6822555661201477
Iteration [23785]: Loss = 5.03541374206543
Iteration [23786]: Loss = 5.029047012329102
Iteration [23787]: Loss = 0.6857478618621826
Iteration [23788]: Loss = 0.6869210600852966
Iteration [23789]: Loss = 5.0099382400512695
Iteration [23790]: Loss = 5.003446102142334
Iteration [23791]: Loss = 0.6905242204666138
Iteration [23792]: Loss = 0.6917238831520081
Iteration [23793]: Loss = 0.692746639251709
Iteration [23794]: Loss = 0.6936095952987671
Iteration [23795]: Loss = 0.6943280696868896
Iteration [23796]: Loss = 0.6949162483215332
Iteration [23797]: Loss = 0.6953870058059692
Iteration [23798]: Loss = 0.6957517862319946
Iteration [23799]: Loss = 4.966780185699463
Iteration [23800]: Loss = 0.6965731382369995
Iteration [23801]: Loss = 0.697011411190033
Iteration [23802]: Loss = 4.959793567657471
Iteration [23803]: Loss = 0.6979570388793945
Iteration [23804]: Loss = 0.6984476447105408
Iteration [23805]: Loss = 4.952003002166748
Iteration [23806]: Loss = 0.6994813680648804
Iteration [23807]: Loss = 0.7000088691711426
Iteration [23808]: Loss = 0.7004249691963196
Iteration [23809]: Loss = 0.7007408142089844
Iteration [23810]: Loss = 0.7009662389755249
Iteration [23811]: Loss = 4.940086364746094
Iteration [23812]: Loss = 0.7015453577041626
Iteration [23813]: Loss = 0.7018787860870361
Iteration [23814]: Loss = 0.702119767665863
Iteration [23815]: Loss = 0.7022780776023865
Iteration [23816]: Loss = 0.7023614645004272
Iteration [23817]: Loss = 0.7023776173591614
Iteration [23818]: Loss = 0.7023328542709351
Iteration [23819]: Loss = 0.7022335529327393
Iteration [23820]: Loss = 0.7020852565765381
Iteration [23821]: Loss = 0.7018924951553345
Iteration [23822]: Loss = 0.70166015625
Iteration [23823]: Loss = 4.93861722946167
Iteration [23824]: Loss = 0.7014576196670532
Iteration [23825]: Loss = 0.7014580965042114
Iteration [23826]: Loss = 0.7013998627662659
Iteration [23827]: Loss = 0.701288640499115
Iteration [23828]: Loss = 0.7011297345161438
Iteration [23829]: Loss = 0.7009280323982239
Iteration [23830]: Loss = 0.7006877660751343
Iteration [23831]: Loss = 4.943725109100342
Iteration [23832]: Loss = 0.7004714608192444
Iteration [23833]: Loss = 0.7004660367965698
Iteration [23834]: Loss = 0.7004026770591736
Iteration [23835]: Loss = 0.7002871632575989
Iteration [23836]: Loss = 0.7001248002052307
Iteration [23837]: Loss = 0.6999202966690063
Iteration [23838]: Loss = 0.6996777057647705
Iteration [23839]: Loss = 0.6994009613990784
Iteration [23840]: Loss = 0.6990935802459717
Iteration [23841]: Loss = 0.6987587213516235
Iteration [23842]: Loss = 0.6983988881111145
Iteration [23843]: Loss = 0.6980169415473938
Iteration [23844]: Loss = 0.6976149082183838
Iteration [23845]: Loss = 0.6971948742866516
Iteration [23846]: Loss = 0.6967589259147644
Iteration [23847]: Loss = 0.6963083744049072
Iteration [23848]: Loss = 0.6958449482917786
Iteration [23849]: Loss = 0.6953697800636292
Iteration [23850]: Loss = 0.6948843598365784
Iteration [23851]: Loss = 0.6943896412849426
Iteration [23852]: Loss = 0.6938866972923279
Iteration [23853]: Loss = 9.268182754516602
Iteration [23854]: Loss = 0.6935833692550659
Iteration [23855]: Loss = 0.6937134861946106
Iteration [23856]: Loss = 4.978667259216309
Iteration [23857]: Loss = 0.6941267251968384
Iteration [23858]: Loss = 0.6943880915641785
Iteration [23859]: Loss = 0.694567084312439
Iteration [23860]: Loss = 0.6946718096733093
Iteration [23861]: Loss = 0.6947097778320312
Iteration [23862]: Loss = 0.6946876049041748
Iteration [23863]: Loss = 0.6946110725402832
Iteration [23864]: Loss = 0.6944857835769653
Iteration [23865]: Loss = 0.694316565990448
Iteration [23866]: Loss = 0.6941078901290894
Iteration [23867]: Loss = 0.6938635110855103
Iteration [23868]: Loss = 0.6935873031616211
Iteration [23869]: Loss = 4.981278896331787
Iteration [23870]: Loss = 0.6933069229125977
Iteration [23871]: Loss = 0.6932730674743652
Iteration [23872]: Loss = 0.6931864023208618
Iteration [23873]: Loss = 0.6930522918701172
Iteration [23874]: Loss = 0.6928753852844238
Iteration [23875]: Loss = 0.6926599740982056
Iteration [23876]: Loss = 0.6924099922180176
Iteration [23877]: Loss = 0.6921287775039673
Iteration [23878]: Loss = 0.6918197274208069
Iteration [23879]: Loss = 0.6914852261543274
Iteration [23880]: Loss = 0.6911284327507019
Iteration [23881]: Loss = 0.6907511353492737
Iteration [23882]: Loss = 0.6903555393218994
Iteration [23883]: Loss = 0.6899436712265015
Iteration [23884]: Loss = 0.6895171403884888
Iteration [23885]: Loss = 0.6890771985054016
Iteration [23886]: Loss = 5.006145000457764
Iteration [23887]: Loss = 0.6885194778442383
Iteration [23888]: Loss = 0.6883683800697327
Iteration [23889]: Loss = 0.6881768107414246
Iteration [23890]: Loss = 0.6879487633705139
Iteration [23891]: Loss = 5.0111846923828125
Iteration [23892]: Loss = 0.6877519488334656
Iteration [23893]: Loss = 0.687754213809967
Iteration [23894]: Loss = 9.3345308303833
Iteration [23895]: Loss = 0.6882911324501038
Iteration [23896]: Loss = 0.6887688040733337
Iteration [23897]: Loss = 0.6891447305679321
Iteration [23898]: Loss = 0.6894286870956421
Iteration [23899]: Loss = 0.6896300911903381
Iteration [23900]: Loss = 0.6897569894790649
Iteration [23901]: Loss = 0.6898165941238403
Iteration [23902]: Loss = 0.6898157596588135
Iteration [23903]: Loss = 0.6897604465484619
Iteration [23904]: Loss = 0.6896560192108154
Iteration [23905]: Loss = 0.6895074248313904
Iteration [23906]: Loss = 0.6893192529678345
Iteration [23907]: Loss = 0.6890952587127686
Iteration [23908]: Loss = 0.6888388395309448
Iteration [23909]: Loss = 0.6885536909103394
Iteration [23910]: Loss = 0.6882425546646118
Iteration [23911]: Loss = 5.010001182556152
Iteration [23912]: Loss = 0.6878999471664429
Iteration [23913]: Loss = 0.6878384947776794
Iteration [23914]: Loss = 0.6877288222312927
Iteration [23915]: Loss = 0.6875758171081543
Iteration [23916]: Loss = 0.6873837113380432
Iteration [23917]: Loss = 0.687156617641449
Iteration [23918]: Loss = 0.6868977546691895
Iteration [23919]: Loss = 0.6866105198860168
Iteration [23920]: Loss = 0.6862977743148804
Iteration [23921]: Loss = 0.6859620213508606
Iteration [23922]: Loss = 0.6856057047843933
Iteration [23923]: Loss = 5.024446487426758
Iteration [23924]: Loss = 0.6851866841316223
Iteration [23925]: Loss = 0.6850931644439697
Iteration [23926]: Loss = 5.025939464569092
Iteration [23927]: Loss = 0.6851222515106201
Iteration [23928]: Loss = 0.6852191686630249
Iteration [23929]: Loss = 0.6852525472640991
Iteration [23930]: Loss = 0.685228705406189
Iteration [23931]: Loss = 0.6851533651351929
Iteration [23932]: Loss = 0.6850317120552063
Iteration [23933]: Loss = 0.6848684549331665
Iteration [23934]: Loss = 0.6846673488616943
Iteration [23935]: Loss = 5.0287699699401855
Iteration [23936]: Loss = 0.6845130920410156
Iteration [23937]: Loss = 0.6845318675041199
Iteration [23938]: Loss = 0.6844950914382935
Iteration [23939]: Loss = 5.028902530670166
Iteration [23940]: Loss = 0.6846206784248352
Iteration [23941]: Loss = 0.6847582459449768
Iteration [23942]: Loss = 0.6848285794258118
Iteration [23943]: Loss = 0.6848382353782654
Iteration [23944]: Loss = 0.6847934722900391
Iteration [23945]: Loss = 0.6846994161605835
Iteration [23946]: Loss = 13.71509838104248
Iteration [23947]: Loss = 0.685379683971405
Iteration [23948]: Loss = 0.6860658526420593
Iteration [23949]: Loss = 0.6866323947906494
Iteration [23950]: Loss = 0.6870912909507751
Iteration [23951]: Loss = 0.6874527335166931
Iteration [23952]: Loss = 0.6877266764640808
Iteration [23953]: Loss = 0.6879215240478516
Iteration [23954]: Loss = 0.6880452632904053
Iteration [23955]: Loss = 0.6881046891212463
Iteration [23956]: Loss = 5.008934497833252
Iteration [23957]: Loss = 0.6883858442306519
Iteration [23958]: Loss = 5.006357669830322
Iteration [23959]: Loss = 0.6890429258346558
Iteration [23960]: Loss = 0.6894026398658752
Iteration [23961]: Loss = 0.6896749138832092
Iteration [23962]: Loss = 4.999481678009033
Iteration [23963]: Loss = 0.6903185844421387
Iteration [23964]: Loss = 0.6906723976135254
Iteration [23965]: Loss = 0.6909393668174744
Iteration [23966]: Loss = 0.6911278367042542
Iteration [23967]: Loss = 0.6912456154823303
Iteration [23968]: Loss = 0.6912997961044312
Iteration [23969]: Loss = 0.6912965774536133
Iteration [23970]: Loss = 0.6912416815757751
Iteration [23971]: Loss = 0.6911404132843018
Iteration [23972]: Loss = 0.6909971833229065
Iteration [23973]: Loss = 0.6908162832260132
Iteration [23974]: Loss = 0.6906012892723083
Iteration [23975]: Loss = 0.6903560161590576
Iteration [23976]: Loss = 4.998331546783447
Iteration [23977]: Loss = 0.6901155710220337
Iteration [23978]: Loss = 0.6900929808616638
Iteration [23979]: Loss = 0.690020740032196
Iteration [23980]: Loss = 0.6899038553237915
Iteration [23981]: Loss = 0.6897468566894531
Iteration [23982]: Loss = 0.6895536184310913
Iteration [23983]: Loss = 5.002377510070801
Iteration [23984]: Loss = 0.6894022822380066
Iteration [23985]: Loss = 5.001895904541016
Iteration [23986]: Loss = 0.6897075772285461
Iteration [23987]: Loss = 0.6899171471595764
Iteration [23988]: Loss = 0.6900542378425598
Iteration [23989]: Loss = 0.6901261210441589
Iteration [23990]: Loss = 0.6901389360427856
Iteration [23991]: Loss = 0.6900989413261414
Iteration [23992]: Loss = 0.6900110840797424
Iteration [23993]: Loss = 0.6898802518844604
Iteration [23994]: Loss = 0.6897107362747192
Iteration [23995]: Loss = 0.689506471157074
Iteration [23996]: Loss = 0.6892707347869873
Iteration [23997]: Loss = 0.6890069246292114
Iteration [23998]: Loss = 0.6887176632881165
Iteration [23999]: Loss = 0.6884057521820068
Iteration [24000]: Loss = 0.6880731582641602
Iteration [24001]: Loss = 0.6877223253250122
Iteration [24002]: Loss = 0.6873547434806824
Iteration [24003]: Loss = 0.6869723796844482
Iteration [24004]: Loss = 0.6865766644477844
Iteration [24005]: Loss = 5.019373416900635
Iteration [24006]: Loss = 0.686080813407898
Iteration [24007]: Loss = 0.6859500408172607
Iteration [24008]: Loss = 0.6857807636260986
Iteration [24009]: Loss = 0.6855772733688354
Iteration [24010]: Loss = 0.6853424310684204
Iteration [24011]: Loss = 0.6850798726081848
Iteration [24012]: Loss = 0.6847919821739197
Iteration [24013]: Loss = 5.028504848480225
Iteration [24014]: Loss = 0.6844806671142578
Iteration [24015]: Loss = 0.6844286918640137
Iteration [24016]: Loss = 0.6843305230140686
Iteration [24017]: Loss = 9.375970840454102
Iteration [24018]: Loss = 0.6846651434898376
Iteration [24019]: Loss = 0.685041606426239
Iteration [24020]: Loss = 0.6853300929069519
Iteration [24021]: Loss = 0.6855394244194031
Iteration [24022]: Loss = 0.6856772303581238
Iteration [24023]: Loss = 0.6857506036758423
Iteration [24024]: Loss = 5.021551132202148
Iteration [24025]: Loss = 0.6860530972480774
Iteration [24026]: Loss = 0.6862611770629883
Iteration [24027]: Loss = 0.6863977909088135
Iteration [24028]: Loss = 0.686470091342926
Iteration [24029]: Loss = 0.6864845752716064
Iteration [24030]: Loss = 0.6864467859268188
Iteration [24031]: Loss = 0.6863621473312378
Iteration [24032]: Loss = 0.6862351298332214
Iteration [24033]: Loss = 0.6860700249671936
Iteration [24034]: Loss = 0.6858706474304199
Iteration [24035]: Loss = 5.0222296714782715
Iteration [24036]: Loss = 5.012022495269775
Iteration [24037]: Loss = 0.6860392689704895
Iteration [24038]: Loss = 0.686287522315979
Iteration [24039]: Loss = 0.6864604949951172
Iteration [24040]: Loss = 0.6865657567977905
Iteration [24041]: Loss = 0.6866098046302795
Iteration [24042]: Loss = 0.6865989565849304
Iteration [24043]: Loss = 0.686538577079773
Iteration [24044]: Loss = 0.6864333748817444
Iteration [24045]: Loss = 0.6862879991531372
Iteration [24046]: Loss = 0.6861065030097961
Iteration [24047]: Loss = 0.6858924031257629
Iteration [24048]: Loss = 0.6856489777565002
Iteration [24049]: Loss = 0.6853792071342468
Iteration [24050]: Loss = 0.6850857138633728
Iteration [24051]: Loss = 0.6847710013389587
Iteration [24052]: Loss = 0.6844369769096375
Iteration [24053]: Loss = 0.6840857267379761
Iteration [24054]: Loss = 0.6837191581726074
Iteration [24055]: Loss = 0.6833385229110718
Iteration [24056]: Loss = 0.6829453706741333
Iteration [24057]: Loss = 0.6825410723686218
Iteration [24058]: Loss = 0.6821267604827881
Iteration [24059]: Loss = 0.6817034482955933
Iteration [24060]: Loss = 0.6812719702720642
Iteration [24061]: Loss = 0.6808331608772278
Iteration [24062]: Loss = 5.050809383392334
Iteration [24063]: Loss = 0.6802635192871094
Iteration [24064]: Loss = 0.680101215839386
Iteration [24065]: Loss = 0.6799049377441406
Iteration [24066]: Loss = 0.6796779632568359
Iteration [24067]: Loss = 0.6794235110282898
Iteration [24068]: Loss = 0.6791443228721619
Iteration [24069]: Loss = 0.6788426637649536
Iteration [24070]: Loss = 0.6785210967063904
Iteration [24071]: Loss = 0.6781814694404602
Iteration [24072]: Loss = 0.6778256297111511
Iteration [24073]: Loss = 0.6774553060531616
Iteration [24074]: Loss = 0.6770718693733215
Iteration [24075]: Loss = 0.6766766309738159
Iteration [24076]: Loss = 0.6762709021568298
Iteration [24077]: Loss = 0.6758557558059692
Iteration [24078]: Loss = 5.078103542327881
Iteration [24079]: Loss = 0.6753280758857727
Iteration [24080]: Loss = 0.6751847267150879
Iteration [24081]: Loss = 0.6750057935714722
Iteration [24082]: Loss = 0.6747947335243225
Iteration [24083]: Loss = 0.6745550036430359
Iteration [24084]: Loss = 0.6742894649505615
Iteration [24085]: Loss = 0.6740005016326904
Iteration [24086]: Loss = 0.6736905574798584
Iteration [24087]: Loss = 5.089601516723633
Iteration [24088]: Loss = 0.6733433604240417
Iteration [24089]: Loss = 0.6732770204544067
Iteration [24090]: Loss = 0.6731674671173096
Iteration [24091]: Loss = 0.6730194091796875
Iteration [24092]: Loss = 0.6728362441062927
Iteration [24093]: Loss = 0.6726218461990356
Iteration [24094]: Loss = 5.095078468322754
Iteration [24095]: Loss = 0.6724375486373901
Iteration [24096]: Loss = 0.672440767288208
Iteration [24097]: Loss = 0.6723940372467041
Iteration [24098]: Loss = 0.6723023653030396
Iteration [24099]: Loss = 0.6721703410148621
Iteration [24100]: Loss = 0.6720019578933716
Iteration [24101]: Loss = 0.6718007326126099
Iteration [24102]: Loss = 0.6715700626373291
Iteration [24103]: Loss = 0.6713128089904785
Iteration [24104]: Loss = 0.6710317134857178
Iteration [24105]: Loss = 5.10430383682251
Iteration [24106]: Loss = 0.6707344651222229
Iteration [24107]: Loss = 0.6706897020339966
Iteration [24108]: Loss = 0.6706001162528992
Iteration [24109]: Loss = 5.105757236480713
Iteration [24110]: Loss = 0.6733558177947998
Iteration [24111]: Loss = 0.6734498739242554
Iteration [24112]: Loss = 0.6734849810600281
Iteration [24113]: Loss = 5.089015960693359
Iteration [24114]: Loss = 0.6737263798713684
Iteration [24115]: Loss = 0.6739103198051453
Iteration [24116]: Loss = 0.6740264892578125
Iteration [24117]: Loss = 0.6740815043449402
Iteration [24118]: Loss = 0.6740812659263611
Iteration [24119]: Loss = 0.6740315556526184
Iteration [24120]: Loss = 0.6739369630813599
Iteration [24121]: Loss = 0.6738021969795227
Iteration [24122]: Loss = 0.6736311912536621
Iteration [24123]: Loss = 0.6734276413917542
Iteration [24124]: Loss = 0.6731946468353271
Iteration [24125]: Loss = 0.6729353666305542
Iteration [24126]: Loss = 0.6726523041725159
Iteration [24127]: Loss = 0.6723477840423584
Iteration [24128]: Loss = 0.672024130821228
Iteration [24129]: Loss = 0.6716830730438232
Iteration [24130]: Loss = 0.671326756477356
Iteration [24131]: Loss = 0.6709563136100769
Iteration [24132]: Loss = 0.6705734729766846
Iteration [24133]: Loss = 0.6701793074607849
Iteration [24134]: Loss = 0.6697749495506287
Iteration [24135]: Loss = 0.6693615913391113
Iteration [24136]: Loss = 0.6689401268959045
Iteration [24137]: Loss = 0.6685114502906799
Iteration [24138]: Loss = 0.6680761575698853
Iteration [24139]: Loss = 0.6676350235939026
Iteration [24140]: Loss = 0.6671886444091797
Iteration [24141]: Loss = 0.6667376160621643
Iteration [24142]: Loss = 5.129350185394287
Iteration [24143]: Loss = 0.6661521792411804
Iteration [24144]: Loss = 5.13102912902832
Iteration [24145]: Loss = 0.666114330291748
Iteration [24146]: Loss = 5.129924774169922
Iteration [24147]: Loss = 0.6665176153182983
Iteration [24148]: Loss = 0.6667718887329102
Iteration [24149]: Loss = 0.6669518947601318
Iteration [24150]: Loss = 0.6670649647712708
Iteration [24151]: Loss = 5.124625205993652
Iteration [24152]: Loss = 0.6674414873123169
Iteration [24153]: Loss = 0.6676840782165527
Iteration [24154]: Loss = 0.667853593826294
Iteration [24155]: Loss = 0.6679573059082031
Iteration [24156]: Loss = 0.6680014133453369
Iteration [24157]: Loss = 0.6679921746253967
Iteration [24158]: Loss = 0.6679346561431885
Iteration [24159]: Loss = 0.6678338050842285
Iteration [24160]: Loss = 5.121372222900391
Iteration [24161]: Loss = 0.6678447127342224
Iteration [24162]: Loss = 5.120030879974365
Iteration [24163]: Loss = 0.668285071849823
Iteration [24164]: Loss = 0.6685547828674316
Iteration [24165]: Loss = 0.6687486171722412
Iteration [24166]: Loss = 0.6688740253448486
Iteration [24167]: Loss = 0.6689378619194031
Iteration [24168]: Loss = 0.6689465045928955
Iteration [24169]: Loss = 0.6689050197601318
Iteration [24170]: Loss = 0.6688185930252075
Iteration [24171]: Loss = 0.6686916351318359
Iteration [24172]: Loss = 0.6685282588005066
Iteration [24173]: Loss = 0.6683319211006165
Iteration [24174]: Loss = 0.6681062579154968
Iteration [24175]: Loss = 0.6678539514541626
Iteration [24176]: Loss = 0.6675776243209839
Iteration [24177]: Loss = 0.6672798991203308
Iteration [24178]: Loss = 0.6669628024101257
Iteration [24179]: Loss = 0.6666283011436462
Iteration [24180]: Loss = 0.6662782430648804
Iteration [24181]: Loss = 0.6659139394760132
Iteration [24182]: Loss = 0.6655371785163879
Iteration [24183]: Loss = 0.6651491522789001
Iteration [24184]: Loss = 0.664750874042511
Iteration [24185]: Loss = 0.6643434166908264
Iteration [24186]: Loss = 5.142721176147461
Iteration [24187]: Loss = 0.6638326048851013
Iteration [24188]: Loss = 0.663698136806488
Iteration [24189]: Loss = 0.6635284423828125
Iteration [24190]: Loss = 0.6633267402648926
Iteration [24191]: Loss = 0.6631302833557129
Iteration [24192]: Loss = 0.6629269123077393
Iteration [24193]: Loss = 0.6627050638198853
Iteration [24194]: Loss = 5.151055812835693
Iteration [24195]: Loss = 0.6624734401702881
Iteration [24196]: Loss = 9.639965057373047
Iteration [24197]: Loss = 0.6608226895332336
Iteration [24198]: Loss = 5.158580780029297
Iteration [24199]: Loss = 0.6617227792739868
Iteration [24200]: Loss = 0.6621891260147095
Iteration [24201]: Loss = 0.6625610589981079
Iteration [24202]: Loss = 0.6628478169441223
Iteration [24203]: Loss = 0.663057804107666
Iteration [24204]: Loss = 0.663198709487915
Iteration [24205]: Loss = 0.663277268409729
Iteration [24206]: Loss = 5.146299839019775
Iteration [24207]: Loss = 0.6635948419570923
Iteration [24208]: Loss = 0.6638122797012329
Iteration [24209]: Loss = 0.6639599800109863
Iteration [24210]: Loss = 0.6640445590019226
Iteration [24211]: Loss = 0.6640723943710327
Iteration [24212]: Loss = 0.6640492677688599
Iteration [24213]: Loss = 0.6620064973831177
Iteration [24214]: Loss = 0.6618961691856384
Iteration [24215]: Loss = 0.6617486476898193
Iteration [24216]: Loss = 0.6615675687789917
Iteration [24217]: Loss = 0.661356508731842
Iteration [24218]: Loss = 0.6611182689666748
Iteration [24219]: Loss = 5.160279750823975
Iteration [24220]: Loss = 0.659721851348877
Iteration [24221]: Loss = 0.6596742868423462
Iteration [24222]: Loss = 0.659547746181488
Iteration [24223]: Loss = 0.6593903303146362
Iteration [24224]: Loss = 0.6592515707015991
Iteration [24225]: Loss = 0.6590786576271057
Iteration [24226]: Loss = 0.6588749289512634
Iteration [24227]: Loss = 0.6586436629295349
Iteration [24228]: Loss = 0.6583876013755798
Iteration [24229]: Loss = 14.212045669555664
Iteration [24230]: Loss = 0.6587609648704529
Iteration [24231]: Loss = 0.6593019962310791
Iteration [24232]: Loss = 0.6586964130401611
Iteration [24233]: Loss = 0.6590459942817688
Iteration [24234]: Loss = 0.6593145132064819
Iteration [24235]: Loss = 0.6595099568367004
Iteration [24236]: Loss = 0.6596392393112183
Iteration [24237]: Loss = 0.6597093343734741
Iteration [24238]: Loss = 0.6597258448600769
Iteration [24239]: Loss = 0.659694254398346
Iteration [24240]: Loss = 0.659619152545929
Iteration [24241]: Loss = 0.6595050096511841
Iteration [24242]: Loss = 0.6593557596206665
Iteration [24243]: Loss = 5.169941425323486
Iteration [24244]: Loss = 5.169336318969727
Iteration [24245]: Loss = 0.659640908241272
Iteration [24246]: Loss = 0.659919798374176
Iteration [24247]: Loss = 0.6601245999336243
Iteration [24248]: Loss = 0.6602625846862793
Iteration [24249]: Loss = 0.6603402495384216
Iteration [24250]: Loss = 0.6603636741638184
Iteration [24251]: Loss = 0.6603381633758545
Iteration [24252]: Loss = 9.66702938079834
Iteration [24253]: Loss = 0.6607805490493774
Iteration [24254]: Loss = 0.661195695400238
Iteration [24255]: Loss = 0.6615235805511475
Iteration [24256]: Loss = 0.6617727279663086
Iteration [24257]: Loss = 5.154003143310547
Iteration [24258]: Loss = 0.6623744964599609
Iteration [24259]: Loss = 5.149665832519531
Iteration [24260]: Loss = 5.146446228027344
Iteration [24261]: Loss = 0.6640429496765137
Iteration [24262]: Loss = 0.664689838886261
Iteration [24263]: Loss = 0.6652265191078186
Iteration [24264]: Loss = 0.6656636595726013
Iteration [24265]: Loss = 0.6660112738609314
Iteration [24266]: Loss = 0.6662778854370117
Iteration [24267]: Loss = 0.6664717197418213
Iteration [24268]: Loss = 5.127553939819336
Iteration [24269]: Loss = 0.6669768691062927
Iteration [24270]: Loss = 0.6672700643539429
Iteration [24271]: Loss = 0.6674878001213074
Iteration [24272]: Loss = 0.6676375269889832
Iteration [24273]: Loss = 0.6677257418632507
Iteration [24274]: Loss = 0.6677586436271667
Iteration [24275]: Loss = 0.6677418351173401
Iteration [24276]: Loss = 0.6676800847053528
Iteration [24277]: Loss = 5.122025489807129
Iteration [24278]: Loss = 0.6677483916282654
Iteration [24279]: Loss = 0.6678553819656372
Iteration [24280]: Loss = 0.6679051518440247
Iteration [24281]: Loss = 0.6679036617279053
Iteration [24282]: Loss = 5.120458126068115
Iteration [24283]: Loss = 0.6680744290351868
Iteration [24284]: Loss = 0.6682249903678894
Iteration [24285]: Loss = 0.6683140397071838
Iteration [24286]: Loss = 0.6683478355407715
Iteration [24287]: Loss = 0.6683316230773926
Iteration [24288]: Loss = 0.6682705283164978
Iteration [24289]: Loss = 0.668168842792511
Iteration [24290]: Loss = 0.6680305600166321
Iteration [24291]: Loss = 5.12043571472168
Iteration [24292]: Loss = 5.119822978973389
Iteration [24293]: Loss = 5.117798328399658
Iteration [24294]: Loss = 0.6689110994338989
Iteration [24295]: Loss = 0.6693904399871826
Iteration [24296]: Loss = 0.669775664806366
Iteration [24297]: Loss = 0.6700762510299683
Iteration [24298]: Loss = 0.6703004837036133
Iteration [24299]: Loss = 0.6704556345939636
Iteration [24300]: Loss = 0.6705488562583923
Iteration [24301]: Loss = 0.6705861687660217
Iteration [24302]: Loss = 5.105179309844971
Iteration [24303]: Loss = 0.6708221435546875
Iteration [24304]: Loss = 0.6710000038146973
Iteration [24305]: Loss = 0.6711134910583496
Iteration [24306]: Loss = 0.6711689829826355
Iteration [24307]: Loss = 0.6711723208427429
Iteration [24308]: Loss = 5.102067947387695
Iteration [24309]: Loss = 0.6713501214981079
Iteration [24310]: Loss = 5.099973201751709
Iteration [24311]: Loss = 0.6719005107879639
Iteration [24312]: Loss = 0.6722121238708496
Iteration [24313]: Loss = 5.094705104827881
Iteration [24314]: Loss = 0.6729161143302917
Iteration [24315]: Loss = 0.6732929348945618
Iteration [24316]: Loss = 0.6735855340957642
Iteration [24317]: Loss = 0.6738024353981018
Iteration [24318]: Loss = 5.086324691772461
Iteration [24319]: Loss = 0.6743437647819519
Iteration [24320]: Loss = 0.6746509075164795
Iteration [24321]: Loss = 5.081160068511963
Iteration [24322]: Loss = 0.6753464937210083
Iteration [24323]: Loss = 0.6757190823554993
Iteration [24324]: Loss = 0.6760079860687256
Iteration [24325]: Loss = 0.6762213110923767
Iteration [24326]: Loss = 0.6763662099838257
Iteration [24327]: Loss = 0.6764501333236694
Iteration [24328]: Loss = 0.6764784455299377
Iteration [24329]: Loss = 0.6764569282531738
Iteration [24330]: Loss = 5.072800159454346
Iteration [24331]: Loss = 0.6765902042388916
Iteration [24332]: Loss = 0.6767231822013855
Iteration [24333]: Loss = 0.6767958998680115
Iteration [24334]: Loss = 0.6768143177032471
Iteration [24335]: Loss = 0.6767839193344116
Iteration [24336]: Loss = 0.6767094731330872
Iteration [24337]: Loss = 0.6765954494476318
Iteration [24338]: Loss = 0.6764457821846008
Iteration [24339]: Loss = 0.6762638688087463
Iteration [24340]: Loss = 0.6760530471801758
Iteration [24341]: Loss = 5.075976371765137
Iteration [24342]: Loss = 5.0757155418396
Iteration [24343]: Loss = 0.6761651039123535
Iteration [24344]: Loss = 0.6763898134231567
Iteration [24345]: Loss = 0.6765453219413757
Iteration [24346]: Loss = 0.6766384840011597
Iteration [24347]: Loss = 0.6766752600669861
Iteration [24348]: Loss = 0.6766612529754639
Iteration [24349]: Loss = 5.071632385253906
Iteration [24350]: Loss = 0.6768074631690979
Iteration [24351]: Loss = 0.6769459247589111
Iteration [24352]: Loss = 0.6770235300064087
Iteration [24353]: Loss = 0.6770462393760681
Iteration [24354]: Loss = 0.6770198345184326
Iteration [24355]: Loss = 0.6769488453865051
Iteration [24356]: Loss = 0.6768380403518677
Iteration [24357]: Loss = 0.6766911149024963
Iteration [24358]: Loss = 0.6765117049217224
Iteration [24359]: Loss = 0.6763032674789429
Iteration [24360]: Loss = 0.6760685443878174
Iteration [24361]: Loss = 0.6758100986480713
Iteration [24362]: Loss = 0.6755305528640747
Iteration [24363]: Loss = 5.079214572906494
Iteration [24364]: Loss = 0.6752235293388367
Iteration [24365]: Loss = 0.6751694083213806
Iteration [24366]: Loss = 0.6750734448432922
Iteration [24367]: Loss = 5.080829620361328
Iteration [24368]: Loss = 0.6750805377960205
Iteration [24369]: Loss = 0.6751598715782166
Iteration [24370]: Loss = 0.6751844882965088
Iteration [24371]: Loss = 0.6751596927642822
Iteration [24372]: Loss = 0.6750903725624084
Iteration [24373]: Loss = 5.080603122711182
Iteration [24374]: Loss = 5.079707145690918
Iteration [24375]: Loss = 0.6755470633506775
Iteration [24376]: Loss = 0.6758645176887512
Iteration [24377]: Loss = 0.6761035323143005
Iteration [24378]: Loss = 9.4706392288208
Iteration [24379]: Loss = 0.6769806146621704
Iteration [24380]: Loss = 0.6775726079940796
Iteration [24381]: Loss = 0.6780595779418945
Iteration [24382]: Loss = 5.050247669219971
Iteration [24383]: Loss = 0.6810988187789917
Iteration [24384]: Loss = 0.6819380521774292
Iteration [24385]: Loss = 5.040136337280273
Iteration [24386]: Loss = 0.6826225519180298
Iteration [24387]: Loss = 0.6831327080726624
Iteration [24388]: Loss = 0.6835452914237976
Iteration [24389]: Loss = 0.6838697791099548
Iteration [24390]: Loss = 5.030493259429932
Iteration [24391]: Loss = 0.6845905780792236
Iteration [24392]: Loss = 0.6849716901779175
Iteration [24393]: Loss = 0.6852679252624512
Iteration [24394]: Loss = 0.6854875683784485
Iteration [24395]: Loss = 0.6856380701065063
Iteration [24396]: Loss = 0.6857263445854187
Iteration [24397]: Loss = 0.685758650302887
Iteration [24398]: Loss = 0.6857401728630066
Iteration [24399]: Loss = 0.6856764554977417
Iteration [24400]: Loss = 5.02260160446167
Iteration [24401]: Loss = 5.021729469299316
Iteration [24402]: Loss = 0.6861328482627869
Iteration [24403]: Loss = 0.6864458322525024
Iteration [24404]: Loss = 0.6866804957389832
Iteration [24405]: Loss = 0.6868444085121155
Iteration [24406]: Loss = 0.6869447827339172
Iteration [24407]: Loss = 0.686987578868866
Iteration [24408]: Loss = 0.6869789361953735
Iteration [24409]: Loss = 5.01530122756958
Iteration [24410]: Loss = 0.687129020690918
Iteration [24411]: Loss = 5.013453006744385
Iteration [24412]: Loss = 0.6876449584960938
Iteration [24413]: Loss = 0.6879382133483887
Iteration [24414]: Loss = 0.6881551146507263
Iteration [24415]: Loss = 0.6883029937744141
Iteration [24416]: Loss = 0.6883887052536011
Iteration [24417]: Loss = 0.688418447971344
Iteration [24418]: Loss = 0.6883976459503174
Iteration [24419]: Loss = 0.6883316040039062
Iteration [24420]: Loss = 0.6882244944572449
Iteration [24421]: Loss = 0.6880804896354675
Iteration [24422]: Loss = 0.6879033446311951
Iteration [24423]: Loss = 5.011139392852783
Iteration [24424]: Loss = 0.6877657175064087
Iteration [24425]: Loss = 0.6877806186676025
Iteration [24426]: Loss = 0.6877466440200806
Iteration [24427]: Loss = 0.6876686215400696
Iteration [24428]: Loss = 0.6875507831573486
Iteration [24429]: Loss = 0.687397301197052
Iteration [24430]: Loss = 0.6872116327285767
Iteration [24431]: Loss = 0.6869969367980957
Iteration [24432]: Loss = 0.6867561936378479
Iteration [24433]: Loss = 5.017630100250244
Iteration [24434]: Loss = 0.6865105032920837
Iteration [24435]: Loss = 0.6864796876907349
Iteration [24436]: Loss = 0.6864045262336731
Iteration [24437]: Loss = 0.6862894892692566
Iteration [24438]: Loss = 0.6861384510993958
Iteration [24439]: Loss = 0.6859551072120667
Iteration [24440]: Loss = 0.6857426762580872
Iteration [24441]: Loss = 0.6855038404464722
Iteration [24442]: Loss = 0.68524169921875
Iteration [24443]: Loss = 0.6849582195281982
Iteration [24444]: Loss = 0.6846557855606079
Iteration [24445]: Loss = 0.6843361258506775
Iteration [24446]: Loss = 0.6840010285377502
Iteration [24447]: Loss = 0.6836519837379456
Iteration [24448]: Loss = 0.6832905411720276
Iteration [24449]: Loss = 0.6829180121421814
Iteration [24450]: Loss = 0.6825354099273682
Iteration [24451]: Loss = 0.6821436882019043
Iteration [24452]: Loss = 5.043396472930908
Iteration [24453]: Loss = 9.406261444091797
Iteration [24454]: Loss = 0.6821067929267883
Iteration [24455]: Loss = 0.6824787259101868
Iteration [24456]: Loss = 0.6827669739723206
Iteration [24457]: Loss = 0.6829797029495239
Iteration [24458]: Loss = 0.6831246018409729
Iteration [24459]: Loss = 0.6832081079483032
Iteration [24460]: Loss = 5.03526496887207
Iteration [24461]: Loss = 0.6835165023803711
Iteration [24462]: Loss = 0.6837217211723328
Iteration [24463]: Loss = 0.6838597059249878
Iteration [24464]: Loss = 0.6839370727539062
Iteration [24465]: Loss = 0.6839597821235657
Iteration [24466]: Loss = 5.0314788818359375
Iteration [24467]: Loss = 0.6841639280319214
Iteration [24468]: Loss = 5.029356479644775
Iteration [24469]: Loss = 0.6847226619720459
Iteration [24470]: Loss = 0.6829143762588501
Iteration [24471]: Loss = 0.6852684020996094
Iteration [24472]: Loss = 0.6854323744773865
Iteration [24473]: Loss = 0.6855330467224121
Iteration [24474]: Loss = 0.6855765581130981
Iteration [24475]: Loss = 0.6855688691139221
Iteration [24476]: Loss = 0.6855148077011108
Iteration [24477]: Loss = 0.6854192018508911
Iteration [24478]: Loss = 5.024147033691406
Iteration [24479]: Loss = 0.6854204535484314
Iteration [24480]: Loss = 5.023018836975098
Iteration [24481]: Loss = 0.6858147978782654
Iteration [24482]: Loss = 0.6860563158988953
Iteration [24483]: Loss = 0.6862267255783081
Iteration [24484]: Loss = 0.6863332986831665
Iteration [24485]: Loss = 0.6863821148872375
Iteration [24486]: Loss = 0.6863789558410645
Iteration [24487]: Loss = 0.6863292455673218
Iteration [24488]: Loss = 5.019005298614502
Iteration [24489]: Loss = 0.686408281326294
Iteration [24490]: Loss = 0.6865154504776001
Iteration [24491]: Loss = 0.6865647435188293
Iteration [24492]: Loss = 0.686562180519104
Iteration [24493]: Loss = 5.017518520355225
Iteration [24494]: Loss = 0.6867219805717468
Iteration [24495]: Loss = 0.686863362789154
Iteration [24496]: Loss = 0.6869436502456665
Iteration [24497]: Loss = 0.6869687438011169
Iteration [24498]: Loss = 0.6869442462921143
Iteration [24499]: Loss = 0.68687504529953
Iteration [24500]: Loss = 0.6867655515670776
Iteration [24501]: Loss = 0.6866198778152466
Iteration [24502]: Loss = 0.6864414811134338
Iteration [24503]: Loss = 0.6862336993217468
Iteration [24504]: Loss = 5.020288467407227
Iteration [24505]: Loss = 0.6860435605049133
Iteration [24506]: Loss = 0.6860359907150269
Iteration [24507]: Loss = 5.020381927490234
Iteration [24508]: Loss = 0.6861878037452698
Iteration [24509]: Loss = 5.018526077270508
Iteration [24510]: Loss = 0.6867035627365112
Iteration [24511]: Loss = 0.6869966387748718
Iteration [24512]: Loss = 0.6872135400772095
Iteration [24513]: Loss = 0.6873617768287659
Iteration [24514]: Loss = 0.6874480247497559
Iteration [24515]: Loss = 0.6874787211418152
Iteration [24516]: Loss = 0.6874590516090393
Iteration [24517]: Loss = 0.6873940229415894
Iteration [24518]: Loss = 0.6872884631156921
Iteration [24519]: Loss = 0.6871461272239685
Iteration [24520]: Loss = 0.6869707703590393
Iteration [24521]: Loss = 0.6867655515670776
Iteration [24522]: Loss = 0.6865338087081909
Iteration [24523]: Loss = 0.6862778663635254
Iteration [24524]: Loss = 0.6860002279281616
Iteration [24525]: Loss = 5.021890163421631
Iteration [24526]: Loss = 0.6856910586357117
Iteration [24527]: Loss = 5.022270202636719
Iteration [24528]: Loss = 0.6858351230621338
Iteration [24529]: Loss = 0.6859699487686157
Iteration [24530]: Loss = 0.6860443949699402
Iteration [24531]: Loss = 0.6860642433166504
Iteration [24532]: Loss = 0.6860350370407104
Iteration [24533]: Loss = 5.020493984222412
Iteration [24534]: Loss = 0.6861498951911926
Iteration [24535]: Loss = 5.018815994262695
Iteration [24536]: Loss = 0.6866360306739807
Iteration [24537]: Loss = 0.6869164705276489
Iteration [24538]: Loss = 0.6871221661567688
Iteration [24539]: Loss = 0.687260091304779
Iteration [24540]: Loss = 0.6873372197151184
Iteration [24541]: Loss = 0.6873595118522644
Iteration [24542]: Loss = 0.687332272529602
Iteration [24543]: Loss = 0.6872603893280029
Iteration [24544]: Loss = 0.6871486306190491
Iteration [24545]: Loss = 0.6870007514953613
Iteration [24546]: Loss = 5.0158586502075195
Iteration [24547]: Loss = 5.015361785888672
Iteration [24548]: Loss = 0.6872490644454956
Iteration [24549]: Loss = 5.01216983795166
Iteration [24550]: Loss = 0.6879884600639343
Iteration [24551]: Loss = 5.007481575012207
Iteration [24552]: Loss = 0.6889786720275879
Iteration [24553]: Loss = 0.6894736886024475
Iteration [24554]: Loss = 0.6898724436759949
Iteration [24555]: Loss = 0.6901843547821045
Iteration [24556]: Loss = 0.6904180645942688
Iteration [24557]: Loss = 0.6905809640884399
Iteration [24558]: Loss = 0.6906802654266357
Iteration [24559]: Loss = 9.29910659790039
Iteration [24560]: Loss = 0.6913079619407654
Iteration [24561]: Loss = 0.6917885541915894
Iteration [24562]: Loss = 0.6921744346618652
Iteration [24563]: Loss = 0.6924750804901123
Iteration [24564]: Loss = 4.98438024520874
Iteration [24565]: Loss = 0.6931496858596802
Iteration [24566]: Loss = 0.693509042263031
Iteration [24567]: Loss = 0.6937853693962097
Iteration [24568]: Loss = 0.6939871311187744
Iteration [24569]: Loss = 0.6941214799880981
Iteration [24570]: Loss = 0.6948654055595398
Iteration [24571]: Loss = 0.6948390007019043
Iteration [24572]: Loss = 0.6947916150093079
Iteration [24573]: Loss = 0.6947166323661804
Iteration [24574]: Loss = 0.6946016550064087
Iteration [24575]: Loss = 0.6944506168365479
Iteration [24576]: Loss = 0.6942673325538635
Iteration [24577]: Loss = 0.6940546631813049
Iteration [24578]: Loss = 0.6938159465789795
Iteration [24579]: Loss = 0.6935533881187439
Iteration [24580]: Loss = 0.6932697296142578
Iteration [24581]: Loss = 0.6929669380187988
Iteration [24582]: Loss = 0.692646861076355
Iteration [24583]: Loss = 0.6923114061355591
Iteration [24584]: Loss = 0.6919622421264648
Iteration [24585]: Loss = 0.6916003227233887
Iteration [24586]: Loss = 0.691227376461029
Iteration [24587]: Loss = 0.6908442974090576
Iteration [24588]: Loss = 0.6904523372650146
Iteration [24589]: Loss = 0.6900520324707031
Iteration [24590]: Loss = 5.000680446624756
Iteration [24591]: Loss = 0.6879492998123169
Iteration [24592]: Loss = 0.6878007054328918
Iteration [24593]: Loss = 0.6876200437545776
Iteration [24594]: Loss = 5.012679576873779
Iteration [24595]: Loss = 5.012333869934082
Iteration [24596]: Loss = 0.6877844333648682
Iteration [24597]: Loss = 0.6880165934562683
Iteration [24598]: Loss = 0.6881787180900574
Iteration [24599]: Loss = 0.6882778406143188
Iteration [24600]: Loss = 5.007785320281982
Iteration [24601]: Loss = 5.006227493286133
Iteration [24602]: Loss = 0.689122200012207
Iteration [24603]: Loss = 5.001258373260498
Iteration [24604]: Loss = 0.6901602745056152
Iteration [24605]: Loss = 0.6906751394271851
Iteration [24606]: Loss = 0.6910918951034546
Iteration [24607]: Loss = 0.6914202570915222
Iteration [24608]: Loss = 0.6916688680648804
Iteration [24609]: Loss = 4.988921165466309
Iteration [24610]: Loss = 0.6922552585601807
Iteration [24611]: Loss = 4.985025882720947
Iteration [24612]: Loss = 0.6931171417236328
Iteration [24613]: Loss = 0.6935563683509827
Iteration [24614]: Loss = 0.6939048171043396
Iteration [24615]: Loss = 4.976561069488525
Iteration [24616]: Loss = 4.973966598510742
Iteration [24617]: Loss = 0.6953514218330383
Iteration [24618]: Loss = 0.6959260106086731
Iteration [24619]: Loss = 0.6963962316513062
Iteration [24620]: Loss = 0.6967724561691284
Iteration [24621]: Loss = 0.6970638632774353
Iteration [24622]: Loss = 4.960153102874756
Iteration [24623]: Loss = 0.6977214217185974
Iteration [24624]: Loss = 9.213884353637695
Iteration [24625]: Loss = 4.951496124267578
Iteration [24626]: Loss = 0.6999427676200867
Iteration [24627]: Loss = 0.7008106112480164
Iteration [24628]: Loss = 4.9379801750183105
Iteration [24629]: Loss = 0.702354371547699
Iteration [24630]: Loss = 4.929901599884033
Iteration [24631]: Loss = 4.925394058227539
Iteration [24632]: Loss = 0.7048910856246948
Iteration [24633]: Loss = 4.9165520668029785
Iteration [24634]: Loss = 0.7065263390541077
Iteration [24635]: Loss = 4.908147811889648
Iteration [24636]: Loss = 0.7081553936004639
Iteration [24637]: Loss = 0.7089059352874756
Iteration [24638]: Loss = 0.7095435261726379
Iteration [24639]: Loss = 4.893806457519531
Iteration [24640]: Loss = 0.7107587456703186
Iteration [24641]: Loss = 0.7113321423530579
Iteration [24642]: Loss = 0.7118098735809326
Iteration [24643]: Loss = 4.882997989654541
Iteration [24644]: Loss = 0.7127508521080017
Iteration [24645]: Loss = 0.7132070660591125
Iteration [24646]: Loss = 0.7135790586471558
Iteration [24647]: Loss = 0.7138747572898865
Iteration [24648]: Loss = 4.8733601570129395
Iteration [24649]: Loss = 0.7145043015480042
Iteration [24650]: Loss = 0.7148273587226868
Iteration [24651]: Loss = 0.7150791883468628
Iteration [24652]: Loss = 0.7152667045593262
Iteration [24653]: Loss = 0.7153961658477783
Iteration [24654]: Loss = 0.7154735326766968
Iteration [24655]: Loss = 4.866281032562256
Iteration [24656]: Loss = 0.7157291173934937
Iteration [24657]: Loss = 0.7158926129341125
Iteration [24658]: Loss = 0.7160005569458008
Iteration [24659]: Loss = 0.7160584926605225
Iteration [24660]: Loss = 0.7160711884498596
Iteration [24661]: Loss = 9.011083602905273
Iteration [24662]: Loss = 0.7164500951766968
Iteration [24663]: Loss = 4.859868049621582
Iteration [24664]: Loss = 0.7172683477401733
Iteration [24665]: Loss = 0.717671275138855
Iteration [24666]: Loss = 4.853756427764893
Iteration [24667]: Loss = 0.7184820771217346
Iteration [24668]: Loss = 0.7188816070556641
Iteration [24669]: Loss = 0.7192025184631348
Iteration [24670]: Loss = 0.7194520235061646
Iteration [24671]: Loss = 0.7196375727653503
Iteration [24672]: Loss = 0.7197653651237488
Iteration [24673]: Loss = 4.844521999359131
Iteration [24674]: Loss = 0.7201051712036133
Iteration [24675]: Loss = 4.842214107513428
Iteration [24676]: Loss = 0.7206780910491943
Iteration [24677]: Loss = 0.7209760546684265
Iteration [24678]: Loss = 0.7212050557136536
Iteration [24679]: Loss = 0.7213717699050903
Iteration [24680]: Loss = 0.7214823961257935
Iteration [24681]: Loss = 0.7215427160263062
Iteration [24682]: Loss = 0.7215574383735657
Iteration [24683]: Loss = 0.7215311527252197
Iteration [24684]: Loss = 0.7214679718017578
Iteration [24685]: Loss = 0.7213715314865112
Iteration [24686]: Loss = 0.7212452292442322
Iteration [24687]: Loss = 0.7210919857025146
Iteration [24688]: Loss = 0.7209144830703735
Iteration [24689]: Loss = 0.7207151055335999
Iteration [24690]: Loss = 0.7204961776733398
Iteration [24691]: Loss = 0.7202594876289368
Iteration [24692]: Loss = 0.7200069427490234
Iteration [24693]: Loss = 0.7197400331497192
Iteration [24694]: Loss = 0.7194603681564331
Iteration [24695]: Loss = 0.7191690802574158
Iteration [24696]: Loss = 0.7188674211502075
Iteration [24697]: Loss = 0.7185564041137695
Iteration [24698]: Loss = 0.718237042427063
Iteration [24699]: Loss = 0.7179100513458252
Iteration [24700]: Loss = 0.717576265335083
Iteration [24701]: Loss = 4.85756254196167
Iteration [24702]: Loss = 0.7171288728713989
Iteration [24703]: Loss = 0.7169926166534424
Iteration [24704]: Loss = 0.7168306112289429
Iteration [24705]: Loss = 0.7166454792022705
Iteration [24706]: Loss = 0.7164393663406372
Iteration [24707]: Loss = 4.862700462341309
Iteration [24708]: Loss = 0.7162102460861206
Iteration [24709]: Loss = 0.716167151927948
Iteration [24710]: Loss = 0.7160890102386475
Iteration [24711]: Loss = 0.7159793376922607
Iteration [24712]: Loss = 0.7158412933349609
Iteration [24713]: Loss = 0.7156777381896973
Iteration [24714]: Loss = 0.7154911160469055
Iteration [24715]: Loss = 0.7152839303016663
Iteration [24716]: Loss = 0.7150580883026123
Iteration [24717]: Loss = 0.7148153781890869
Iteration [24718]: Loss = 0.7145577669143677
Iteration [24719]: Loss = 0.7142864465713501
Iteration [24720]: Loss = 0.7140030860900879
Iteration [24721]: Loss = 0.7137086391448975
Iteration [24722]: Loss = 0.7134043574333191
Iteration [24723]: Loss = 0.7130913138389587
Iteration [24724]: Loss = 0.7127702832221985
Iteration [24725]: Loss = 0.7124421000480652
Iteration [24726]: Loss = 0.7121075987815857
Iteration [24727]: Loss = 0.7117671966552734
Iteration [24728]: Loss = 4.886962413787842
Iteration [24729]: Loss = 0.7113104462623596
Iteration [24730]: Loss = 0.7100779414176941
Iteration [24731]: Loss = 0.7099139094352722
Iteration [24732]: Loss = 0.7097271084785461
Iteration [24733]: Loss = 4.896662712097168
Iteration [24734]: Loss = 0.7095330953598022
Iteration [24735]: Loss = 0.7095059752464294
Iteration [24736]: Loss = 4.897059440612793
Iteration [24737]: Loss = 0.7095843553543091
Iteration [24738]: Loss = 0.7096731662750244
Iteration [24739]: Loss = 4.895669937133789
Iteration [24740]: Loss = 0.7099499106407166
Iteration [24741]: Loss = 0.7101230621337891
Iteration [24742]: Loss = 0.7102401852607727
Iteration [24743]: Loss = 0.7103066444396973
Iteration [24744]: Loss = 0.7103275060653687
Iteration [24745]: Loss = 0.710307240486145
Iteration [24746]: Loss = 0.7102500200271606
Iteration [24747]: Loss = 0.7101593017578125
Iteration [24748]: Loss = 0.7100387811660767
Iteration [24749]: Loss = 4.894766807556152
Iteration [24750]: Loss = 4.894426345825195
Iteration [24751]: Loss = 0.7102161645889282
Iteration [24752]: Loss = 4.892117500305176
Iteration [24753]: Loss = 0.7107826471328735
Iteration [24754]: Loss = 0.7110794186592102
Iteration [24755]: Loss = 0.7113077640533447
Iteration [24756]: Loss = 0.7114742994308472
Iteration [24757]: Loss = 4.886129379272461
Iteration [24758]: Loss = 4.884612560272217
Iteration [24759]: Loss = 0.7123495936393738
Iteration [24760]: Loss = 0.7127305269241333
Iteration [24761]: Loss = 0.7130346298217773
Iteration [24762]: Loss = 0.7132692337036133
Iteration [24763]: Loss = 0.7134414911270142
Iteration [24764]: Loss = 0.7135573029518127
Iteration [24765]: Loss = 4.875788688659668
Iteration [24766]: Loss = 0.7138792872428894
Iteration [24767]: Loss = 0.7140713334083557
Iteration [24768]: Loss = 0.7142051458358765
Iteration [24769]: Loss = 0.7142863273620605
Iteration [24770]: Loss = 0.714320182800293
Iteration [24771]: Loss = 4.872302532196045
Iteration [24772]: Loss = 0.7145017385482788
Iteration [24773]: Loss = 0.7146340012550354
Iteration [24774]: Loss = 0.7147138118743896
Iteration [24775]: Loss = 4.870104789733887
Iteration [24776]: Loss = 4.868956089019775
Iteration [24777]: Loss = 0.7153760194778442
Iteration [24778]: Loss = 0.7156990766525269
Iteration [24779]: Loss = 0.7159509062767029
Iteration [24780]: Loss = 0.7161382436752319
Iteration [24781]: Loss = 4.862433433532715
Iteration [24782]: Loss = 0.7165818810462952
Iteration [24783]: Loss = 4.8596272468566895
Iteration [24784]: Loss = 4.857534408569336
Iteration [24785]: Loss = 0.7178138494491577
Iteration [24786]: Loss = 0.7182896733283997
Iteration [24787]: Loss = 0.7186789512634277
Iteration [24788]: Loss = 0.7189899682998657
Iteration [24789]: Loss = 0.7192306518554688
Iteration [24790]: Loss = 0.7194079160690308
Iteration [24791]: Loss = 0.7195279002189636
Iteration [24792]: Loss = 0.7195963263511658
Iteration [24793]: Loss = 0.7196183800697327
Iteration [24794]: Loss = 0.719598650932312
Iteration [24795]: Loss = 0.7195411324501038
Iteration [24796]: Loss = 0.7194496989250183
Iteration [24797]: Loss = 4.847085952758789
Iteration [24798]: Loss = 0.7194160223007202
Iteration [24799]: Loss = 0.7194560766220093
Iteration [24800]: Loss = 0.7194522619247437
Iteration [24801]: Loss = 0.7194092869758606
Iteration [24802]: Loss = 0.7193309664726257
Iteration [24803]: Loss = 4.847620964050293
Iteration [24804]: Loss = 0.7193195819854736
Iteration [24805]: Loss = 0.7193690538406372
Iteration [24806]: Loss = 0.7193739414215088
Iteration [24807]: Loss = 4.847031593322754
Iteration [24808]: Loss = 0.7195047736167908
Iteration [24809]: Loss = 0.7196148037910461
Iteration [24810]: Loss = 8.971035957336426
Iteration [24811]: Loss = 0.7201586961746216
Iteration [24812]: Loss = 0.72055584192276
Iteration [24813]: Loss = 0.7208741903305054
Iteration [24814]: Loss = 0.7211215496063232
Iteration [24815]: Loss = 8.953153610229492
Iteration [24816]: Loss = 0.721896231174469
Iteration [24817]: Loss = 0.7223900556564331
Iteration [24818]: Loss = 0.7227957248687744
Iteration [24819]: Loss = 0.7231217622756958
Iteration [24820]: Loss = 4.826947212219238
Iteration [24821]: Loss = 0.7237993478775024
Iteration [24822]: Loss = 0.7241411209106445
Iteration [24823]: Loss = 0.7244096994400024
Iteration [24824]: Loss = 0.7246120572090149
Iteration [24825]: Loss = 0.7247547507286072
Iteration [24826]: Loss = 0.7248439788818359
Iteration [24827]: Loss = 0.7248846888542175
Iteration [24828]: Loss = 4.8195061683654785
Iteration [24829]: Loss = 0.7250739336013794
Iteration [24830]: Loss = 0.725207507610321
Iteration [24831]: Loss = 0.7252882719039917
Iteration [24832]: Loss = 0.725321352481842
Iteration [24833]: Loss = 0.7253117561340332
Iteration [24834]: Loss = 0.725263237953186
Iteration [24835]: Loss = 0.7251801490783691
Iteration [24836]: Loss = 0.7250657081604004
Iteration [24837]: Loss = 0.7249231338500977
Iteration [24838]: Loss = 0.7247551083564758
Iteration [24839]: Loss = 0.7245643138885498
Iteration [24840]: Loss = 0.7243528366088867
Iteration [24841]: Loss = 0.7241228818893433
Iteration [24842]: Loss = 0.7238763570785522
Iteration [24843]: Loss = 0.7236148118972778
Iteration [24844]: Loss = 0.723339855670929
Iteration [24845]: Loss = 0.7230527400970459
Iteration [24846]: Loss = 0.7227548360824585
Iteration [24847]: Loss = 0.7224470376968384
Iteration [24848]: Loss = 0.7221304774284363
Iteration [24849]: Loss = 0.7218059301376343
Iteration [24850]: Loss = 0.7214744091033936
Iteration [24851]: Loss = 0.7211365699768066
Iteration [24852]: Loss = 0.7207928895950317
Iteration [24853]: Loss = 0.7204440832138062
Iteration [24854]: Loss = 0.7200906872749329
Iteration [24855]: Loss = 0.7197331786155701
Iteration [24856]: Loss = 0.7193719744682312
Iteration [24857]: Loss = 0.7190074920654297
Iteration [24858]: Loss = 0.7186400890350342
Iteration [24859]: Loss = 0.7182698249816895
Iteration [24860]: Loss = 4.854246139526367
Iteration [24861]: Loss = 4.854935646057129
Iteration [24862]: Loss = 0.7178329229354858
Iteration [24863]: Loss = 0.7178594470024109
Iteration [24864]: Loss = 0.7178441882133484
Iteration [24865]: Loss = 4.8547797203063965
Iteration [24866]: Loss = 0.7179399728775024
Iteration [24867]: Loss = 0.7180348038673401
Iteration [24868]: Loss = 0.718080997467041
Iteration [24869]: Loss = 0.7180833220481873
Iteration [24870]: Loss = 0.7180460691452026
Iteration [24871]: Loss = 0.7179732322692871
Iteration [24872]: Loss = 0.7178683876991272
Iteration [24873]: Loss = 0.717734694480896
Iteration [24874]: Loss = 0.717574954032898
Iteration [24875]: Loss = 0.7173917889595032
Iteration [24876]: Loss = 0.717187762260437
Iteration [24877]: Loss = 0.7169646620750427
Iteration [24878]: Loss = 0.7167245745658875
Iteration [24879]: Loss = 0.7164691090583801
Iteration [24880]: Loss = 0.7161998748779297
Iteration [24881]: Loss = 0.715918242931366
Iteration [24882]: Loss = 0.7156254649162292
Iteration [24883]: Loss = 0.7153226733207703
Iteration [24884]: Loss = 0.7150108218193054
Iteration [24885]: Loss = 4.8703837394714355
Iteration [24886]: Loss = 0.7146015167236328
Iteration [24887]: Loss = 0.7144816517829895
Iteration [24888]: Loss = 0.7143347263336182
Iteration [24889]: Loss = 0.7141632437705994
Iteration [24890]: Loss = 0.7139695882797241
Iteration [24891]: Loss = 0.713756263256073
Iteration [24892]: Loss = 0.7135249376296997
Iteration [24893]: Loss = 0.7132776379585266
Iteration [24894]: Loss = 0.7130157947540283
Iteration [24895]: Loss = 0.7127408981323242
Iteration [24896]: Loss = 0.7124543786048889
Iteration [24897]: Loss = 0.7121573686599731
Iteration [24898]: Loss = 0.7118507623672485
Iteration [24899]: Loss = 4.886381149291992
Iteration [24900]: Loss = 0.711451530456543
Iteration [24901]: Loss = 0.7113365530967712
Iteration [24902]: Loss = 0.7111940383911133
Iteration [24903]: Loss = 4.888973236083984
Iteration [24904]: Loss = 0.7110748291015625
Iteration [24905]: Loss = 0.7110791802406311
Iteration [24906]: Loss = 0.7110442519187927
Iteration [24907]: Loss = 0.7109736204147339
Iteration [24908]: Loss = 0.7108711004257202
Iteration [24909]: Loss = 0.71073979139328
Iteration [24910]: Loss = 4.891238212585449
Iteration [24911]: Loss = 0.7106398344039917
Iteration [24912]: Loss = 0.7106527090072632
Iteration [24913]: Loss = 4.89102029800415
Iteration [24914]: Loss = 4.890134334564209
Iteration [24915]: Loss = 0.7111533880233765
Iteration [24916]: Loss = 0.7114337682723999
Iteration [24917]: Loss = 0.7116472721099854
Iteration [24918]: Loss = 0.7118005156517029
Iteration [24919]: Loss = 0.7118995189666748
Iteration [24920]: Loss = 0.7119495272636414
Iteration [24921]: Loss = 0.7119554877281189
Iteration [24922]: Loss = 0.7119218111038208
Iteration [24923]: Loss = 0.7118523716926575
Iteration [24924]: Loss = 0.7117506861686707
Iteration [24925]: Loss = 0.711620032787323
Iteration [24926]: Loss = 0.7114632725715637
Iteration [24927]: Loss = 0.7112830877304077
Iteration [24928]: Loss = 0.7110817432403564
Iteration [24929]: Loss = 0.7108612656593323
Iteration [24930]: Loss = 0.7106238007545471
Iteration [24931]: Loss = 0.7103707790374756
Iteration [24932]: Loss = 0.7101039886474609
Iteration [24933]: Loss = 0.709824800491333
Iteration [24934]: Loss = 4.896589756011963
Iteration [24935]: Loss = 0.7094728946685791
Iteration [24936]: Loss = 0.7093786001205444
Iteration [24937]: Loss = 0.7092546820640564
Iteration [24938]: Loss = 0.7091040015220642
Iteration [24939]: Loss = 0.7089293003082275
Iteration [24940]: Loss = 0.7087331414222717
Iteration [24941]: Loss = 4.901795387268066
Iteration [24942]: Loss = 0.7085232138633728
Iteration [24943]: Loss = 9.095386505126953
Iteration [24944]: Loss = 0.7088937163352966
Iteration [24945]: Loss = 0.7092189788818359
Iteration [24946]: Loss = 0.7094733715057373
Iteration [24947]: Loss = 0.7096637487411499
Iteration [24948]: Loss = 0.7097963094711304
Iteration [24949]: Loss = 0.709877073764801
Iteration [24950]: Loss = 0.7099108695983887
Iteration [24951]: Loss = 0.7099026441574097
Iteration [24952]: Loss = 0.7098563313484192
Iteration [24953]: Loss = 0.7097758054733276
Iteration [24954]: Loss = 0.7096644639968872
Iteration [24955]: Loss = 4.896636009216309
Iteration [24956]: Loss = 0.7095986604690552
Iteration [24957]: Loss = 0.7096258401870728
Iteration [24958]: Loss = 0.7096115350723267
Iteration [24959]: Loss = 0.7095597386360168
Iteration [24960]: Loss = 0.7094744443893433
Iteration [24961]: Loss = 0.7093586325645447
Iteration [24962]: Loss = 0.7092156410217285
Iteration [24963]: Loss = 0.7090479135513306
Iteration [24964]: Loss = 0.7088581323623657
Iteration [24965]: Loss = 0.7086485028266907
Iteration [24966]: Loss = 4.902289390563965
Iteration [24967]: Loss = 0.708415150642395
Iteration [24968]: Loss = 0.7083711624145508
Iteration [24969]: Loss = 4.9029459953308105
Iteration [24970]: Loss = 9.096155166625977
Iteration [24971]: Loss = 0.7089670896530151
Iteration [24972]: Loss = 0.7094205617904663
Iteration [24973]: Loss = 0.7097905278205872
Iteration [24974]: Loss = 0.7100852131843567
Iteration [24975]: Loss = 0.7103121280670166
Iteration [24976]: Loss = 0.7104777693748474
Iteration [24977]: Loss = 0.7105883955955505
Iteration [24978]: Loss = 4.890896797180176
Iteration [24979]: Loss = 0.7109009027481079
Iteration [24980]: Loss = 4.888657093048096
Iteration [24981]: Loss = 0.7114542722702026
Iteration [24982]: Loss = 0.711745023727417
Iteration [24983]: Loss = 0.7119680047035217
Iteration [24984]: Loss = 0.712130069732666
Iteration [24985]: Loss = 4.882813930511475
Iteration [24986]: Loss = 0.7125303149223328
Iteration [24987]: Loss = 0.7127554416656494
Iteration [24988]: Loss = 0.7129193544387817
Iteration [24989]: Loss = 0.7130283117294312
Iteration [24990]: Loss = 0.7130873799324036
Iteration [24991]: Loss = 0.7131019830703735
Iteration [24992]: Loss = 0.713076114654541
Iteration [24993]: Loss = 4.878870964050293
Iteration [24994]: Loss = 0.7131550312042236
Iteration [24995]: Loss = 0.7132431864738464
Iteration [24996]: Loss = 0.7132837176322937
Iteration [24997]: Loss = 0.7132812738418579
Iteration [24998]: Loss = 0.7132401466369629
Iteration [24999]: Loss = 0.7131643295288086
Iteration [25000]: Loss = 0.7130571007728577
Iteration [25001]: Loss = 4.879340171813965
Iteration [25002]: Loss = 0.7129970788955688
Iteration [25003]: Loss = 4.878810882568359
Iteration [25004]: Loss = 0.7132487893104553
Iteration [25005]: Loss = 0.7134106755256653
Iteration [25006]: Loss = 0.7135174870491028
Iteration [25007]: Loss = 0.7135748267173767
Iteration [25008]: Loss = 0.7135875821113586
Iteration [25009]: Loss = 4.87610387802124
Iteration [25010]: Loss = 0.7137322425842285
Iteration [25011]: Loss = 0.713848352432251
Iteration [25012]: Loss = 0.7139139771461487
Iteration [25013]: Loss = 0.7139343023300171
Iteration [25014]: Loss = 0.7139133810997009
Iteration [25015]: Loss = 0.7138556838035583
Iteration [25016]: Loss = 0.7137647867202759
Iteration [25017]: Loss = 0.7136439085006714
Iteration [25018]: Loss = 0.713496208190918
Iteration [25019]: Loss = 0.7133240699768066
Iteration [25020]: Loss = 0.7131302356719971
Iteration [25021]: Loss = 0.7129166722297668
Iteration [25022]: Loss = 0.7126855850219727
Iteration [25023]: Loss = 4.8817925453186035
Iteration [25024]: Loss = 4.881916522979736
Iteration [25025]: Loss = 0.7125893831253052
Iteration [25026]: Loss = 0.7127084136009216
Iteration [25027]: Loss = 0.7127767205238342
Iteration [25028]: Loss = 4.879960060119629
Iteration [25029]: Loss = 0.7130168676376343
Iteration [25030]: Loss = 0.7131738662719727
Iteration [25031]: Loss = 0.7132762670516968
Iteration [25032]: Loss = 4.877273082733154
Iteration [25033]: Loss = 0.7135744690895081
Iteration [25034]: Loss = 0.713756263256073
Iteration [25035]: Loss = 0.7138808369636536
Iteration [25036]: Loss = 0.7139540910720825
Iteration [25037]: Loss = 0.713981032371521
Iteration [25038]: Loss = 0.7139663100242615
Iteration [25039]: Loss = 0.7139139771461487
Iteration [25040]: Loss = 4.874748706817627
Iteration [25041]: Loss = 0.7139476537704468
Iteration [25042]: Loss = 0.7140166759490967
Iteration [25043]: Loss = 0.71403968334198
Iteration [25044]: Loss = 0.7116450667381287
Iteration [25045]: Loss = 0.7115898132324219
Iteration [25046]: Loss = 0.7115010619163513
Iteration [25047]: Loss = 0.7113824486732483
Iteration [25048]: Loss = 0.7112365961074829
Iteration [25049]: Loss = 0.7110666036605835
Iteration [25050]: Loss = 0.710874617099762
Iteration [25051]: Loss = 0.7106629014015198
Iteration [25052]: Loss = 0.7104332447052002
Iteration [25053]: Loss = 0.7101877927780151
Iteration [25054]: Loss = 0.7099279761314392
Iteration [25055]: Loss = 4.89597225189209
Iteration [25056]: Loss = 0.7096084356307983
Iteration [25057]: Loss = 0.7095275521278381
Iteration [25058]: Loss = 0.7094157934188843
Iteration [25059]: Loss = 0.7092766165733337
Iteration [25060]: Loss = 0.7091122269630432
Iteration [25061]: Loss = 0.7089255452156067
Iteration [25062]: Loss = 4.900763511657715
Iteration [25063]: Loss = 4.900699138641357
Iteration [25064]: Loss = 0.7089408040046692
Iteration [25065]: Loss = 0.7090907692909241
Iteration [25066]: Loss = 0.7091871500015259
Iteration [25067]: Loss = 0.7092350721359253
Iteration [25068]: Loss = 0.7092394232749939
Iteration [25069]: Loss = 0.7092044949531555
Iteration [25070]: Loss = 0.7091342806816101
Iteration [25071]: Loss = 0.7090322971343994
Iteration [25072]: Loss = 0.708901584148407
Iteration [25073]: Loss = 0.708745002746582
Iteration [25074]: Loss = 0.708565354347229
Iteration [25075]: Loss = 0.7083646655082703
Iteration [25076]: Loss = 0.708145260810852
Iteration [25077]: Loss = 0.7079088091850281
Iteration [25078]: Loss = 0.7076572179794312
Iteration [25079]: Loss = 0.7073919773101807
Iteration [25080]: Loss = 0.7071142792701721
Iteration [25081]: Loss = 0.7068254947662354
Iteration [25082]: Loss = 0.7065268158912659
Iteration [25083]: Loss = 0.7062192559242249
Iteration [25084]: Loss = 0.7059035897254944
Iteration [25085]: Loss = 0.7055806517601013
Iteration [25086]: Loss = 4.918597221374512
Iteration [25087]: Loss = 0.7051551938056946
Iteration [25088]: Loss = 0.7050298452377319
Iteration [25089]: Loss = 4.920523643493652
Iteration [25090]: Loss = 0.704941987991333
Iteration [25091]: Loss = 0.7049605846405029
Iteration [25092]: Loss = 0.704938530921936
Iteration [25093]: Loss = 0.7048801183700562
Iteration [25094]: Loss = 0.7047888040542603
Iteration [25095]: Loss = 0.7046679854393005
Iteration [25096]: Loss = 0.7045205235481262
Iteration [25097]: Loss = 0.7043491005897522
Iteration [25098]: Loss = 0.7041561007499695
Iteration [25099]: Loss = 0.7039436101913452
Iteration [25100]: Loss = 0.7037137150764465
Iteration [25101]: Loss = 0.7034679651260376
Iteration [25102]: Loss = 0.7032082080841064
Iteration [25103]: Loss = 0.7029357552528381
Iteration [25104]: Loss = 4.932061195373535
Iteration [25105]: Loss = 0.7025972008705139
Iteration [25106]: Loss = 0.7025094628334045
Iteration [25107]: Loss = 4.933413028717041
Iteration [25108]: Loss = 0.7024863362312317
Iteration [25109]: Loss = 0.7025330662727356
Iteration [25110]: Loss = 0.702536404132843
Iteration [25111]: Loss = 0.7001833915710449
Iteration [25112]: Loss = 0.70011305809021
Iteration [25113]: Loss = 0.7000113725662231
Iteration [25114]: Loss = 4.9465012550354
Iteration [25115]: Loss = 0.6999653577804565
Iteration [25116]: Loss = 0.7000023722648621
Iteration [25117]: Loss = 0.6999973654747009
Iteration [25118]: Loss = 0.6999545097351074
Iteration [25119]: Loss = 0.6998774409294128
Iteration [25120]: Loss = 0.6997696757316589
Iteration [25121]: Loss = 4.9477949142456055
Iteration [25122]: Loss = 0.6997131705284119
Iteration [25123]: Loss = 0.6997458338737488
Iteration [25124]: Loss = 0.699737012386322
Iteration [25125]: Loss = 0.699690580368042
Iteration [25126]: Loss = 0.6996103525161743
Iteration [25127]: Loss = 0.6994996070861816
Iteration [25128]: Loss = 4.949221134185791
Iteration [25129]: Loss = 4.948819160461426
Iteration [25130]: Loss = 0.6997078657150269
Iteration [25131]: Loss = 0.6999123692512512
Iteration [25132]: Loss = 0.700058102607727
Iteration [25133]: Loss = 0.7001509070396423
Iteration [25134]: Loss = 0.7001960277557373
Iteration [25135]: Loss = 0.7001981735229492
Iteration [25136]: Loss = 0.7001616954803467
Iteration [25137]: Loss = 0.7000903487205505
Iteration [25138]: Loss = 0.6999877691268921
Iteration [25139]: Loss = 4.946630001068115
Iteration [25140]: Loss = 0.6999399662017822
Iteration [25141]: Loss = 0.6999764442443848
Iteration [25142]: Loss = 0.6999709606170654
Iteration [25143]: Loss = 0.6999275088310242
Iteration [25144]: Loss = 0.6998498439788818
Iteration [25145]: Loss = 0.6997416019439697
Iteration [25146]: Loss = 0.6996055245399475
Iteration [25147]: Loss = 0.6994446516036987
Iteration [25148]: Loss = 0.6992612481117249
Iteration [25149]: Loss = 4.950812816619873
Iteration [25150]: Loss = 0.6990759372711182
Iteration [25151]: Loss = 0.6990541219711304
Iteration [25152]: Loss = 0.6989959478378296
Iteration [25153]: Loss = 0.6989052295684814
Iteration [25154]: Loss = 0.6987849473953247
Iteration [25155]: Loss = 0.6986382007598877
Iteration [25156]: Loss = 0.6984677910804749
Iteration [25157]: Loss = 0.6982756853103638
Iteration [25158]: Loss = 0.6980644464492798
Iteration [25159]: Loss = 0.6978359222412109
Iteration [25160]: Loss = 0.6975915431976318
Iteration [25161]: Loss = 0.6973332762718201
Iteration [25162]: Loss = 0.6970622539520264
Iteration [25163]: Loss = 0.6967799067497253
Iteration [25164]: Loss = 0.6964872479438782
Iteration [25165]: Loss = 0.6961854100227356
Iteration [25166]: Loss = 0.6958754062652588
Iteration [25167]: Loss = 0.6955580115318298
Iteration [25168]: Loss = 0.6952337026596069
Iteration [25169]: Loss = 4.972683906555176
Iteration [25170]: Loss = 0.6948097348213196
Iteration [25171]: Loss = 0.6946868896484375
Iteration [25172]: Loss = 0.694537878036499
Iteration [25173]: Loss = 0.6943655014038086
Iteration [25174]: Loss = 0.694172203540802
Iteration [25175]: Loss = 0.6939597129821777
Iteration [25176]: Loss = 0.6937300562858582
Iteration [25177]: Loss = 0.6934850811958313
Iteration [25178]: Loss = 0.6932263374328613
Iteration [25179]: Loss = 0.6929550766944885
Iteration [25180]: Loss = 0.6926727294921875
Iteration [25181]: Loss = 0.6923802495002747
Iteration [25182]: Loss = 4.987679481506348
Iteration [25183]: Loss = 0.6920111775398254
Iteration [25184]: Loss = 0.6919123530387878
Iteration [25185]: Loss = 4.989243984222412
Iteration [25186]: Loss = 0.6918738484382629
Iteration [25187]: Loss = 0.6919156908988953
Iteration [25188]: Loss = 0.6919152140617371
Iteration [25189]: Loss = 0.6918766498565674
Iteration [25190]: Loss = 0.6918036341667175
Iteration [25191]: Loss = 4.9896979331970215
Iteration [25192]: Loss = 4.989112377166748
Iteration [25193]: Loss = 0.6921111941337585
Iteration [25194]: Loss = 0.6923447847366333
Iteration [25195]: Loss = 0.6925169229507446
Iteration [25196]: Loss = 0.6926337480545044
Iteration [25197]: Loss = 0.6927009224891663
Iteration [25198]: Loss = 4.984249591827393
Iteration [25199]: Loss = 0.6929457783699036
Iteration [25200]: Loss = 0.693108320236206
Iteration [25201]: Loss = 0.6932163238525391
Iteration [25202]: Loss = 0.6932754516601562
Iteration [25203]: Loss = 0.6932903528213501
Iteration [25204]: Loss = 4.9813666343688965
Iteration [25205]: Loss = 0.693446159362793
Iteration [25206]: Loss = 0.693570613861084
Iteration [25207]: Loss = 0.6936442852020264
Iteration [25208]: Loss = 0.6936724185943604
Iteration [25209]: Loss = 0.6936594247817993
Iteration [25210]: Loss = 4.979540824890137
Iteration [25211]: Loss = 0.6937674880027771
Iteration [25212]: Loss = 0.6938714981079102
Iteration [25213]: Loss = 0.6939268708229065
Iteration [25214]: Loss = 0.6939384341239929
Iteration [25215]: Loss = 0.693910539150238
Iteration [25216]: Loss = 0.6938470602035522
Iteration [25217]: Loss = 0.6937516331672668
Iteration [25218]: Loss = 0.6936272382736206
Iteration [25219]: Loss = 0.6934770345687866
Iteration [25220]: Loss = 0.6933034658432007
Iteration [25221]: Loss = 4.982199192047119
Iteration [25222]: Loss = 0.6931372880935669
Iteration [25223]: Loss = 0.6931246519088745
Iteration [25224]: Loss = 0.6930749416351318
Iteration [25225]: Loss = 0.6929919719696045
Iteration [25226]: Loss = 0.6928789615631104
Iteration [25227]: Loss = 0.6927387714385986
Iteration [25228]: Loss = 4.985039710998535
Iteration [25229]: Loss = 0.6926300525665283
Iteration [25230]: Loss = 0.692642092704773
Iteration [25231]: Loss = 0.6926144957542419
Iteration [25232]: Loss = 0.6925514340400696
Iteration [25233]: Loss = 0.6924562454223633
Iteration [25234]: Loss = 0.6923323273658752
Iteration [25235]: Loss = 0.6921823024749756
Iteration [25236]: Loss = 0.6920090317726135
Iteration [25237]: Loss = 0.6918147206306458
Iteration [25238]: Loss = 0.6916015148162842
Iteration [25239]: Loss = 0.6913711428642273
Iteration [25240]: Loss = 4.99276065826416
Iteration [25241]: Loss = 0.6911091208457947
Iteration [25242]: Loss = 0.691055953502655
Iteration [25243]: Loss = 0.6909699440002441
Iteration [25244]: Loss = 0.6908541321754456
Iteration [25245]: Loss = 0.6907116174697876
Iteration [25246]: Loss = 0.6905451416969299
Iteration [25247]: Loss = 0.690356969833374
Iteration [25248]: Loss = 0.6901492476463318
Iteration [25249]: Loss = 0.6899241209030151
Iteration [25250]: Loss = 0.689683198928833
Iteration [25251]: Loss = 0.6894279718399048
Iteration [25252]: Loss = 0.6891599893569946
Iteration [25253]: Loss = 0.6888805031776428
Iteration [25254]: Loss = 9.324073791503906
Iteration [25255]: Loss = 0.6887765526771545
Iteration [25256]: Loss = 0.6889062523841858
Iteration [25257]: Loss = 9.31944465637207
Iteration [25258]: Loss = 5.001482009887695
Iteration [25259]: Loss = 0.6901538372039795
Iteration [25260]: Loss = 0.6907099485397339
Iteration [25261]: Loss = 0.6911734938621521
Iteration [25262]: Loss = 0.6915533542633057
Iteration [25263]: Loss = 0.6918576955795288
Iteration [25264]: Loss = 0.6920943260192871
Iteration [25265]: Loss = 0.692269504070282
Iteration [25266]: Loss = 0.6923896670341492
Iteration [25267]: Loss = 0.6924598217010498
Iteration [25268]: Loss = 0.6924852728843689
Iteration [25269]: Loss = 0.6924704313278198
Iteration [25270]: Loss = 4.985866546630859
Iteration [25271]: Loss = 0.6925740838050842
Iteration [25272]: Loss = 0.6926759481430054
Iteration [25273]: Loss = 0.6927297115325928
Iteration [25274]: Loss = 0.6927403211593628
Iteration [25275]: Loss = 4.98430871963501
Iteration [25276]: Loss = 0.6928876638412476
Iteration [25277]: Loss = 0.6930077075958252
Iteration [25278]: Loss = 0.6930782794952393
Iteration [25279]: Loss = 0.6931037902832031
Iteration [25280]: Loss = 0.6930890083312988
Iteration [25281]: Loss = 0.6930376291275024
Iteration [25282]: Loss = 0.6929535865783691
Iteration [25283]: Loss = 0.6928399205207825
Iteration [25284]: Loss = 0.6926997303962708
Iteration [25285]: Loss = 0.6925354599952698
Iteration [25286]: Loss = 0.6923497915267944
Iteration [25287]: Loss = 0.6921446919441223
Iteration [25288]: Loss = 9.285104751586914
Iteration [25289]: Loss = 0.6921612024307251
Iteration [25290]: Loss = 0.6923390626907349
Iteration [25291]: Loss = 0.6924616098403931
Iteration [25292]: Loss = 0.6925342679023743
Iteration [25293]: Loss = 0.6925622820854187
Iteration [25294]: Loss = 4.985171794891357
Iteration [25295]: Loss = 0.6927382946014404
Iteration [25296]: Loss = 0.6928706169128418
Iteration [25297]: Loss = 0.6929522156715393
Iteration [25298]: Loss = 0.6929877996444702
Iteration [25299]: Loss = 0.6929821968078613
Iteration [25300]: Loss = 0.6929395794868469
Iteration [25301]: Loss = 0.6928634643554688
Iteration [25302]: Loss = 0.692757248878479
Iteration [25303]: Loss = 0.6926239132881165
Iteration [25304]: Loss = 4.985617160797119
Iteration [25305]: Loss = 0.6925246715545654
Iteration [25306]: Loss = 4.985224723815918
Iteration [25307]: Loss = 0.6927533149719238
Iteration [25308]: Loss = 0.6929081082344055
Iteration [25309]: Loss = 0.6930098533630371
Iteration [25310]: Loss = 0.6930636167526245
Iteration [25311]: Loss = 0.6930744647979736
Iteration [25312]: Loss = 0.6930464506149292
Iteration [25313]: Loss = 0.6929833889007568
Iteration [25314]: Loss = 4.983366966247559
Iteration [25315]: Loss = 0.6930043697357178
Iteration [25316]: Loss = 0.693070650100708
Iteration [25317]: Loss = 0.6930925846099854
Iteration [25318]: Loss = 0.6930747032165527
Iteration [25319]: Loss = 0.6930207014083862
Iteration [25320]: Loss = 0.6929343938827515
Iteration [25321]: Loss = 0.6928189396858215
Iteration [25322]: Loss = 4.984494209289551
Iteration [25323]: Loss = 0.6927503347396851
Iteration [25324]: Loss = 0.6927785277366638
Iteration [25325]: Loss = 0.6927661299705505
Iteration [25326]: Loss = 0.6927172541618347
Iteration [25327]: Loss = 0.6926354169845581
Iteration [25328]: Loss = 0.6925240755081177
Iteration [25329]: Loss = 0.6923859715461731
Iteration [25330]: Loss = 0.692223846912384
Iteration [25331]: Loss = 0.6920401453971863
Iteration [25332]: Loss = 0.6918370127677917
Iteration [25333]: Loss = 0.6916164755821228
Iteration [25334]: Loss = 0.691379964351654
Iteration [25335]: Loss = 0.6911295056343079
Iteration [25336]: Loss = 4.994145393371582
Iteration [25337]: Loss = 0.6908308863639832
Iteration [25338]: Loss = 4.994704723358154
Iteration [25339]: Loss = 0.6909002065658569
Iteration [25340]: Loss = 0.6909874677658081
Iteration [25341]: Loss = 0.6910282373428345
Iteration [25342]: Loss = 0.6910274028778076
Iteration [25343]: Loss = 9.295992851257324
Iteration [25344]: Loss = 0.6913903951644897
Iteration [25345]: Loss = 0.6917146444320679
Iteration [25346]: Loss = 4.988261699676514
Iteration [25347]: Loss = 4.985983371734619
Iteration [25348]: Loss = 0.6929805278778076
Iteration [25349]: Loss = 0.6934686303138733
Iteration [25350]: Loss = 0.6938707828521729
Iteration [25351]: Loss = 0.6941956877708435
Iteration [25352]: Loss = 0.6944507360458374
Iteration [25353]: Loss = 0.6946428418159485
Iteration [25354]: Loss = 0.6947782039642334
Iteration [25355]: Loss = 4.972900867462158
Iteration [25356]: Loss = 0.6951370239257812
Iteration [25357]: Loss = 0.6953466534614563
Iteration [25358]: Loss = 0.6954977512359619
Iteration [25359]: Loss = 0.6955962181091309
Iteration [25360]: Loss = 0.6956472396850586
Iteration [25361]: Loss = 0.6956554651260376
Iteration [25362]: Loss = 0.6956250071525574
Iteration [25363]: Loss = 4.969213962554932
Iteration [25364]: Loss = 4.968472003936768
Iteration [25365]: Loss = 4.966756820678711
Iteration [25366]: Loss = 0.6965157389640808
Iteration [25367]: Loss = 0.6969197392463684
Iteration [25368]: Loss = 0.6972461342811584
Iteration [25369]: Loss = 0.6975023150444031
Iteration [25370]: Loss = 0.6976950764656067
Iteration [25371]: Loss = 0.6978311538696289
Iteration [25372]: Loss = 0.6979156732559204
Iteration [25373]: Loss = 0.6979540586471558
Iteration [25374]: Loss = 4.956619739532471
Iteration [25375]: Loss = 0.6981462836265564
Iteration [25376]: Loss = 0.6982844471931458
Iteration [25377]: Loss = 0.6983712315559387
Iteration [25378]: Loss = 0.698411226272583
Iteration [25379]: Loss = 4.954212188720703
Iteration [25380]: Loss = 0.6986063718795776
Iteration [25381]: Loss = 0.698745846748352
Iteration [25382]: Loss = 0.6988336443901062
Iteration [25383]: Loss = 0.6988747119903564
Iteration [25384]: Loss = 0.6988738179206848
Iteration [25385]: Loss = 0.6988349556922913
Iteration [25386]: Loss = 0.6987621784210205
Iteration [25387]: Loss = 0.6986585855484009
Iteration [25388]: Loss = 0.6985273361206055
Iteration [25389]: Loss = 0.6983713507652283
Iteration [25390]: Loss = 0.6981926560401917
Iteration [25391]: Loss = 0.6979940533638
Iteration [25392]: Loss = 0.697777271270752
Iteration [25393]: Loss = 0.6975442171096802
Iteration [25394]: Loss = 0.6972963809967041
Iteration [25395]: Loss = 0.6970353722572327
Iteration [25396]: Loss = 4.962869644165039
Iteration [25397]: Loss = 0.696716845035553
Iteration [25398]: Loss = 0.6966378688812256
Iteration [25399]: Loss = 0.6965289115905762
Iteration [25400]: Loss = 0.6963927745819092
Iteration [25401]: Loss = 0.6962324380874634
Iteration [25402]: Loss = 0.696050226688385
Iteration [25403]: Loss = 0.6958481669425964
Iteration [25404]: Loss = 0.6956285238265991
Iteration [25405]: Loss = 0.6953928470611572
Iteration [25406]: Loss = 0.6951428055763245
Iteration [25407]: Loss = 0.6948798298835754
Iteration [25408]: Loss = 0.6946053504943848
Iteration [25409]: Loss = 0.6943203210830688
Iteration [25410]: Loss = 0.6940257549285889
Iteration [25411]: Loss = 0.6937229037284851
Iteration [25412]: Loss = 0.6934124827384949
Iteration [25413]: Loss = 4.982271671295166
Iteration [25414]: Loss = 0.6930108070373535
Iteration [25415]: Loss = 0.6928972005844116
Iteration [25416]: Loss = 4.984068393707275
Iteration [25417]: Loss = 0.6928315758705139
Iteration [25418]: Loss = 0.6928609609603882
Iteration [25419]: Loss = 0.6928495168685913
Iteration [25420]: Loss = 0.6928016543388367
Iteration [25421]: Loss = 0.6927209496498108
Iteration [25422]: Loss = 0.6926102042198181
Iteration [25423]: Loss = 0.6924729347229004
Iteration [25424]: Loss = 0.6923116445541382
Iteration [25425]: Loss = 0.6921285390853882
Iteration [25426]: Loss = 0.6919258832931519
Iteration [25427]: Loss = 0.6917057037353516
Iteration [25428]: Loss = 0.6914698481559753
Iteration [25429]: Loss = 0.6912198066711426
Iteration [25430]: Loss = 0.6909568905830383
Iteration [25431]: Loss = 0.6906824707984924
Iteration [25432]: Loss = 0.6903976798057556
Iteration [25433]: Loss = 0.6901036500930786
Iteration [25434]: Loss = 0.6898012757301331
Iteration [25435]: Loss = 0.6894913911819458
Iteration [25436]: Loss = 5.003198623657227
Iteration [25437]: Loss = 0.6890921592712402
Iteration [25438]: Loss = 0.6889801025390625
Iteration [25439]: Loss = 0.688841700553894
Iteration [25440]: Loss = 0.6886793375015259
Iteration [25441]: Loss = 0.6884955167770386
Iteration [25442]: Loss = 0.6882924437522888
Iteration [25443]: Loss = 0.6880720257759094
Iteration [25444]: Loss = 0.6878358721733093
Iteration [25445]: Loss = 0.6875858902931213
Iteration [25446]: Loss = 0.6873230338096619
Iteration [25447]: Loss = 0.6870489716529846
Iteration [25448]: Loss = 0.6867643594741821
Iteration [25449]: Loss = 5.017743110656738
Iteration [25450]: Loss = 0.686409592628479
Iteration [25451]: Loss = 0.6863170266151428
Iteration [25452]: Loss = 0.6861960887908936
Iteration [25453]: Loss = 0.68604975938797
Iteration [25454]: Loss = 0.6858803629875183
Iteration [25455]: Loss = 0.6856903433799744
Iteration [25456]: Loss = 0.6854817271232605
Iteration [25457]: Loss = 0.6852564811706543
Iteration [25458]: Loss = 5.025608062744141
Iteration [25459]: Loss = 0.6850031018257141
Iteration [25460]: Loss = 5.02594518661499
Iteration [25461]: Loss = 0.6851122379302979
Iteration [25462]: Loss = 5.024518966674805
Iteration [25463]: Loss = 0.6855143904685974
Iteration [25464]: Loss = 5.021668910980225
Iteration [25465]: Loss = 5.019461631774902
Iteration [25466]: Loss = 0.6888611316680908
Iteration [25467]: Loss = 0.6920539140701294
Iteration [25468]: Loss = 0.6924082040786743
Iteration [25469]: Loss = 0.6926532983779907
Iteration [25470]: Loss = 0.6928001046180725
Iteration [25471]: Loss = 0.6928585767745972
Iteration [25472]: Loss = 0.6928377747535706
Iteration [25473]: Loss = 0.6928166747093201
Iteration [25474]: Loss = 0.692846953868866
Iteration [25475]: Loss = 0.6928362250328064
Iteration [25476]: Loss = 0.6927886605262756
Iteration [25477]: Loss = 0.6927078366279602
Iteration [25478]: Loss = 0.6925970315933228
Iteration [25479]: Loss = 0.6924593448638916
Iteration [25480]: Loss = 0.692297101020813
Iteration [25481]: Loss = 0.6921133399009705
Iteration [25482]: Loss = 4.988579273223877
Iteration [25483]: Loss = 0.6933505535125732
Iteration [25484]: Loss = 0.693329930305481
Iteration [25485]: Loss = 0.6932731866836548
Iteration [25486]: Loss = 0.6931840181350708
Iteration [25487]: Loss = 0.6930656433105469
Iteration [25488]: Loss = 0.692920982837677
Iteration [25489]: Loss = 0.6927527189254761
Iteration [25490]: Loss = 4.985100746154785
Iteration [25491]: Loss = 0.6911764144897461
Iteration [25492]: Loss = 0.6911672949790955
Iteration [25493]: Loss = 0.6911209225654602
Iteration [25494]: Loss = 0.6910413503646851
Iteration [25495]: Loss = 0.6909317970275879
Iteration [25496]: Loss = 0.6907950043678284
Iteration [25497]: Loss = 0.6906340718269348
Iteration [25498]: Loss = 0.6904511451721191
Iteration [25499]: Loss = 0.6902485489845276
Iteration [25500]: Loss = 0.6900281310081482
Iteration [25501]: Loss = 0.689791738986969
Iteration [25502]: Loss = 0.6895410418510437
Iteration [25503]: Loss = 0.6892773509025574
Iteration [25504]: Loss = 0.6890022158622742
Iteration [25505]: Loss = 0.688716471195221
Iteration [25506]: Loss = 0.688421368598938
Iteration [25507]: Loss = 0.6881178617477417
Iteration [25508]: Loss = 0.6878066062927246
Iteration [25509]: Loss = 0.6874885559082031
Iteration [25510]: Loss = 0.6871646046638489
Iteration [25511]: Loss = 5.015779972076416
Iteration [25512]: Loss = 0.6867427825927734
Iteration [25513]: Loss = 5.016928195953369
Iteration [25514]: Loss = 5.016416072845459
Iteration [25515]: Loss = 0.6870056390762329
Iteration [25516]: Loss = 0.687227725982666
Iteration [25517]: Loss = 0.6873902082443237
Iteration [25518]: Loss = 0.6874983906745911
Iteration [25519]: Loss = 0.6875583529472351
Iteration [25520]: Loss = 0.6875743865966797
Iteration [25521]: Loss = 0.6875510215759277
Iteration [25522]: Loss = 0.6874921321868896
Iteration [25523]: Loss = 0.6874012351036072
Iteration [25524]: Loss = 0.687281608581543
Iteration [25525]: Loss = 5.014156341552734
Iteration [25526]: Loss = 0.6844130158424377
Iteration [25527]: Loss = 0.6844327449798584
Iteration [25528]: Loss = 0.6844048500061035
Iteration [25529]: Loss = 0.6843346953392029
Iteration [25530]: Loss = 0.684252917766571
Iteration [25531]: Loss = 0.6841415762901306
Iteration [25532]: Loss = 0.6840038299560547
Iteration [25533]: Loss = 0.6838422417640686
Iteration [25534]: Loss = 0.683659017086029
Iteration [25535]: Loss = 0.6834564805030823
Iteration [25536]: Loss = 0.6832364797592163
Iteration [25537]: Loss = 0.6830008029937744
Iteration [25538]: Loss = 0.6827510595321655
Iteration [25539]: Loss = 0.6824884414672852
Iteration [25540]: Loss = 9.399443626403809
Iteration [25541]: Loss = 0.682413637638092
Iteration [25542]: Loss = 5.038971424102783
Iteration [25543]: Loss = 0.6828857064247131
Iteration [25544]: Loss = 0.6831458806991577
Iteration [25545]: Loss = 0.6833428144454956
Iteration [25546]: Loss = 5.033926486968994
Iteration [25547]: Loss = 0.6838111281394958
Iteration [25548]: Loss = 0.6840694546699524
Iteration [25549]: Loss = 0.6842648386955261
Iteration [25550]: Loss = 0.6844034194946289
Iteration [25551]: Loss = 5.0284552574157715
Iteration [25552]: Loss = 0.684771716594696
Iteration [25553]: Loss = 0.6849871873855591
Iteration [25554]: Loss = 0.6851438879966736
Iteration [25555]: Loss = 0.6852477192878723
Iteration [25556]: Loss = 0.6853037476539612
Iteration [25557]: Loss = 0.6853167414665222
Iteration [25558]: Loss = 0.6852909922599792
Iteration [25559]: Loss = 0.6852304339408875
Iteration [25560]: Loss = 0.6851383447647095
Iteration [25561]: Loss = 0.685018002986908
Iteration [25562]: Loss = 0.6848721504211426
Iteration [25563]: Loss = 0.6847034096717834
Iteration [25564]: Loss = 0.6845138669013977
Iteration [25565]: Loss = 0.6843059659004211
Iteration [25566]: Loss = 0.6840811967849731
Iteration [25567]: Loss = 0.6838414072990417
Iteration [25568]: Loss = 0.6835880279541016
Iteration [25569]: Loss = 0.683322548866272
Iteration [25570]: Loss = 0.6830462217330933
Iteration [25571]: Loss = 0.6827597618103027
Iteration [25572]: Loss = 5.0394673347473145
Iteration [25573]: Loss = 0.6824032664299011
Iteration [25574]: Loss = 0.6823105216026306
Iteration [25575]: Loss = 5.040966987609863
Iteration [25576]: Loss = 0.6822843551635742
Iteration [25577]: Loss = 5.040187835693359
Iteration [25578]: Loss = 0.6825786828994751
Iteration [25579]: Loss = 0.6827631592750549
Iteration [25580]: Loss = 0.6828919649124146
Iteration [25581]: Loss = 0.6829705834388733
Iteration [25582]: Loss = 5.0365309715271
Iteration [25583]: Loss = 0.6832370758056641
Iteration [25584]: Loss = 0.6834094524383545
Iteration [25585]: Loss = 5.033683776855469
Iteration [25586]: Loss = 5.032007217407227
Iteration [25587]: Loss = 0.6843161582946777
Iteration [25588]: Loss = 5.027261257171631
Iteration [25589]: Loss = 0.6852680444717407
Iteration [25590]: Loss = 0.6857324838638306
Iteration [25591]: Loss = 0.6861134767532349
Iteration [25592]: Loss = 0.6864192485809326
Iteration [25593]: Loss = 0.6881451606750488
Iteration [25594]: Loss = 0.6883113384246826
Iteration [25595]: Loss = 0.6884152293205261
Iteration [25596]: Loss = 0.6884627342224121
Iteration [25597]: Loss = 0.6884596943855286
Iteration [25598]: Loss = 0.6884109973907471
Iteration [25599]: Loss = 0.688357949256897
Iteration [25600]: Loss = 0.6882740259170532
Iteration [25601]: Loss = 0.68816077709198
Iteration [25602]: Loss = 0.6880208253860474
Iteration [25603]: Loss = 0.6878573298454285
Iteration [25604]: Loss = 0.6876723766326904
Iteration [25605]: Loss = 0.6874679327011108
Iteration [25606]: Loss = 0.6872463226318359
Iteration [25607]: Loss = 5.014841556549072
Iteration [25608]: Loss = 0.6869988441467285
Iteration [25609]: Loss = 5.0151472091674805
Iteration [25610]: Loss = 0.6871128082275391
Iteration [25611]: Loss = 0.68722003698349
Iteration [25612]: Loss = 0.6872788667678833
Iteration [25613]: Loss = 0.6872941255569458
Iteration [25614]: Loss = 0.6872701644897461
Iteration [25615]: Loss = 0.6872107982635498
Iteration [25616]: Loss = 5.01424503326416
Iteration [25617]: Loss = 0.6872406601905823
Iteration [25618]: Loss = 0.687312126159668
Iteration [25619]: Loss = 0.687338650226593
Iteration [25620]: Loss = 0.6873247623443604
Iteration [25621]: Loss = 0.6872745156288147
Iteration [25622]: Loss = 0.6871916055679321
Iteration [25623]: Loss = 5.014463901519775
Iteration [25624]: Loss = 0.6871811747550964
Iteration [25625]: Loss = 0.6863276958465576
Iteration [25626]: Loss = 0.6875144243240356
Iteration [25627]: Loss = 0.6858985424041748
Iteration [25628]: Loss = 0.6858359575271606
Iteration [25629]: Loss = 0.6857420802116394
Iteration [25630]: Loss = 0.6856198310852051
Iteration [25631]: Loss = 0.6854721903800964
Iteration [25632]: Loss = 0.685301661491394
Iteration [25633]: Loss = 0.685110330581665
Iteration [25634]: Loss = 0.6849005222320557
Iteration [25635]: Loss = 0.684674084186554
Iteration [25636]: Loss = 0.6844325065612793
Iteration [25637]: Loss = 0.6841775178909302
Iteration [25638]: Loss = 0.6839103698730469
Iteration [25639]: Loss = 0.6836321353912354
Iteration [25640]: Loss = 0.6833441257476807
Iteration [25641]: Loss = 0.6854059100151062
Iteration [25642]: Loss = 0.6851008534431458
Iteration [25643]: Loss = 0.6847883462905884
Iteration [25644]: Loss = 0.68446946144104
Iteration [25645]: Loss = 9.376522064208984
Iteration [25646]: Loss = 0.6842978000640869
Iteration [25647]: Loss = 0.6843985915184021
Iteration [25648]: Loss = 0.6844519972801208
Iteration [25649]: Loss = 0.6844626665115356
Iteration [25650]: Loss = 0.6844348311424255
Iteration [25651]: Loss = 5.029097557067871
Iteration [25652]: Loss = 0.6845186948776245
Iteration [25653]: Loss = 5.0277910232543945
Iteration [25654]: Loss = 0.6849005222320557
Iteration [25655]: Loss = 5.0250349044799805
Iteration [25656]: Loss = 0.6855228543281555
Iteration [25657]: Loss = 13.691652297973633
Iteration [25658]: Loss = 0.686794638633728
Iteration [25659]: Loss = 0.6876124739646912
Iteration [25660]: Loss = 0.6883127689361572
Iteration [25661]: Loss = 9.320358276367188
Iteration [25662]: Loss = 4.999505519866943
Iteration [25663]: Loss = 0.6909191608428955
Iteration [25664]: Loss = 4.988984107971191
Iteration [25665]: Loss = 4.983569622039795
Iteration [25666]: Loss = 0.6939599514007568
Iteration [25667]: Loss = 0.694922924041748
Iteration [25668]: Loss = 0.6957542300224304
Iteration [25669]: Loss = 0.6964664459228516
Iteration [25670]: Loss = 4.961243629455566
Iteration [25671]: Loss = 0.6978092193603516
Iteration [25672]: Loss = 0.6984370946884155
Iteration [25673]: Loss = 0.6989659667015076
Iteration [25674]: Loss = 0.6994051933288574
Iteration [25675]: Loss = 4.947115898132324
Iteration [25676]: Loss = 0.7002800703048706
Iteration [25677]: Loss = 0.7007079124450684
Iteration [25678]: Loss = 0.701056182384491
Iteration [25679]: Loss = 0.7013326287269592
Iteration [25680]: Loss = 0.7015444040298462
Iteration [25681]: Loss = 0.701697826385498
Iteration [25682]: Loss = 0.701798677444458
Iteration [25683]: Loss = 0.7018522024154663
Iteration [25684]: Loss = 0.7018629908561707
Iteration [25685]: Loss = 4.936307430267334
Iteration [25686]: Loss = 0.7020047903060913
Iteration [25687]: Loss = 0.7021198868751526
Iteration [25688]: Loss = 4.934481143951416
Iteration [25689]: Loss = 0.7024399042129517
Iteration [25690]: Loss = 0.702630877494812
Iteration [25691]: Loss = 0.7027656435966492
Iteration [25692]: Loss = 0.7028495669364929
Iteration [25693]: Loss = 0.7028877139091492
Iteration [25694]: Loss = 0.7028846144676208
Iteration [25695]: Loss = 0.7028443813323975
Iteration [25696]: Loss = 4.93144416809082
Iteration [25697]: Loss = 4.930778503417969
Iteration [25698]: Loss = 0.7032077312469482
Iteration [25699]: Loss = 4.9279255867004395
Iteration [25700]: Loss = 4.925799369812012
Iteration [25701]: Loss = 0.7044210433959961
Iteration [25702]: Loss = 0.7048900127410889
Iteration [25703]: Loss = 0.7052751183509827
Iteration [25704]: Loss = 0.7055845260620117
Iteration [25705]: Loss = 0.7058256268501282
Iteration [25706]: Loss = 0.7060052752494812
Iteration [25707]: Loss = 0.7061294317245483
Iteration [25708]: Loss = 0.7062034606933594
Iteration [25709]: Loss = 0.7062326669692993
Iteration [25710]: Loss = 0.706221342086792
Iteration [25711]: Loss = 0.7061733603477478
Iteration [25712]: Loss = 0.7060924768447876
Iteration [25713]: Loss = 0.7059820890426636
Iteration [25714]: Loss = 0.7058449387550354
Iteration [25715]: Loss = 0.7056838870048523
Iteration [25716]: Loss = 0.7055010795593262
Iteration [25717]: Loss = 0.705298900604248
Iteration [25718]: Loss = 0.705079197883606
Iteration [25719]: Loss = 4.920702934265137
Iteration [25720]: Loss = 0.7048265933990479
Iteration [25721]: Loss = 0.7047735452651978
Iteration [25722]: Loss = 0.7046881318092346
Iteration [25723]: Loss = 0.7045736908912659
Iteration [25724]: Loss = 0.7044328451156616
Iteration [25725]: Loss = 0.7042684555053711
Iteration [25726]: Loss = 0.7040829658508301
Iteration [25727]: Loss = 0.7038781046867371
Iteration [25728]: Loss = 0.703656017780304
Iteration [25729]: Loss = 0.7034186124801636
Iteration [25730]: Loss = 4.929384708404541
Iteration [25731]: Loss = 9.155953407287598
Iteration [25732]: Loss = 0.703532338142395
Iteration [25733]: Loss = 0.7038516998291016
Iteration [25734]: Loss = 0.704102098941803
Iteration [25735]: Loss = 0.7042902708053589
Iteration [25736]: Loss = 0.7044223546981812
Iteration [25737]: Loss = 0.7045038938522339
Iteration [25738]: Loss = 0.7045398354530334
Iteration [25739]: Loss = 4.922300338745117
Iteration [25740]: Loss = 4.921323299407959
Iteration [25741]: Loss = 0.7050864100456238
Iteration [25742]: Loss = 0.7053757309913635
Iteration [25743]: Loss = 0.7055990099906921
Iteration [25744]: Loss = 0.7057625651359558
Iteration [25745]: Loss = 0.7058723568916321
Iteration [25746]: Loss = 4.91507625579834
Iteration [25747]: Loss = 0.7061819434165955
Iteration [25748]: Loss = 0.706368088722229
Iteration [25749]: Loss = 9.117836952209473
Iteration [25750]: Loss = 0.7070342302322388
Iteration [25751]: Loss = 0.7074800133705139
Iteration [25752]: Loss = 0.7078443169593811
Iteration [25753]: Loss = 0.7081349492073059
Iteration [25754]: Loss = 0.70835942029953
Iteration [25755]: Loss = 0.7085240483283997
Iteration [25756]: Loss = 0.7086349725723267
Iteration [25757]: Loss = 0.7086974382400513
Iteration [25758]: Loss = 0.7087161540985107
Iteration [25759]: Loss = 4.900882720947266
Iteration [25760]: Loss = 0.708868682384491
Iteration [25761]: Loss = 0.7089872360229492
Iteration [25762]: Loss = 0.7090564966201782
Iteration [25763]: Loss = 0.7090813517570496
Iteration [25764]: Loss = 4.898984432220459
Iteration [25765]: Loss = 0.7092442512512207
Iteration [25766]: Loss = 4.897443771362305
Iteration [25767]: Loss = 0.7096694111824036
Iteration [25768]: Loss = 0.7099040746688843
Iteration [25769]: Loss = 0.7100778222084045
Iteration [25770]: Loss = 0.7101966738700867
Iteration [25771]: Loss = 0.71026611328125
Iteration [25772]: Loss = 0.7102911472320557
Iteration [25773]: Loss = 0.7102758288383484
Iteration [25774]: Loss = 0.7102245688438416
Iteration [25775]: Loss = 0.7101407647132874
Iteration [25776]: Loss = 0.7100275158882141
Iteration [25777]: Loss = 0.7098879814147949
Iteration [25778]: Loss = 0.7097247242927551
Iteration [25779]: Loss = 0.7095400094985962
Iteration [25780]: Loss = 4.897603511810303
Iteration [25781]: Loss = 0.7093451619148254
Iteration [25782]: Loss = 0.709315836429596
Iteration [25783]: Loss = 0.7092516422271729
Iteration [25784]: Loss = 0.7091564536094666
Iteration [25785]: Loss = 4.899155139923096
Iteration [25786]: Loss = 0.7091142535209656
Iteration [25787]: Loss = 0.7091500163078308
Iteration [25788]: Loss = 0.7091445326805115
Iteration [25789]: Loss = 0.7091019153594971
Iteration [25790]: Loss = 0.7090258598327637
Iteration [25791]: Loss = 0.708919882774353
Iteration [25792]: Loss = 0.70878666639328
Iteration [25793]: Loss = 0.7086291313171387
Iteration [25794]: Loss = 0.7084496021270752
Iteration [25795]: Loss = 0.7082504034042358
Iteration [25796]: Loss = 0.7080334424972534
Iteration [25797]: Loss = 0.7078002691268921
Iteration [25798]: Loss = 0.7075527906417847
Iteration [25799]: Loss = 0.7072924971580505
Iteration [25800]: Loss = 0.7070204615592957
Iteration [25801]: Loss = 0.7067378759384155
Iteration [25802]: Loss = 0.7064459919929504
Iteration [25803]: Loss = 0.7061455845832825
Iteration [25804]: Loss = 0.7058375477790833
Iteration [25805]: Loss = 4.917195796966553
Iteration [25806]: Loss = 0.7054335474967957
Iteration [25807]: Loss = 0.7053157687187195
Iteration [25808]: Loss = 4.919005393981934
Iteration [25809]: Loss = 0.7052367329597473
Iteration [25810]: Loss = 0.7052573561668396
Iteration [25811]: Loss = 0.705238401889801
Iteration [25812]: Loss = 0.7051838636398315
Iteration [25813]: Loss = 0.7050971984863281
Iteration [25814]: Loss = 4.919990062713623
Iteration [25815]: Loss = 0.7050714492797852
Iteration [25816]: Loss = 0.7051147818565369
Iteration [25817]: Loss = 0.705116331577301
Iteration [25818]: Loss = 0.7050802707672119
Iteration [25819]: Loss = 0.7050100564956665
Iteration [25820]: Loss = 0.7049093246459961
Iteration [25821]: Loss = 0.7047811150550842
Iteration [25822]: Loss = 0.7046282291412354
Iteration [25823]: Loss = 0.7044528722763062
Iteration [25824]: Loss = 4.923735618591309
Iteration [25825]: Loss = 0.7042760252952576
Iteration [25826]: Loss = 0.7042551636695862
Iteration [25827]: Loss = 0.7041988968849182
Iteration [25828]: Loss = 0.7041108012199402
Iteration [25829]: Loss = 0.7039937376976013
Iteration [25830]: Loss = 0.7038509845733643
Iteration [25831]: Loss = 0.7036848068237305
Iteration [25832]: Loss = 0.7034976482391357
Iteration [25833]: Loss = 0.703291654586792
Iteration [25834]: Loss = 0.7030686736106873
Iteration [25835]: Loss = 0.70283043384552
Iteration [25836]: Loss = 0.7025783061981201
Iteration [25837]: Loss = 0.7023138403892517
Iteration [25838]: Loss = 0.7020383477210999
Iteration [25839]: Loss = 0.7017527222633362
Iteration [25840]: Loss = 0.701458215713501
Iteration [25841]: Loss = 9.178543090820312
Iteration [25842]: Loss = 0.7013102173805237
Iteration [25843]: Loss = 4.938509941101074
Iteration [25844]: Loss = 0.701697587966919
Iteration [25845]: Loss = 0.7019172310829163
Iteration [25846]: Loss = 0.7020779252052307
Iteration [25847]: Loss = 0.7021853923797607
Iteration [25848]: Loss = 0.7022448778152466
Iteration [25849]: Loss = 4.934092044830322
Iteration [25850]: Loss = 0.7024694085121155
Iteration [25851]: Loss = 0.7026195526123047
Iteration [25852]: Loss = 0.702717661857605
Iteration [25853]: Loss = 0.7027685642242432
Iteration [25854]: Loss = 0.702777087688446
Iteration [25855]: Loss = 0.702747642993927
Iteration [25856]: Loss = 4.931896209716797
Iteration [25857]: Loss = 0.7028197050094604
Iteration [25858]: Loss = 0.7029049396514893
Iteration [25859]: Loss = 0.7029445171356201
Iteration [25860]: Loss = 0.7029426097869873
Iteration [25861]: Loss = 0.7029037475585938
Iteration [25862]: Loss = 0.7028312683105469
Iteration [25863]: Loss = 0.7027287483215332
Iteration [25864]: Loss = 0.7025989294052124
Iteration [25865]: Loss = 0.7024447321891785
Iteration [25866]: Loss = 0.7022686004638672
Iteration [25867]: Loss = 0.7020725011825562
Iteration [25868]: Loss = 0.7018588185310364
Iteration [25869]: Loss = 0.7016289234161377
Iteration [25870]: Loss = 0.7013845443725586
Iteration [25871]: Loss = 4.939995288848877
Iteration [25872]: Loss = 0.7010906934738159
Iteration [25873]: Loss = 4.940553188323975
Iteration [25874]: Loss = 0.7011514902114868
Iteration [25875]: Loss = 0.7012322545051575
Iteration [25876]: Loss = 0.7012677192687988
Iteration [25877]: Loss = 0.701262354850769
Iteration [25878]: Loss = 0.7012200951576233
Iteration [25879]: Loss = 0.7011447548866272
Iteration [25880]: Loss = 0.7010395526885986
Iteration [25881]: Loss = 0.7009074687957764
Iteration [25882]: Loss = 0.7007513046264648
Iteration [25883]: Loss = 0.7005732655525208
Iteration [25884]: Loss = 0.7003757357597351
Iteration [25885]: Loss = 0.7001605033874512
Iteration [25886]: Loss = 0.6999292969703674
Iteration [25887]: Loss = 4.947535037994385
Iteration [25888]: Loss = 9.195677757263184
Iteration [25889]: Loss = 0.700059175491333
Iteration [25890]: Loss = 0.7003830671310425
Iteration [25891]: Loss = 4.942549705505371
Iteration [25892]: Loss = 0.7010598182678223
Iteration [25893]: Loss = 0.7014027833938599
Iteration [25894]: Loss = 0.7016748189926147
Iteration [25895]: Loss = 4.936060905456543
Iteration [25896]: Loss = 0.7022623419761658
Iteration [25897]: Loss = 0.7025673389434814
Iteration [25898]: Loss = 0.7028048038482666
Iteration [25899]: Loss = 4.930349349975586
Iteration [25900]: Loss = 0.7033329606056213
Iteration [25901]: Loss = 0.7036125659942627
Iteration [25902]: Loss = 0.7038270235061646
Iteration [25903]: Loss = 0.703982949256897
Iteration [25904]: Loss = 0.7019292712211609
Iteration [25905]: Loss = 0.7019846439361572
Iteration [25906]: Loss = 0.7019972801208496
Iteration [25907]: Loss = 0.7019714713096619
Iteration [25908]: Loss = 0.7019110918045044
Iteration [25909]: Loss = 0.7018194794654846
Iteration [25910]: Loss = 0.7016998529434204
Iteration [25911]: Loss = 0.7015548944473267
Iteration [25912]: Loss = 0.7013871669769287
Iteration [25913]: Loss = 0.701198935508728
Iteration [25914]: Loss = 0.7009922862052917
Iteration [25915]: Loss = 0.7007690668106079
Iteration [25916]: Loss = 0.700531005859375
Iteration [25917]: Loss = 0.7002794742584229
Iteration [25918]: Loss = 0.7000157237052917
Iteration [25919]: Loss = 0.6997412443161011
Iteration [25920]: Loss = 0.6994568705558777
Iteration [25921]: Loss = 0.6991638541221619
Iteration [25922]: Loss = 0.6988629102706909
Iteration [25923]: Loss = 0.6985548138618469
Iteration [25924]: Loss = 0.6982402801513672
Iteration [25925]: Loss = 0.6979201436042786
Iteration [25926]: Loss = 0.6975948810577393
Iteration [25927]: Loss = 0.6972649097442627
Iteration [25928]: Loss = 9.227035522460938
Iteration [25929]: Loss = 0.6932903528213501
Iteration [25930]: Loss = 0.6933648586273193
Iteration [25931]: Loss = 0.6912451386451721
Iteration [25932]: Loss = 0.6912362575531006
Iteration [25933]: Loss = 0.6911917924880981
Iteration [25934]: Loss = 0.6911154389381409
Iteration [25935]: Loss = 0.6910101771354675
Iteration [25936]: Loss = 0.690879225730896
Iteration [25937]: Loss = 0.6907248497009277
Iteration [25938]: Loss = 0.690549373626709
Iteration [25939]: Loss = 0.690355122089386
Iteration [25940]: Loss = 0.6901437044143677
Iteration [25941]: Loss = 0.6899170875549316
Iteration [25942]: Loss = 0.6896765232086182
Iteration [25943]: Loss = 0.689423680305481
Iteration [25944]: Loss = 0.6891598105430603
Iteration [25945]: Loss = 5.00474739074707
Iteration [25946]: Loss = 0.6888346076011658
Iteration [25947]: Loss = 0.6887519955635071
Iteration [25948]: Loss = 0.6886414885520935
Iteration [25949]: Loss = 0.6885055303573608
Iteration [25950]: Loss = 0.6883468627929688
Iteration [25951]: Loss = 0.6881676912307739
Iteration [25952]: Loss = 0.687969982624054
Iteration [25953]: Loss = 0.6877557039260864
Iteration [25954]: Loss = 0.6875265836715698
Iteration [25955]: Loss = 0.6872838139533997
Iteration [25956]: Loss = 5.01473331451416
Iteration [25957]: Loss = 0.6869955658912659
Iteration [25958]: Loss = 0.6869292259216309
Iteration [25959]: Loss = 0.6868331432342529
Iteration [25960]: Loss = 0.6867103576660156
Iteration [25961]: Loss = 0.6865635514259338
Iteration [25962]: Loss = 0.6863950490951538
Iteration [25963]: Loss = 0.6862070560455322
Iteration [25964]: Loss = 0.6860016584396362
Iteration [25965]: Loss = 0.68578040599823
Iteration [25966]: Loss = 0.6855449080467224
Iteration [25967]: Loss = 0.6852965354919434
Iteration [25968]: Loss = 0.685036838054657
Iteration [25969]: Loss = 0.6847668290138245
Iteration [25970]: Loss = 0.6844874024391174
Iteration [25971]: Loss = 5.030034065246582
Iteration [25972]: Loss = 0.6841375827789307
Iteration [25973]: Loss = 0.6840453743934631
Iteration [25974]: Loss = 0.6839262247085571
Iteration [25975]: Loss = 0.6837828159332275
Iteration [25976]: Loss = 0.6836174130439758
Iteration [25977]: Loss = 5.034201622009277
Iteration [25978]: Loss = 0.6834625005722046
Iteration [25979]: Loss = 0.6834535598754883
Iteration [25980]: Loss = 0.6834093332290649
Iteration [25981]: Loss = 0.6833333373069763
Iteration [25982]: Loss = 0.6832287311553955
Iteration [25983]: Loss = 5.036017417907715
Iteration [25984]: Loss = 5.035586833953857
Iteration [25985]: Loss = 0.6823797225952148
Iteration [25986]: Loss = 5.038817405700684
Iteration [25987]: Loss = 0.6858912706375122
Iteration [25988]: Loss = 0.6861934661865234
Iteration [25989]: Loss = 0.6934852004051208
Iteration [25990]: Loss = 0.6930599212646484
Iteration [25991]: Loss = 0.6931796073913574
Iteration [25992]: Loss = 0.6930354833602905
Iteration [25993]: Loss = 0.6930623054504395
Iteration [25994]: Loss = 0.693049430847168
Iteration [25995]: Loss = 0.6930010318756104
Iteration [25996]: Loss = 0.6929203867912292
Iteration [25997]: Loss = 0.6928108930587769
Iteration [25998]: Loss = 0.6926754713058472
Iteration [25999]: Loss = 0.6925164461135864
Iteration [26000]: Loss = 0.69233638048172
Iteration [26001]: Loss = 0.6921371221542358
Iteration [26002]: Loss = 4.988519191741943
Iteration [26003]: Loss = 0.6919233798980713
Iteration [26004]: Loss = 0.6918885707855225
Iteration [26005]: Loss = 0.6918203234672546
Iteration [26006]: Loss = 0.6917218565940857
Iteration [26007]: Loss = 0.6915963888168335
Iteration [26008]: Loss = 0.6914465427398682
Iteration [26009]: Loss = 0.6912745237350464
Iteration [26010]: Loss = 0.6910829544067383
Iteration [26011]: Loss = 0.690873384475708
Iteration [26012]: Loss = 0.6906479001045227
Iteration [26013]: Loss = 4.996593952178955
Iteration [26014]: Loss = 0.6903893947601318
Iteration [26015]: Loss = 0.6905582547187805
Iteration [26016]: Loss = 0.6904733777046204
Iteration [26017]: Loss = 0.6903599500656128
Iteration [26018]: Loss = 0.6902210116386414
Iteration [26019]: Loss = 0.6900590062141418
Iteration [26020]: Loss = 0.6905513405799866
Iteration [26021]: Loss = 0.6896749138832092
Iteration [26022]: Loss = 0.689456582069397
Iteration [26023]: Loss = 0.6892233490943909
Iteration [26024]: Loss = 0.6889764070510864
Iteration [26025]: Loss = 0.6887171864509583
Iteration [26026]: Loss = 0.688447117805481
Iteration [26027]: Loss = 0.6881670951843262
Iteration [26028]: Loss = 0.6878781318664551
Iteration [26029]: Loss = 0.6875811815261841
Iteration [26030]: Loss = 0.6872770190238953
Iteration [26031]: Loss = 0.6869663000106812
Iteration [26032]: Loss = 0.6866500377655029
Iteration [26033]: Loss = 0.6863282918930054
Iteration [26034]: Loss = 0.6860018968582153
Iteration [26035]: Loss = 5.022062301635742
Iteration [26036]: Loss = 0.6838734149932861
Iteration [26037]: Loss = 0.6837486028671265
Iteration [26038]: Loss = 9.38298225402832
Iteration [26039]: Loss = 0.6838969588279724
Iteration [26040]: Loss = 0.6841282844543457
Iteration [26041]: Loss = 0.6843003630638123
Iteration [26042]: Loss = 0.6844190359115601
Iteration [26043]: Loss = 0.6844895482063293
Iteration [26044]: Loss = 5.028315544128418
Iteration [26045]: Loss = 0.6847378015518188
Iteration [26046]: Loss = 5.026233196258545
Iteration [26047]: Loss = 5.02437686920166
Iteration [26048]: Loss = 5.02164888381958
Iteration [26049]: Loss = 9.35995864868164
Iteration [26050]: Loss = 0.6857304573059082
Iteration [26051]: Loss = 0.6865787506103516
Iteration [26052]: Loss = 0.6873073577880859
Iteration [26053]: Loss = 0.687927782535553
Iteration [26054]: Loss = 0.6884506344795227
Iteration [26055]: Loss = 0.6888854503631592
Iteration [26056]: Loss = 0.6892410516738892
Iteration [26057]: Loss = 0.6895250082015991
Iteration [26058]: Loss = 5.0001444816589355
Iteration [26059]: Loss = 0.6901357769966125
Iteration [26060]: Loss = 0.6904520988464355
Iteration [26061]: Loss = 0.6907004714012146
Iteration [26062]: Loss = 0.690887987613678
Iteration [26063]: Loss = 0.6910203695297241
Iteration [26064]: Loss = 4.992880821228027
Iteration [26065]: Loss = 0.6913716197013855
Iteration [26066]: Loss = 0.6915770769119263
Iteration [26067]: Loss = 0.6917255520820618
Iteration [26068]: Loss = 0.6918230056762695
Iteration [26069]: Loss = 0.691874086856842
Iteration [26070]: Loss = 0.6918836832046509
Iteration [26071]: Loss = 0.6918559074401855
Iteration [26072]: Loss = 0.6917942762374878
Iteration [26073]: Loss = 0.6917023658752441
Iteration [26074]: Loss = 0.6915830373764038
Iteration [26075]: Loss = 4.991088390350342
Iteration [26076]: Loss = 0.6915042400360107
Iteration [26077]: Loss = 0.6915262937545776
Iteration [26078]: Loss = 0.6915099024772644
Iteration [26079]: Loss = 0.6936190128326416
Iteration [26080]: Loss = 0.6935359835624695
Iteration [26081]: Loss = 0.693424642086029
Iteration [26082]: Loss = 0.6932876110076904
Iteration [26083]: Loss = 4.9820990562438965
Iteration [26084]: Loss = 0.6931785345077515
Iteration [26085]: Loss = 4.981780529022217
Iteration [26086]: Loss = 4.980704307556152
Iteration [26087]: Loss = 0.6937664151191711
Iteration [26088]: Loss = 0.7011718153953552
Iteration [26089]: Loss = 0.6942983269691467
Iteration [26090]: Loss = 0.6944685578346252
Iteration [26091]: Loss = 4.97437047958374
Iteration [26092]: Loss = 0.6948837637901306
Iteration [26093]: Loss = 0.6951160430908203
Iteration [26094]: Loss = 4.97064733505249
Iteration [26095]: Loss = 4.9688029289245605
Iteration [26096]: Loss = 4.966125965118408
Iteration [26097]: Loss = 0.6967942118644714
Iteration [26098]: Loss = 0.6973425149917603
Iteration [26099]: Loss = 0.697799801826477
Iteration [26100]: Loss = 0.6981748342514038
Iteration [26101]: Loss = 0.6984758377075195
Iteration [26102]: Loss = 0.698710024356842
Iteration [26103]: Loss = 4.951722621917725
Iteration [26104]: Loss = 0.6992336511611938
Iteration [26105]: Loss = 0.699511706829071
Iteration [26106]: Loss = 0.6997250318527222
Iteration [26107]: Loss = 0.6998803019523621
Iteration [26108]: Loss = 0.6999830603599548
Iteration [26109]: Loss = 0.700038492679596
Iteration [26110]: Loss = 0.7000513672828674
Iteration [26111]: Loss = 0.7000259160995483
Iteration [26112]: Loss = 0.6999658942222595
Iteration [26113]: Loss = 0.6998748183250427
Iteration [26114]: Loss = 0.6997556686401367
Iteration [26115]: Loss = 0.6996113061904907
Iteration [26116]: Loss = 0.6994441747665405
Iteration [26117]: Loss = 0.6992565393447876
Iteration [26118]: Loss = 0.6990506649017334
Iteration [26119]: Loss = 0.6988282203674316
Iteration [26120]: Loss = 0.6985907554626465
Iteration [26121]: Loss = 0.6983399391174316
Iteration [26122]: Loss = 0.6980772018432617
Iteration [26123]: Loss = 0.6978033781051636
Iteration [26124]: Loss = 0.6975200176239014
Iteration [26125]: Loss = 0.6972277760505676
Iteration [26126]: Loss = 0.6969276666641235
Iteration [26127]: Loss = 4.963618755340576
Iteration [26128]: Loss = 4.964045524597168
Iteration [26129]: Loss = 0.6966611742973328
Iteration [26130]: Loss = 0.6967339515686035
Iteration [26131]: Loss = 0.6967624425888062
Iteration [26132]: Loss = 0.696751058101654
Iteration [26133]: Loss = 0.6967039108276367
Iteration [26134]: Loss = 0.6966243386268616
Iteration [26135]: Loss = 0.6965158581733704
Iteration [26136]: Loss = 0.6963810324668884
Iteration [26137]: Loss = 0.6962226033210754
Iteration [26138]: Loss = 0.6960430145263672
Iteration [26139]: Loss = 0.6958443522453308
Iteration [26140]: Loss = 0.6956284046173096
Iteration [26141]: Loss = 0.695397138595581
Iteration [26142]: Loss = 0.6951519250869751
Iteration [26143]: Loss = 0.6948940753936768
Iteration [26144]: Loss = 0.6946249008178711
Iteration [26145]: Loss = 0.6943458318710327
Iteration [26146]: Loss = 0.6940575242042542
Iteration [26147]: Loss = 0.6937609314918518
Iteration [26148]: Loss = 0.6934571862220764
Iteration [26149]: Loss = 0.6931467056274414
Iteration [26150]: Loss = 4.983679294586182
Iteration [26151]: Loss = 0.692742109298706
Iteration [26152]: Loss = 0.6926259398460388
Iteration [26153]: Loss = 0.692484438419342
Iteration [26154]: Loss = 4.986393451690674
Iteration [26155]: Loss = 0.6923684477806091
Iteration [26156]: Loss = 0.6923752427101135
Iteration [26157]: Loss = 0.6923444271087646
Iteration [26158]: Loss = 0.6922797560691833
Iteration [26159]: Loss = 0.6921849250793457
Iteration [26160]: Loss = 0.6920623779296875
Iteration [26161]: Loss = 4.988550186157227
Iteration [26162]: Loss = 0.6919792890548706
Iteration [26163]: Loss = 4.988098621368408
Iteration [26164]: Loss = 0.6922146081924438
Iteration [26165]: Loss = 0.6923710703849792
Iteration [26166]: Loss = 0.6924753189086914
Iteration [26167]: Loss = 0.6925320029258728
Iteration [26168]: Loss = 0.6925463080406189
Iteration [26169]: Loss = 0.6925222873687744
Iteration [26170]: Loss = 0.692463755607605
Iteration [26171]: Loss = 0.6923741698265076
Iteration [26172]: Loss = 0.6922564506530762
Iteration [26173]: Loss = 0.6921135783195496
Iteration [26174]: Loss = 0.6919480562210083
Iteration [26175]: Loss = 0.6917622089385986
Iteration [26176]: Loss = 0.6915578842163086
Iteration [26177]: Loss = 4.991632461547852
Iteration [26178]: Loss = 0.691335141658783
Iteration [26179]: Loss = 0.6912967562675476
Iteration [26180]: Loss = 0.6912252306938171
Iteration [26181]: Loss = 0.691123902797699
Iteration [26182]: Loss = 0.6909958720207214
Iteration [26183]: Loss = 4.994266033172607
Iteration [26184]: Loss = 4.993945121765137
Iteration [26185]: Loss = 0.6911540031433105
Iteration [26186]: Loss = 0.6913427114486694
Iteration [26187]: Loss = 0.6914757490158081
Iteration [26188]: Loss = 0.6915587186813354
Iteration [26189]: Loss = 0.691596508026123
Iteration [26190]: Loss = 0.6915937066078186
Iteration [26191]: Loss = 0.691554069519043
Iteration [26192]: Loss = 0.6914817094802856
Iteration [26193]: Loss = 0.6913794875144958
Iteration [26194]: Loss = 0.6912505030632019
Iteration [26195]: Loss = 0.6910973787307739
Iteration [26196]: Loss = 0.6909225583076477
Iteration [26197]: Loss = 0.6907281875610352
Iteration [26198]: Loss = 4.99601411819458
Iteration [26199]: Loss = 0.6905232667922974
Iteration [26200]: Loss = 0.6904925107955933
Iteration [26201]: Loss = 0.6904279589653015
Iteration [26202]: Loss = 0.6903328895568848
Iteration [26203]: Loss = 0.6902103424072266
Iteration [26204]: Loss = 4.998439788818359
Iteration [26205]: Loss = 0.6901280879974365
Iteration [26206]: Loss = 0.69014972448349
Iteration [26207]: Loss = 0.690132200717926
Iteration [26208]: Loss = 0.6900796890258789
Iteration [26209]: Loss = 0.6899954676628113
Iteration [26210]: Loss = 0.6898826360702515
Iteration [26211]: Loss = 0.6897440552711487
Iteration [26212]: Loss = 0.6895824670791626
Iteration [26213]: Loss = 0.6894001364707947
Iteration [26214]: Loss = 0.689198911190033
Iteration [26215]: Loss = 0.6889809370040894
Iteration [26216]: Loss = 0.6887477040290833
Iteration [26217]: Loss = 0.6885008215904236
Iteration [26218]: Loss = 0.688241720199585
Iteration [26219]: Loss = 5.009659290313721
Iteration [26220]: Loss = 0.6879269480705261
Iteration [26221]: Loss = 0.6878499984741211
Iteration [26222]: Loss = 0.6877439022064209
Iteration [26223]: Loss = 0.68761146068573
Iteration [26224]: Loss = 0.6874552965164185
Iteration [26225]: Loss = 0.6872779726982117
Iteration [26226]: Loss = 0.6870814561843872
Iteration [26227]: Loss = 0.6868675351142883
Iteration [26228]: Loss = 0.6866381168365479
Iteration [26229]: Loss = 0.6863948106765747
Iteration [26230]: Loss = 0.686138927936554
Iteration [26231]: Loss = 0.6858717203140259
Iteration [26232]: Loss = 0.6855943202972412
Iteration [26233]: Loss = 0.6853078603744507
Iteration [26234]: Loss = 0.6850131154060364
Iteration [26235]: Loss = 0.6847110390663147
Iteration [26236]: Loss = 0.6844022870063782
Iteration [26237]: Loss = 0.6840875744819641
Iteration [26238]: Loss = 0.6837674379348755
Iteration [26239]: Loss = 0.6834425926208496
Iteration [26240]: Loss = 0.6831132769584656
Iteration [26241]: Loss = 5.037747859954834
Iteration [26242]: Loss = 0.6826807856559753
Iteration [26243]: Loss = 0.6825547218322754
Iteration [26244]: Loss = 0.6824044585227966
Iteration [26245]: Loss = 0.6822322607040405
Iteration [26246]: Loss = 0.6820408701896667
Iteration [26247]: Loss = 0.6818315982818604
Iteration [26248]: Loss = 0.6816068291664124
Iteration [26249]: Loss = 0.6813675761222839
Iteration [26250]: Loss = 0.6811155676841736
Iteration [26251]: Loss = 0.6808519959449768
Iteration [26252]: Loss = 0.6805781722068787
Iteration [26253]: Loss = 0.6802949905395508
Iteration [26254]: Loss = 0.6800034046173096
Iteration [26255]: Loss = 0.6797043085098267
Iteration [26256]: Loss = 0.6793983578681946
Iteration [26257]: Loss = 0.679086446762085
Iteration [26258]: Loss = 0.6787691116333008
Iteration [26259]: Loss = 9.444477081298828
Iteration [26260]: Loss = 0.6812450289726257
Iteration [26261]: Loss = 0.6813416481018066
Iteration [26262]: Loss = 0.6813923120498657
Iteration [26263]: Loss = 0.6814013719558716
Iteration [26264]: Loss = 0.6813730001449585
Iteration [26265]: Loss = 5.045761585235596
Iteration [26266]: Loss = 0.6814541816711426
Iteration [26267]: Loss = 0.6815469264984131
Iteration [26268]: Loss = 0.6815937757492065
Iteration [26269]: Loss = 0.6815994381904602
Iteration [26270]: Loss = 0.6815680861473083
Iteration [26271]: Loss = 0.6815033555030823
Iteration [26272]: Loss = 0.6814084053039551
Iteration [26273]: Loss = 0.6812865734100342
Iteration [26274]: Loss = 0.6811401844024658
Iteration [26275]: Loss = 0.6809719800949097
Iteration [26276]: Loss = 0.6807838082313538
Iteration [26277]: Loss = 0.6805779933929443
Iteration [26278]: Loss = 0.680355966091156
Iteration [26279]: Loss = 5.0522780418396
Iteration [26280]: Loss = 0.6801074743270874
Iteration [26281]: Loss = 0.6800597310066223
Iteration [26282]: Loss = 0.6799803972244263
Iteration [26283]: Loss = 0.6798723936080933
Iteration [26284]: Loss = 0.6797386407852173
Iteration [26285]: Loss = 0.6795817613601685
Iteration [26286]: Loss = 0.6794039011001587
Iteration [26287]: Loss = 0.6792073845863342
Iteration [26288]: Loss = 0.678993821144104
Iteration [26289]: Loss = 0.6787651181221008
Iteration [26290]: Loss = 0.6785228252410889
Iteration [26291]: Loss = 0.6782680153846741
Iteration [26292]: Loss = 0.6780024170875549
Iteration [26293]: Loss = 9.453125953674316
Iteration [26294]: Loss = 0.677915096282959
Iteration [26295]: Loss = 0.6780486702919006
Iteration [26296]: Loss = 0.678132951259613
Iteration [26297]: Loss = 5.062971591949463
Iteration [26298]: Loss = 0.6784067749977112
Iteration [26299]: Loss = 0.6785816550254822
Iteration [26300]: Loss = 0.6787030100822449
Iteration [26301]: Loss = 0.6787760257720947
Iteration [26302]: Loss = 0.6788057088851929
Iteration [26303]: Loss = 0.6787959933280945
Iteration [26304]: Loss = 0.6787511110305786
Iteration [26305]: Loss = 0.6786743402481079
Iteration [26306]: Loss = 0.6785690188407898
Iteration [26307]: Loss = 0.6784378886222839
Iteration [26308]: Loss = 0.6782835721969604
Iteration [26309]: Loss = 0.6781083345413208
Iteration [26310]: Loss = 0.6779143810272217
Iteration [26311]: Loss = 0.6777035593986511
Iteration [26312]: Loss = 5.066800594329834
Iteration [26313]: Loss = 0.6774739027023315
Iteration [26314]: Loss = 0.6774344444274902
Iteration [26315]: Loss = 0.6773626804351807
Iteration [26316]: Loss = 0.6772619485855103
Iteration [26317]: Loss = 0.6771350502967834
Iteration [26318]: Loss = 0.6769843697547913
Iteration [26319]: Loss = 0.6768126487731934
Iteration [26320]: Loss = 0.6766217350959778
Iteration [26321]: Loss = 0.6764135956764221
Iteration [26322]: Loss = 5.073908805847168
Iteration [26323]: Loss = 5.073912620544434
Iteration [26324]: Loss = 0.6763882040977478
Iteration [26325]: Loss = 0.6765312552452087
Iteration [26326]: Loss = 0.6766238808631897
Iteration [26327]: Loss = 0.6766711473464966
Iteration [26328]: Loss = 5.071214199066162
Iteration [26329]: Loss = 0.676882803440094
Iteration [26330]: Loss = 5.0692596435546875
Iteration [26331]: Loss = 5.067422866821289
Iteration [26332]: Loss = 0.6778626441955566
Iteration [26333]: Loss = 0.6782754063606262
Iteration [26334]: Loss = 0.6786109209060669
Iteration [26335]: Loss = 0.6788768768310547
Iteration [26336]: Loss = 0.6790801882743835
Iteration [26337]: Loss = 0.6792268753051758
Iteration [26338]: Loss = 0.6793228387832642
Iteration [26339]: Loss = 5.0563740730285645
Iteration [26340]: Loss = 0.6796168684959412
Iteration [26341]: Loss = 0.6798002123832703
Iteration [26342]: Loss = 0.6799291372299194
Iteration [26343]: Loss = 0.6800088882446289
Iteration [26344]: Loss = 0.6800441741943359
Iteration [26345]: Loss = 0.680039644241333
Iteration [26346]: Loss = 0.6799991130828857
Iteration [26347]: Loss = 0.6799262166023254
Iteration [26348]: Loss = 5.053897857666016
Iteration [26349]: Loss = 5.05330753326416
Iteration [26350]: Loss = 0.680227518081665
Iteration [26351]: Loss = 0.680457592010498
Iteration [26352]: Loss = 0.6806282997131348
Iteration [26353]: Loss = 0.6807457208633423
Iteration [26354]: Loss = 0.6808150410652161
Iteration [26355]: Loss = 5.048330783843994
Iteration [26356]: Loss = 0.6818267703056335
Iteration [26357]: Loss = 0.6819902658462524
Iteration [26358]: Loss = 0.6821008920669556
Iteration [26359]: Loss = 0.6821641325950623
Iteration [26360]: Loss = 5.040994644165039
Iteration [26361]: Loss = 0.6824016571044922
Iteration [26362]: Loss = 0.6825606822967529
Iteration [26363]: Loss = 0.6826674342155457
Iteration [26364]: Loss = 0.6827268600463867
Iteration [26365]: Loss = 0.6827438473701477
Iteration [26366]: Loss = 0.6827226281166077
Iteration [26367]: Loss = 0.6826668381690979
Iteration [26368]: Loss = 0.6825798749923706
Iteration [26369]: Loss = 0.682465136051178
Iteration [26370]: Loss = 0.682325005531311
Iteration [26371]: Loss = 0.6821622848510742
Iteration [26372]: Loss = 0.6819790601730347
Iteration [26373]: Loss = 0.6817775964736938
Iteration [26374]: Loss = 0.6815596222877502
Iteration [26375]: Loss = 0.6813267469406128
Iteration [26376]: Loss = 0.6810802817344666
Iteration [26377]: Loss = 0.68082195520401
Iteration [26378]: Loss = 0.6805528402328491
Iteration [26379]: Loss = 0.6802738308906555
Iteration [26380]: Loss = 0.6799861788749695
Iteration [26381]: Loss = 0.6796905994415283
Iteration [26382]: Loss = 0.6793878674507141
Iteration [26383]: Loss = 5.057988166809082
Iteration [26384]: Loss = 0.6790018081665039
Iteration [26385]: Loss = 0.6788961291313171
Iteration [26386]: Loss = 0.6787641644477844
Iteration [26387]: Loss = 0.6786090135574341
Iteration [26388]: Loss = 0.6784327626228333
Iteration [26389]: Loss = 0.6782374978065491
Iteration [26390]: Loss = 0.6780253052711487
Iteration [26391]: Loss = 0.677797794342041
Iteration [26392]: Loss = 0.6775563955307007
Iteration [26393]: Loss = 0.6773024797439575
Iteration [26394]: Loss = 5.0692267417907715
Iteration [26395]: Loss = 0.6770006418228149
Iteration [26396]: Loss = 0.6769309639930725
Iteration [26397]: Loss = 0.6768317222595215
Iteration [26398]: Loss = 5.071056365966797
Iteration [26399]: Loss = 0.6767939925193787
Iteration [26400]: Loss = 5.070333480834961
Iteration [26401]: Loss = 0.677075982093811
Iteration [26402]: Loss = 0.6772550940513611
Iteration [26403]: Loss = 0.6773799657821655
Iteration [26404]: Loss = 0.6774559020996094
Iteration [26405]: Loss = 0.677487850189209
Iteration [26406]: Loss = 0.6774801015853882
Iteration [26407]: Loss = 0.6774366497993469
Iteration [26408]: Loss = 5.067441463470459
Iteration [26409]: Loss = 0.6774941086769104
Iteration [26410]: Loss = 0.6775773167610168
Iteration [26411]: Loss = 5.066037654876709
Iteration [26412]: Loss = 0.677851140499115
Iteration [26413]: Loss = 0.6780266165733337
Iteration [26414]: Loss = 0.678148090839386
Iteration [26415]: Loss = 5.062704086303711
Iteration [26416]: Loss = 0.6784870624542236
Iteration [26417]: Loss = 0.6786901950836182
Iteration [26418]: Loss = 0.6788365840911865
Iteration [26419]: Loss = 0.6789319515228271
Iteration [26420]: Loss = 5.058523654937744
Iteration [26421]: Loss = 0.6792259812355042
Iteration [26422]: Loss = 0.6794098019599915
Iteration [26423]: Loss = 0.6795389652252197
Iteration [26424]: Loss = 5.055026531219482
Iteration [26425]: Loss = 0.6798904538154602
Iteration [26426]: Loss = 0.6800987124443054
Iteration [26427]: Loss = 0.6802496314048767
Iteration [26428]: Loss = 0.6803489923477173
Iteration [26429]: Loss = 5.0507330894470215
Iteration [26430]: Loss = 0.68064945936203
Iteration [26431]: Loss = 0.6808359622955322
Iteration [26432]: Loss = 0.6809672713279724
Iteration [26433]: Loss = 0.6810488104820251
Iteration [26434]: Loss = 0.6810855865478516
Iteration [26435]: Loss = 5.047013282775879
Iteration [26436]: Loss = 0.6812789440155029
Iteration [26437]: Loss = 0.6814196705818176
Iteration [26438]: Loss = 5.044675350189209
Iteration [26439]: Loss = 0.6817907094955444
Iteration [26440]: Loss = 0.6820069551467896
Iteration [26441]: Loss = 5.0410990715026855
Iteration [26442]: Loss = 0.6825070977210999
Iteration [26443]: Loss = 0.6827782988548279
Iteration [26444]: Loss = 0.6829859018325806
Iteration [26445]: Loss = 5.035811424255371
Iteration [26446]: Loss = 5.033992290496826
Iteration [26447]: Loss = 5.031275749206543
Iteration [26448]: Loss = 0.6846192479133606
Iteration [26449]: Loss = 0.6851667165756226
Iteration [26450]: Loss = 0.685623049736023
Iteration [26451]: Loss = 0.685997486114502
Iteration [26452]: Loss = 0.6862976551055908
Iteration [26453]: Loss = 0.6865313053131104
Iteration [26454]: Loss = 0.6867047548294067
Iteration [26455]: Loss = 5.015839576721191
Iteration [26456]: Loss = 0.6871299147605896
Iteration [26457]: Loss = 0.6873688697814941
Iteration [26458]: Loss = 5.011944770812988
Iteration [26459]: Loss = 0.6879056096076965
Iteration [26460]: Loss = 0.6881917715072632
Iteration [26461]: Loss = 0.6884125471115112
Iteration [26462]: Loss = 0.6885743141174316
Iteration [26463]: Loss = 0.6886827945709229
Iteration [26464]: Loss = 0.688743531703949
Iteration [26465]: Loss = 0.6887611150741577
Iteration [26466]: Loss = 0.6887397766113281
Iteration [26467]: Loss = 0.688683271408081
Iteration [26468]: Loss = 0.6885954737663269
Iteration [26469]: Loss = 0.6884791851043701
Iteration [26470]: Loss = 0.6883374452590942
Iteration [26471]: Loss = 0.6881725192070007
Iteration [26472]: Loss = 5.009576797485352
Iteration [26473]: Loss = 5.009399890899658
Iteration [26474]: Loss = 0.6882482171058655
Iteration [26475]: Loss = 0.6884170174598694
Iteration [26476]: Loss = 0.6885318756103516
Iteration [26477]: Loss = 0.6885981559753418
Iteration [26478]: Loss = 0.6886207461357117
Iteration [26479]: Loss = 0.6886039972305298
Iteration [26480]: Loss = 0.688551664352417
Iteration [26481]: Loss = 0.6884674429893494
Iteration [26482]: Loss = 0.6883543729782104
Iteration [26483]: Loss = 0.6882154941558838
Iteration [26484]: Loss = 0.6880531907081604
Iteration [26485]: Loss = 0.6878699064254761
Iteration [26486]: Loss = 0.6876676678657532
Iteration [26487]: Loss = 5.0124735832214355
Iteration [26488]: Loss = 5.012457370758057
Iteration [26489]: Loss = 0.687653660774231
Iteration [26490]: Loss = 0.6877985596656799
Iteration [26491]: Loss = 0.687891960144043
Iteration [26492]: Loss = 0.687938928604126
Iteration [26493]: Loss = 0.6879440546035767
Iteration [26494]: Loss = 0.6879115700721741
Iteration [26495]: Loss = 0.6878451108932495
Iteration [26496]: Loss = 5.010861396789551
Iteration [26497]: Loss = 0.6878606677055359
Iteration [26498]: Loss = 5.009910583496094
Iteration [26499]: Loss = 0.6881819367408752
Iteration [26500]: Loss = 5.007482528686523
Iteration [26501]: Loss = 0.6887503266334534
Iteration [26502]: Loss = 5.003866672515869
Iteration [26503]: Loss = 0.6895182132720947
Iteration [26504]: Loss = 4.999297142028809
Iteration [26505]: Loss = 0.6904470920562744
Iteration [26506]: Loss = 0.6909002661705017
Iteration [26507]: Loss = 0.6912713646888733
Iteration [26508]: Loss = 0.6915683150291443
Iteration [26509]: Loss = 0.6917984485626221
Iteration [26510]: Loss = 0.6919683814048767
Iteration [26511]: Loss = 0.6920840740203857
Iteration [26512]: Loss = 0.692150890827179
Iteration [26513]: Loss = 0.6921736001968384
Iteration [26514]: Loss = 0.6921565532684326
Iteration [26515]: Loss = 0.6921040415763855
Iteration [26516]: Loss = 4.987995624542236
Iteration [26517]: Loss = 0.6921420693397522
Iteration [26518]: Loss = 0.6922152042388916
Iteration [26519]: Loss = 0.6922436356544495
Iteration [26520]: Loss = 0.6922319531440735
Iteration [26521]: Loss = 0.6921839714050293
Iteration [26522]: Loss = 0.6921030879020691
Iteration [26523]: Loss = 0.6919930577278137
Iteration [26524]: Loss = 0.6918565034866333
Iteration [26525]: Loss = 0.6916959881782532
Iteration [26526]: Loss = 0.6915140748023987
Iteration [26527]: Loss = 0.691312849521637
Iteration [26528]: Loss = 0.6910942792892456
Iteration [26529]: Loss = 0.6908600330352783
Iteration [26530]: Loss = 4.995505332946777
Iteration [26531]: Loss = 0.6905884742736816
Iteration [26532]: Loss = 4.995941162109375
Iteration [26533]: Loss = 0.690677285194397
Iteration [26534]: Loss = 0.6907724142074585
Iteration [26535]: Loss = 0.6908206939697266
Iteration [26536]: Loss = 0.6908267736434937
Iteration [26537]: Loss = 4.994527339935303
Iteration [26538]: Loss = 0.6909656524658203
Iteration [26539]: Loss = 0.6910820007324219
Iteration [26540]: Loss = 0.6911494731903076
Iteration [26541]: Loss = 0.6911727786064148
Iteration [26542]: Loss = 0.6911563873291016
Iteration [26543]: Loss = 0.6911040544509888
Iteration [26544]: Loss = 0.6910196542739868
Iteration [26545]: Loss = 4.993932723999023
Iteration [26546]: Loss = 0.6910037994384766
Iteration [26547]: Loss = 0.6910543441772461
Iteration [26548]: Loss = 0.691062331199646
Iteration [26549]: Loss = 0.6910322308540344
Iteration [26550]: Loss = 0.6909675598144531
Iteration [26551]: Loss = 0.6908719539642334
Iteration [26552]: Loss = 0.6907482743263245
Iteration [26553]: Loss = 0.6905996203422546
Iteration [26554]: Loss = 0.6904281973838806
Iteration [26555]: Loss = 0.6902364492416382
Iteration [26556]: Loss = 0.6900262832641602
Iteration [26557]: Loss = 0.6897997260093689
Iteration [26558]: Loss = 0.6895581483840942
Iteration [26559]: Loss = 0.6893032789230347
Iteration [26560]: Loss = 0.6890363693237305
Iteration [26561]: Loss = 0.6887587308883667
Iteration [26562]: Loss = 0.6884713172912598
Iteration [26563]: Loss = 0.6881751418113708
Iteration [26564]: Loss = 0.6878712177276611
Iteration [26565]: Loss = 0.6875600814819336
Iteration [26566]: Loss = 0.6872428059577942
Iteration [26567]: Loss = 0.686919629573822
Iteration [26568]: Loss = 0.686591386795044
Iteration [26569]: Loss = 0.6862586736679077
Iteration [26570]: Loss = 0.6859216690063477
Iteration [26571]: Loss = 0.6855810880661011
Iteration [26572]: Loss = 0.6852372288703918
Iteration [26573]: Loss = 0.6848902702331543
Iteration [26574]: Loss = 5.028183460235596
Iteration [26575]: Loss = 0.6844287514686584
Iteration [26576]: Loss = 0.6842906475067139
Iteration [26577]: Loss = 5.030416965484619
Iteration [26578]: Loss = 0.6841857433319092
Iteration [26579]: Loss = 0.6841994524002075
Iteration [26580]: Loss = 0.6841745376586914
Iteration [26581]: Loss = 5.030493259429932
Iteration [26582]: Loss = 0.6842632293701172
Iteration [26583]: Loss = 0.6843593716621399
Iteration [26584]: Loss = 0.6844087839126587
Iteration [26585]: Loss = 5.028860569000244
Iteration [26586]: Loss = 0.6846240162849426
Iteration [26587]: Loss = 0.6847741603851318
Iteration [26588]: Loss = 0.6848721504211426
Iteration [26589]: Loss = 5.026111602783203
Iteration [26590]: Loss = 0.6851704120635986
Iteration [26591]: Loss = 0.6853557825088501
Iteration [26592]: Loss = 0.6854854822158813
Iteration [26593]: Loss = 5.022637844085693
Iteration [26594]: Loss = 0.6858376264572144
Iteration [26595]: Loss = 0.6860458850860596
Iteration [26596]: Loss = 0.6861963272094727
Iteration [26597]: Loss = 0.686294436454773
Iteration [26598]: Loss = 0.6863453388214111
Iteration [26599]: Loss = 0.6863539814949036
Iteration [26600]: Loss = 0.6863242983818054
Iteration [26601]: Loss = 0.6862603425979614
Iteration [26602]: Loss = 0.6861652731895447
Iteration [26603]: Loss = 0.6860423684120178
Iteration [26604]: Loss = 0.6858943104743958
Iteration [26605]: Loss = 0.685723602771759
Iteration [26606]: Loss = 0.6855326890945435
Iteration [26607]: Loss = 0.6853233575820923
Iteration [26608]: Loss = 0.6850974559783936
Iteration [26609]: Loss = 0.6848567724227905
Iteration [26610]: Loss = 0.6846027374267578
Iteration [26611]: Loss = 0.6843368411064148
Iteration [26612]: Loss = 0.6840599775314331
Iteration [26613]: Loss = 0.6837734580039978
Iteration [26614]: Loss = 0.6834782361984253
Iteration [26615]: Loss = 0.6831750273704529
Iteration [26616]: Loss = 0.6828649640083313
Iteration [26617]: Loss = 0.682548463344574
Iteration [26618]: Loss = 0.6822262406349182
Iteration [26619]: Loss = 0.6818990707397461
Iteration [26620]: Loss = 0.6815671920776367
Iteration [26621]: Loss = 0.6812312602996826
Iteration [26622]: Loss = 0.6808915138244629
Iteration [26623]: Loss = 0.6805486679077148
Iteration [26624]: Loss = 0.6802026033401489
Iteration [26625]: Loss = 0.6798540353775024
Iteration [26626]: Loss = 0.6795031428337097
Iteration [26627]: Loss = 0.6791499853134155
Iteration [26628]: Loss = 5.0595479011535645
Iteration [26629]: Loss = 0.6786801218986511
Iteration [26630]: Loss = 0.6785396337509155
Iteration [26631]: Loss = 5.0618510246276855
Iteration [26632]: Loss = 0.6784326434135437
Iteration [26633]: Loss = 5.061461925506592
Iteration [26634]: Loss = 0.6786627769470215
Iteration [26635]: Loss = 0.6788203120231628
Iteration [26636]: Loss = 0.678925096988678
Iteration [26637]: Loss = 5.058517932891846
Iteration [26638]: Loss = 5.057118892669678
Iteration [26639]: Loss = 0.6796690821647644
Iteration [26640]: Loss = 5.05281925201416
Iteration [26641]: Loss = 5.049978733062744
Iteration [26642]: Loss = 0.6812082529067993
Iteration [26643]: Loss = 5.0432353019714355
Iteration [26644]: Loss = 0.682483434677124
Iteration [26645]: Loss = 0.683086097240448
Iteration [26646]: Loss = 0.6835918426513672
Iteration [26647]: Loss = 0.6840103268623352
Iteration [26648]: Loss = 0.6843500733375549
Iteration [26649]: Loss = 0.6846187710762024
Iteration [26650]: Loss = 0.6848235726356506
Iteration [26651]: Loss = 0.684970498085022
Iteration [26652]: Loss = 0.6850655674934387
Iteration [26653]: Loss = 9.365043640136719
Iteration [26654]: Loss = 0.6855943202972412
Iteration [26655]: Loss = 0.6859899163246155
Iteration [26656]: Loss = 0.6863090991973877
Iteration [26657]: Loss = 0.6865597367286682
Iteration [26658]: Loss = 0.6867481470108032
Iteration [26659]: Loss = 0.6868806481361389
Iteration [26660]: Loss = 0.6869628429412842
Iteration [26661]: Loss = 0.6869994401931763
Iteration [26662]: Loss = 0.6869952082633972
Iteration [26663]: Loss = 0.686954140663147
Iteration [26664]: Loss = 0.6868799328804016
Iteration [26665]: Loss = 0.6867758631706238
Iteration [26666]: Loss = 5.0168046951293945
Iteration [26667]: Loss = 0.6867278814315796
Iteration [26668]: Loss = 0.6867655515670776
Iteration [26669]: Loss = 5.016172885894775
Iteration [26670]: Loss = 0.6869595050811768
Iteration [26671]: Loss = 0.6871001720428467
Iteration [26672]: Loss = 0.687189519405365
Iteration [26673]: Loss = 0.6872327327728271
Iteration [26674]: Loss = 0.6872344017028809
Iteration [26675]: Loss = 5.013819694519043
Iteration [26676]: Loss = 5.012912750244141
Iteration [26677]: Loss = 5.011020660400391
Iteration [26678]: Loss = 0.6882343292236328
Iteration [26679]: Loss = 5.005949974060059
Iteration [26680]: Loss = 0.6892456412315369
Iteration [26681]: Loss = 5.000198841094971
Iteration [26682]: Loss = 0.6903731226921082
Iteration [26683]: Loss = 0.6909111738204956
Iteration [26684]: Loss = 4.991517543792725
Iteration [26685]: Loss = 0.6919598579406738
Iteration [26686]: Loss = 0.6924641132354736
Iteration [26687]: Loss = 0.6928809881210327
Iteration [26688]: Loss = 0.6932189464569092
Iteration [26689]: Loss = 0.6934857964515686
Iteration [26690]: Loss = 0.6936886310577393
Iteration [26691]: Loss = 0.6938337087631226
Iteration [26692]: Loss = 0.6939267516136169
Iteration [26693]: Loss = 4.9776129722595215
Iteration [26694]: Loss = 0.6942136287689209
Iteration [26695]: Loss = 0.694392740726471
Iteration [26696]: Loss = 0.6945164203643799
Iteration [26697]: Loss = 0.6945900321006775
Iteration [26698]: Loss = 0.694618821144104
Iteration [26699]: Loss = 0.6946070194244385
Iteration [26700]: Loss = 0.6945585608482361
Iteration [26701]: Loss = 0.6944773197174072
Iteration [26702]: Loss = 4.975527763366699
Iteration [26703]: Loss = 0.6944662928581238
Iteration [26704]: Loss = 0.6945184469223022
Iteration [26705]: Loss = 0.6945277452468872
Iteration [26706]: Loss = 0.6944983601570129
Iteration [26707]: Loss = 0.6944342851638794
Iteration [26708]: Loss = 0.6943387985229492
Iteration [26709]: Loss = 0.6942151784896851
Iteration [26710]: Loss = 0.6940659880638123
Iteration [26711]: Loss = 0.69389408826828
Iteration [26712]: Loss = 0.693701446056366
Iteration [26713]: Loss = 4.980173110961914
Iteration [26714]: Loss = 0.6935006976127625
Iteration [26715]: Loss = 0.6934723258018494
Iteration [26716]: Loss = 0.6934090852737427
Iteration [26717]: Loss = 0.6933143138885498
Iteration [26718]: Loss = 0.693191409111023
Iteration [26719]: Loss = 4.982548713684082
Iteration [26720]: Loss = 0.6931097507476807
Iteration [26721]: Loss = 0.6931321620941162
Iteration [26722]: Loss = 0.6931147575378418
Iteration [26723]: Loss = 4.982451438903809
Iteration [26724]: Loss = 0.6932132244110107
Iteration [26725]: Loss = 0.6933122873306274
Iteration [26726]: Loss = 0.6933639049530029
Iteration [26727]: Loss = 4.98079776763916
Iteration [26728]: Loss = 0.6935805082321167
Iteration [26729]: Loss = 0.6937299370765686
Iteration [26730]: Loss = 0.6938266754150391
Iteration [26731]: Loss = 4.97812557220459
Iteration [26732]: Loss = 0.6941204071044922
Iteration [26733]: Loss = 0.6943026185035706
Iteration [26734]: Loss = 0.6944290399551392
Iteration [26735]: Loss = 0.6945049166679382
Iteration [26736]: Loss = 0.6945357322692871
Iteration [26737]: Loss = 0.6945255994796753
Iteration [26738]: Loss = 0.6944785714149475
Iteration [26739]: Loss = 0.6943984627723694
Iteration [26740]: Loss = 0.6942885518074036
Iteration [26741]: Loss = 0.694151759147644
Iteration [26742]: Loss = 0.6939908266067505
Iteration [26743]: Loss = 0.6938080787658691
Iteration [26744]: Loss = 0.6936057806015015
Iteration [26745]: Loss = 0.6933857202529907
Iteration [26746]: Loss = 0.6931499242782593
Iteration [26747]: Loss = 4.983310222625732
Iteration [26748]: Loss = 0.6928757429122925
Iteration [26749]: Loss = 0.692816436290741
Iteration [26750]: Loss = 0.6927251815795898
Iteration [26751]: Loss = 0.692605197429657
Iteration [26752]: Loss = 4.985651016235352
Iteration [26753]: Loss = 0.6925291419029236
Iteration [26754]: Loss = 0.6925542950630188
Iteration [26755]: Loss = 0.6925390362739563
Iteration [26756]: Loss = 0.6924876570701599
Iteration [26757]: Loss = 4.985949516296387
Iteration [26758]: Loss = 4.985283851623535
Iteration [26759]: Loss = 4.983621120452881
Iteration [26760]: Loss = 0.6933221817016602
Iteration [26761]: Loss = 0.6937177777290344
Iteration [26762]: Loss = 0.6940364241600037
Iteration [26763]: Loss = 0.6942854523658752
Iteration [26764]: Loss = 0.6944721341133118
Iteration [26765]: Loss = 0.694602370262146
Iteration [26766]: Loss = 0.6946818828582764
Iteration [26767]: Loss = 0.6947155594825745
Iteration [26768]: Loss = 0.694707989692688
Iteration [26769]: Loss = 0.6946633458137512
Iteration [26770]: Loss = 0.6945852637290955
Iteration [26771]: Loss = 4.974941730499268
Iteration [26772]: Loss = 0.6953027844429016
Iteration [26773]: Loss = 0.695357620716095
Iteration [26774]: Loss = 0.6953689455986023
Iteration [26775]: Loss = 0.6953413486480713
Iteration [26776]: Loss = 0.695278525352478
Iteration [26777]: Loss = 0.6951841115951538
Iteration [26778]: Loss = 0.6950610280036926
Iteration [26779]: Loss = 4.972638130187988
Iteration [26780]: Loss = 0.6949790716171265
Iteration [26781]: Loss = 0.6950014233589172
Iteration [26782]: Loss = 0.6949834823608398
Iteration [26783]: Loss = 0.6949295401573181
Iteration [26784]: Loss = 4.9730048179626465
Iteration [26785]: Loss = 0.6949656009674072
Iteration [26786]: Loss = 4.9719719886779785
Iteration [26787]: Loss = 0.6953034996986389
Iteration [26788]: Loss = 4.969505786895752
Iteration [26789]: Loss = 4.967495441436768
Iteration [26790]: Loss = 0.6964269876480103
Iteration [26791]: Loss = 0.6968771815299988
Iteration [26792]: Loss = 0.6972447633743286
Iteration [26793]: Loss = 0.6975378394126892
Iteration [26794]: Loss = 4.957601547241211
Iteration [26795]: Loss = 0.6981663703918457
Iteration [26796]: Loss = 0.6984910368919373
Iteration [26797]: Loss = 0.6987452507019043
Iteration [26798]: Loss = 0.6989362835884094
Iteration [26799]: Loss = 4.950747966766357
Iteration [26800]: Loss = 0.6993898153305054
Iteration [26801]: Loss = 0.699639618396759
Iteration [26802]: Loss = 0.6998264193534851
Iteration [26803]: Loss = 0.6999565362930298
Iteration [26804]: Loss = 4.945694923400879
Iteration [26805]: Loss = 0.7003058791160583
Iteration [26806]: Loss = 0.7005112171173096
Iteration [26807]: Loss = 0.700657844543457
Iteration [26808]: Loss = 0.7007516622543335
Iteration [26809]: Loss = 0.7007979154586792
Iteration [26810]: Loss = 0.7008011341094971
Iteration [26811]: Loss = 0.7007659673690796
Iteration [26812]: Loss = 0.700695812702179
Iteration [26813]: Loss = 4.942776679992676
Iteration [26814]: Loss = 0.7007030248641968
Iteration [26815]: Loss = 4.941899299621582
Iteration [26816]: Loss = 0.7010152339935303
Iteration [26817]: Loss = 0.7012047171592712
Iteration [26818]: Loss = 0.7013370394706726
Iteration [26819]: Loss = 0.7014178037643433
Iteration [26820]: Loss = 4.9383015632629395
Iteration [26821]: Loss = 0.7016827464103699
Iteration [26822]: Loss = 4.936220645904541
Iteration [26823]: Loss = 0.7022031545639038
Iteration [26824]: Loss = 0.7024810910224915
Iteration [26825]: Loss = 0.7026931047439575
Iteration [26826]: Loss = 0.702845573425293
Iteration [26827]: Loss = 0.7029445767402649
Iteration [26828]: Loss = 0.702995240688324
Iteration [26829]: Loss = 0.7030024528503418
Iteration [26830]: Loss = 0.702970564365387
Iteration [26831]: Loss = 0.7029032707214355
Iteration [26832]: Loss = 0.7028042078018188
Iteration [26833]: Loss = 9.161188125610352
Iteration [26834]: Loss = 0.7029967904090881
Iteration [26835]: Loss = 0.7032471299171448
Iteration [26836]: Loss = 0.7034342885017395
Iteration [26837]: Loss = 4.927324295043945
Iteration [26838]: Loss = 0.7038795351982117
Iteration [26839]: Loss = 4.9244208335876465
Iteration [26840]: Loss = 4.922256946563721
Iteration [26841]: Loss = 0.705116331577301
Iteration [26842]: Loss = 0.7055944204330444
Iteration [26843]: Loss = 4.914801120758057
Iteration [26844]: Loss = 0.7065367102622986
Iteration [26845]: Loss = 4.9096174240112305
Iteration [26846]: Loss = 0.7076014280319214
Iteration [26847]: Loss = 0.7081106305122375
Iteration [26848]: Loss = 0.708530843257904
Iteration [26849]: Loss = 0.7088709473609924
Iteration [26850]: Loss = 0.7091388702392578
Iteration [26851]: Loss = 0.7093415260314941
Iteration [26852]: Loss = 4.896839618682861
Iteration [26853]: Loss = 0.7098118662834167
Iteration [26854]: Loss = 0.7100671529769897
Iteration [26855]: Loss = 0.7102586030960083
Iteration [26856]: Loss = 4.892207622528076
Iteration [26857]: Loss = 0.7107093334197998
Iteration [26858]: Loss = 0.7109561562538147
Iteration [26859]: Loss = 0.7111399173736572
Iteration [26860]: Loss = 0.7112665176391602
Iteration [26861]: Loss = 0.7113419771194458
Iteration [26862]: Loss = 0.711371123790741
Iteration [26863]: Loss = 0.7113587260246277
Iteration [26864]: Loss = 4.887537002563477
Iteration [26865]: Loss = 0.7114608287811279
Iteration [26866]: Loss = 0.7115590572357178
Iteration [26867]: Loss = 0.7116087675094604
Iteration [26868]: Loss = 0.7116147875785828
Iteration [26869]: Loss = 0.7115814089775085
Iteration [26870]: Loss = 0.711512565612793
Iteration [26871]: Loss = 0.7114119529724121
Iteration [26872]: Loss = 0.71128249168396
Iteration [26873]: Loss = 0.7111270427703857
Iteration [26874]: Loss = 0.7109483480453491
Iteration [26875]: Loss = 0.7107487916946411
Iteration [26876]: Loss = 4.891504764556885
Iteration [26877]: Loss = 0.7105313539505005
Iteration [26878]: Loss = 4.891690254211426
Iteration [26879]: Loss = 0.7106572389602661
Iteration [26880]: Loss = 0.7107657790184021
Iteration [26881]: Loss = 0.710824728012085
Iteration [26882]: Loss = 0.710839033126831
Iteration [26883]: Loss = 0.7108132243156433
Iteration [26884]: Loss = 0.7107511758804321
Iteration [26885]: Loss = 4.890859603881836
Iteration [26886]: Loss = 0.7107689380645752
Iteration [26887]: Loss = 0.7108314037322998
Iteration [26888]: Loss = 0.710848867893219
Iteration [26889]: Loss = 4.8899970054626465
Iteration [26890]: Loss = 0.71100252866745
Iteration [26891]: Loss = 0.7111228704452515
Iteration [26892]: Loss = 0.7111924290657043
Iteration [26893]: Loss = 0.7112163305282593
Iteration [26894]: Loss = 0.7111989855766296
Iteration [26895]: Loss = 4.888373374938965
Iteration [26896]: Loss = 0.71129310131073
Iteration [26897]: Loss = 0.7113879919052124
Iteration [26898]: Loss = 0.7114347219467163
Iteration [26899]: Loss = 0.7114378809928894
Iteration [26900]: Loss = 0.7114019393920898
Iteration [26901]: Loss = 0.7113305926322937
Iteration [26902]: Loss = 0.7112276554107666
Iteration [26903]: Loss = 0.7110960483551025
Iteration [26904]: Loss = 0.710938572883606
Iteration [26905]: Loss = 0.7107579708099365
Iteration [26906]: Loss = 0.7105566263198853
Iteration [26907]: Loss = 4.892492771148682
Iteration [26908]: Loss = 0.7103365659713745
Iteration [26909]: Loss = 0.7102980017662048
Iteration [26910]: Loss = 0.7102243304252625
Iteration [26911]: Loss = 0.7101191878318787
Iteration [26912]: Loss = 4.894282817840576
Iteration [26913]: Loss = 0.7100638747215271
Iteration [26914]: Loss = 0.7100954055786133
Iteration [26915]: Loss = 0.7100849747657776
Iteration [26916]: Loss = 0.7100367546081543
Iteration [26917]: Loss = 4.894442558288574
Iteration [26918]: Loss = 0.7100786566734314
Iteration [26919]: Loss = 0.7101516723632812
Iteration [26920]: Loss = 0.7101784348487854
Iteration [26921]: Loss = 0.7101638913154602
Iteration [26922]: Loss = 4.893639087677002
Iteration [26923]: Loss = 0.7102632522583008
Iteration [26924]: Loss = 0.710360586643219
Iteration [26925]: Loss = 0.7104095816612244
Iteration [26926]: Loss = 0.710414707660675
Iteration [26927]: Loss = 0.710380494594574
Iteration [26928]: Loss = 0.7103107571601868
Iteration [26929]: Loss = 0.7102091312408447
Iteration [26930]: Loss = 0.7100786566734314
Iteration [26931]: Loss = 0.7099222540855408
Iteration [26932]: Loss = 0.7097427845001221
Iteration [26933]: Loss = 0.7095422148704529
Iteration [26934]: Loss = 9.08602237701416
Iteration [26935]: Loss = 0.7095596194267273
Iteration [26936]: Loss = 0.7097343802452087
Iteration [26937]: Loss = 0.7098532915115356
Iteration [26938]: Loss = 0.709921658039093
Iteration [26939]: Loss = 0.7099447250366211
Iteration [26940]: Loss = 0.7099267840385437
Iteration [26941]: Loss = 0.7098719477653503
Iteration [26942]: Loss = 0.7097838521003723
Iteration [26943]: Loss = 0.7096660137176514
Iteration [26944]: Loss = 0.7095212340354919
Iteration [26945]: Loss = 0.7093520760536194
Iteration [26946]: Loss = 4.898497581481934
Iteration [26947]: Loss = 0.7091873288154602
Iteration [26948]: Loss = 9.087712287902832
Iteration [26949]: Loss = 0.7095884680747986
Iteration [26950]: Loss = 0.7099250555038452
Iteration [26951]: Loss = 4.893240451812744
Iteration [26952]: Loss = 0.7106236219406128
Iteration [26953]: Loss = 0.7109759449958801
Iteration [26954]: Loss = 0.7112548351287842
Iteration [26955]: Loss = 0.7114673852920532
Iteration [26956]: Loss = 4.885950088500977
Iteration [26957]: Loss = 0.7119535803794861
Iteration [26958]: Loss = 0.71221524477005
Iteration [26959]: Loss = 4.881925582885742
Iteration [26960]: Loss = 0.7127848863601685
Iteration [26961]: Loss = 0.7130818367004395
Iteration [26962]: Loss = 0.713310718536377
Iteration [26963]: Loss = 0.7134783267974854
Iteration [26964]: Loss = 0.7135906219482422
Iteration [26965]: Loss = 0.713653028011322
Iteration [26966]: Loss = 0.7136706709861755
Iteration [26967]: Loss = 0.713647723197937
Iteration [26968]: Loss = 0.7135884165763855
Iteration [26969]: Loss = 0.7134963274002075
Iteration [26970]: Loss = 0.713374674320221
Iteration [26971]: Loss = 0.7132264375686646
Iteration [26972]: Loss = 4.87866735458374
Iteration [26973]: Loss = 0.7130956649780273
Iteration [26974]: Loss = 0.7130943536758423
Iteration [26975]: Loss = 0.7130541801452637
Iteration [26976]: Loss = 4.879046440124512
Iteration [26977]: Loss = 0.7131083011627197
Iteration [26978]: Loss = 0.7131856679916382
Iteration [26979]: Loss = 0.7132165431976318
Iteration [26980]: Loss = 0.7132057547569275
Iteration [26981]: Loss = 0.7131573557853699
Iteration [26982]: Loss = 0.7130748629570007
Iteration [26983]: Loss = 0.7129620313644409
Iteration [26984]: Loss = 0.7128217220306396
Iteration [26985]: Loss = 4.880684852600098
Iteration [26986]: Loss = 0.7127045392990112
Iteration [26987]: Loss = 0.7127090096473694
Iteration [26988]: Loss = 0.7126742601394653
Iteration [26989]: Loss = 0.7126043438911438
Iteration [26990]: Loss = 0.7125027179718018
Iteration [26991]: Loss = 0.7123724222183228
Iteration [26992]: Loss = 0.712216317653656
Iteration [26993]: Loss = 0.7120371460914612
Iteration [26994]: Loss = 0.7118371725082397
Iteration [26995]: Loss = 0.7116182446479797
Iteration [26996]: Loss = 0.7113826870918274
Iteration [26997]: Loss = 0.7111316323280334
Iteration [26998]: Loss = 0.7108670473098755
Iteration [26999]: Loss = 0.7105902433395386
Iteration [27000]: Loss = 0.7103022933006287
Iteration [27001]: Loss = 4.894187927246094
Iteration [27002]: Loss = 0.7099341750144958
Iteration [27003]: Loss = 4.8950676918029785
Iteration [27004]: Loss = 0.709937572479248
Iteration [27005]: Loss = 0.7099938988685608
Iteration [27006]: Loss = 0.710006058216095
Iteration [27007]: Loss = 4.894321441650391
Iteration [27008]: Loss = 0.7101503610610962
Iteration [27009]: Loss = 0.710266649723053
Iteration [27010]: Loss = 4.892511367797852
Iteration [27011]: Loss = 4.891204357147217
Iteration [27012]: Loss = 0.7110157012939453
Iteration [27013]: Loss = 0.7113615274429321
Iteration [27014]: Loss = 4.8858795166015625
Iteration [27015]: Loss = 0.7120760083198547
Iteration [27016]: Loss = 0.7124351263046265
Iteration [27017]: Loss = 0.7127198576927185
Iteration [27018]: Loss = 0.7129377126693726
Iteration [27019]: Loss = 0.7130950689315796
Iteration [27020]: Loss = 4.877939224243164
Iteration [27021]: Loss = 0.7134867310523987
Iteration [27022]: Loss = 0.7137081623077393
Iteration [27023]: Loss = 4.874541759490967
Iteration [27024]: Loss = 4.872819423675537
Iteration [27025]: Loss = 0.7147111296653748
Iteration [27026]: Loss = 4.868194580078125
Iteration [27027]: Loss = 0.7156918048858643
Iteration [27028]: Loss = 4.862954139709473
Iteration [27029]: Loss = 0.7167840003967285
Iteration [27030]: Loss = 0.7173037528991699
Iteration [27031]: Loss = 0.717732846736908
Iteration [27032]: Loss = 0.7180806398391724
Iteration [27033]: Loss = 0.7183547019958496
Iteration [27034]: Loss = 0.7185624241828918
Iteration [27035]: Loss = 0.7187103629112244
Iteration [27036]: Loss = 0.7188045382499695
Iteration [27037]: Loss = 0.7188501954078674
Iteration [27038]: Loss = 0.718852162361145
Iteration [27039]: Loss = 0.7188146114349365
Iteration [27040]: Loss = 0.7187416553497314
Iteration [27041]: Loss = 0.7186367511749268
Iteration [27042]: Loss = 0.7185031175613403
Iteration [27043]: Loss = 0.7183435559272766
Iteration [27044]: Loss = 0.7181606888771057
Iteration [27045]: Loss = 4.853947162628174
Iteration [27046]: Loss = 0.7179700136184692
Iteration [27047]: Loss = 0.7179427146911621
Iteration [27048]: Loss = 0.7178789973258972
Iteration [27049]: Loss = 0.7177823185920715
Iteration [27050]: Loss = 4.8554558753967285
Iteration [27051]: Loss = 0.7177391052246094
Iteration [27052]: Loss = 0.7177746295928955
Iteration [27053]: Loss = 0.7177674770355225
Iteration [27054]: Loss = 4.85512638092041
Iteration [27055]: Loss = 4.854348182678223
Iteration [27056]: Loss = 0.7182125449180603
Iteration [27057]: Loss = 0.7184754610061646
Iteration [27058]: Loss = 0.7186732292175293
Iteration [27059]: Loss = 0.7188119888305664
Iteration [27060]: Loss = 0.7188978791236877
Iteration [27061]: Loss = 0.7189359068870544
Iteration [27062]: Loss = 0.7189309000968933
Iteration [27063]: Loss = 4.849289417266846
Iteration [27064]: Loss = 0.7190439701080322
Iteration [27065]: Loss = 0.7191458940505981
Iteration [27066]: Loss = 0.71919846534729
Iteration [27067]: Loss = 0.7192065119743347
Iteration [27068]: Loss = 0.7191745042800903
Iteration [27069]: Loss = 0.7191063165664673
Iteration [27070]: Loss = 4.848696231842041
Iteration [27071]: Loss = 0.719111442565918
Iteration [27072]: Loss = 4.84788703918457
Iteration [27073]: Loss = 0.7194139957427979
Iteration [27074]: Loss = 0.7195966839790344
Iteration [27075]: Loss = 0.7197219133377075
Iteration [27076]: Loss = 0.7197953462600708
Iteration [27077]: Loss = 0.7198220491409302
Iteration [27078]: Loss = 0.7198068499565125
Iteration [27079]: Loss = 0.7197538614273071
Iteration [27080]: Loss = 0.719666600227356
Iteration [27081]: Loss = 0.7195488214492798
Iteration [27082]: Loss = 0.7194032073020935
Iteration [27083]: Loss = 0.7192328572273254
Iteration [27084]: Loss = 4.84852409362793
Iteration [27085]: Loss = 0.7190635204315186
Iteration [27086]: Loss = 0.7190452814102173
Iteration [27087]: Loss = 0.7189894914627075
Iteration [27088]: Loss = 0.7188999652862549
Iteration [27089]: Loss = 0.718779981136322
Iteration [27090]: Loss = 0.7186324596405029
Iteration [27091]: Loss = 0.7184604406356812
Iteration [27092]: Loss = 0.7182661294937134
Iteration [27093]: Loss = 0.7180517911911011
Iteration [27094]: Loss = 0.7178196310997009
Iteration [27095]: Loss = 0.7175710201263428
Iteration [27096]: Loss = 0.7173080444335938
Iteration [27097]: Loss = 0.7170319557189941
Iteration [27098]: Loss = 0.716744065284729
Iteration [27099]: Loss = 0.7164455652236938
Iteration [27100]: Loss = 0.7161376476287842
Iteration [27101]: Loss = 0.7158211469650269
Iteration [27102]: Loss = 0.7154969573020935
Iteration [27103]: Loss = 0.7151657938957214
Iteration [27104]: Loss = 0.7148285508155823
Iteration [27105]: Loss = 4.871420383453369
Iteration [27106]: Loss = 0.7143758535385132
Iteration [27107]: Loss = 4.872674942016602
Iteration [27108]: Loss = 0.7143113017082214
Iteration [27109]: Loss = 0.7143387198448181
Iteration [27110]: Loss = 0.7143239974975586
Iteration [27111]: Loss = 0.714271605014801
Iteration [27112]: Loss = 0.7141852974891663
Iteration [27113]: Loss = 0.7140682935714722
Iteration [27114]: Loss = 0.7139239311218262
Iteration [27115]: Loss = 0.7137546539306641
Iteration [27116]: Loss = 0.7135631442070007
Iteration [27117]: Loss = 4.877160549163818
Iteration [27118]: Loss = 0.7133597135543823
Iteration [27119]: Loss = 0.7133278250694275
Iteration [27120]: Loss = 0.7132601141929626
Iteration [27121]: Loss = 0.7131597399711609
Iteration [27122]: Loss = 0.7130303382873535
Iteration [27123]: Loss = 4.87957763671875
Iteration [27124]: Loss = 0.712933361530304
Iteration [27125]: Loss = 4.879212379455566
Iteration [27126]: Loss = 0.713157057762146
Iteration [27127]: Loss = 0.7133075594902039
Iteration [27128]: Loss = 4.876896381378174
Iteration [27129]: Loss = 0.71368807554245
Iteration [27130]: Loss = 0.7139052152633667
Iteration [27131]: Loss = 0.7140616178512573
Iteration [27132]: Loss = 0.7141631245613098
Iteration [27133]: Loss = 0.7142154574394226
Iteration [27134]: Loss = 0.7142232656478882
Iteration [27135]: Loss = 0.7141910195350647
Iteration [27136]: Loss = 0.7141229510307312
Iteration [27137]: Loss = 0.7140222787857056
Iteration [27138]: Loss = 0.71389240026474
Iteration [27139]: Loss = 4.8752121925354
Iteration [27140]: Loss = 0.713794469833374
Iteration [27141]: Loss = 0.7138074636459351
Iteration [27142]: Loss = 0.7137799859046936
Iteration [27143]: Loss = 4.8753132820129395
Iteration [27144]: Loss = 0.7138569355010986
Iteration [27145]: Loss = 0.7139446139335632
Iteration [27146]: Loss = 4.873955726623535
Iteration [27147]: Loss = 4.872772693634033
Iteration [27148]: Loss = 0.7146263718605042
Iteration [27149]: Loss = 0.7149547934532166
Iteration [27150]: Loss = 0.7152113914489746
Iteration [27151]: Loss = 0.7154030799865723
Iteration [27152]: Loss = 0.7155365943908691
Iteration [27153]: Loss = 0.7156174182891846
Iteration [27154]: Loss = 0.7156507968902588
Iteration [27155]: Loss = 4.86558723449707
Iteration [27156]: Loss = 0.7158312797546387
Iteration [27157]: Loss = 0.7159628868103027
Iteration [27158]: Loss = 0.7160420417785645
Iteration [27159]: Loss = 0.7160738706588745
Iteration [27160]: Loss = 0.7160631418228149
Iteration [27161]: Loss = 0.7160142064094543
Iteration [27162]: Loss = 0.7159305810928345
Iteration [27163]: Loss = 0.7158159017562866
Iteration [27164]: Loss = 0.7156732678413391
Iteration [27165]: Loss = 0.7155053615570068
Iteration [27166]: Loss = 0.7153147459030151
Iteration [27167]: Loss = 0.715103805065155
Iteration [27168]: Loss = 0.7148746252059937
Iteration [27169]: Loss = 0.7146286368370056
Iteration [27170]: Loss = 0.7143679261207581
Iteration [27171]: Loss = 0.7140937447547913
Iteration [27172]: Loss = 9.035892486572266
Iteration [27173]: Loss = 0.7139866352081299
Iteration [27174]: Loss = 4.873326778411865
Iteration [27175]: Loss = 0.7144156694412231
Iteration [27176]: Loss = 0.7146531343460083
Iteration [27177]: Loss = 0.7148279547691345
Iteration [27178]: Loss = 0.7149462103843689
Iteration [27179]: Loss = 0.7150136232376099
Iteration [27180]: Loss = 0.7150352001190186
Iteration [27181]: Loss = 0.7150154709815979
Iteration [27182]: Loss = 0.7149584293365479
Iteration [27183]: Loss = 0.714867889881134
Iteration [27184]: Loss = 0.7147473096847534
Iteration [27185]: Loss = 0.7145995497703552
Iteration [27186]: Loss = 0.7144273519515991
Iteration [27187]: Loss = 0.7142330408096313
Iteration [27188]: Loss = 0.7140190005302429
Iteration [27189]: Loss = 0.7137871384620667
Iteration [27190]: Loss = 0.713539183139801
Iteration [27191]: Loss = 0.713276743888855
Iteration [27192]: Loss = 0.713001549243927
Iteration [27193]: Loss = 0.7127144932746887
Iteration [27194]: Loss = 0.7124170660972595
Iteration [27195]: Loss = 0.712110161781311
Iteration [27196]: Loss = 0.7117947936058044
Iteration [27197]: Loss = 0.7114717960357666
Iteration [27198]: Loss = 4.888385772705078
Iteration [27199]: Loss = 0.7110444903373718
Iteration [27200]: Loss = 0.7109177112579346
Iteration [27201]: Loss = 9.069853782653809
Iteration [27202]: Loss = 4.888798713684082
Iteration [27203]: Loss = 0.7115238904953003
Iteration [27204]: Loss = 4.884517192840576
Iteration [27205]: Loss = 4.8817901611328125
Iteration [27206]: Loss = 9.043575286865234
Iteration [27207]: Loss = 0.7141502499580383
Iteration [27208]: Loss = 0.7150423526763916
Iteration [27209]: Loss = 0.7158079743385315
Iteration [27210]: Loss = 0.7164592742919922
Iteration [27211]: Loss = 4.8587141036987305
Iteration [27212]: Loss = 4.855264663696289
Iteration [27213]: Loss = 0.7185060381889343
Iteration [27214]: Loss = 0.7191988229751587
Iteration [27215]: Loss = 0.7197842597961426
Iteration [27216]: Loss = 0.7202727198600769
Iteration [27217]: Loss = 0.7206739187240601
Iteration [27218]: Loss = 0.7209962606430054
Iteration [27219]: Loss = 0.7212395071983337
Iteration [27220]: Loss = 0.7214167714118958
Iteration [27221]: Loss = 0.7215394377708435
Iteration [27222]: Loss = 0.7216128706932068
Iteration [27223]: Loss = 4.835551738739014
Iteration [27224]: Loss = 0.7218519449234009
Iteration [27225]: Loss = 0.7220041155815125
Iteration [27226]: Loss = 0.7221040725708008
Iteration [27227]: Loss = 0.7221571207046509
Iteration [27228]: Loss = 0.7221675515174866
Iteration [27229]: Loss = 0.722139835357666
Iteration [27230]: Loss = 0.7220778465270996
Iteration [27231]: Loss = 4.833847522735596
Iteration [27232]: Loss = 0.7220854759216309
Iteration [27233]: Loss = 0.7221388816833496
Iteration [27234]: Loss = 0.7221499681472778
Iteration [27235]: Loss = 4.833162784576416
Iteration [27236]: Loss = 0.7222825288772583
Iteration [27237]: Loss = 0.7223893404006958
Iteration [27238]: Loss = 4.831547260284424
Iteration [27239]: Loss = 0.7226854562759399
Iteration [27240]: Loss = 4.829496383666992
Iteration [27241]: Loss = 0.7232040762901306
Iteration [27242]: Loss = 0.7234753370285034
Iteration [27243]: Loss = 0.7236824631690979
Iteration [27244]: Loss = 0.7238318920135498
Iteration [27245]: Loss = 0.7239289879798889
Iteration [27246]: Loss = 0.7239794135093689
Iteration [27247]: Loss = 4.823923587799072
Iteration [27248]: Loss = 0.7241785526275635
Iteration [27249]: Loss = 0.7243136167526245
Iteration [27250]: Loss = 0.7243977785110474
Iteration [27251]: Loss = 8.918972969055176
Iteration [27252]: Loss = 0.724872887134552
Iteration [27253]: Loss = 0.725229024887085
Iteration [27254]: Loss = 0.7255128026008606
Iteration [27255]: Loss = 0.7257312536239624
Iteration [27256]: Loss = 0.7258908748626709
Iteration [27257]: Loss = 0.7259974479675293
Iteration [27258]: Loss = 0.7260562181472778
Iteration [27259]: Loss = 0.7260720133781433
Iteration [27260]: Loss = 0.7260489463806152
Iteration [27261]: Loss = 0.7259909510612488
Iteration [27262]: Loss = 4.814481258392334
Iteration [27263]: Loss = 0.7260041236877441
Iteration [27264]: Loss = 0.7260593175888062
Iteration [27265]: Loss = 0.7260718941688538
Iteration [27266]: Loss = 0.7260457277297974
Iteration [27267]: Loss = 0.7259851694107056
Iteration [27268]: Loss = 0.7258932590484619
Iteration [27269]: Loss = 0.725773274898529
Iteration [27270]: Loss = 0.7256280779838562
Iteration [27271]: Loss = 0.7254599928855896
Iteration [27272]: Loss = 4.817584991455078
Iteration [27273]: Loss = 0.7252854108810425
Iteration [27274]: Loss = 0.7252607941627502
Iteration [27275]: Loss = 0.7252013683319092
Iteration [27276]: Loss = 0.725110650062561
Iteration [27277]: Loss = 4.818964004516602
Iteration [27278]: Loss = 4.818586826324463
Iteration [27279]: Loss = 0.7253202795982361
Iteration [27280]: Loss = 0.7255100011825562
Iteration [27281]: Loss = 0.7256436944007874
Iteration [27282]: Loss = 0.725726842880249
Iteration [27283]: Loss = 0.7257644534111023
Iteration [27284]: Loss = 0.7257610559463501
Iteration [27285]: Loss = 0.7257208228111267
Iteration [27286]: Loss = 0.7256471514701843
Iteration [27287]: Loss = 0.7255434989929199
Iteration [27288]: Loss = 0.7254128456115723
Iteration [27289]: Loss = 0.7252579927444458
Iteration [27290]: Loss = 0.725081205368042
Iteration [27291]: Loss = 4.819491386413574
Iteration [27292]: Loss = 0.7248921990394592
Iteration [27293]: Loss = 0.7248614430427551
Iteration [27294]: Loss = 0.7247965931892395
Iteration [27295]: Loss = 4.820399761199951
Iteration [27296]: Loss = 4.819917678833008
Iteration [27297]: Loss = 0.7250698804855347
Iteration [27298]: Loss = 0.7252771854400635
Iteration [27299]: Loss = 0.7254263758659363
Iteration [27300]: Loss = 0.7255236506462097
Iteration [27301]: Loss = 0.7255737781524658
Iteration [27302]: Loss = 0.7255817651748657
Iteration [27303]: Loss = 0.7255514860153198
Iteration [27304]: Loss = 0.7254868149757385
Iteration [27305]: Loss = 0.7253912687301636
Iteration [27306]: Loss = 0.7252679467201233
Iteration [27307]: Loss = 4.818333148956299
Iteration [27308]: Loss = 0.7251700758934021
Iteration [27309]: Loss = 0.7251783609390259
Iteration [27310]: Loss = 0.7251484394073486
Iteration [27311]: Loss = 0.7250841856002808
Iteration [27312]: Loss = 4.8189778327941895
Iteration [27313]: Loss = 0.7250872850418091
Iteration [27314]: Loss = 0.7251385450363159
Iteration [27315]: Loss = 0.7251474261283875
Iteration [27316]: Loss = 0.7251180410385132
Iteration [27317]: Loss = 0.7250542640686035
Iteration [27318]: Loss = 0.7249593734741211
Iteration [27319]: Loss = 0.7248365879058838
Iteration [27320]: Loss = 0.7246886491775513
Iteration [27321]: Loss = 0.7245180606842041
Iteration [27322]: Loss = 0.7243270874023438
Iteration [27323]: Loss = 0.7241178750991821
Iteration [27324]: Loss = 0.7238921523094177
Iteration [27325]: Loss = 0.7236514687538147
Iteration [27326]: Loss = 0.7233975529670715
Iteration [27327]: Loss = 0.723131537437439
Iteration [27328]: Loss = 0.7228547930717468
Iteration [27329]: Loss = 0.722568154335022
Iteration [27330]: Loss = 4.832416534423828
Iteration [27331]: Loss = 0.7221928238868713
Iteration [27332]: Loss = 0.7220833897590637
Iteration [27333]: Loss = 0.721947431564331
Iteration [27334]: Loss = 0.7217879295349121
Iteration [27335]: Loss = 4.835725784301758
Iteration [27336]: Loss = 0.7216293215751648
Iteration [27337]: Loss = 0.721612274646759
Iteration [27338]: Loss = 0.7215597629547119
Iteration [27339]: Loss = 0.7214751839637756
Iteration [27340]: Loss = 4.836945056915283
Iteration [27341]: Loss = 0.721444845199585
Iteration [27342]: Loss = 0.721482515335083
Iteration [27343]: Loss = 8.951241493225098
Iteration [27344]: Loss = 4.834367275238037
Iteration [27345]: Loss = 0.7224239110946655
Iteration [27346]: Loss = 0.7228769659996033
Iteration [27347]: Loss = 4.827582359313965
Iteration [27348]: Loss = 0.7237647771835327
Iteration [27349]: Loss = 0.7241930961608887
Iteration [27350]: Loss = 0.7245420217514038
Iteration [27351]: Loss = 0.7248192429542542
Iteration [27352]: Loss = 0.7250314950942993
Iteration [27353]: Loss = 0.7251855731010437
Iteration [27354]: Loss = 0.725287139415741
Iteration [27355]: Loss = 0.7253413200378418
Iteration [27356]: Loss = 4.8171844482421875
Iteration [27357]: Loss = 0.7255465388298035
Iteration [27358]: Loss = 0.7256837487220764
Iteration [27359]: Loss = 0.7257700562477112
Iteration [27360]: Loss = 0.7258104681968689
Iteration [27361]: Loss = 4.814933776855469
Iteration [27362]: Loss = 0.7241559624671936
Iteration [27363]: Loss = 0.7242804169654846
Iteration [27364]: Loss = 0.7243531346321106
Iteration [27365]: Loss = 0.7243790626525879
Iteration [27366]: Loss = 0.7243630886077881
Iteration [27367]: Loss = 4.822333335876465
Iteration [27368]: Loss = 0.7244552969932556
Iteration [27369]: Loss = 0.7245476841926575
Iteration [27370]: Loss = 0.7245912551879883
Iteration [27371]: Loss = 0.7245910167694092
Iteration [27372]: Loss = 0.7245514392852783
Iteration [27373]: Loss = 0.7244762182235718
Iteration [27374]: Loss = 0.7243689894676208
Iteration [27375]: Loss = 0.7242329716682434
Iteration [27376]: Loss = 0.7240710258483887
Iteration [27377]: Loss = 0.7238858938217163
Iteration [27378]: Loss = 0.7236796021461487
Iteration [27379]: Loss = 0.7234543561935425
Iteration [27380]: Loss = 0.7232121825218201
Iteration [27381]: Loss = 0.7229546308517456
Iteration [27382]: Loss = 0.7226834297180176
Iteration [27383]: Loss = 4.831788063049316
Iteration [27384]: Loss = 0.72234046459198
Iteration [27385]: Loss = 0.7222475409507751
Iteration [27386]: Loss = 0.7221245765686035
Iteration [27387]: Loss = 0.7219743728637695
Iteration [27388]: Loss = 0.7217999696731567
Iteration [27389]: Loss = 0.7216033339500427
Iteration [27390]: Loss = 0.7213869094848633
Iteration [27391]: Loss = 0.721152663230896
Iteration [27392]: Loss = 4.839230060577393
Iteration [27393]: Loss = 0.7208735942840576
Iteration [27394]: Loss = 0.7208081483840942
Iteration [27395]: Loss = 0.7207099199295044
Iteration [27396]: Loss = 0.7205821871757507
Iteration [27397]: Loss = 0.7204276919364929
Iteration [27398]: Loss = 0.7202491760253906
Iteration [27399]: Loss = 0.7200492024421692
Iteration [27400]: Loss = 0.7198299169540405
Iteration [27401]: Loss = 0.7195929884910583
Iteration [27402]: Loss = 0.7193405032157898
Iteration [27403]: Loss = 0.7190737724304199
Iteration [27404]: Loss = 0.7187944054603577
Iteration [27405]: Loss = 4.85120964050293
Iteration [27406]: Loss = 0.7184388041496277
Iteration [27407]: Loss = 0.7183412313461304
Iteration [27408]: Loss = 0.718214213848114
Iteration [27409]: Loss = 0.7180604934692383
Iteration [27410]: Loss = 8.990754127502441
Iteration [27411]: Loss = 0.7181535959243774
Iteration [27412]: Loss = 0.7183585166931152
Iteration [27413]: Loss = 0.7185039520263672
Iteration [27414]: Loss = 0.7185961604118347
Iteration [27415]: Loss = 0.7186399698257446
Iteration [27416]: Loss = 0.7186404466629028
Iteration [27417]: Loss = 0.7186017632484436
Iteration [27418]: Loss = 0.7185279130935669
Iteration [27419]: Loss = 0.7184222936630249
Iteration [27420]: Loss = 0.7182881832122803
Iteration [27421]: Loss = 0.7181283235549927
Iteration [27422]: Loss = 4.854006767272949
Iteration [27423]: Loss = 0.717976450920105
Iteration [27424]: Loss = 0.7179654836654663
Iteration [27425]: Loss = 0.7179166078567505
Iteration [27426]: Loss = 0.7178335189819336
Iteration [27427]: Loss = 4.855137825012207
Iteration [27428]: Loss = 0.7178130149841309
Iteration [27429]: Loss = 0.7178579568862915
Iteration [27430]: Loss = 0.7178594470024109
Iteration [27431]: Loss = 4.854626178741455
Iteration [27432]: Loss = 4.853814601898193
Iteration [27433]: Loss = 0.7183242440223694
Iteration [27434]: Loss = 0.7185919880867004
Iteration [27435]: Loss = 0.7187942862510681
Iteration [27436]: Loss = 0.7189372777938843
Iteration [27437]: Loss = 0.7190269231796265
Iteration [27438]: Loss = 0.7190685272216797
Iteration [27439]: Loss = 0.7190667986869812
Iteration [27440]: Loss = 0.7190262079238892
Iteration [27441]: Loss = 0.7189503312110901
Iteration [27442]: Loss = 0.7188428640365601
Iteration [27443]: Loss = 0.7187070846557617
Iteration [27444]: Loss = 0.7185455560684204
Iteration [27445]: Loss = 0.7183609008789062
Iteration [27446]: Loss = 0.718155562877655
Iteration [27447]: Loss = 0.7179313898086548
Iteration [27448]: Loss = 4.855284214019775
Iteration [27449]: Loss = 8.993101119995117
Iteration [27450]: Loss = 0.7180798053741455
Iteration [27451]: Loss = 4.851677417755127
Iteration [27452]: Loss = 0.7189007997512817
Iteration [27453]: Loss = 4.847203254699707
Iteration [27454]: Loss = 4.844423294067383
Iteration [27455]: Loss = 4.84096097946167
Iteration [27456]: Loss = 0.7213727831840515
Iteration [27457]: Loss = 4.833421230316162
Iteration [27458]: Loss = 4.829349040985107
Iteration [27459]: Loss = 0.7238225340843201
Iteration [27460]: Loss = 0.7246227264404297
Iteration [27461]: Loss = 0.7253046035766602
Iteration [27462]: Loss = 0.725879967212677
Iteration [27463]: Loss = 4.812230587005615
Iteration [27464]: Loss = 0.7269730567932129
Iteration [27465]: Loss = 0.7274662256240845
Iteration [27466]: Loss = 0.7278733253479004
Iteration [27467]: Loss = 0.7282028198242188
Iteration [27468]: Loss = 0.7284624576568604
Iteration [27469]: Loss = 0.7286590933799744
Iteration [27470]: Loss = 0.7287988066673279
Iteration [27471]: Loss = 0.7288872599601746
Iteration [27472]: Loss = 0.7289297580718994
Iteration [27473]: Loss = 0.7289305925369263
Iteration [27474]: Loss = 0.728894054889679
Iteration [27475]: Loss = 4.800145626068115
Iteration [27476]: Loss = 0.7289429903030396
Iteration [27477]: Loss = 0.7290129065513611
Iteration [27478]: Loss = 4.799095153808594
Iteration [27479]: Loss = 4.798091888427734
Iteration [27480]: Loss = 0.7296106219291687
Iteration [27481]: Loss = 4.794872760772705
Iteration [27482]: Loss = 0.7303487658500671
Iteration [27483]: Loss = 0.7307124733924866
Iteration [27484]: Loss = 0.7310026288032532
Iteration [27485]: Loss = 0.7312266230583191
Iteration [27486]: Loss = 4.787631511688232
Iteration [27487]: Loss = 0.7317203283309937
Iteration [27488]: Loss = 0.7319796085357666
Iteration [27489]: Loss = 4.783820152282715
Iteration [27490]: Loss = 0.7325335741043091
Iteration [27491]: Loss = 0.7328184247016907
Iteration [27492]: Loss = 0.733037531375885
Iteration [27493]: Loss = 0.7331972122192383
Iteration [27494]: Loss = 0.733303427696228
Iteration [27495]: Loss = 4.778075218200684
Iteration [27496]: Loss = 0.7335953116416931
Iteration [27497]: Loss = 0.7337684631347656
Iteration [27498]: Loss = 0.7338865399360657
Iteration [27499]: Loss = 4.775203227996826
Iteration [27500]: Loss = 0.7341989874839783
Iteration [27501]: Loss = 0.7343807220458984
Iteration [27502]: Loss = 0.7345067262649536
Iteration [27503]: Loss = 4.772175312042236
Iteration [27504]: Loss = 0.7348322868347168
Iteration [27505]: Loss = 0.7350194454193115
Iteration [27506]: Loss = 0.7351503968238831
Iteration [27507]: Loss = 0.7352304458618164
Iteration [27508]: Loss = 0.7352648973464966
Iteration [27509]: Loss = 0.735258162021637
Iteration [27510]: Loss = 0.7352141737937927
Iteration [27511]: Loss = 0.7351366877555847
Iteration [27512]: Loss = 0.7350291609764099
Iteration [27513]: Loss = 0.7348945736885071
Iteration [27514]: Loss = 0.7347356081008911
Iteration [27515]: Loss = 0.7345545291900635
Iteration [27516]: Loss = 4.773279190063477
Iteration [27517]: Loss = 0.734355628490448
Iteration [27518]: Loss = 0.7343196272850037
Iteration [27519]: Loss = 0.734249472618103
Iteration [27520]: Loss = 0.734148383140564
Iteration [27521]: Loss = 0.7340195775032043
Iteration [27522]: Loss = 0.7338658571243286
Iteration [27523]: Loss = 0.733689546585083
Iteration [27524]: Loss = 0.7334931492805481
Iteration [27525]: Loss = 0.7332784533500671
Iteration [27526]: Loss = 0.7330474257469177
Iteration [27527]: Loss = 0.7328015565872192
Iteration [27528]: Loss = 0.7325425148010254
Iteration [27529]: Loss = 0.7322715520858765
Iteration [27530]: Loss = 0.731989860534668
Iteration [27531]: Loss = 0.7316985726356506
Iteration [27532]: Loss = 0.7313985228538513
Iteration [27533]: Loss = 0.7310906648635864
Iteration [27534]: Loss = 0.7307759523391724
Iteration [27535]: Loss = 0.7304549217224121
Iteration [27536]: Loss = 0.7301281690597534
Iteration [27537]: Loss = 0.7297963500022888
Iteration [27538]: Loss = 0.7294600605964661
Iteration [27539]: Loss = 0.7291195392608643
Iteration [27540]: Loss = 0.7287755608558655
Iteration [27541]: Loss = 0.7284282445907593
Iteration [27542]: Loss = 0.7280779480934143
Iteration [27543]: Loss = 0.727725088596344
Iteration [27544]: Loss = 0.7273699045181274
Iteration [27545]: Loss = 0.7270124554634094
Iteration [27546]: Loss = 0.7266532778739929
Iteration [27547]: Loss = 0.7262924313545227
Iteration [27548]: Loss = 0.7259300947189331
Iteration [27549]: Loss = 0.7255663871765137
Iteration [27550]: Loss = 0.7252014875411987
Iteration [27551]: Loss = 0.7248355746269226
Iteration [27552]: Loss = 4.821545600891113
Iteration [27553]: Loss = 0.724324107170105
Iteration [27554]: Loss = 0.724156379699707
Iteration [27555]: Loss = 0.723967969417572
Iteration [27556]: Loss = 0.7237609624862671
Iteration [27557]: Loss = 4.826150894165039
Iteration [27558]: Loss = 0.7235209941864014
Iteration [27559]: Loss = 4.8264875411987305
Iteration [27560]: Loss = 4.825805187225342
Iteration [27561]: Loss = 4.824278831481934
Iteration [27562]: Loss = 0.7243770956993103
Iteration [27563]: Loss = 0.7247554659843445
Iteration [27564]: Loss = 0.7250590920448303
Iteration [27565]: Loss = 0.7252948880195618
Iteration [27566]: Loss = 0.7254700660705566
Iteration [27567]: Loss = 0.7255902886390686
Iteration [27568]: Loss = 0.7256610989570618
Iteration [27569]: Loss = 0.7256874442100525
Iteration [27570]: Loss = 0.725673496723175
Iteration [27571]: Loss = 0.7256235480308533
Iteration [27572]: Loss = 0.7255409955978394
Iteration [27573]: Loss = 0.7254291772842407
Iteration [27574]: Loss = 0.7252909541130066
Iteration [27575]: Loss = 0.7251289486885071
Iteration [27576]: Loss = 0.7249456644058228
Iteration [27577]: Loss = 0.7247430682182312
Iteration [27578]: Loss = 0.7245230674743652
Iteration [27579]: Loss = 0.7242875695228577
Iteration [27580]: Loss = 0.7240381836891174
Iteration [27581]: Loss = 0.7237759828567505
Iteration [27582]: Loss = 4.826322555541992
Iteration [27583]: Loss = 0.7234421968460083
Iteration [27584]: Loss = 0.7233504056930542
Iteration [27585]: Loss = 0.723230242729187
Iteration [27586]: Loss = 0.7230846881866455
Iteration [27587]: Loss = 0.7229162454605103
Iteration [27588]: Loss = 0.7227270603179932
Iteration [27589]: Loss = 0.7225192189216614
Iteration [27590]: Loss = 0.7222946882247925
Iteration [27591]: Loss = 4.833498001098633
Iteration [27592]: Loss = 0.7220256924629211
Iteration [27593]: Loss = 0.7219617366790771
Iteration [27594]: Loss = 0.7218666672706604
Iteration [27595]: Loss = 4.835045337677002
Iteration [27596]: Loss = 0.7218189835548401
Iteration [27597]: Loss = 0.721849262714386
Iteration [27598]: Loss = 0.7218390703201294
Iteration [27599]: Loss = 0.7217925786972046
Iteration [27600]: Loss = 0.7217133641242981
Iteration [27601]: Loss = 0.7216045260429382
Iteration [27602]: Loss = 0.7214691638946533
Iteration [27603]: Loss = 0.7213097214698792
Iteration [27604]: Loss = 0.7211288809776306
Iteration [27605]: Loss = 0.7209286093711853
Iteration [27606]: Loss = 4.840184211730957
Iteration [27607]: Loss = 0.7207015156745911
Iteration [27608]: Loss = 0.7206556797027588
Iteration [27609]: Loss = 0.7205768823623657
Iteration [27610]: Loss = 0.7204685807228088
Iteration [27611]: Loss = 0.7203338146209717
Iteration [27612]: Loss = 0.7201749682426453
Iteration [27613]: Loss = 0.7199946045875549
Iteration [27614]: Loss = 0.719794750213623
Iteration [27615]: Loss = 0.7195774912834167
Iteration [27616]: Loss = 0.7193445563316345
Iteration [27617]: Loss = 0.719097375869751
Iteration [27618]: Loss = 0.718837559223175
Iteration [27619]: Loss = 0.7185661792755127
Iteration [27620]: Loss = 0.7182847857475281
Iteration [27621]: Loss = 0.7179938554763794
Iteration [27622]: Loss = 0.717694878578186
Iteration [27623]: Loss = 0.7173882722854614
Iteration [27624]: Loss = 0.7170749306678772
Iteration [27625]: Loss = 0.7167555689811707
Iteration [27626]: Loss = 0.7164309620857239
Iteration [27627]: Loss = 0.7161012887954712
Iteration [27628]: Loss = 0.7157673835754395
Iteration [27629]: Loss = 0.7154295444488525
Iteration [27630]: Loss = 4.868378162384033
Iteration [27631]: Loss = 0.714969277381897
Iteration [27632]: Loss = 0.7148250341415405
Iteration [27633]: Loss = 0.7146579027175903
Iteration [27634]: Loss = 0.7144703269004822
Iteration [27635]: Loss = 0.7142642140388489
Iteration [27636]: Loss = 0.714041531085968
Iteration [27637]: Loss = 0.7138038277626038
Iteration [27638]: Loss = 0.7135526537895203
Iteration [27639]: Loss = 0.7132894396781921
Iteration [27640]: Loss = 0.7130154371261597
Iteration [27641]: Loss = 4.88030481338501
Iteration [27642]: Loss = 0.7126646637916565
Iteration [27643]: Loss = 0.7125673890113831
Iteration [27644]: Loss = 0.7124426960945129
Iteration [27645]: Loss = 0.7122935056686401
Iteration [27646]: Loss = 0.7121219038963318
Iteration [27647]: Loss = 0.7119302749633789
Iteration [27648]: Loss = 0.7117208242416382
Iteration [27649]: Loss = 0.7114951014518738
Iteration [27650]: Loss = 0.7112548351287842
Iteration [27651]: Loss = 0.7110013961791992
Iteration [27652]: Loss = 4.890454292297363
Iteration [27653]: Loss = 0.7106866836547852
Iteration [27654]: Loss = 4.891121864318848
Iteration [27655]: Loss = 4.8905348777771
Iteration [27656]: Loss = 0.711012065410614
Iteration [27657]: Loss = 0.7112379670143127
Iteration [27658]: Loss = 0.7114042639732361
Iteration [27659]: Loss = 0.7115172147750854
Iteration [27660]: Loss = 0.7115817070007324
Iteration [27661]: Loss = 0.7116028070449829
Iteration [27662]: Loss = 4.886133193969727
Iteration [27663]: Loss = 4.885257244110107
Iteration [27664]: Loss = 0.7120993137359619
Iteration [27665]: Loss = 0.7123709917068481
Iteration [27666]: Loss = 0.7125785946846008
Iteration [27667]: Loss = 0.7127285003662109
Iteration [27668]: Loss = 0.7128263115882874
Iteration [27669]: Loss = 0.7128772735595703
Iteration [27670]: Loss = 0.7128860354423523
Iteration [27671]: Loss = 0.7128567099571228
Iteration [27672]: Loss = 0.712793231010437
Iteration [27673]: Loss = 0.7126988172531128
Iteration [27674]: Loss = 4.881091117858887
Iteration [27675]: Loss = 0.7126554250717163
Iteration [27676]: Loss = 0.7126891016960144
Iteration [27677]: Loss = 0.71268230676651
Iteration [27678]: Loss = 0.7126389741897583
Iteration [27679]: Loss = 0.7125627994537354
Iteration [27680]: Loss = 0.7124570608139038
Iteration [27681]: Loss = 4.882370948791504
Iteration [27682]: Loss = 0.7123942375183105
Iteration [27683]: Loss = 0.712419867515564
Iteration [27684]: Loss = 4.881958961486816
Iteration [27685]: Loss = 0.7125813961029053
Iteration [27686]: Loss = 0.7127024531364441
Iteration [27687]: Loss = 0.7127742767333984
Iteration [27688]: Loss = 0.7128019332885742
Iteration [27689]: Loss = 0.7127894759178162
Iteration [27690]: Loss = 0.7127412557601929
Iteration [27691]: Loss = 0.7126603722572327
Iteration [27692]: Loss = 0.7125504016876221
Iteration [27693]: Loss = 0.7124141454696655
Iteration [27694]: Loss = 0.7122543454170227
Iteration [27695]: Loss = 0.7120732069015503
Iteration [27696]: Loss = 0.7118727564811707
Iteration [27697]: Loss = 0.7116552591323853
Iteration [27698]: Loss = 0.7114222049713135
Iteration [27699]: Loss = 0.7111750841140747
Iteration [27700]: Loss = 0.7109155058860779
Iteration [27701]: Loss = 0.7106446623802185
Iteration [27702]: Loss = 0.710363507270813
Iteration [27703]: Loss = 0.7100734710693359
Iteration [27704]: Loss = 0.7097750306129456
Iteration [27705]: Loss = 0.7094692587852478
Iteration [27706]: Loss = 0.70915687084198
Iteration [27707]: Loss = 0.7088385224342346
Iteration [27708]: Loss = 0.7085148692131042
Iteration [27709]: Loss = 0.7081863880157471
Iteration [27710]: Loss = 0.7078534960746765
Iteration [27711]: Loss = 0.7075167894363403
Iteration [27712]: Loss = 4.9086761474609375
Iteration [27713]: Loss = 0.7070615887641907
Iteration [27714]: Loss = 0.706920862197876
Iteration [27715]: Loss = 0.706757128238678
Iteration [27716]: Loss = 0.7065727114677429
Iteration [27717]: Loss = 0.7063697576522827
Iteration [27718]: Loss = 0.7061499357223511
Iteration [27719]: Loss = 0.705915093421936
Iteration [27720]: Loss = 0.7056666612625122
Iteration [27721]: Loss = 0.7054058909416199
Iteration [27722]: Loss = 0.7051343321800232
Iteration [27723]: Loss = 0.7048527598381042
Iteration [27724]: Loss = 0.7045624852180481
Iteration [27725]: Loss = 0.7042641043663025
Iteration [27726]: Loss = 0.7039585709571838
Iteration [27727]: Loss = 0.7036466598510742
Iteration [27728]: Loss = 0.7033287882804871
Iteration [27729]: Loss = 0.7030057311058044
Iteration [27730]: Loss = 0.7026782035827637
Iteration [27731]: Loss = 0.7023463249206543
Iteration [27732]: Loss = 0.7020108103752136
Iteration [27733]: Loss = 0.701671838760376
Iteration [27734]: Loss = 0.7013298273086548
Iteration [27735]: Loss = 0.7009851932525635
Iteration [27736]: Loss = 0.7006381750106812
Iteration [27737]: Loss = 0.7002889513969421
Iteration [27738]: Loss = 0.6999377012252808
Iteration [27739]: Loss = 0.6995849013328552
Iteration [27740]: Loss = 0.699230432510376
Iteration [27741]: Loss = 0.6988746523857117
Iteration [27742]: Loss = 0.6985175609588623
Iteration [27743]: Loss = 0.6981594562530518
Iteration [27744]: Loss = 0.6978004574775696
Iteration [27745]: Loss = 0.697440505027771
Iteration [27746]: Loss = 0.6970798969268799
Iteration [27747]: Loss = 4.963101863861084
Iteration [27748]: Loss = 0.6965870261192322
Iteration [27749]: Loss = 0.6964319944381714
Iteration [27750]: Loss = 0.6962558627128601
Iteration [27751]: Loss = 0.6960605382919312
Iteration [27752]: Loss = 0.6958480477333069
Iteration [27753]: Loss = 0.6956202387809753
Iteration [27754]: Loss = 0.6953785419464111
Iteration [27755]: Loss = 0.6951243877410889
Iteration [27756]: Loss = 0.694858968257904
Iteration [27757]: Loss = 0.6945833563804626
Iteration [27758]: Loss = 0.6942988038063049
Iteration [27759]: Loss = 0.694006085395813
Iteration [27760]: Loss = 0.6937059760093689
Iteration [27761]: Loss = 0.6933992505073547
Iteration [27762]: Loss = 4.982316493988037
Iteration [27763]: Loss = 0.6929996013641357
Iteration [27764]: Loss = 0.6928849220275879
Iteration [27765]: Loss = 4.984132289886475
Iteration [27766]: Loss = 0.6928132176399231
Iteration [27767]: Loss = 0.6928381323814392
Iteration [27768]: Loss = 0.6928240656852722
Iteration [27769]: Loss = 0.6927749514579773
Iteration [27770]: Loss = 0.6926941871643066
Iteration [27771]: Loss = 0.6925849914550781
Iteration [27772]: Loss = 0.6924502849578857
Iteration [27773]: Loss = 0.6922924518585205
Iteration [27774]: Loss = 0.6921139359474182
Iteration [27775]: Loss = 0.6919167041778564
Iteration [27776]: Loss = 0.691702663898468
Iteration [27777]: Loss = 0.6914734244346619
Iteration [27778]: Loss = 0.6912307143211365
Iteration [27779]: Loss = 4.993561744689941
Iteration [27780]: Loss = 0.6909410357475281
Iteration [27781]: Loss = 0.6908732652664185
Iteration [27782]: Loss = 0.690775990486145
Iteration [27783]: Loss = 0.6906519532203674
Iteration [27784]: Loss = 0.6905039548873901
Iteration [27785]: Loss = 0.6903342604637146
Iteration [27786]: Loss = 4.9980010986328125
Iteration [27787]: Loss = 0.6901695728302002
Iteration [27788]: Loss = 0.6901551485061646
Iteration [27789]: Loss = 0.6901060342788696
Iteration [27790]: Loss = 0.690025269985199
Iteration [27791]: Loss = 4.999225616455078
Iteration [27792]: Loss = 0.6900127530097961
Iteration [27793]: Loss = 0.6900632977485657
Iteration [27794]: Loss = 0.6900723576545715
Iteration [27795]: Loss = 0.6900442838668823
Iteration [27796]: Loss = 0.6899824738502502
Iteration [27797]: Loss = 0.6898905038833618
Iteration [27798]: Loss = 0.6897712349891663
Iteration [27799]: Loss = 0.689627468585968
Iteration [27800]: Loss = 0.6894617080688477
Iteration [27801]: Loss = 5.002655982971191
Iteration [27802]: Loss = 0.689303994178772
Iteration [27803]: Loss = 0.6892929077148438
Iteration [27804]: Loss = 0.6892464756965637
Iteration [27805]: Loss = 0.6891682744026184
Iteration [27806]: Loss = 5.003805160522461
Iteration [27807]: Loss = 0.6891604661941528
Iteration [27808]: Loss = 0.6892132759094238
Iteration [27809]: Loss = 0.6892243027687073
Iteration [27810]: Loss = 0.6891979575157166
Iteration [27811]: Loss = 0.689137876033783
Iteration [27812]: Loss = 0.6890473961830139
Iteration [27813]: Loss = 0.6889294385910034
Iteration [27814]: Loss = 0.6887868642807007
Iteration [27815]: Loss = 0.6886221766471863
Iteration [27816]: Loss = 0.6884375810623169
Iteration [27817]: Loss = 5.008243560791016
Iteration [27818]: Loss = 0.6882482171058655
Iteration [27819]: Loss = 0.6882237792015076
Iteration [27820]: Loss = 0.6881653070449829
Iteration [27821]: Loss = 0.6880764961242676
Iteration [27822]: Loss = 0.6879600286483765
Iteration [27823]: Loss = 0.6878187656402588
Iteration [27824]: Loss = 0.6876552700996399
Iteration [27825]: Loss = 0.687471866607666
Iteration [27826]: Loss = 0.6872701644897461
Iteration [27827]: Loss = 0.6870524287223816
Iteration [27828]: Loss = 0.686819851398468
Iteration [27829]: Loss = 0.6865742802619934
Iteration [27830]: Loss = 0.6863168478012085
Iteration [27831]: Loss = 0.6860486268997192
Iteration [27832]: Loss = 0.6857709884643555
Iteration [27833]: Loss = 5.023073196411133
Iteration [27834]: Loss = 5.023402690887451
Iteration [27835]: Loss = 0.6855646967887878
Iteration [27836]: Loss = 5.022149085998535
Iteration [27837]: Loss = 0.6859323978424072
Iteration [27838]: Loss = 0.6861456632614136
Iteration [27839]: Loss = 0.6863016486167908
Iteration [27840]: Loss = 0.6864058375358582
Iteration [27841]: Loss = 0.6864633560180664
Iteration [27842]: Loss = 0.6864787340164185
Iteration [27843]: Loss = 0.6864562630653381
Iteration [27844]: Loss = 0.6863999962806702
Iteration [27845]: Loss = 5.018597602844238
Iteration [27846]: Loss = 0.6864300966262817
Iteration [27847]: Loss = 0.6864997148513794
Iteration [27848]: Loss = 0.6865259408950806
Iteration [27849]: Loss = 5.017514705657959
Iteration [27850]: Loss = 0.6866974234580994
Iteration [27851]: Loss = 0.6868271231651306
Iteration [27852]: Loss = 5.015389442443848
Iteration [27853]: Loss = 5.013947486877441
Iteration [27854]: Loss = 0.6876102685928345
Iteration [27855]: Loss = 0.6879661679267883
Iteration [27856]: Loss = 0.6882504820823669
Iteration [27857]: Loss = 0.6917669773101807
Iteration [27858]: Loss = 0.691928505897522
Iteration [27859]: Loss = 0.6920375227928162
Iteration [27860]: Loss = 0.6920987963676453
Iteration [27861]: Loss = 0.6921175122261047
Iteration [27862]: Loss = 4.98757791519165
Iteration [27863]: Loss = 4.982552528381348
Iteration [27864]: Loss = 0.6933957934379578
Iteration [27865]: Loss = 0.6936774253845215
Iteration [27866]: Loss = 0.6938945651054382
Iteration [27867]: Loss = 0.6940532922744751
Iteration [27868]: Loss = 0.6941595673561096
Iteration [27869]: Loss = 0.6942183971405029
Iteration [27870]: Loss = 4.976225852966309
Iteration [27871]: Loss = 0.6944437026977539
Iteration [27872]: Loss = 0.694595456123352
Iteration [27873]: Loss = 0.6946951150894165
Iteration [27874]: Loss = 0.6947479844093323
Iteration [27875]: Loss = 0.6947590112686157
Iteration [27876]: Loss = 4.973592281341553
Iteration [27877]: Loss = 0.6949023008346558
Iteration [27878]: Loss = 0.6950188279151917
Iteration [27879]: Loss = 0.6950870752334595
Iteration [27880]: Loss = 4.971583843231201
Iteration [27881]: Loss = 0.6953281164169312
Iteration [27882]: Loss = 0.695486307144165
Iteration [27883]: Loss = 0.695591926574707
Iteration [27884]: Loss = 0.6956502199172974
Iteration [27885]: Loss = 0.6956657767295837
Iteration [27886]: Loss = 0.6956428289413452
Iteration [27887]: Loss = 0.6955853700637817
Iteration [27888]: Loss = 0.695496678352356
Iteration [27889]: Loss = 0.6953799724578857
Iteration [27890]: Loss = 0.6952378153800964
Iteration [27891]: Loss = 4.971787929534912
Iteration [27892]: Loss = 0.6931371688842773
Iteration [27893]: Loss = 4.982020378112793
Iteration [27894]: Loss = 0.6933419704437256
Iteration [27895]: Loss = 0.6934850811958313
Iteration [27896]: Loss = 0.6935771703720093
Iteration [27897]: Loss = 0.6936231851577759
Iteration [27898]: Loss = 0.6936280727386475
Iteration [27899]: Loss = 4.979614734649658
Iteration [27900]: Loss = 0.6937611699104309
Iteration [27901]: Loss = 0.6938735246658325
Iteration [27902]: Loss = 0.6939380764961243
Iteration [27903]: Loss = 0.6939593553543091
Iteration [27904]: Loss = 0.6939416527748108
Iteration [27905]: Loss = 0.6938890814781189
Iteration [27906]: Loss = 0.6938048601150513
Iteration [27907]: Loss = 0.6936920881271362
Iteration [27908]: Loss = 0.6935538649559021
Iteration [27909]: Loss = 0.6933926939964294
Iteration [27910]: Loss = 0.6932106018066406
Iteration [27911]: Loss = 0.6930098533630371
Iteration [27912]: Loss = 0.6927923560142517
Iteration [27913]: Loss = 0.6925597786903381
Iteration [27914]: Loss = 0.692313551902771
Iteration [27915]: Loss = 0.6920552253723145
Iteration [27916]: Loss = 0.6917857527732849
Iteration [27917]: Loss = 0.6915065050125122
Iteration [27918]: Loss = 0.6912182569503784
Iteration [27919]: Loss = 0.6909220814704895
Iteration [27920]: Loss = 0.6906187534332275
Iteration [27921]: Loss = 9.303937911987305
Iteration [27922]: Loss = 0.6904582977294922
Iteration [27923]: Loss = 0.6905563473701477
Iteration [27924]: Loss = 0.6906084418296814
Iteration [27925]: Loss = 0.6906188726425171
Iteration [27926]: Loss = 4.995611667633057
Iteration [27927]: Loss = 0.6907618045806885
Iteration [27928]: Loss = 0.6908785104751587
Iteration [27929]: Loss = 0.6909472346305847
Iteration [27930]: Loss = 4.993577480316162
Iteration [27931]: Loss = 0.6911895871162415
Iteration [27932]: Loss = 0.6913486123085022
Iteration [27933]: Loss = 0.6914553642272949
Iteration [27934]: Loss = 0.6915150880813599
Iteration [27935]: Loss = 0.6915323734283447
Iteration [27936]: Loss = 0.6915114521980286
Iteration [27937]: Loss = 4.990996360778809
Iteration [27938]: Loss = 0.6916007995605469
Iteration [27939]: Loss = 0.6916946172714233
Iteration [27940]: Loss = 0.6917425394058228
Iteration [27941]: Loss = 0.6917491555213928
Iteration [27942]: Loss = 0.6917186379432678
Iteration [27943]: Loss = 0.6916546821594238
Iteration [27944]: Loss = 0.6915604472160339
Iteration [27945]: Loss = 0.6914393305778503
Iteration [27946]: Loss = 0.6912936568260193
Iteration [27947]: Loss = 0.6911259293556213
Iteration [27948]: Loss = 0.690938413143158
Iteration [27949]: Loss = 0.6907331347465515
Iteration [27950]: Loss = 0.6905117630958557
Iteration [27951]: Loss = 0.6902759075164795
Iteration [27952]: Loss = 0.6900272369384766
Iteration [27953]: Loss = 0.6897667646408081
Iteration [27954]: Loss = 5.001476764678955
Iteration [27955]: Loss = 0.6894477605819702
Iteration [27956]: Loss = 0.689367949962616
Iteration [27957]: Loss = 5.002742767333984
Iteration [27958]: Loss = 5.002218246459961
Iteration [27959]: Loss = 0.6896399855613708
Iteration [27960]: Loss = 0.689858078956604
Iteration [27961]: Loss = 0.6900178790092468
Iteration [27962]: Loss = 0.6901256442070007
Iteration [27963]: Loss = 0.6901861429214478
Iteration [27964]: Loss = 0.6902040839195251
Iteration [27965]: Loss = 0.6901839971542358
Iteration [27966]: Loss = 0.6901291608810425
Iteration [27967]: Loss = 0.690043568611145
Iteration [27968]: Loss = 0.6899298429489136
Iteration [27969]: Loss = 0.6897910237312317
Iteration [27970]: Loss = 0.6896296143531799
Iteration [27971]: Loss = 0.6894477605819702
Iteration [27972]: Loss = 0.6892474293708801
Iteration [27973]: Loss = 5.014593601226807
Iteration [27974]: Loss = 5.014585018157959
Iteration [27975]: Loss = 0.6872531175613403
Iteration [27976]: Loss = 0.6873937845230103
Iteration [27977]: Loss = 0.6874841451644897
Iteration [27978]: Loss = 0.6875293254852295
Iteration [27979]: Loss = 5.012014389038086
Iteration [27980]: Loss = 0.6877327561378479
Iteration [27981]: Loss = 0.6878755688667297
Iteration [27982]: Loss = 0.6879680156707764
Iteration [27983]: Loss = 0.6880149245262146
Iteration [27984]: Loss = 0.6880208253860474
Iteration [27985]: Loss = 0.6879898905754089
Iteration [27986]: Loss = 0.6879255175590515
Iteration [27987]: Loss = 5.01041316986084
Iteration [27988]: Loss = 0.6879419684410095
Iteration [27989]: Loss = 5.00947904586792
Iteration [27990]: Loss = 0.6882567405700684
Iteration [27991]: Loss = 0.688447117805481
Iteration [27992]: Loss = 0.688582181930542
Iteration [27993]: Loss = 0.6886675953865051
Iteration [27994]: Loss = 5.005701541900635
Iteration [27995]: Loss = 0.6889393925666809
Iteration [27996]: Loss = 0.6891112327575684
Iteration [27997]: Loss = 0.6892296671867371
Iteration [27998]: Loss = 0.6892999410629272
Iteration [27999]: Loss = 0.6893268823623657
Iteration [28000]: Loss = 0.689314603805542
Iteration [28001]: Loss = 0.6892672181129456
Iteration [28002]: Loss = 0.6891883015632629
Iteration [28003]: Loss = 0.6890806555747986
Iteration [28004]: Loss = 0.6889472007751465
Iteration [28005]: Loss = 0.6887907981872559
Iteration [28006]: Loss = 0.6886134743690491
Iteration [28007]: Loss = 0.688417375087738
Iteration [28008]: Loss = 0.6882044672966003
Iteration [28009]: Loss = 0.6879764795303345
Iteration [28010]: Loss = 5.010932922363281
Iteration [28011]: Loss = 5.011049270629883
Iteration [28012]: Loss = 0.6878891587257385
Iteration [28013]: Loss = 0.6880112290382385
Iteration [28014]: Loss = 5.009051322937012
Iteration [28015]: Loss = 0.6883459091186523
Iteration [28016]: Loss = 0.6885448098182678
Iteration [28017]: Loss = 0.6886875629425049
Iteration [28018]: Loss = 5.005317687988281
Iteration [28019]: Loss = 0.6890573501586914
Iteration [28020]: Loss = 0.6892709732055664
Iteration [28021]: Loss = 0.6894271373748779
Iteration [28022]: Loss = 0.6895313858985901
Iteration [28023]: Loss = 0.6895887851715088
Iteration [28024]: Loss = 0.6896039843559265
Iteration [28025]: Loss = 0.6895812749862671
Iteration [28026]: Loss = 0.6895244121551514
Iteration [28027]: Loss = 0.6894367337226868
Iteration [28028]: Loss = 0.6893211603164673
Iteration [28029]: Loss = 0.6891807317733765
Iteration [28030]: Loss = 0.6890177130699158
Iteration [28031]: Loss = 0.6888346672058105
Iteration [28032]: Loss = 0.6886333227157593
Iteration [28033]: Loss = 0.6884155869483948
Iteration [28034]: Loss = 5.008521556854248
Iteration [28035]: Loss = 0.6881700754165649
Iteration [28036]: Loss = 0.6881217956542969
Iteration [28037]: Loss = 0.6880419850349426
Iteration [28038]: Loss = 5.009863376617432
Iteration [28039]: Loss = 0.6880319118499756
Iteration [28040]: Loss = 9.330025672912598
Iteration [28041]: Loss = 5.006532669067383
Iteration [28042]: Loss = 0.6891681551933289
Iteration [28043]: Loss = 0.6896860599517822
Iteration [28044]: Loss = 0.6901166439056396
Iteration [28045]: Loss = 0.6904682517051697
Iteration [28046]: Loss = 0.6907488703727722
Iteration [28047]: Loss = 0.6909654140472412
Iteration [28048]: Loss = 0.6911241412162781
Iteration [28049]: Loss = 0.691230833530426
Iteration [28050]: Loss = 4.991880416870117
Iteration [28051]: Loss = 0.691537618637085
Iteration [28052]: Loss = 4.989569664001465
Iteration [28053]: Loss = 0.6920839548110962
Iteration [28054]: Loss = 0.6923722624778748
Iteration [28055]: Loss = 4.984928607940674
Iteration [28056]: Loss = 4.982836723327637
Iteration [28057]: Loss = 0.693534791469574
Iteration [28058]: Loss = 0.6939903497695923
Iteration [28059]: Loss = 0.6943643093109131
Iteration [28060]: Loss = 0.6946648955345154
Iteration [28061]: Loss = 0.694899320602417
Iteration [28062]: Loss = 0.6950739026069641
Iteration [28063]: Loss = 0.6951947808265686
Iteration [28064]: Loss = 0.6952670812606812
Iteration [28065]: Loss = 4.970611095428467
Iteration [28066]: Loss = 0.695513904094696
Iteration [28067]: Loss = 0.695673942565918
Iteration [28068]: Loss = 0.6957815885543823
Iteration [28069]: Loss = 0.6958421468734741
Iteration [28070]: Loss = 0.6958600282669067
Iteration [28071]: Loss = 0.6958395838737488
Iteration [28072]: Loss = 0.6957845687866211
Iteration [28073]: Loss = 0.6956985592842102
Iteration [28074]: Loss = 0.6955846548080444
Iteration [28075]: Loss = 0.6954452991485596
Iteration [28076]: Loss = 0.6952834129333496
Iteration [28077]: Loss = 0.6951010227203369
Iteration [28078]: Loss = 0.694900393486023
Iteration [28079]: Loss = 0.6946830749511719
Iteration [28080]: Loss = 0.694450855255127
Iteration [28081]: Loss = 0.6942053437232971
Iteration [28082]: Loss = 0.6939477324485779
Iteration [28083]: Loss = 9.26466178894043
Iteration [28084]: Loss = 4.978210926055908
Iteration [28085]: Loss = 0.6942143440246582
Iteration [28086]: Loss = 4.9748358726501465
Iteration [28087]: Loss = 0.6949422955513
Iteration [28088]: Loss = 0.695307195186615
Iteration [28089]: Loss = 4.969004154205322
Iteration [28090]: Loss = 0.696053683757782
Iteration [28091]: Loss = 0.6964263916015625
Iteration [28092]: Loss = 0.6967257261276245
Iteration [28093]: Loss = 0.6969591379165649
Iteration [28094]: Loss = 0.69713294506073
Iteration [28095]: Loss = 0.6972530484199524
Iteration [28096]: Loss = 0.6973249912261963
Iteration [28097]: Loss = 0.6973532438278198
Iteration [28098]: Loss = 0.6973422169685364
Iteration [28099]: Loss = 4.960061550140381
Iteration [28100]: Loss = 0.6974458694458008
Iteration [28101]: Loss = 0.6975443363189697
Iteration [28102]: Loss = 0.697596549987793
Iteration [28103]: Loss = 0.6976071000099182
Iteration [28104]: Loss = 0.6975801587104797
Iteration [28105]: Loss = 4.95888614654541
Iteration [28106]: Loss = 0.6976563930511475
Iteration [28107]: Loss = 0.6977431178092957
Iteration [28108]: Loss = 0.6977849006652832
Iteration [28109]: Loss = 0.6977859735488892
Iteration [28110]: Loss = 0.6977505087852478
Iteration [28111]: Loss = 0.6976821422576904
Iteration [28112]: Loss = 0.6975840926170349
Iteration [28113]: Loss = 0.69745934009552
Iteration [28114]: Loss = 0.6973104476928711
Iteration [28115]: Loss = 0.697140097618103
Iteration [28116]: Loss = 0.6935327649116516
Iteration [28117]: Loss = 0.6933236122131348
Iteration [28118]: Loss = 0.693096399307251
Iteration [28119]: Loss = 0.6928526163101196
Iteration [28120]: Loss = 0.6925942897796631
Iteration [28121]: Loss = 0.6923225522041321
Iteration [28122]: Loss = 0.6920389533042908
Iteration [28123]: Loss = 0.6917444467544556
Iteration [28124]: Loss = 0.6914405226707458
Iteration [28125]: Loss = 0.6911279559135437
Iteration [28126]: Loss = 0.6908074617385864
Iteration [28127]: Loss = 0.69048011302948
Iteration [28128]: Loss = 0.6901464462280273
Iteration [28129]: Loss = 0.6898070573806763
Iteration [28130]: Loss = 0.6894627809524536
Iteration [28131]: Loss = 9.3179349899292
Iteration [28132]: Loss = 0.6892549395561218
Iteration [28133]: Loss = 0.6893433928489685
Iteration [28134]: Loss = 0.6893843412399292
Iteration [28135]: Loss = 0.6893829703330994
Iteration [28136]: Loss = 9.315250396728516
Iteration [28137]: Loss = 0.6897544264793396
Iteration [28138]: Loss = 0.6900867819786072
Iteration [28139]: Loss = 0.6903479099273682
Iteration [28140]: Loss = 0.6905447840690613
Iteration [28141]: Loss = 0.690683901309967
Iteration [28142]: Loss = 0.6907707452774048
Iteration [28143]: Loss = 0.6908107995986938
Iteration [28144]: Loss = 0.6908081769943237
Iteration [28145]: Loss = 4.994671821594238
Iteration [28146]: Loss = 4.993773937225342
Iteration [28147]: Loss = 0.6912912130355835
Iteration [28148]: Loss = 0.6915729641914368
Iteration [28149]: Loss = 4.9892258644104
Iteration [28150]: Loss = 0.6921858787536621
Iteration [28151]: Loss = 4.985405921936035
Iteration [28152]: Loss = 9.253084182739258
Iteration [28153]: Loss = 0.6954933404922485
Iteration [28154]: Loss = 0.6961932182312012
Iteration [28155]: Loss = 0.6967883706092834
Iteration [28156]: Loss = 0.6972888708114624
Iteration [28157]: Loss = 0.6977041959762573
Iteration [28158]: Loss = 0.6980426907539368
Iteration [28159]: Loss = 0.6983116269111633
Iteration [28160]: Loss = 0.6985183954238892
Iteration [28161]: Loss = 0.6986686587333679
Iteration [28162]: Loss = 0.6987681984901428
Iteration [28163]: Loss = 0.6988221406936646
Iteration [28164]: Loss = 0.6988347172737122
Iteration [28165]: Loss = 4.9521098136901855
Iteration [28166]: Loss = 0.6989759206771851
Iteration [28167]: Loss = 0.6990892887115479
Iteration [28168]: Loss = 0.6991554498672485
Iteration [28169]: Loss = 0.6991792321205139
Iteration [28170]: Loss = 4.950252532958984
Iteration [28171]: Loss = 0.6993393301963806
Iteration [28172]: Loss = 0.6994607448577881
Iteration [28173]: Loss = 0.6995341181755066
Iteration [28174]: Loss = 0.6995643973350525
Iteration [28175]: Loss = 0.6995556354522705
Iteration [28176]: Loss = 0.6995119452476501
Iteration [28177]: Loss = 0.699436604976654
Iteration [28178]: Loss = 0.6993329524993896
Iteration [28179]: Loss = 0.6992035508155823
Iteration [28180]: Loss = 0.6990512609481812
Iteration [28181]: Loss = 0.6988781094551086
Iteration [28182]: Loss = 0.698686420917511
Iteration [28183]: Loss = 0.6984777450561523
Iteration [28184]: Loss = 0.6982541084289551
Iteration [28185]: Loss = 4.956273078918457
Iteration [28186]: Loss = 4.9564032554626465
Iteration [28187]: Loss = 0.698157787322998
Iteration [28188]: Loss = 0.6982711553573608
Iteration [28189]: Loss = 0.6983374357223511
Iteration [28190]: Loss = 0.6983612775802612
Iteration [28191]: Loss = 0.698346734046936
Iteration [28192]: Loss = 0.6982978582382202
Iteration [28193]: Loss = 0.6982179284095764
Iteration [28194]: Loss = 0.6981101036071777
Iteration [28195]: Loss = 0.6979770064353943
Iteration [28196]: Loss = 4.957300186157227
Iteration [28197]: Loss = 0.6978698372840881
Iteration [28198]: Loss = 0.6978776454925537
Iteration [28199]: Loss = 0.6978488564491272
Iteration [28200]: Loss = 0.6977869272232056
Iteration [28201]: Loss = 0.6976953148841858
Iteration [28202]: Loss = 0.6975768804550171
Iteration [28203]: Loss = 0.6974344253540039
Iteration [28204]: Loss = 0.6972701549530029
Iteration [28205]: Loss = 4.961164951324463
Iteration [28206]: Loss = 0.6971100568771362
Iteration [28207]: Loss = 0.6970954537391663
Iteration [28208]: Loss = 0.6970464587211609
Iteration [28209]: Loss = 0.6969664096832275
Iteration [28210]: Loss = 0.6968584656715393
Iteration [28211]: Loss = 0.6967253088951111
Iteration [28212]: Loss = 0.6965696811676025
Iteration [28213]: Loss = 0.6963934898376465
Iteration [28214]: Loss = 0.6961990594863892
Iteration [28215]: Loss = 0.6959880590438843
Iteration [28216]: Loss = 0.6957622170448303
Iteration [28217]: Loss = 4.9694085121154785
Iteration [28218]: Loss = 4.969542980194092
Iteration [28219]: Loss = 4.968666076660156
Iteration [28220]: Loss = 0.6960015296936035
Iteration [28221]: Loss = 0.6962701082229614
Iteration [28222]: Loss = 0.69647616147995
Iteration [28223]: Loss = 0.6966258883476257
Iteration [28224]: Loss = 0.6967249512672424
Iteration [28225]: Loss = 4.96278715133667
Iteration [28226]: Loss = 0.6970147490501404
Iteration [28227]: Loss = 4.960609436035156
Iteration [28228]: Loss = 0.6975395679473877
Iteration [28229]: Loss = 4.9573235511779785
Iteration [28230]: Loss = 4.955025672912598
Iteration [28231]: Loss = 0.6988353133201599
Iteration [28232]: Loss = 0.6993229985237122
Iteration [28233]: Loss = 0.6997263431549072
Iteration [28234]: Loss = 0.7000537514686584
Iteration [28235]: Loss = 0.7003127336502075
Iteration [28236]: Loss = 4.943217754364014
Iteration [28237]: Loss = 4.941312789916992
Iteration [28238]: Loss = 0.7013905048370361
Iteration [28239]: Loss = 0.7018190026283264
Iteration [28240]: Loss = 0.7021690011024475
Iteration [28241]: Loss = 0.7024479508399963
Iteration [28242]: Loss = 0.702663242816925
Iteration [28243]: Loss = 0.702820897102356
Iteration [28244]: Loss = 4.930633068084717
Iteration [28245]: Loss = 0.703209400177002
Iteration [28246]: Loss = 0.7034279108047485
Iteration [28247]: Loss = 0.7035883069038391
Iteration [28248]: Loss = 0.703696608543396
Iteration [28249]: Loss = 0.7037579417228699
Iteration [28250]: Loss = 0.7037767171859741
Iteration [28251]: Loss = 0.7037575840950012
Iteration [28252]: Loss = 0.7037038803100586
Iteration [28253]: Loss = 0.7036193013191223
Iteration [28254]: Loss = 0.7035067677497864
Iteration [28255]: Loss = 0.7033692598342896
Iteration [28256]: Loss = 0.7032089233398438
Iteration [28257]: Loss = 4.930105209350586
Iteration [28258]: Loss = 0.7030544877052307
Iteration [28259]: Loss = 0.7030416131019592
Iteration [28260]: Loss = 0.7029938101768494
Iteration [28261]: Loss = 4.930697917938232
Iteration [28262]: Loss = 0.7030312418937683
Iteration [28263]: Loss = 0.7031000852584839
Iteration [28264]: Loss = 0.7031258940696716
Iteration [28265]: Loss = 0.7031128406524658
Iteration [28266]: Loss = 0.7030646800994873
Iteration [28267]: Loss = 4.930330276489258
Iteration [28268]: Loss = 0.7031018137931824
Iteration [28269]: Loss = 4.929368495941162
Iteration [28270]: Loss = 0.7034202814102173
Iteration [28271]: Loss = 0.7036089301109314
Iteration [28272]: Loss = 0.7037426233291626
Iteration [28273]: Loss = 0.7038266658782959
Iteration [28274]: Loss = 0.7038658857345581
Iteration [28275]: Loss = 0.7038649320602417
Iteration [28276]: Loss = 0.7038278579711914
Iteration [28277]: Loss = 0.7037579417228699
Iteration [28278]: Loss = 0.7036586999893188
Iteration [28279]: Loss = 4.927488803863525
Iteration [28280]: Loss = 0.7036082148551941
Iteration [28281]: Loss = 4.926935195922852
Iteration [28282]: Loss = 0.7038560509681702
Iteration [28283]: Loss = 0.7040144801139832
Iteration [28284]: Loss = 0.7041208744049072
Iteration [28285]: Loss = 0.7041803002357483
Iteration [28286]: Loss = 0.7041975855827332
Iteration [28287]: Loss = 0.7041764855384827
Iteration [28288]: Loss = 4.924440860748291
Iteration [28289]: Loss = 0.7042597532272339
Iteration [28290]: Loss = 0.7043481469154358
Iteration [28291]: Loss = 0.7043913006782532
Iteration [28292]: Loss = 0.7043938040733337
Iteration [28293]: Loss = 0.7043595910072327
Iteration [28294]: Loss = 4.92355489730835
Iteration [28295]: Loss = 0.7044202089309692
Iteration [28296]: Loss = 0.7044989466667175
Iteration [28297]: Loss = 0.7045333981513977
Iteration [28298]: Loss = 0.7045279741287231
Iteration [28299]: Loss = 0.7044867873191833
Iteration [28300]: Loss = 0.7044129967689514
Iteration [28301]: Loss = 4.923461437225342
Iteration [28302]: Loss = 0.7044063210487366
Iteration [28303]: Loss = 0.7044563889503479
Iteration [28304]: Loss = 0.7044650316238403
Iteration [28305]: Loss = 0.7044362425804138
Iteration [28306]: Loss = 0.7043740153312683
Iteration [28307]: Loss = 4.923611164093018
Iteration [28308]: Loss = 9.141746520996094
Iteration [28309]: Loss = 0.7048898935317993
Iteration [28310]: Loss = 0.7053070664405823
Iteration [28311]: Loss = 0.7056466937065125
Iteration [28312]: Loss = 0.7059164047241211
Iteration [28313]: Loss = 0.706122875213623
Iteration [28314]: Loss = 4.913328647613525
Iteration [28315]: Loss = 4.911674499511719
Iteration [28316]: Loss = 4.909229755401611
Iteration [28317]: Loss = 4.906078815460205
Iteration [28318]: Loss = 0.7084195017814636
Iteration [28319]: Loss = 0.7090474367141724
Iteration [28320]: Loss = 0.7095769643783569
Iteration [28321]: Loss = 0.7100174427032471
Iteration [28322]: Loss = 0.7103779315948486
Iteration [28323]: Loss = 0.710666298866272
Iteration [28324]: Loss = 0.7108892798423767
Iteration [28325]: Loss = 4.888835430145264
Iteration [28326]: Loss = 0.7113872766494751
Iteration [28327]: Loss = 4.885794639587402
Iteration [28328]: Loss = 0.7120741605758667
Iteration [28329]: Loss = 0.7124184966087341
Iteration [28330]: Loss = 0.712692141532898
Iteration [28331]: Loss = 0.7129018306732178
Iteration [28332]: Loss = 4.878667831420898
Iteration [28333]: Loss = 0.7133766412734985
Iteration [28334]: Loss = 0.7136305570602417
Iteration [28335]: Loss = 0.7138224244117737
Iteration [28336]: Loss = 0.7139585018157959
Iteration [28337]: Loss = 0.7140443325042725
Iteration [28338]: Loss = 0.7140848636627197
Iteration [28339]: Loss = 4.873448848724365
Iteration [28340]: Loss = 0.7142701745033264
Iteration [28341]: Loss = 0.7144004106521606
Iteration [28342]: Loss = 4.871445178985596
Iteration [28343]: Loss = 0.7147389054298401
Iteration [28344]: Loss = 4.86915397644043
Iteration [28345]: Loss = 0.7152957916259766
Iteration [28346]: Loss = 0.715584397315979
Iteration [28347]: Loss = 0.7158074975013733
Iteration [28348]: Loss = 0.7159715294837952
Iteration [28349]: Loss = 0.7160823941230774
Iteration [28350]: Loss = 4.863048553466797
Iteration [28351]: Loss = 0.7163873910903931
Iteration [28352]: Loss = 4.860918998718262
Iteration [28353]: Loss = 0.716916561126709
Iteration [28354]: Loss = 0.7171931266784668
Iteration [28355]: Loss = 4.856715679168701
Iteration [28356]: Loss = 0.717781126499176
Iteration [28357]: Loss = 0.7180827260017395
Iteration [28358]: Loss = 0.7183173894882202
Iteration [28359]: Loss = 0.7184917330741882
Iteration [28360]: Loss = 0.7186117172241211
Iteration [28361]: Loss = 0.7186827659606934
Iteration [28362]: Loss = 0.7187096476554871
Iteration [28363]: Loss = 0.7186968326568604
Iteration [28364]: Loss = 0.7186480164527893
Iteration [28365]: Loss = 0.7185671925544739
Iteration [28366]: Loss = 0.7184571623802185
Iteration [28367]: Loss = 0.7183210849761963
Iteration [28368]: Loss = 0.718161404132843
Iteration [28369]: Loss = 0.7179806232452393
Iteration [28370]: Loss = 0.7177807688713074
Iteration [28371]: Loss = 0.7175636887550354
Iteration [28372]: Loss = 4.857087135314941
Iteration [28373]: Loss = 0.7176037430763245
Iteration [28374]: Loss = 0.7175460457801819
Iteration [28375]: Loss = 0.7174569964408875
Iteration [28376]: Loss = 0.7173397541046143
Iteration [28377]: Loss = 0.7171971201896667
Iteration [28378]: Loss = 0.717031717300415
Iteration [28379]: Loss = 0.7168456315994263
Iteration [28380]: Loss = 4.860555648803711
Iteration [28381]: Loss = 0.7166433930397034
Iteration [28382]: Loss = 0.716608464717865
Iteration [28383]: Loss = 0.7165400385856628
Iteration [28384]: Loss = 0.7164413332939148
Iteration [28385]: Loss = 0.7163152694702148
Iteration [28386]: Loss = 4.862950801849365
Iteration [28387]: Loss = 4.862693786621094
Iteration [28388]: Loss = 4.861526012420654
Iteration [28389]: Loss = 0.7168423533439636
Iteration [28390]: Loss = 0.7171605229377747
Iteration [28391]: Loss = 0.7174100279808044
Iteration [28392]: Loss = 0.7175977230072021
Iteration [28393]: Loss = 0.7177296876907349
Iteration [28394]: Loss = 4.854676723480225
Iteration [28395]: Loss = 4.853377342224121
Iteration [28396]: Loss = 4.851280689239502
Iteration [28397]: Loss = 0.7190507650375366
Iteration [28398]: Loss = 0.7195196747779846
Iteration [28399]: Loss = 4.844203472137451
Iteration [28400]: Loss = 0.7204362154006958
Iteration [28401]: Loss = 0.7208778858184814
Iteration [28402]: Loss = 4.837557315826416
Iteration [28403]: Loss = 4.835026741027832
Iteration [28404]: Loss = 4.831836223602295
Iteration [28405]: Loss = 0.7231519818305969
Iteration [28406]: Loss = 0.7238014340400696
Iteration [28407]: Loss = 0.724349319934845
Iteration [28408]: Loss = 0.7248054146766663
Iteration [28409]: Loss = 0.7251789569854736
Iteration [28410]: Loss = 0.7254779934883118
Iteration [28411]: Loss = 0.7257097363471985
Iteration [28412]: Loss = 0.7258809208869934
Iteration [28413]: Loss = 0.7259976863861084
Iteration [28414]: Loss = 4.813676357269287
Iteration [28415]: Loss = 0.7263104319572449
Iteration [28416]: Loss = 0.7264936566352844
Iteration [28417]: Loss = 0.7266210913658142
Iteration [28418]: Loss = 0.7266983389854431
Iteration [28419]: Loss = 0.7267303466796875
Iteration [28420]: Loss = 4.810450077056885
Iteration [28421]: Loss = 0.7268980145454407
Iteration [28422]: Loss = 0.7270194888114929
Iteration [28423]: Loss = 0.7270912528038025
Iteration [28424]: Loss = 0.7271181344985962
Iteration [28425]: Loss = 4.808567047119141
Iteration [28426]: Loss = 0.7272773385047913
Iteration [28427]: Loss = 0.7273951172828674
Iteration [28428]: Loss = 0.7274634838104248
Iteration [28429]: Loss = 0.727487325668335
Iteration [28430]: Loss = 0.7274711728096008
Iteration [28431]: Loss = 0.7274187207221985
Iteration [28432]: Loss = 4.8074421882629395
Iteration [28433]: Loss = 0.7274425625801086
Iteration [28434]: Loss = 0.7275026440620422
Iteration [28435]: Loss = 0.7275190353393555
Iteration [28436]: Loss = 4.806646347045898
Iteration [28437]: Loss = 0.727033793926239
Iteration [28438]: Loss = 0.7271436452865601
Iteration [28439]: Loss = 4.808075428009033
Iteration [28440]: Loss = 4.806899547576904
Iteration [28441]: Loss = 0.727844774723053
Iteration [28442]: Loss = 4.803356647491455
Iteration [28443]: Loss = 0.7286420464515686
Iteration [28444]: Loss = 0.7290319204330444
Iteration [28445]: Loss = 0.7293452024459839
Iteration [28446]: Loss = 0.729589581489563
Iteration [28447]: Loss = 0.7297718524932861
Iteration [28448]: Loss = 0.7298980951309204
Iteration [28449]: Loss = 4.794529438018799
Iteration [28450]: Loss = 0.7302265167236328
Iteration [28451]: Loss = 0.7304161787033081
Iteration [28452]: Loss = 0.7305490970611572
Iteration [28453]: Loss = 0.7306308746337891
Iteration [28454]: Loss = 0.7306665182113647
Iteration [28455]: Loss = 4.7911834716796875
Iteration [28456]: Loss = 4.790310859680176
Iteration [28457]: Loss = 0.7311853766441345
Iteration [28458]: Loss = 0.7314587235450745
Iteration [28459]: Loss = 0.7316669225692749
Iteration [28460]: Loss = 4.785563945770264
Iteration [28461]: Loss = 0.732134997844696
Iteration [28462]: Loss = 0.7323839068412781
Iteration [28463]: Loss = 0.7325701713562012
Iteration [28464]: Loss = 0.7326997518539429
Iteration [28465]: Loss = 4.780898094177246
Iteration [28466]: Loss = 0.7330334186553955
Iteration [28467]: Loss = 0.7332249879837036
Iteration [28468]: Loss = 0.7333593368530273
Iteration [28469]: Loss = 0.7334422469139099
Iteration [28470]: Loss = 0.7334787845611572
Iteration [28471]: Loss = 4.777533531188965
Iteration [28472]: Loss = 0.7336530089378357
Iteration [28473]: Loss = 0.7337765693664551
Iteration [28474]: Loss = 0.7338497042655945
Iteration [28475]: Loss = 0.7338773608207703
Iteration [28476]: Loss = 0.7338640689849854
Iteration [28477]: Loss = 0.7338138222694397
Iteration [28478]: Loss = 0.7337303757667542
Iteration [28479]: Loss = 0.7336170077323914
Iteration [28480]: Loss = 0.7334767580032349
Iteration [28481]: Loss = 0.73331218957901
Iteration [28482]: Loss = 0.7331258654594421
Iteration [28483]: Loss = 0.7329197525978088
Iteration [28484]: Loss = 0.7326961755752563
Iteration [28485]: Loss = 0.7324565649032593
Iteration [28486]: Loss = 0.7322026491165161
Iteration [28487]: Loss = 0.7319358587265015
Iteration [28488]: Loss = 4.7863359451293945
Iteration [28489]: Loss = 0.7315927743911743
Iteration [28490]: Loss = 0.7314963936805725
Iteration [28491]: Loss = 0.7313714027404785
Iteration [28492]: Loss = 0.7312206625938416
Iteration [28493]: Loss = 0.7310466766357422
Iteration [28494]: Loss = 0.7308520674705505
Iteration [28495]: Loss = 0.7306386828422546
Iteration [28496]: Loss = 4.792410850524902
Iteration [28497]: Loss = 4.792515277862549
Iteration [28498]: Loss = 4.79170560836792
Iteration [28499]: Loss = 0.7308877110481262
Iteration [28500]: Loss = 0.7311508059501648
Iteration [28501]: Loss = 0.7313495874404907
Iteration [28502]: Loss = 4.78714656829834
Iteration [28503]: Loss = 0.7318023443222046
Iteration [28504]: Loss = 0.7320449352264404
Iteration [28505]: Loss = 0.7322253584861755
Iteration [28506]: Loss = 0.7323495745658875
Iteration [28507]: Loss = 0.7324233055114746
Iteration [28508]: Loss = 0.7324514985084534
Iteration [28509]: Loss = 0.7324385643005371
Iteration [28510]: Loss = 0.7323887348175049
Iteration [28511]: Loss = 0.7323055863380432
Iteration [28512]: Loss = 0.7321923971176147
Iteration [28513]: Loss = 4.784419059753418
Iteration [28514]: Loss = 0.7321118116378784
Iteration [28515]: Loss = 0.7321271896362305
Iteration [28516]: Loss = 0.7321028709411621
Iteration [28517]: Loss = 0.7320425510406494
Iteration [28518]: Loss = 0.7319501042366028
Iteration [28519]: Loss = 4.7855048179626465
Iteration [28520]: Loss = 0.7319047451019287
Iteration [28521]: Loss = 0.7319353222846985
Iteration [28522]: Loss = 0.7319244146347046
Iteration [28523]: Loss = 0.7318764925003052
Iteration [28524]: Loss = 0.731795072555542
Iteration [28525]: Loss = 0.7316833138465881
Iteration [28526]: Loss = 0.7315446734428406
Iteration [28527]: Loss = 0.7313814163208008
Iteration [28528]: Loss = 0.7311962842941284
Iteration [28529]: Loss = 0.7309912443161011
Iteration [28530]: Loss = 0.7307683825492859
Iteration [28531]: Loss = 0.7305295467376709
Iteration [28532]: Loss = 0.7302762269973755
Iteration [28533]: Loss = 0.730009913444519
Iteration [28534]: Loss = 0.7297320365905762
Iteration [28535]: Loss = 0.7294436097145081
Iteration [28536]: Loss = 0.7291457653045654
Iteration [28537]: Loss = 0.7288395166397095
Iteration [28538]: Loss = 0.7285255789756775
Iteration [28539]: Loss = 0.7282047271728516
Iteration [28540]: Loss = 0.7278777360916138
Iteration [28541]: Loss = 0.7275453209877014
Iteration [28542]: Loss = 0.7272080183029175
Iteration [28543]: Loss = 0.7268661856651306
Iteration [28544]: Loss = 0.7265204191207886
Iteration [28545]: Loss = 0.7261708974838257
Iteration [28546]: Loss = 4.814889907836914
Iteration [28547]: Loss = 0.7256890535354614
Iteration [28548]: Loss = 0.7255344390869141
Iteration [28549]: Loss = 0.7253572940826416
Iteration [28550]: Loss = 0.725159764289856
Iteration [28551]: Loss = 0.7249438762664795
Iteration [28552]: Loss = 0.724711537361145
Iteration [28553]: Loss = 0.7244644165039062
Iteration [28554]: Loss = 0.7242038249969482
Iteration [28555]: Loss = 0.7239312529563904
Iteration [28556]: Loss = 0.7236478924751282
Iteration [28557]: Loss = 0.7233549356460571
Iteration [28558]: Loss = 0.7230532169342041
Iteration [28559]: Loss = 0.7227436304092407
Iteration [28560]: Loss = 0.7224270105361938
Iteration [28561]: Loss = 0.7221040725708008
Iteration [28562]: Loss = 0.7217754125595093
Iteration [28563]: Loss = 0.7214418053627014
Iteration [28564]: Loss = 0.7211033701896667
Iteration [28565]: Loss = 0.7207610607147217
Iteration [28566]: Loss = 0.7204149961471558
Iteration [28567]: Loss = 0.7200655937194824
Iteration [28568]: Loss = 0.7197133302688599
Iteration [28569]: Loss = 0.7193583846092224
Iteration [28570]: Loss = 0.7190009951591492
Iteration [28571]: Loss = 0.7186416387557983
Iteration [28572]: Loss = 0.7182803750038147
Iteration [28573]: Loss = 4.8541460037231445
Iteration [28574]: Loss = 0.7177805304527283
Iteration [28575]: Loss = 0.7176194787025452
Iteration [28576]: Loss = 0.7174367308616638
Iteration [28577]: Loss = 0.71723473072052
Iteration [28578]: Loss = 0.7170150279998779
Iteration [28579]: Loss = 0.7167795896530151
Iteration [28580]: Loss = 0.716529905796051
Iteration [28581]: Loss = 4.862434387207031
Iteration [28582]: Loss = 0.7162212133407593
Iteration [28583]: Loss = 0.7161417007446289
Iteration [28584]: Loss = 0.7160326242446899
Iteration [28585]: Loss = 0.7158967852592468
Iteration [28586]: Loss = 4.865106582641602
Iteration [28587]: Loss = 0.7157824039459229
Iteration [28588]: Loss = 0.7157859206199646
Iteration [28589]: Loss = 0.7157515287399292
Iteration [28590]: Loss = 0.715682864189148
Iteration [28591]: Loss = 0.7155834436416626
Iteration [28592]: Loss = 0.7154562473297119
Iteration [28593]: Loss = 4.867288112640381
Iteration [28594]: Loss = 0.7153568863868713
Iteration [28595]: Loss = 0.7153670191764832
Iteration [28596]: Loss = 0.7175477743148804
Iteration [28597]: Loss = 0.7174841165542603
Iteration [28598]: Loss = 0.7173891067504883
Iteration [28599]: Loss = 0.717265784740448
Iteration [28600]: Loss = 0.7171168923377991
Iteration [28601]: Loss = 0.7169451117515564
Iteration [28602]: Loss = 0.7167526483535767
Iteration [28603]: Loss = 0.7165416479110718
Iteration [28604]: Loss = 0.7163138389587402
Iteration [28605]: Loss = 0.716070830821991
Iteration [28606]: Loss = 0.715814471244812
Iteration [28607]: Loss = 0.7155457139015198
Iteration [28608]: Loss = 0.715266227722168
Iteration [28609]: Loss = 0.7149766683578491
Iteration [28610]: Loss = 0.7146784067153931
Iteration [28611]: Loss = 0.7143721580505371
Iteration [28612]: Loss = 0.7140588164329529
Iteration [28613]: Loss = 0.7137388586997986
Iteration [28614]: Loss = 0.7134132385253906
Iteration [28615]: Loss = 0.7130825519561768
Iteration [28616]: Loss = 0.7127470970153809
Iteration [28617]: Loss = 0.7124074697494507
Iteration [28618]: Loss = 0.7120642066001892
Iteration [28619]: Loss = 0.7117173671722412
Iteration [28620]: Loss = 4.887236595153809
Iteration [28621]: Loss = 0.7112448811531067
Iteration [28622]: Loss = 0.7110968232154846
Iteration [28623]: Loss = 0.7109259366989136
Iteration [28624]: Loss = 4.890463352203369
Iteration [28625]: Loss = 0.7107535004615784
Iteration [28626]: Loss = 0.7107333540916443
Iteration [28627]: Loss = 0.7106775641441345
Iteration [28628]: Loss = 0.7105899453163147
Iteration [28629]: Loss = 0.7104734182357788
Iteration [28630]: Loss = 0.7103309035301208
Iteration [28631]: Loss = 0.7101651430130005
Iteration [28632]: Loss = 0.7099782824516296
Iteration [28633]: Loss = 4.89537239074707
Iteration [28634]: Loss = 0.7097792625427246
Iteration [28635]: Loss = 0.709747850894928
Iteration [28636]: Loss = 9.081986427307129
Iteration [28637]: Loss = 0.7100399732589722
Iteration [28638]: Loss = 0.710325300693512
Iteration [28639]: Loss = 0.7105449438095093
Iteration [28640]: Loss = 0.710705578327179
Iteration [28641]: Loss = 0.7124212980270386
Iteration [28642]: Loss = 0.7124806046485901
Iteration [28643]: Loss = 0.7124965786933899
Iteration [28644]: Loss = 0.712473452091217
Iteration [28645]: Loss = 0.7124150991439819
Iteration [28646]: Loss = 0.7123252153396606
Iteration [28647]: Loss = 0.7122067213058472
Iteration [28648]: Loss = 0.7120627760887146
Iteration [28649]: Loss = 0.7118955850601196
Iteration [28650]: Loss = 0.711707592010498
Iteration [28651]: Loss = 0.7115009427070618
Iteration [28652]: Loss = 0.711277425289154
Iteration [28653]: Loss = 0.7110387682914734
Iteration [28654]: Loss = 0.7107864022254944
Iteration [28655]: Loss = 4.891546726226807
Iteration [28656]: Loss = 0.710474967956543
Iteration [28657]: Loss = 0.7103952169418335
Iteration [28658]: Loss = 0.7102861404418945
Iteration [28659]: Loss = 0.7101504802703857
Iteration [28660]: Loss = 0.709990918636322
Iteration [28661]: Loss = 0.7098098993301392
Iteration [28662]: Loss = 0.7096095681190491
Iteration [28663]: Loss = 0.709391713142395
Iteration [28664]: Loss = 0.7091583609580994
Iteration [28665]: Loss = 0.7089108228683472
Iteration [28666]: Loss = 0.7086507081985474
Iteration [28667]: Loss = 0.7083790302276611
Iteration [28668]: Loss = 0.7080973386764526
Iteration [28669]: Loss = 0.7078062295913696
Iteration [28670]: Loss = 0.7075070142745972
Iteration [28671]: Loss = 0.7072001099586487
Iteration [28672]: Loss = 0.7068866491317749
Iteration [28673]: Loss = 0.7065671682357788
Iteration [28674]: Loss = 0.7062423229217529
Iteration [28675]: Loss = 0.7059126496315002
Iteration [28676]: Loss = 4.91690731048584
Iteration [28677]: Loss = 0.7054705023765564
Iteration [28678]: Loss = 0.7053360342979431
Iteration [28679]: Loss = 0.7051777243614197
Iteration [28680]: Loss = 0.7049981355667114
Iteration [28681]: Loss = 0.7047990560531616
Iteration [28682]: Loss = 0.7045827507972717
Iteration [28683]: Loss = 0.7043507695198059
Iteration [28684]: Loss = 4.924525260925293
Iteration [28685]: Loss = 0.7040760517120361
Iteration [28686]: Loss = 0.7040130496025085
Iteration [28687]: Loss = 0.7039192914962769
Iteration [28688]: Loss = 0.7037975788116455
Iteration [28689]: Loss = 4.926877498626709
Iteration [28690]: Loss = 0.7037114500999451
Iteration [28691]: Loss = 0.7037286758422852
Iteration [28692]: Loss = 4.926584243774414
Iteration [28693]: Loss = 0.7038798928260803
Iteration [28694]: Loss = 0.7039984464645386
Iteration [28695]: Loss = 0.7040680050849915
Iteration [28696]: Loss = 0.7040933966636658
Iteration [28697]: Loss = 0.7040793299674988
Iteration [28698]: Loss = 0.7040293216705322
Iteration [28699]: Loss = 0.7039472460746765
Iteration [28700]: Loss = 0.7038360238075256
Iteration [28701]: Loss = 4.9266276359558105
Iteration [28702]: Loss = 0.7037678360939026
Iteration [28703]: Loss = 0.7037929892539978
Iteration [28704]: Loss = 0.7037784457206726
Iteration [28705]: Loss = 0.7037280797958374
Iteration [28706]: Loss = 0.7036455273628235
Iteration [28707]: Loss = 0.7035342454910278
Iteration [28708]: Loss = 0.7033966779708862
Iteration [28709]: Loss = 0.7032358050346375
Iteration [28710]: Loss = 0.7030536532402039
Iteration [28711]: Loss = 4.931018352508545
Iteration [28712]: Loss = 0.7028646469116211
Iteration [28713]: Loss = 0.7028383612632751
Iteration [28714]: Loss = 0.702777624130249
Iteration [28715]: Loss = 0.7026857733726501
Iteration [28716]: Loss = 0.7025657892227173
Iteration [28717]: Loss = 0.7024207711219788
Iteration [28718]: Loss = 0.7022530436515808
Iteration [28719]: Loss = 0.7020648121833801
Iteration [28720]: Loss = 0.7018583416938782
Iteration [28721]: Loss = 0.7016351819038391
Iteration [28722]: Loss = 4.938589572906494
Iteration [28723]: Loss = 0.7013766169548035
Iteration [28724]: Loss = 0.7013208270072937
Iteration [28725]: Loss = 0.7012336850166321
Iteration [28726]: Loss = 0.7011182308197021
Iteration [28727]: Loss = 0.7009770274162292
Iteration [28728]: Loss = 0.7008126974105835
Iteration [28729]: Loss = 4.942602157592773
Iteration [28730]: Loss = 0.7006551027297974
Iteration [28731]: Loss = 0.700642466545105
Iteration [28732]: Loss = 0.7005941867828369
Iteration [28733]: Loss = 0.7005136013031006
Iteration [28734]: Loss = 0.7004038691520691
Iteration [28735]: Loss = 4.9444804191589355
Iteration [28736]: Loss = 0.7003394961357117
Iteration [28737]: Loss = 0.700366735458374
Iteration [28738]: Loss = 0.700354278087616
Iteration [28739]: Loss = 0.7003058791160583
Iteration [28740]: Loss = 0.7002251744270325
Iteration [28741]: Loss = 0.7001156806945801
Iteration [28742]: Loss = 0.6999797224998474
Iteration [28743]: Loss = 0.6998204588890076
Iteration [28744]: Loss = 0.6996398568153381
Iteration [28745]: Loss = 0.6994402408599854
Iteration [28746]: Loss = 9.200665473937988
Iteration [28747]: Loss = 0.6994513869285583
Iteration [28748]: Loss = 0.6996200680732727
Iteration [28749]: Loss = 0.6997351050376892
Iteration [28750]: Loss = 0.6998019814491272
Iteration [28751]: Loss = 0.6998253464698792
Iteration [28752]: Loss = 0.6998095512390137
Iteration [28753]: Loss = 0.6997585296630859
Iteration [28754]: Loss = 0.6996758580207825
Iteration [28755]: Loss = 0.699564516544342
Iteration [28756]: Loss = 0.6994273662567139
Iteration [28757]: Loss = 0.6992671489715576
Iteration [28758]: Loss = 0.6990858912467957
Iteration [28759]: Loss = 0.6988860368728638
Iteration [28760]: Loss = 0.6986692547798157
Iteration [28761]: Loss = 0.6984372138977051
Iteration [28762]: Loss = 0.6981915831565857
Iteration [28763]: Loss = 0.697933554649353
Iteration [28764]: Loss = 0.6976645588874817
Iteration [28765]: Loss = 4.959590911865234
Iteration [28766]: Loss = 0.6973282098770142
Iteration [28767]: Loss = 0.6972397565841675
Iteration [28768]: Loss = 0.6971235275268555
Iteration [28769]: Loss = 0.6969819664955139
Iteration [28770]: Loss = 0.696817934513092
Iteration [28771]: Loss = 0.6966334581375122
Iteration [28772]: Loss = 0.6964305639266968
Iteration [28773]: Loss = 0.6962111592292786
Iteration [28774]: Loss = 0.6959769129753113
Iteration [28775]: Loss = 4.968319416046143
Iteration [28776]: Loss = 0.6957005858421326
Iteration [28777]: Loss = 0.6956380605697632
Iteration [28778]: Loss = 0.695544958114624
Iteration [28779]: Loss = 0.695424497127533
Iteration [28780]: Loss = 0.6952793598175049
Iteration [28781]: Loss = 0.6951119899749756
Iteration [28782]: Loss = 0.6949245929718018
Iteration [28783]: Loss = 4.973659038543701
Iteration [28784]: Loss = 0.694728672504425
Iteration [28785]: Loss = 0.6947004795074463
Iteration [28786]: Loss = 0.6946384310722351
Iteration [28787]: Loss = 0.6945458650588989
Iteration [28788]: Loss = 0.6944260597229004
Iteration [28789]: Loss = 0.694281280040741
Iteration [28790]: Loss = 4.976863861083984
Iteration [28791]: Loss = 0.6941584944725037
Iteration [28792]: Loss = 0.694161593914032
Iteration [28793]: Loss = 0.6941276788711548
Iteration [28794]: Loss = 0.6940605044364929
Iteration [28795]: Loss = 0.6939634084701538
Iteration [28796]: Loss = 0.6938393115997314
Iteration [28797]: Loss = 0.6936907768249512
Iteration [28798]: Loss = 0.6935206055641174
Iteration [28799]: Loss = 0.6933306455612183
Iteration [28800]: Loss = 4.982122898101807
Iteration [28801]: Loss = 0.6931309700012207
Iteration [28802]: Loss = 4.98223876953125
Iteration [28803]: Loss = 0.6932690143585205
Iteration [28804]: Loss = 0.6933834552764893
Iteration [28805]: Loss = 0.6934499144554138
Iteration [28806]: Loss = 0.6934730410575867
Iteration [28807]: Loss = 0.693457305431366
Iteration [28808]: Loss = 4.980618000030518
Iteration [28809]: Loss = 0.6935549378395081
Iteration [28810]: Loss = 0.6936521530151367
Iteration [28811]: Loss = 0.6937031149864197
Iteration [28812]: Loss = 0.6937121748924255
Iteration [28813]: Loss = 0.6936836242675781
Iteration [28814]: Loss = 0.6936215162277222
Iteration [28815]: Loss = 0.6935287117958069
Iteration [28816]: Loss = 0.6934086680412292
Iteration [28817]: Loss = 4.9813761711120605
Iteration [28818]: Loss = 0.6933280229568481
Iteration [28819]: Loss = 4.980921745300293
Iteration [28820]: Loss = 4.979789733886719
Iteration [28821]: Loss = 0.6939480304718018
Iteration [28822]: Loss = 0.6942585706710815
Iteration [28823]: Loss = 0.6945016980171204
Iteration [28824]: Loss = 0.6946841478347778
Iteration [28825]: Loss = 0.6948116421699524
Iteration [28826]: Loss = 0.6948898434638977
Iteration [28827]: Loss = 0.6949234008789062
Iteration [28828]: Loss = 0.6949170827865601
Iteration [28829]: Loss = 0.6948745846748352
Iteration [28830]: Loss = 0.6947996020317078
Iteration [28831]: Loss = 0.6946953535079956
Iteration [28832]: Loss = 0.6945647597312927
Iteration [28833]: Loss = 0.6944102644920349
Iteration [28834]: Loss = 0.6942346096038818
Iteration [28835]: Loss = 0.6940397620201111
Iteration [28836]: Loss = 0.6938273906707764
Iteration [28837]: Loss = 0.6935997009277344
Iteration [28838]: Loss = 0.6933577060699463
Iteration [28839]: Loss = 4.9822282791137695
Iteration [28840]: Loss = 4.982407569885254
Iteration [28841]: Loss = 0.693233847618103
Iteration [28842]: Loss = 4.9809441566467285
Iteration [28843]: Loss = 0.6936391592025757
Iteration [28844]: Loss = 0.6938674449920654
Iteration [28845]: Loss = 0.6940364837646484
Iteration [28846]: Loss = 0.6941518783569336
Iteration [28847]: Loss = 0.6942192316055298
Iteration [28848]: Loss = 0.6942430734634399
Iteration [28849]: Loss = 4.976261615753174
Iteration [28850]: Loss = 0.6944084167480469
Iteration [28851]: Loss = 0.6945343017578125
Iteration [28852]: Loss = 0.6946110725402832
Iteration [28853]: Loss = 0.6946434378623962
Iteration [28854]: Loss = 0.694635808467865
Iteration [28855]: Loss = 4.974332332611084
Iteration [28856]: Loss = 0.6947470307350159
Iteration [28857]: Loss = 0.694849967956543
Iteration [28858]: Loss = 0.6949058771133423
Iteration [28859]: Loss = 0.6949194669723511
Iteration [28860]: Loss = 0.6948950290679932
Iteration [28861]: Loss = 0.6948361396789551
Iteration [28862]: Loss = 0.694746196269989
Iteration [28863]: Loss = 4.9741387367248535
Iteration [28864]: Loss = 0.6947174072265625
Iteration [28865]: Loss = 4.973440647125244
Iteration [28866]: Loss = 4.972208499908447
Iteration [28867]: Loss = 0.6953965425491333
Iteration [28868]: Loss = 0.6957230567932129
Iteration [28869]: Loss = 4.966994762420654
Iteration [28870]: Loss = 4.9647536277771
Iteration [28871]: Loss = 0.6969800591468811
Iteration [28872]: Loss = 4.959192276000977
Iteration [28873]: Loss = 4.955904960632324
Iteration [28874]: Loss = 9.205047607421875
Iteration [28875]: Loss = 0.6999319195747375
Iteration [28876]: Loss = 0.7008782625198364
Iteration [28877]: Loss = 0.701694667339325
Iteration [28878]: Loss = 0.7023935914039612
Iteration [28879]: Loss = 4.930323123931885
Iteration [28880]: Loss = 0.7037102580070496
Iteration [28881]: Loss = 0.7043253183364868
Iteration [28882]: Loss = 0.7048428654670715
Iteration [28883]: Loss = 0.7052720785140991
Iteration [28884]: Loss = 0.7056218385696411
Iteration [28885]: Loss = 0.7058999538421631
Iteration [28886]: Loss = 0.706113338470459
Iteration [28887]: Loss = 0.7062686681747437
Iteration [28888]: Loss = 4.912820339202881
Iteration [28889]: Loss = 0.7066543102264404
Iteration [28890]: Loss = 0.7068719267845154
Iteration [28891]: Loss = 0.7070310115814209
Iteration [28892]: Loss = 0.7071369886398315
Iteration [28893]: Loss = 0.7071954011917114
Iteration [28894]: Loss = 0.7072108387947083
Iteration [28895]: Loss = 0.7071877717971802
Iteration [28896]: Loss = 0.707129716873169
Iteration [28897]: Loss = 0.7070403099060059
Iteration [28898]: Loss = 0.7069225907325745
Iteration [28899]: Loss = 0.7067794799804688
Iteration [28900]: Loss = 0.7066135406494141
Iteration [28901]: Loss = 0.7064269185066223
Iteration [28902]: Loss = 0.7062218189239502
Iteration [28903]: Loss = 4.914734840393066
Iteration [28904]: Loss = 0.7059918642044067
Iteration [28905]: Loss = 0.7059475779533386
Iteration [28906]: Loss = 0.705870509147644
Iteration [28907]: Loss = 0.7057639360427856
Iteration [28908]: Loss = 0.705630898475647
Iteration [28909]: Loss = 4.917447090148926
Iteration [28910]: Loss = 0.7055244445800781
Iteration [28911]: Loss = 0.7055327892303467
Iteration [28912]: Loss = 0.7055030465126038
Iteration [28913]: Loss = 0.7054392099380493
Iteration [28914]: Loss = 4.918115139007568
Iteration [28915]: Loss = 0.7054509520530701
Iteration [28916]: Loss = 0.7055097222328186
Iteration [28917]: Loss = 0.7055253982543945
Iteration [28918]: Loss = 4.917301177978516
Iteration [28919]: Loss = 0.7056730389595032
Iteration [28920]: Loss = 0.7057893872261047
Iteration [28921]: Loss = 0.7058572173118591
Iteration [28922]: Loss = 0.7058812975883484
Iteration [28923]: Loss = 0.7058656811714172
Iteration [28924]: Loss = 0.7058145999908447
Iteration [28925]: Loss = 4.91611909866333
Iteration [28926]: Loss = 0.7058477997779846
Iteration [28927]: Loss = 0.7059155702590942
Iteration [28928]: Loss = 0.7059395909309387
Iteration [28929]: Loss = 4.915126323699951
Iteration [28930]: Loss = 4.914212703704834
Iteration [28931]: Loss = 0.7064512968063354
Iteration [28932]: Loss = 0.7067295908927917
Iteration [28933]: Loss = 0.7069429755210876
Iteration [28934]: Loss = 0.7070981860160828
Iteration [28935]: Loss = 0.7072005867958069
Iteration [28936]: Loss = 0.7072557210922241
Iteration [28937]: Loss = 0.7072680592536926
Iteration [28938]: Loss = 0.7072420716285706
Iteration [28939]: Loss = 0.7071813344955444
Iteration [28940]: Loss = 0.7070894241333008
Iteration [28941]: Loss = 0.7069693207740784
Iteration [28942]: Loss = 0.7068240642547607
Iteration [28943]: Loss = 0.7066559791564941
Iteration [28944]: Loss = 0.7064675092697144
Iteration [28945]: Loss = 0.7062604427337646
Iteration [28946]: Loss = 0.7060368061065674
Iteration [28947]: Loss = 0.705798327922821
Iteration [28948]: Loss = 4.917073726654053
Iteration [28949]: Loss = 0.705511748790741
Iteration [28950]: Loss = 0.7054435610771179
Iteration [28951]: Loss = 0.7053449749946594
Iteration [28952]: Loss = 4.918764591217041
Iteration [28953]: Loss = 0.7052974700927734
Iteration [28954]: Loss = 0.7053309679031372
Iteration [28955]: Loss = 0.705324113368988
Iteration [28956]: Loss = 0.7052807807922363
Iteration [28957]: Loss = 0.7052045464515686
Iteration [28958]: Loss = 4.91938591003418
Iteration [28959]: Loss = 0.7051952481269836
Iteration [28960]: Loss = 0.7052451968193054
Iteration [28961]: Loss = 0.7052528858184814
Iteration [28962]: Loss = 0.7052227258682251
Iteration [28963]: Loss = 0.7051583528518677
Iteration [28964]: Loss = 4.9195685386657715
Iteration [28965]: Loss = 0.7051695585250854
Iteration [28966]: Loss = 4.9187164306640625
Iteration [28967]: Loss = 0.7054724097251892
Iteration [28968]: Loss = 0.7056552767753601
Iteration [28969]: Loss = 0.7057827711105347
Iteration [28970]: Loss = 0.7058603167533875
Iteration [28971]: Loss = 0.7058930993080139
Iteration [28972]: Loss = 0.7058851718902588
Iteration [28973]: Loss = 0.7058409452438354
Iteration [28974]: Loss = 0.7057638168334961
Iteration [28975]: Loss = 4.916501998901367
Iteration [28976]: Loss = 0.7057531476020813
Iteration [28977]: Loss = 0.7058024406433105
Iteration [28978]: Loss = 0.7058095335960388
Iteration [28979]: Loss = 0.7057786583900452
Iteration [28980]: Loss = 0.70571368932724
Iteration [28981]: Loss = 0.7056178450584412
Iteration [28982]: Loss = 4.917342185974121
Iteration [28983]: Loss = 0.7055753469467163
Iteration [28984]: Loss = 4.9167399406433105
Iteration [28985]: Loss = 0.7058349251747131
Iteration [28986]: Loss = 0.7059993743896484
Iteration [28987]: Loss = 0.7061101794242859
Iteration [28988]: Loss = 0.7061727046966553
Iteration [28989]: Loss = 0.7061917185783386
Iteration [28990]: Loss = 0.7061716914176941
Iteration [28991]: Loss = 4.914135456085205
Iteration [28992]: Loss = 0.7062582969665527
Iteration [28993]: Loss = 0.7063488960266113
Iteration [28994]: Loss = 0.706393301486969
Iteration [28995]: Loss = 0.7063959836959839
Iteration [28996]: Loss = 0.7063610553741455
Iteration [28997]: Loss = 0.7062922120094299
Iteration [28998]: Loss = 0.7061929702758789
Iteration [28999]: Loss = 0.706066370010376
Iteration [29000]: Loss = 0.7071558833122253
Iteration [29001]: Loss = 0.7069821357727051
Iteration [29002]: Loss = 4.91067361831665
Iteration [29003]: Loss = 0.7068066596984863
Iteration [29004]: Loss = 0.7067857384681702
Iteration [29005]: Loss = 0.7067292928695679
Iteration [29006]: Loss = 0.7066413760185242
Iteration [29007]: Loss = 0.706524670124054
Iteration [29008]: Loss = 0.7063822150230408
Iteration [29009]: Loss = 0.7062166333198547
Iteration [29010]: Loss = 0.706030011177063
Iteration [29011]: Loss = 0.7058247923851013
Iteration [29012]: Loss = 4.916784286499023
Iteration [29013]: Loss = 4.916820526123047
Iteration [29014]: Loss = 0.7057814002037048
Iteration [29015]: Loss = 0.7059116959571838
Iteration [29016]: Loss = 0.7059915065765381
Iteration [29017]: Loss = 0.7060261368751526
Iteration [29018]: Loss = 0.7060199975967407
Iteration [29019]: Loss = 0.7059770226478577
Iteration [29020]: Loss = 0.7059009671211243
Iteration [29021]: Loss = 0.705795168876648
Iteration [29022]: Loss = 0.7056623697280884
Iteration [29023]: Loss = 0.7055056095123291
Iteration [29024]: Loss = 0.7053269743919373
Iteration [29025]: Loss = 0.7051287889480591
Iteration [29026]: Loss = 0.7049129605293274
Iteration [29027]: Loss = 0.704681396484375
Iteration [29028]: Loss = 0.7044355273246765
Iteration [29029]: Loss = 4.9241533279418945
Iteration [29030]: Loss = 0.7041374444961548
Iteration [29031]: Loss = 4.924732208251953
Iteration [29032]: Loss = 0.7041923999786377
Iteration [29033]: Loss = 0.7042700052261353
Iteration [29034]: Loss = 4.923501014709473
Iteration [29035]: Loss = 0.7045245170593262
Iteration [29036]: Loss = 0.7046871781349182
Iteration [29037]: Loss = 0.7047961950302124
Iteration [29038]: Loss = 0.7048572301864624
Iteration [29039]: Loss = 0.7048748135566711
Iteration [29040]: Loss = 0.704853355884552
Iteration [29041]: Loss = 0.704796552658081
Iteration [29042]: Loss = 0.7047081589698792
Iteration [29043]: Loss = 0.7045911550521851
Iteration [29044]: Loss = 0.704448401927948
Iteration [29045]: Loss = 0.7042825222015381
Iteration [29046]: Loss = 0.7040958404541016
Iteration [29047]: Loss = 0.7038904428482056
Iteration [29048]: Loss = 4.926787376403809
Iteration [29049]: Loss = 0.7036616802215576
Iteration [29050]: Loss = 0.7036187052726746
Iteration [29051]: Loss = 9.151333808898926
Iteration [29052]: Loss = 0.7038947343826294
Iteration [29053]: Loss = 0.7041749954223633
Iteration [29054]: Loss = 0.704390287399292
Iteration [29055]: Loss = 0.7045471668243408
Iteration [29056]: Loss = 0.7046513557434082
Iteration [29057]: Loss = 0.7047081589698792
Iteration [29058]: Loss = 0.7047220468521118
Iteration [29059]: Loss = 0.7046975493431091
Iteration [29060]: Loss = 0.7046383023262024
Iteration [29061]: Loss = 0.7045477628707886
Iteration [29062]: Loss = 0.7044291496276855
Iteration [29063]: Loss = 0.7042853236198425
Iteration [29064]: Loss = 0.7041184902191162
Iteration [29065]: Loss = 0.7039312124252319
Iteration [29066]: Loss = 0.7037253975868225
Iteration [29067]: Loss = 0.7035030722618103
Iteration [29068]: Loss = 4.9288740158081055
Iteration [29069]: Loss = 0.7032449245452881
Iteration [29070]: Loss = 0.7031890749931335
Iteration [29071]: Loss = 0.7031018137931824
Iteration [29072]: Loss = 0.702985942363739
Iteration [29073]: Loss = 0.7028446197509766
Iteration [29074]: Loss = 0.7026803493499756
Iteration [29075]: Loss = 0.702495276927948
Iteration [29076]: Loss = 0.7022915482521057
Iteration [29077]: Loss = 4.935081481933594
Iteration [29078]: Loss = 0.7020655870437622
Iteration [29079]: Loss = 4.93532657623291
Iteration [29080]: Loss = 0.7021785974502563
Iteration [29081]: Loss = 0.7022809982299805
Iteration [29082]: Loss = 0.7023360729217529
Iteration [29083]: Loss = 0.7023487091064453
Iteration [29084]: Loss = 0.7023230791091919
Iteration [29085]: Loss = 0.702262818813324
Iteration [29086]: Loss = 4.934558868408203
Iteration [29087]: Loss = 0.7022819519042969
Iteration [29088]: Loss = 0.7023444175720215
Iteration [29089]: Loss = 0.7023636102676392
Iteration [29090]: Loss = 0.7023438215255737
Iteration [29091]: Loss = 0.702288806438446
Iteration [29092]: Loss = 0.702202320098877
Iteration [29093]: Loss = 0.7020872831344604
Iteration [29094]: Loss = 0.7019466161727905
Iteration [29095]: Loss = 4.936580657958984
Iteration [29096]: Loss = 0.7018284797668457
Iteration [29097]: Loss = 0.7018327116966248
Iteration [29098]: Loss = 0.7017993927001953
Iteration [29099]: Loss = 0.701732337474823
Iteration [29100]: Loss = 0.7016347050666809
Iteration [29101]: Loss = 0.7015097737312317
Iteration [29102]: Loss = 0.7013603448867798
Iteration [29103]: Loss = 4.939676284790039
Iteration [29104]: Loss = 0.7012273073196411
Iteration [29105]: Loss = 0.7012252807617188
Iteration [29106]: Loss = 0.7011863589286804
Iteration [29107]: Loss = 0.7011140584945679
Iteration [29108]: Loss = 0.7010120153427124
Iteration [29109]: Loss = 0.7008830904960632
Iteration [29110]: Loss = 0.7007299065589905
Iteration [29111]: Loss = 0.7005549073219299
Iteration [29112]: Loss = 0.700360119342804
Iteration [29113]: Loss = 0.7001478672027588
Iteration [29114]: Loss = 0.6999197006225586
Iteration [29115]: Loss = 0.6996771693229675
Iteration [29116]: Loss = 0.6994218826293945
Iteration [29117]: Loss = 0.6991548538208008
Iteration [29118]: Loss = 0.6988775134086609
Iteration [29119]: Loss = 0.698590874671936
Iteration [29120]: Loss = 4.954808235168457
Iteration [29121]: Loss = 0.6982247829437256
Iteration [29122]: Loss = 0.6981238722801208
Iteration [29123]: Loss = 4.956381797790527
Iteration [29124]: Loss = 0.698074996471405
Iteration [29125]: Loss = 0.6981093883514404
Iteration [29126]: Loss = 0.6981031894683838
Iteration [29127]: Loss = 0.6980607509613037
Iteration [29128]: Loss = 0.6979854106903076
Iteration [29129]: Loss = 0.697880744934082
Iteration [29130]: Loss = 0.6977495551109314
Iteration [29131]: Loss = 0.697594404220581
Iteration [29132]: Loss = 0.6974177956581116
Iteration [29133]: Loss = 4.960452556610107
Iteration [29134]: Loss = 0.697239875793457
Iteration [29135]: Loss = 0.6962648034095764
Iteration [29136]: Loss = 0.696168839931488
Iteration [29137]: Loss = 0.696018636226654
Iteration [29138]: Loss = 0.6958248615264893
Iteration [29139]: Loss = 0.6955946683883667
Iteration [29140]: Loss = 0.6953334808349609
Iteration [29141]: Loss = 0.6950457096099854
Iteration [29142]: Loss = 0.694734513759613
Iteration [29143]: Loss = 4.975334167480469
Iteration [29144]: Loss = 0.6944035291671753
Iteration [29145]: Loss = 0.6943575143814087
Iteration [29146]: Loss = 4.976039409637451
Iteration [29147]: Loss = 4.975201606750488
Iteration [29148]: Loss = 0.6947929263114929
Iteration [29149]: Loss = 0.6950783133506775
Iteration [29150]: Loss = 4.970627784729004
Iteration [29151]: Loss = 0.6957033276557922
Iteration [29152]: Loss = 0.6960310935974121
Iteration [29153]: Loss = 0.6961126327514648
Iteration [29154]: Loss = 0.6962978839874268
Iteration [29155]: Loss = 0.6964225769042969
Iteration [29156]: Loss = 0.6964927911758423
Iteration [29157]: Loss = 0.6965140700340271
Iteration [29158]: Loss = 0.6964913606643677
Iteration [29159]: Loss = 0.6964288949966431
Iteration [29160]: Loss = 0.6963306665420532
Iteration [29161]: Loss = 0.6962004899978638
Iteration [29162]: Loss = 4.966672420501709
Iteration [29163]: Loss = 0.6961183547973633
Iteration [29164]: Loss = 0.6961461901664734
Iteration [29165]: Loss = 0.6961299777030945
Iteration [29166]: Loss = 0.6960737705230713
Iteration [29167]: Loss = 4.966985702514648
Iteration [29168]: Loss = 0.6961164474487305
Iteration [29169]: Loss = 4.965854167938232
Iteration [29170]: Loss = 0.6964825987815857
Iteration [29171]: Loss = 0.6966995000839233
Iteration [29172]: Loss = 0.6968539357185364
Iteration [29173]: Loss = 0.6969522833824158
Iteration [29174]: Loss = 0.6970000267028809
Iteration [29175]: Loss = 0.6970023512840271
Iteration [29176]: Loss = 0.6969635486602783
Iteration [29177]: Loss = 0.6968879103660583
Iteration [29178]: Loss = 0.6967789530754089
Iteration [29179]: Loss = 0.696640133857727
Iteration [29180]: Loss = 0.6964744925498962
Iteration [29181]: Loss = 0.6962844133377075
Iteration [29182]: Loss = 4.9665069580078125
Iteration [29183]: Loss = 0.696097195148468
Iteration [29184]: Loss = 0.6960785388946533
Iteration [29185]: Loss = 0.6960213780403137
Iteration [29186]: Loss = 4.967263698577881
Iteration [29187]: Loss = 0.6960596442222595
Iteration [29188]: Loss = 0.6961366534233093
Iteration [29189]: Loss = 0.6961655616760254
Iteration [29190]: Loss = 0.6961513757705688
Iteration [29191]: Loss = 0.696098268032074
Iteration [29192]: Loss = 0.6960100531578064
Iteration [29193]: Loss = 0.6958903670310974
Iteration [29194]: Loss = 0.6957422494888306
Iteration [29195]: Loss = 0.6955686211585999
Iteration [29196]: Loss = 0.6953719258308411
Iteration [29197]: Loss = 0.6951545476913452
Iteration [29198]: Loss = 0.6949183940887451
Iteration [29199]: Loss = 0.6946656107902527
Iteration [29200]: Loss = 0.6943977475166321
Iteration [29201]: Loss = 0.6941162347793579
Iteration [29202]: Loss = 4.978410720825195
Iteration [29203]: Loss = 0.6937723755836487
Iteration [29204]: Loss = 0.6936870813369751
Iteration [29205]: Loss = 4.979748725891113
Iteration [29206]: Loss = 0.693677544593811
Iteration [29207]: Loss = 0.6937342286109924
Iteration [29208]: Loss = 0.6937451958656311
Iteration [29209]: Loss = 0.6937152743339539
Iteration [29210]: Loss = 4.979335784912109
Iteration [29211]: Loss = 0.6937993764877319
Iteration [29212]: Loss = 0.6938955187797546
Iteration [29213]: Loss = 0.6939422488212585
Iteration [29214]: Loss = 0.6939446330070496
Iteration [29215]: Loss = 9.2620210647583
Iteration [29216]: Loss = 0.694326639175415
Iteration [29217]: Loss = 0.6946655511856079
Iteration [29218]: Loss = 0.6949318051338196
Iteration [29219]: Loss = 0.6951321959495544
Iteration [29220]: Loss = 0.6952736377716064
Iteration [29221]: Loss = 0.6953616738319397
Iteration [29222]: Loss = 0.6954018473625183
Iteration [29223]: Loss = 0.6953986883163452
Iteration [29224]: Loss = 0.6953567862510681
Iteration [29225]: Loss = 0.6952797174453735
Iteration [29226]: Loss = 0.6951709985733032
Iteration [29227]: Loss = 4.971993923187256
Iteration [29228]: Loss = 0.6951180100440979
Iteration [29229]: Loss = 0.6951545476913452
Iteration [29230]: Loss = 0.695148229598999
Iteration [29231]: Loss = 0.6951034069061279
Iteration [29232]: Loss = 0.695023775100708
Iteration [29233]: Loss = 0.6949130296707153
Iteration [29234]: Loss = 0.6947740316390991
Iteration [29235]: Loss = 0.6946098804473877
Iteration [29236]: Loss = 0.6944228410720825
Iteration [29237]: Loss = 0.6942152976989746
Iteration [29238]: Loss = 4.977527618408203
Iteration [29239]: Loss = 0.6939934492111206
Iteration [29240]: Loss = 0.6939582824707031
Iteration [29241]: Loss = 0.6938875317573547
Iteration [29242]: Loss = 4.978610992431641
Iteration [29243]: Loss = 0.6938992142677307
Iteration [29244]: Loss = 4.977663993835449
Iteration [29245]: Loss = 0.694226861000061
Iteration [29246]: Loss = 4.975214958190918
Iteration [29247]: Loss = 0.6948090195655823
Iteration [29248]: Loss = 4.971561431884766
Iteration [29249]: Loss = 4.96902322769165
Iteration [29250]: Loss = 4.965669631958008
Iteration [29251]: Loss = 4.961589813232422
Iteration [29252]: Loss = 0.6979042291641235
Iteration [29253]: Loss = 9.206961631774902
Iteration [29254]: Loss = 0.6997982263565063
Iteration [29255]: Loss = 4.942636489868164
Iteration [29256]: Loss = 0.7016939520835876
Iteration [29257]: Loss = 0.7026225328445435
Iteration [29258]: Loss = 0.7034207582473755
Iteration [29259]: Loss = 0.7041015028953552
Iteration [29260]: Loss = 4.921652793884277
Iteration [29261]: Loss = 0.7053408622741699
Iteration [29262]: Loss = 0.7059177160263062
Iteration [29263]: Loss = 0.7064006924629211
Iteration [29264]: Loss = 0.7067989110946655
Iteration [29265]: Loss = 0.7071206569671631
Iteration [29266]: Loss = 0.7073734998703003
Iteration [29267]: Loss = 0.7075641751289368
Iteration [29268]: Loss = 4.9059929847717285
Iteration [29269]: Loss = 0.7081270813941956
Iteration [29270]: Loss = 0.7083694934844971
Iteration [29271]: Loss = 0.7085508704185486
Iteration [29272]: Loss = 0.7086771130561829
Iteration [29273]: Loss = 0.7087536454200745
Iteration [29274]: Loss = 0.7087854743003845
Iteration [29275]: Loss = 0.7087770104408264
Iteration [29276]: Loss = 0.7087323069572449
Iteration [29277]: Loss = 0.7086548209190369
Iteration [29278]: Loss = 0.7085478901863098
Iteration [29279]: Loss = 0.7084144949913025
Iteration [29280]: Loss = 4.9031291007995605
Iteration [29281]: Loss = 0.7083063125610352
Iteration [29282]: Loss = 0.7083132266998291
Iteration [29283]: Loss = 0.708282470703125
Iteration [29284]: Loss = 0.7082175016403198
Iteration [29285]: Loss = 0.7081218957901001
Iteration [29286]: Loss = 0.7079986929893494
Iteration [29287]: Loss = 0.7078505754470825
Iteration [29288]: Loss = 4.906090259552002
Iteration [29289]: Loss = 0.7077174186706543
Iteration [29290]: Loss = 0.707713782787323
Iteration [29291]: Loss = 4.906123638153076
Iteration [29292]: Loss = 4.905333042144775
Iteration [29293]: Loss = 0.7081559896469116
Iteration [29294]: Loss = 0.7084147334098816
Iteration [29295]: Loss = 0.7086106538772583
Iteration [29296]: Loss = 0.7087500095367432
Iteration [29297]: Loss = 0.7088382840156555
Iteration [29298]: Loss = 0.7088807821273804
Iteration [29299]: Loss = 0.7088816165924072
Iteration [29300]: Loss = 0.7088452577590942
Iteration [29301]: Loss = 0.7087754011154175
Iteration [29302]: Loss = 4.900986194610596
Iteration [29303]: Loss = 0.7087756395339966
Iteration [29304]: Loss = 0.7088288068771362
Iteration [29305]: Loss = 0.708839476108551
Iteration [29306]: Loss = 0.70881187915802
Iteration [29307]: Loss = 0.7087498903274536
Iteration [29308]: Loss = 0.7086567282676697
Iteration [29309]: Loss = 0.7085356712341309
Iteration [29310]: Loss = 0.7083895802497864
Iteration [29311]: Loss = 4.903316020965576
Iteration [29312]: Loss = 0.7082595825195312
Iteration [29313]: Loss = 0.7082574367523193
Iteration [29314]: Loss = 0.7082182168960571
Iteration [29315]: Loss = 0.7081458568572998
Iteration [29316]: Loss = 0.7080434560775757
Iteration [29317]: Loss = 0.7079139947891235
Iteration [29318]: Loss = 0.7077602744102478
Iteration [29319]: Loss = 0.7075846195220947
Iteration [29320]: Loss = 0.7073892951011658
Iteration [29321]: Loss = 0.7071762681007385
Iteration [29322]: Loss = 0.7069472074508667
Iteration [29323]: Loss = 0.7067039608955383
Iteration [29324]: Loss = 0.7064476013183594
Iteration [29325]: Loss = 0.7061797976493835
Iteration [29326]: Loss = 0.7059014439582825
Iteration [29327]: Loss = 0.7056137323379517
Iteration [29328]: Loss = 0.7053175568580627
Iteration [29329]: Loss = 0.7050139307975769
Iteration [29330]: Loss = 4.921428203582764
Iteration [29331]: Loss = 4.921879768371582
Iteration [29332]: Loss = 0.7047292590141296
Iteration [29333]: Loss = 4.920959949493408
Iteration [29334]: Loss = 4.919671058654785
Iteration [29335]: Loss = 0.7054582834243774
Iteration [29336]: Loss = 0.7057950496673584
Iteration [29337]: Loss = 4.9144182205200195
Iteration [29338]: Loss = 0.7064912915229797
Iteration [29339]: Loss = 0.7068414688110352
Iteration [29340]: Loss = 0.7071198225021362
Iteration [29341]: Loss = 0.7073333263397217
Iteration [29342]: Loss = 4.907074451446533
Iteration [29343]: Loss = 4.905378818511963
Iteration [29344]: Loss = 0.7083054780960083
Iteration [29345]: Loss = 0.7087068557739258
Iteration [29346]: Loss = 0.7090314030647278
Iteration [29347]: Loss = 0.7092863917350769
Iteration [29348]: Loss = 0.7094787955284119
Iteration [29349]: Loss = 0.7096148729324341
Iteration [29350]: Loss = 4.895742416381836
Iteration [29351]: Loss = 0.7099668979644775
Iteration [29352]: Loss = 4.8933424949646
Iteration [29353]: Loss = 0.7105425596237183
Iteration [29354]: Loss = 0.7108408808708191
Iteration [29355]: Loss = 0.7110721468925476
Iteration [29356]: Loss = 0.7112431526184082
Iteration [29357]: Loss = 0.7113597393035889
Iteration [29358]: Loss = 0.7114273309707642
Iteration [29359]: Loss = 0.7114507555961609
Iteration [29360]: Loss = 0.7114344835281372
Iteration [29361]: Loss = 0.711382269859314
Iteration [29362]: Loss = 4.88759183883667
Iteration [29363]: Loss = 0.7114125490188599
Iteration [29364]: Loss = 0.7114782333374023
Iteration [29365]: Loss = 0.7114999294281006
Iteration [29366]: Loss = 0.7114821076393127
Iteration [29367]: Loss = 0.7114285826683044
Iteration [29368]: Loss = 0.711342990398407
Iteration [29369]: Loss = 0.7112282514572144
Iteration [29370]: Loss = 0.711087703704834
Iteration [29371]: Loss = 4.889499187469482
Iteration [29372]: Loss = 4.889278411865234
Iteration [29373]: Loss = 0.7111959457397461
Iteration [29374]: Loss = 0.7113649249076843
Iteration [29375]: Loss = 0.7114797830581665
Iteration [29376]: Loss = 0.7115455865859985
Iteration [29377]: Loss = 0.7115674614906311
Iteration [29378]: Loss = 0.7115497589111328
Iteration [29379]: Loss = 0.7114962935447693
Iteration [29380]: Loss = 0.7114105820655823
Iteration [29381]: Loss = 0.7112958431243896
Iteration [29382]: Loss = 0.7111552953720093
Iteration [29383]: Loss = 0.7109910845756531
Iteration [29384]: Loss = 0.7108057141304016
Iteration [29385]: Loss = 0.7106013894081116
Iteration [29386]: Loss = 4.892270565032959
Iteration [29387]: Loss = 0.7103720307350159
Iteration [29388]: Loss = 0.7103275060653687
Iteration [29389]: Loss = 0.7102499008178711
Iteration [29390]: Loss = 0.7101425528526306
Iteration [29391]: Loss = 0.7100086212158203
Iteration [29392]: Loss = 4.894975185394287
Iteration [29393]: Loss = 0.7098992466926575
Iteration [29394]: Loss = 0.7099059820175171
Iteration [29395]: Loss = 0.7098745107650757
Iteration [29396]: Loss = 0.7098088264465332
Iteration [29397]: Loss = 0.7097120881080627
Iteration [29398]: Loss = 0.7095877528190613
Iteration [29399]: Loss = 4.8970818519592285
Iteration [29400]: Loss = 0.7094950675964355
Iteration [29401]: Loss = 0.7114920616149902
Iteration [29402]: Loss = 0.7114667892456055
Iteration [29403]: Loss = 0.7114065885543823
Iteration [29404]: Loss = 0.7113147974014282
Iteration [29405]: Loss = 0.7111945152282715
Iteration [29406]: Loss = 4.888862133026123
Iteration [29407]: Loss = 4.88855504989624
Iteration [29408]: Loss = 0.7113538980484009
Iteration [29409]: Loss = 0.7115370035171509
Iteration [29410]: Loss = 0.7116644978523254
Iteration [29411]: Loss = 0.71174156665802
Iteration [29412]: Loss = 0.7117733955383301
Iteration [29413]: Loss = 0.7117645740509033
Iteration [29414]: Loss = 0.7117188572883606
Iteration [29415]: Loss = 0.7116401195526123
Iteration [29416]: Loss = 0.7115315198898315
Iteration [29417]: Loss = 0.7113961577415466
Iteration [29418]: Loss = 0.7112365961074829
Iteration [29419]: Loss = 0.7110552787780762
Iteration [29420]: Loss = 0.7108545899391174
Iteration [29421]: Loss = 0.7106360793113708
Iteration [29422]: Loss = 0.7104018330574036
Iteration [29423]: Loss = 4.89342737197876
Iteration [29424]: Loss = 0.7101218104362488
Iteration [29425]: Loss = 0.710055947303772
Iteration [29426]: Loss = 0.7099590301513672
Iteration [29427]: Loss = 0.7098342180252075
Iteration [29428]: Loss = 0.7096841931343079
Iteration [29429]: Loss = 4.896705627441406
Iteration [29430]: Loss = 0.7095483541488647
Iteration [29431]: Loss = 0.7095440030097961
Iteration [29432]: Loss = 4.896753311157227
Iteration [29433]: Loss = 0.709656834602356
Iteration [29434]: Loss = 0.7097584009170532
Iteration [29435]: Loss = 0.7098122239112854
Iteration [29436]: Loss = 4.895113945007324
Iteration [29437]: Loss = 0.7100244760513306
Iteration [29438]: Loss = 0.7101684212684631
Iteration [29439]: Loss = 0.7102603316307068
Iteration [29440]: Loss = 0.7103055715560913
Iteration [29441]: Loss = 0.7103087306022644
Iteration [29442]: Loss = 0.7102739214897156
Iteration [29443]: Loss = 4.893163681030273
Iteration [29444]: Loss = 4.8925018310546875
Iteration [29445]: Loss = 0.7106426358222961
Iteration [29446]: Loss = 0.7090167999267578
Iteration [29447]: Loss = 0.7091946005821228
Iteration [29448]: Loss = 0.7093170881271362
Iteration [29449]: Loss = 0.7093899846076965
Iteration [29450]: Loss = 4.897184371948242
Iteration [29451]: Loss = 0.7096349000930786
Iteration [29452]: Loss = 0.7097926139831543
Iteration [29453]: Loss = 0.7098971605300903
Iteration [29454]: Loss = 0.709953784942627
Iteration [29455]: Loss = 0.7099671363830566
Iteration [29456]: Loss = 0.7099417448043823
Iteration [29457]: Loss = 0.7098811864852905
Iteration [29458]: Loss = 0.7097891569137573
Iteration [29459]: Loss = 0.7096685767173767
Iteration [29460]: Loss = 0.709522545337677
Iteration [29461]: Loss = 0.709353506565094
Iteration [29462]: Loss = 0.7091636657714844
Iteration [29463]: Loss = 0.7089552283287048
Iteration [29464]: Loss = 4.900706768035889
Iteration [29465]: Loss = 0.7087197303771973
Iteration [29466]: Loss = 0.7086731195449829
Iteration [29467]: Loss = 0.7085935473442078
Iteration [29468]: Loss = 0.7084842324256897
Iteration [29469]: Loss = 0.7083484530448914
Iteration [29470]: Loss = 0.708188533782959
Iteration [29471]: Loss = 0.7080071568489075
Iteration [29472]: Loss = 0.7078062295913696
Iteration [29473]: Loss = 0.7075877785682678
Iteration [29474]: Loss = 0.7073535919189453
Iteration [29475]: Loss = 9.110983848571777
Iteration [29476]: Loss = 4.908026218414307
Iteration [29477]: Loss = 0.7076718211174011
Iteration [29478]: Loss = 0.7079667448997498
Iteration [29479]: Loss = 0.7081952095031738
Iteration [29480]: Loss = 0.7083636522293091
Iteration [29481]: Loss = 0.7084782123565674
Iteration [29482]: Loss = 0.7085438966751099
Iteration [29483]: Loss = 0.7085658311843872
Iteration [29484]: Loss = 4.901636600494385
Iteration [29485]: Loss = 0.7087233662605286
Iteration [29486]: Loss = 0.7088438272476196
Iteration [29487]: Loss = 0.7089149355888367
Iteration [29488]: Loss = 0.7089416980743408
Iteration [29489]: Loss = 0.7089283466339111
Iteration [29490]: Loss = 0.7088790535926819
Iteration [29491]: Loss = 0.7087973356246948
Iteration [29492]: Loss = 0.708686351776123
Iteration [29493]: Loss = 0.7085491418838501
Iteration [29494]: Loss = 0.7083882093429565
Iteration [29495]: Loss = 0.7082058787345886
Iteration [29496]: Loss = 0.7080045342445374
Iteration [29497]: Loss = 0.7077857851982117
Iteration [29498]: Loss = 0.7075514793395996
Iteration [29499]: Loss = 0.7073032259941101
Iteration [29500]: Loss = 0.7070424556732178
Iteration [29501]: Loss = 4.910767555236816
Iteration [29502]: Loss = 0.7067177295684814
Iteration [29503]: Loss = 0.7066330909729004
Iteration [29504]: Loss = 0.706519603729248
Iteration [29505]: Loss = 0.7063801288604736
Iteration [29506]: Loss = 0.706217348575592
Iteration [29507]: Loss = 0.7060334086418152
Iteration [29508]: Loss = 0.7058305740356445
Iteration [29509]: Loss = 0.7056106328964233
Iteration [29510]: Loss = 0.7053753733634949
Iteration [29511]: Loss = 0.7051263451576233
Iteration [29512]: Loss = 0.7048649191856384
Iteration [29513]: Loss = 0.7045924067497253
Iteration [29514]: Loss = 0.7043096423149109
Iteration [29515]: Loss = 0.7040179967880249
Iteration [29516]: Loss = 0.7037181854248047
Iteration [29517]: Loss = 0.7034111618995667
Iteration [29518]: Loss = 0.7030975818634033
Iteration [29519]: Loss = 4.931406497955322
Iteration [29520]: Loss = 0.7026839852333069
Iteration [29521]: Loss = 0.702562153339386
Iteration [29522]: Loss = 0.7024152278900146
Iteration [29523]: Loss = 0.7022459506988525
Iteration [29524]: Loss = 4.93515682220459
Iteration [29525]: Loss = 0.7020788788795471
Iteration [29526]: Loss = 0.70206218957901
Iteration [29527]: Loss = 0.7020099759101868
Iteration [29528]: Loss = 0.7019258141517639
Iteration [29529]: Loss = 0.7018129825592041
Iteration [29530]: Loss = 0.7016743421554565
Iteration [29531]: Loss = 0.7015122771263123
Iteration [29532]: Loss = 0.7013294696807861
Iteration [29533]: Loss = 4.9399943351745605
Iteration [29534]: Loss = 0.7011393308639526
Iteration [29535]: Loss = 0.7011130452156067
Iteration [29536]: Loss = 0.7010522484779358
Iteration [29537]: Loss = 0.7009603977203369
Iteration [29538]: Loss = 0.7008405923843384
Iteration [29539]: Loss = 0.7006956934928894
Iteration [29540]: Loss = 0.7005281448364258
Iteration [29541]: Loss = 0.700340211391449
Iteration [29542]: Loss = 0.7001339793205261
Iteration [29543]: Loss = 4.946346282958984
Iteration [29544]: Loss = 0.6999045610427856
Iteration [29545]: Loss = 0.6998615860939026
Iteration [29546]: Loss = 0.6997859477996826
Iteration [29547]: Loss = 0.701555073261261
Iteration [29548]: Loss = 0.7014232277870178
Iteration [29549]: Loss = 0.7012672424316406
Iteration [29550]: Loss = 0.7010897397994995
Iteration [29551]: Loss = 0.7008926868438721
Iteration [29552]: Loss = 0.7006780505180359
Iteration [29553]: Loss = 0.700447678565979
Iteration [29554]: Loss = 0.700203001499176
Iteration [29555]: Loss = 0.6999457478523254
Iteration [29556]: Loss = 0.6996768116950989
Iteration [29557]: Loss = 0.6993977427482605
Iteration [29558]: Loss = 0.6991093158721924
Iteration [29559]: Loss = 0.6988124251365662
Iteration [29560]: Loss = 0.6985082030296326
Iteration [29561]: Loss = 0.6981972455978394
Iteration [29562]: Loss = 4.956991672515869
Iteration [29563]: Loss = 0.6977899670600891
Iteration [29564]: Loss = 0.6976717114448547
Iteration [29565]: Loss = 0.6975283026695251
Iteration [29566]: Loss = 4.959714889526367
Iteration [29567]: Loss = 0.6974072456359863
Iteration [29568]: Loss = 0.6974109411239624
Iteration [29569]: Loss = 0.6973773241043091
Iteration [29570]: Loss = 0.6973100304603577
Iteration [29571]: Loss = 0.6972123384475708
Iteration [29572]: Loss = 0.6970874071121216
Iteration [29573]: Loss = 4.9619460105896
Iteration [29574]: Loss = 0.696998119354248
Iteration [29575]: Loss = 0.6970154643058777
Iteration [29576]: Loss = 0.6969940662384033
Iteration [29577]: Loss = 4.961946964263916
Iteration [29578]: Loss = 0.6970818042755127
Iteration [29579]: Loss = 0.6971744298934937
Iteration [29580]: Loss = 4.9604573249816895
Iteration [29581]: Loss = 0.697456955909729
Iteration [29582]: Loss = 0.6976326107978821
Iteration [29583]: Loss = 4.95765495300293
Iteration [29584]: Loss = 0.698056697845459
Iteration [29585]: Loss = 0.69829261302948
Iteration [29586]: Loss = 4.953904151916504
Iteration [29587]: Loss = 0.6988194584846497
Iteration [29588]: Loss = 0.6990992426872253
Iteration [29589]: Loss = 0.6993139982223511
Iteration [29590]: Loss = 0.6994703412055969
Iteration [29591]: Loss = 0.6995739936828613
Iteration [29592]: Loss = 9.195999145507812
Iteration [29593]: Loss = 0.7001014351844788
Iteration [29594]: Loss = 0.7004891037940979
Iteration [29595]: Loss = 4.941695213317871
Iteration [29596]: Loss = 0.7012740969657898
Iteration [29597]: Loss = 0.701663076877594
Iteration [29598]: Loss = 0.7019764184951782
Iteration [29599]: Loss = 0.7022218108177185
Iteration [29600]: Loss = 0.7024058699607849
Iteration [29601]: Loss = 4.932671070098877
Iteration [29602]: Loss = 4.931073188781738
Iteration [29603]: Loss = 0.7033100724220276
Iteration [29604]: Loss = 0.7036947011947632
Iteration [29605]: Loss = 0.7040042281150818
Iteration [29606]: Loss = 0.704245924949646
Iteration [29607]: Loss = 0.7044265866279602
Iteration [29608]: Loss = 0.7045520544052124
Iteration [29609]: Loss = 0.7046279311180115
Iteration [29610]: Loss = 0.7046592235565186
Iteration [29611]: Loss = 0.7046502828598022
Iteration [29612]: Loss = 0.7046049237251282
Iteration [29613]: Loss = 0.7045270204544067
Iteration [29614]: Loss = 0.7044196128845215
Iteration [29615]: Loss = 4.923588275909424
Iteration [29616]: Loss = 4.923216819763184
Iteration [29617]: Loss = 0.704613983631134
Iteration [29618]: Loss = 0.7048076391220093
Iteration [29619]: Loss = 0.7049451470375061
Iteration [29620]: Loss = 0.7050316333770752
Iteration [29621]: Loss = 0.7050724029541016
Iteration [29622]: Loss = 0.7050719261169434
Iteration [29623]: Loss = 0.7050343155860901
Iteration [29624]: Loss = 0.7049631476402283
Iteration [29625]: Loss = 0.7048619389533997
Iteration [29626]: Loss = 4.921273231506348
Iteration [29627]: Loss = 0.7048103213310242
Iteration [29628]: Loss = 0.7048422694206238
Iteration [29629]: Loss = 0.7048338055610657
Iteration [29630]: Loss = 0.7047891020774841
Iteration [29631]: Loss = 4.92138671875
Iteration [29632]: Loss = 4.9207539558410645
Iteration [29633]: Loss = 0.7051356434822083
Iteration [29634]: Loss = 0.7053701877593994
Iteration [29635]: Loss = 0.7055443525314331
Iteration [29636]: Loss = 0.7056639790534973
Iteration [29637]: Loss = 0.7057344913482666
Iteration [29638]: Loss = 0.705760657787323
Iteration [29639]: Loss = 0.7051963210105896
Iteration [29640]: Loss = 0.7051467299461365
Iteration [29641]: Loss = 0.7056158185005188
Iteration [29642]: Loss = 0.7055050134658813
Iteration [29643]: Loss = 0.705367922782898
Iteration [29644]: Loss = 4.918825149536133
Iteration [29645]: Loss = 0.7052550911903381
Iteration [29646]: Loss = 0.7052609920501709
Iteration [29647]: Loss = 4.918713092803955
Iteration [29648]: Loss = 0.7053923010826111
Iteration [29649]: Loss = 0.7055020928382874
Iteration [29650]: Loss = 0.7055637836456299
Iteration [29651]: Loss = 0.7055820226669312
Iteration [29652]: Loss = 0.7055612206459045
Iteration [29653]: Loss = 0.7055052518844604
Iteration [29654]: Loss = 4.917738914489746
Iteration [29655]: Loss = 0.7055307030677795
Iteration [29656]: Loss = 0.7055955529212952
Iteration [29657]: Loss = 0.7056166529655457
Iteration [29658]: Loss = 0.7055982947349548
Iteration [29659]: Loss = 4.917083263397217
Iteration [29660]: Loss = 0.7056883573532104
Iteration [29661]: Loss = 0.705780565738678
Iteration [29662]: Loss = 0.7058263421058655
Iteration [29663]: Loss = 0.7058303356170654
Iteration [29664]: Loss = 0.7057965397834778
Iteration [29665]: Loss = 0.7057287693023682
Iteration [29666]: Loss = 0.7056304216384888
Iteration [29667]: Loss = 0.7055045366287231
Iteration [29668]: Loss = 0.7053539156913757
Iteration [29669]: Loss = 4.918960094451904
Iteration [29670]: Loss = 0.7052180171012878
Iteration [29671]: Loss = 0.7052143216133118
Iteration [29672]: Loss = 0.7051734924316406
Iteration [29673]: Loss = 0.7050994634628296
Iteration [29674]: Loss = 0.7049954533576965
Iteration [29675]: Loss = 0.7048645615577698
Iteration [29676]: Loss = 0.7047093510627747
Iteration [29677]: Loss = 0.7045323252677917
Iteration [29678]: Loss = 0.7043355703353882
Iteration [29679]: Loss = 0.7041211724281311
Iteration [29680]: Loss = 0.703890860080719
Iteration [29681]: Loss = 0.703646183013916
Iteration [29682]: Loss = 0.7033886313438416
Iteration [29683]: Loss = 0.7031194567680359
Iteration [29684]: Loss = 0.7028399705886841
Iteration [29685]: Loss = 0.702551007270813
Iteration [29686]: Loss = 4.934131622314453
Iteration [29687]: Loss = 0.7021799087524414
Iteration [29688]: Loss = 0.7020764946937561
Iteration [29689]: Loss = 0.7019461393356323
Iteration [29690]: Loss = 0.7017915844917297
Iteration [29691]: Loss = 0.7016150951385498
Iteration [29692]: Loss = 0.7014191150665283
Iteration [29693]: Loss = 4.9395880699157715
Iteration [29694]: Loss = 0.7012071013450623
Iteration [29695]: Loss = 0.7011715769767761
Iteration [29696]: Loss = 0.7011023163795471
Iteration [29697]: Loss = 0.701002836227417
Iteration [29698]: Loss = 0.700875997543335
Iteration [29699]: Loss = 0.7007246017456055
Iteration [29700]: Loss = 0.7005513310432434
Iteration [29701]: Loss = 4.9440107345581055
Iteration [29702]: Loss = 0.7003781795501709
Iteration [29703]: Loss = 0.7003592848777771
Iteration [29704]: Loss = 0.7003050446510315
Iteration [29705]: Loss = 0.7002192139625549
Iteration [29706]: Loss = 0.7001045942306519
Iteration [29707]: Loss = 0.6999643445014954
Iteration [29708]: Loss = 0.6998009085655212
Iteration [29709]: Loss = 0.6996166706085205
Iteration [29710]: Loss = 0.6994135975837708
Iteration [29711]: Loss = 4.950101375579834
Iteration [29712]: Loss = 0.6991903781890869
Iteration [29713]: Loss = 0.6991502046585083
Iteration [29714]: Loss = 0.6990768909454346
Iteration [29715]: Loss = 0.6984364986419678
Iteration [29716]: Loss = 4.95474910736084
Iteration [29717]: Loss = 0.6983847618103027
Iteration [29718]: Loss = 0.6984178423881531
Iteration [29719]: Loss = 0.6984105110168457
Iteration [29720]: Loss = 0.6983668804168701
Iteration [29721]: Loss = 0.6982904672622681
Iteration [29722]: Loss = 0.6981846690177917
Iteration [29723]: Loss = 4.9560866355896
Iteration [29724]: Loss = 4.955690383911133
Iteration [29725]: Loss = 0.6983895301818848
Iteration [29726]: Loss = 0.698588490486145
Iteration [29727]: Loss = 0.6987305283546448
Iteration [29728]: Loss = 0.6988214254379272
Iteration [29729]: Loss = 0.6988661289215088
Iteration [29730]: Loss = 4.9517998695373535
Iteration [29731]: Loss = 4.950768947601318
Iteration [29732]: Loss = 0.6994368433952332
Iteration [29733]: Loss = 0.6997336745262146
Iteration [29734]: Loss = 0.6999641060829163
Iteration [29735]: Loss = 0.7001343369483948
Iteration [29736]: Loss = 0.700250506401062
Iteration [29737]: Loss = 0.7003179788589478
Iteration [29738]: Loss = 4.944095134735107
Iteration [29739]: Loss = 0.7005566954612732
Iteration [29740]: Loss = 0.7007132172584534
Iteration [29741]: Loss = 0.7008169889450073
Iteration [29742]: Loss = 0.7008733153343201
Iteration [29743]: Loss = 0.7008867859840393
Iteration [29744]: Loss = 0.7008616924285889
Iteration [29745]: Loss = 0.7008018493652344
Iteration [29746]: Loss = 0.6988350749015808
Iteration [29747]: Loss = 4.952602386474609
Iteration [29748]: Loss = 4.952144145965576
Iteration [29749]: Loss = 0.6990759372711182
Iteration [29750]: Loss = 0.6992842555046082
Iteration [29751]: Loss = 9.198240280151367
Iteration [29752]: Loss = 0.6999891996383667
Iteration [29753]: Loss = 0.7004520297050476
Iteration [29754]: Loss = 4.941535472869873
Iteration [29755]: Loss = 0.7013654112815857
Iteration [29756]: Loss = 0.7018090486526489
Iteration [29757]: Loss = 0.7021718621253967
Iteration [29758]: Loss = 0.7024616003036499
Iteration [29759]: Loss = 4.931884765625
Iteration [29760]: Loss = 4.929843902587891
Iteration [29761]: Loss = 0.7036232352256775
Iteration [29762]: Loss = 0.7040767669677734
Iteration [29763]: Loss = 0.7044483423233032
Iteration [29764]: Loss = 0.7047460079193115
Iteration [29765]: Loss = 0.7049771547317505
Iteration [29766]: Loss = 4.919128894805908
Iteration [29767]: Loss = 0.705493152141571
Iteration [29768]: Loss = 0.7057666778564453
Iteration [29769]: Loss = 0.7059760689735413
Iteration [29770]: Loss = 0.7061273455619812
Iteration [29771]: Loss = 0.706226646900177
Iteration [29772]: Loss = 0.7062786817550659
Iteration [29773]: Loss = 4.913248538970947
Iteration [29774]: Loss = 0.7064884901046753
Iteration [29775]: Loss = 0.7066314220428467
Iteration [29776]: Loss = 4.911010265350342
Iteration [29777]: Loss = 0.7069963216781616
Iteration [29778]: Loss = 0.7072054147720337
Iteration [29779]: Loss = 4.907752513885498
Iteration [29780]: Loss = 4.906074523925781
Iteration [29781]: Loss = 0.7081671357154846
Iteration [29782]: Loss = 0.7085660696029663
Iteration [29783]: Loss = 0.7088882923126221
Iteration [29784]: Loss = 0.7091411352157593
Iteration [29785]: Loss = 0.7093315720558167
Iteration [29786]: Loss = 0.7094658613204956
Iteration [29787]: Loss = 0.7095493078231812
Iteration [29788]: Loss = 0.709587037563324
Iteration [29789]: Loss = 0.7095837593078613
Iteration [29790]: Loss = 0.7095434069633484
Iteration [29791]: Loss = 0.7094695568084717
Iteration [29792]: Loss = 0.7093656659126282
Iteration [29793]: Loss = 0.7092347741127014
Iteration [29794]: Loss = 0.7090795040130615
Iteration [29795]: Loss = 0.7089021801948547
Iteration [29796]: Loss = 0.7087052464485168
Iteration [29797]: Loss = 0.7084905505180359
Iteration [29798]: Loss = 0.7082597017288208
Iteration [29799]: Loss = 0.7080146670341492
Iteration [29800]: Loss = 0.7077566385269165
Iteration [29801]: Loss = 0.7074870467185974
Iteration [29802]: Loss = 0.7072068452835083
Iteration [29803]: Loss = 0.7069172263145447
Iteration [29804]: Loss = 0.7066192626953125
Iteration [29805]: Loss = 0.7063137292861938
Iteration [29806]: Loss = 0.7060011625289917
Iteration [29807]: Loss = 0.7056826949119568
Iteration [29808]: Loss = 0.705358624458313
Iteration [29809]: Loss = 0.7050296068191528
Iteration [29810]: Loss = 4.921465873718262
Iteration [29811]: Loss = 0.7045891284942627
Iteration [29812]: Loss = 4.922709941864014
Iteration [29813]: Loss = 0.7045278549194336
Iteration [29814]: Loss = 4.922191619873047
Iteration [29815]: Loss = 0.7047728896141052
Iteration [29816]: Loss = 0.7049312591552734
Iteration [29817]: Loss = 0.7050366997718811
Iteration [29818]: Loss = 0.7050945162773132
Iteration [29819]: Loss = 0.7051092386245728
Iteration [29820]: Loss = 0.7050852179527283
Iteration [29821]: Loss = 0.7050264477729797
Iteration [29822]: Loss = 0.704936146736145
Iteration [29823]: Loss = 0.7048176527023315
Iteration [29824]: Loss = 0.7046736478805542
Iteration [29825]: Loss = 0.7045067548751831
Iteration [29826]: Loss = 0.7043193578720093
Iteration [29827]: Loss = 0.7041133046150208
Iteration [29828]: Loss = 0.7038906216621399
Iteration [29829]: Loss = 0.7036527991294861
Iteration [29830]: Loss = 4.928170204162598
Iteration [29831]: Loss = 0.703368604183197
Iteration [29832]: Loss = 0.7033017873764038
Iteration [29833]: Loss = 0.7032043933868408
Iteration [29834]: Loss = 4.929840087890625
Iteration [29835]: Loss = 0.7031601667404175
Iteration [29836]: Loss = 0.7031955718994141
Iteration [29837]: Loss = 0.7031901478767395
Iteration [29838]: Loss = 0.703148365020752
Iteration [29839]: Loss = 0.703073263168335
Iteration [29840]: Loss = 0.7029687166213989
Iteration [29841]: Loss = 0.7028371691703796
Iteration [29842]: Loss = 0.7026815414428711
Iteration [29843]: Loss = 0.7025042772293091
Iteration [29844]: Loss = 0.7023074626922607
Iteration [29845]: Loss = 0.7020930647850037
Iteration [29846]: Loss = 0.7018628716468811
Iteration [29847]: Loss = 0.7016184329986572
Iteration [29848]: Loss = 4.938776969909668
Iteration [29849]: Loss = 4.938971996307373
Iteration [29850]: Loss = 4.938141822814941
Iteration [29851]: Loss = 0.7018190026283264
Iteration [29852]: Loss = 0.7020845413208008
Iteration [29853]: Loss = 0.7022866606712341
Iteration [29854]: Loss = 0.7024314999580383
Iteration [29855]: Loss = 0.7025248408317566
Iteration [29856]: Loss = 0.70257169008255
Iteration [29857]: Loss = 0.702576756477356
Iteration [29858]: Loss = 4.932621002197266
Iteration [29859]: Loss = 0.7027076482772827
Iteration [29860]: Loss = 4.931199073791504
Iteration [29861]: Loss = 4.929685592651367
Iteration [29862]: Loss = 0.7035638689994812
Iteration [29863]: Loss = 0.7039361000061035
Iteration [29864]: Loss = 0.70423424243927
Iteration [29865]: Loss = 0.7044655680656433
Iteration [29866]: Loss = 0.7046366333961487
Iteration [29867]: Loss = 0.7047535181045532
Iteration [29868]: Loss = 0.7048214077949524
Iteration [29869]: Loss = 0.7048452496528625
Iteration [29870]: Loss = 0.7048293352127075
Iteration [29871]: Loss = 0.704777717590332
Iteration [29872]: Loss = 0.7046940326690674
Iteration [29873]: Loss = 0.7045812010765076
Iteration [29874]: Loss = 0.7044422626495361
Iteration [29875]: Loss = 0.7042800188064575
Iteration [29876]: Loss = 0.7040964365005493
Iteration [29877]: Loss = 0.7038938403129578
Iteration [29878]: Loss = 0.7036740779876709
Iteration [29879]: Loss = 0.7034391164779663
Iteration [29880]: Loss = 0.70319002866745
Iteration [29881]: Loss = 0.7029286623001099
Iteration [29882]: Loss = 0.7026559114456177
Iteration [29883]: Loss = 0.7023731470108032
Iteration [29884]: Loss = 0.7020814418792725
Iteration [29885]: Loss = 0.7017815113067627
Iteration [29886]: Loss = 4.938188552856445
Iteration [29887]: Loss = 0.7013919949531555
Iteration [29888]: Loss = 0.7012807726860046
Iteration [29889]: Loss = 0.7011434435844421
Iteration [29890]: Loss = 0.7009826898574829
Iteration [29891]: Loss = 4.941699504852295
Iteration [29892]: Loss = 9.1822509765625
Iteration [29893]: Loss = 0.7012783885002136
Iteration [29894]: Loss = 0.7016446590423584
Iteration [29895]: Loss = 0.7019375562667847
Iteration [29896]: Loss = 0.7021645307540894
Iteration [29897]: Loss = 0.7023320198059082
Iteration [29898]: Loss = 0.702445924282074
Iteration [29899]: Loss = 0.7025114893913269
Iteration [29900]: Loss = 0.7025334239006042
Iteration [29901]: Loss = 0.7025163173675537
Iteration [29902]: Loss = 0.7024638652801514
Iteration [29903]: Loss = 0.7023795247077942
Iteration [29904]: Loss = 0.7022666931152344
Iteration [29905]: Loss = 0.702127993106842
Iteration [29906]: Loss = 0.7019659280776978
Iteration [29907]: Loss = 0.7017831802368164
Iteration [29908]: Loss = 0.7015815377235413
Iteration [29909]: Loss = 0.7013630270957947
Iteration [29910]: Loss = 0.7011292576789856
Iteration [29911]: Loss = 0.7008817791938782
Iteration [29912]: Loss = 0.7006219625473022
Iteration [29913]: Loss = 0.7003511190414429
Iteration [29914]: Loss = 0.700070321559906
Iteration [29915]: Loss = 0.6997803449630737
Iteration [29916]: Loss = 0.6994825601577759
Iteration [29917]: Loss = 0.6991773843765259
Iteration [29918]: Loss = 0.6988658905029297
Iteration [29919]: Loss = 4.953482627868652
Iteration [29920]: Loss = 0.698456883430481
Iteration [29921]: Loss = 0.6983375549316406
Iteration [29922]: Loss = 0.6981931328773499
Iteration [29923]: Loss = 0.6980263590812683
Iteration [29924]: Loss = 0.6978391408920288
Iteration [29925]: Loss = 0.6976339221000671
Iteration [29926]: Loss = 0.6974121332168579
Iteration [29927]: Loss = 0.6971757411956787
Iteration [29928]: Loss = 0.6969259977340698
Iteration [29929]: Loss = 0.6966642141342163
Iteration [29930]: Loss = 4.964824676513672
Iteration [29931]: Loss = 0.6963410973548889
Iteration [29932]: Loss = 0.6962586045265198
Iteration [29933]: Loss = 0.6961475014686584
Iteration [29934]: Loss = 0.6960107684135437
Iteration [29935]: Loss = 0.6958507895469666
Iteration [29936]: Loss = 4.968632698059082
Iteration [29937]: Loss = 0.695701539516449
Iteration [29938]: Loss = 0.6956933736801147
Iteration [29939]: Loss = 0.6956491470336914
Iteration [29940]: Loss = 0.695572555065155
Iteration [29941]: Loss = 0.6954666972160339
Iteration [29942]: Loss = 0.6953346729278564
Iteration [29943]: Loss = 0.6951790452003479
Iteration [29944]: Loss = 0.6950021386146545
Iteration [29945]: Loss = 4.973199844360352
Iteration [29946]: Loss = 0.6948243379592896
Iteration [29947]: Loss = 0.6948040127754211
Iteration [29948]: Loss = 0.6947488784790039
Iteration [29949]: Loss = 0.6946626305580139
Iteration [29950]: Loss = 0.6945480704307556
Iteration [29951]: Loss = 0.6944082379341125
Iteration [29952]: Loss = 0.6942455768585205
Iteration [29953]: Loss = 4.977138996124268
Iteration [29954]: Loss = 0.6940922141075134
Iteration [29955]: Loss = 0.6940825581550598
Iteration [29956]: Loss = 0.694037139415741
Iteration [29957]: Loss = 4.977684497833252
Iteration [29958]: Loss = 0.6940839886665344
Iteration [29959]: Loss = 0.6941596865653992
Iteration [29960]: Loss = 0.6941909193992615
Iteration [29961]: Loss = 0.6941823363304138
Iteration [29962]: Loss = 0.6941379308700562
Iteration [29963]: Loss = 0.6940612196922302
Iteration [29964]: Loss = 4.977705955505371
Iteration [29965]: Loss = 0.6940547823905945
Iteration [29966]: Loss = 0.6941076517105103
Iteration [29967]: Loss = 0.6941184997558594
Iteration [29968]: Loss = 4.976984977722168
Iteration [29969]: Loss = 0.6942615509033203
Iteration [29970]: Loss = 0.6943781971931458
Iteration [29971]: Loss = 0.694446325302124
Iteration [29972]: Loss = 0.6944710612297058
Iteration [29973]: Loss = 0.6944564580917358
Iteration [29974]: Loss = 4.975314617156982
Iteration [29975]: Loss = 0.6945562958717346
Iteration [29976]: Loss = 0.6946542263031006
Iteration [29977]: Loss = 0.6947057247161865
Iteration [29978]: Loss = 0.6947153210639954
Iteration [29979]: Loss = 0.6946871280670166
Iteration [29980]: Loss = 0.6946249008178711
Iteration [29981]: Loss = 0.6945322751998901
Iteration [29982]: Loss = 0.6944118142127991
Iteration [29983]: Loss = 0.6942667365074158
Iteration [29984]: Loss = 0.6940993070602417
Iteration [29985]: Loss = 4.977938175201416
Iteration [29986]: Loss = 0.6939379572868347
Iteration [29987]: Loss = 0.6939249634742737
Iteration [29988]: Loss = 4.978124618530273
Iteration [29989]: Loss = 0.6940275430679321
Iteration [29990]: Loss = 0.6941268444061279
Iteration [29991]: Loss = 0.6941794753074646
Iteration [29992]: Loss = 0.6941902041435242
Iteration [29993]: Loss = 0.6941630244255066
Iteration [29994]: Loss = 0.6941018104553223
Iteration [29995]: Loss = 0.6940097808837891
Iteration [29996]: Loss = 0.6938901543617249
Iteration [29997]: Loss = 0.6937456727027893
Iteration [29998]: Loss = 9.265830039978027
Iteration [29999]: Loss = 0.6938530206680298
Iteration [30000]: Loss = 0.6940637230873108
Iteration [30001]: Loss = 0.6942169666290283
Iteration [30002]: Loss = 0.6943182945251465
Iteration [30003]: Loss = 0.6943731904029846
Iteration [30004]: Loss = 0.6943859457969666
Iteration [30005]: Loss = 0.6943608522415161
Iteration [30006]: Loss = 0.6943017840385437
Iteration [30007]: Loss = 0.6942120790481567
Iteration [30008]: Loss = 4.9769673347473145
Iteration [30009]: Loss = 0.6941825747489929
Iteration [30010]: Loss = 0.6942254304885864
Iteration [30011]: Loss = 0.6942274570465088
Iteration [30012]: Loss = 0.6941925287246704
Iteration [30013]: Loss = 0.6941245794296265
Iteration [30014]: Loss = 0.6940268278121948
Iteration [30015]: Loss = 0.693902313709259
Iteration [30016]: Loss = 0.6937534213066101
Iteration [30017]: Loss = 0.6935830116271973
Iteration [30018]: Loss = 0.6933929324150085
Iteration [30019]: Loss = 0.6931850910186768
Iteration [30020]: Loss = 0.6929615139961243
Iteration [30021]: Loss = 0.6927235722541809
Iteration [30022]: Loss = 0.6924729347229004
Iteration [30023]: Loss = 0.6922106742858887
Iteration [30024]: Loss = 0.6919379830360413
Iteration [30025]: Loss = 0.6916559934616089
Iteration [30026]: Loss = 0.6913655996322632
Iteration [30027]: Loss = 0.691067636013031
Iteration [30028]: Loss = 0.690762996673584
Iteration [30029]: Loss = 4.996358871459961
Iteration [30030]: Loss = 0.6903678774833679
Iteration [30031]: Loss = 0.6902555823326111
Iteration [30032]: Loss = 0.6901180744171143
Iteration [30033]: Loss = 0.6899576783180237
Iteration [30034]: Loss = 0.6897768378257751
Iteration [30035]: Loss = 5.001038551330566
Iteration [30036]: Loss = 5.000952243804932
Iteration [30037]: Loss = 0.6898028254508972
Iteration [30038]: Loss = 0.6899546384811401
Iteration [30039]: Loss = 0.6900548338890076
Iteration [30040]: Loss = 0.6901088953018188
Iteration [30041]: Loss = 0.690121054649353
Iteration [30042]: Loss = 4.998265266418457
Iteration [30043]: Loss = 0.6902672052383423
Iteration [30044]: Loss = 0.6903854608535767
Iteration [30045]: Loss = 4.996340751647949
Iteration [30046]: Loss = 4.994965076446533
Iteration [30047]: Loss = 0.6911379098892212
Iteration [30048]: Loss = 0.6914845705032349
Iteration [30049]: Loss = 0.6917604207992554
Iteration [30050]: Loss = 0.6919724345207214
Iteration [30051]: Loss = 0.6921269297599792
Iteration [30052]: Loss = 0.6922294497489929
Iteration [30053]: Loss = 0.6922851800918579
Iteration [30054]: Loss = 4.986505508422852
Iteration [30055]: Loss = 0.6925054788589478
Iteration [30056]: Loss = 0.6926549673080444
Iteration [30057]: Loss = 0.6927530765533447
Iteration [30058]: Loss = 0.692804753780365
Iteration [30059]: Loss = 0.6928147673606873
Iteration [30060]: Loss = 4.9839091300964355
Iteration [30061]: Loss = 4.98300838470459
Iteration [30062]: Loss = 0.6933025121688843
Iteration [30063]: Loss = 0.6935776472091675
Iteration [30064]: Loss = 0.6937887072563171
Iteration [30065]: Loss = 0.6939423680305481
Iteration [30066]: Loss = 4.977234840393066
Iteration [30067]: Loss = 0.6943293809890747
Iteration [30068]: Loss = 0.6945494413375854
Iteration [30069]: Loss = 4.973701477050781
Iteration [30070]: Loss = 0.6950500011444092
Iteration [30071]: Loss = 4.970489501953125
Iteration [30072]: Loss = 0.6957530379295349
Iteration [30073]: Loss = 0.6961077451705933
Iteration [30074]: Loss = 0.6963906288146973
Iteration [30075]: Loss = 4.963680267333984
Iteration [30076]: Loss = 0.6969976425170898
Iteration [30077]: Loss = 0.6973113417625427
Iteration [30078]: Loss = 0.697557270526886
Iteration [30079]: Loss = 0.6977418065071106
Iteration [30080]: Loss = 0.6978713870048523
Iteration [30081]: Loss = 4.95661735534668
Iteration [30082]: Loss = 0.698215901851654
Iteration [30083]: Loss = 0.698417603969574
Iteration [30084]: Loss = 0.6985622644424438
Iteration [30085]: Loss = 0.6986558437347412
Iteration [30086]: Loss = 0.6987031698226929
Iteration [30087]: Loss = 0.6987089514732361
Iteration [30088]: Loss = 0.6986773014068604
Iteration [30089]: Loss = 4.953150749206543
Iteration [30090]: Loss = 0.6987460851669312
Iteration [30091]: Loss = 4.952004432678223
Iteration [30092]: Loss = 0.6990988850593567
Iteration [30093]: Loss = 0.6993038058280945
Iteration [30094]: Loss = 0.6994515061378479
Iteration [30095]: Loss = 0.6995475888252258
Iteration [30096]: Loss = 4.947987079620361
Iteration [30097]: Loss = 0.6998347043991089
Iteration [30098]: Loss = 0.7000116109848022
Iteration [30099]: Loss = 0.7001340985298157
Iteration [30100]: Loss = 0.7002074122428894
Iteration [30101]: Loss = 0.7002364993095398
Iteration [30102]: Loss = 0.7002256512641907
Iteration [30103]: Loss = 0.7001789808273315
Iteration [30104]: Loss = 0.7000999450683594
Iteration [30105]: Loss = 0.6999918222427368
Iteration [30106]: Loss = 0.6998574137687683
Iteration [30107]: Loss = 0.6996992230415344
Iteration [30108]: Loss = 0.6995199918746948
Iteration [30109]: Loss = 0.6993216872215271
Iteration [30110]: Loss = 0.6991060376167297
Iteration [30111]: Loss = 0.6988750100135803
Iteration [30112]: Loss = 0.6986299753189087
Iteration [30113]: Loss = 0.6983725428581238
Iteration [30114]: Loss = 0.698103666305542
Iteration [30115]: Loss = 0.6978246569633484
Iteration [30116]: Loss = 0.6975366473197937
Iteration [30117]: Loss = 0.6972403526306152
Iteration [30118]: Loss = 0.6969367265701294
Iteration [30119]: Loss = 4.963586807250977
Iteration [30120]: Loss = 0.6965422034263611
Iteration [30121]: Loss = 0.6964293718338013
Iteration [30122]: Loss = 0.696290910243988
Iteration [30123]: Loss = 4.966207981109619
Iteration [30124]: Loss = 4.965949058532715
Iteration [30125]: Loss = 0.6964163780212402
Iteration [30126]: Loss = 0.6965937614440918
Iteration [30127]: Loss = 0.6967167258262634
Iteration [30128]: Loss = 0.6967907547950745
Iteration [30129]: Loss = 4.962564945220947
Iteration [30130]: Loss = 0.697040855884552
Iteration [30131]: Loss = 4.9605536460876465
Iteration [30132]: Loss = 0.697541356086731
Iteration [30133]: Loss = 0.6978096961975098
Iteration [30134]: Loss = 0.6980143785476685
Iteration [30135]: Loss = 0.6981620192527771
Iteration [30136]: Loss = 0.6982579827308655
Iteration [30137]: Loss = 9.211186408996582
Iteration [30138]: Loss = 0.6987715363502502
Iteration [30139]: Loss = 0.6991530656814575
Iteration [30140]: Loss = 4.948706150054932
Iteration [30141]: Loss = 0.6999273896217346
Iteration [30142]: Loss = 4.944251537322998
Iteration [30143]: Loss = 0.7008485794067383
Iteration [30144]: Loss = 4.9391188621521
Iteration [30145]: Loss = 0.7018881440162659
Iteration [30146]: Loss = 0.7023853063583374
Iteration [30147]: Loss = 0.7027965188026428
Iteration [30148]: Loss = 0.7031300663948059
Iteration [30149]: Loss = 0.7033936977386475
Iteration [30150]: Loss = 0.7035942077636719
Iteration [30151]: Loss = 0.7037378549575806
Iteration [30152]: Loss = 0.7038302421569824
Iteration [30153]: Loss = 0.7038764953613281
Iteration [30154]: Loss = 0.7038812041282654
Iteration [30155]: Loss = 0.7038483023643494
Iteration [30156]: Loss = 0.70378178358078
Iteration [30157]: Loss = 0.70368492603302
Iteration [30158]: Loss = 0.7035607695579529
Iteration [30159]: Loss = 0.703411877155304
Iteration [30160]: Loss = 0.7032408714294434
Iteration [30161]: Loss = 0.703049898147583
Iteration [30162]: Loss = 0.7028408050537109
Iteration [30163]: Loss = 0.7026157379150391
Iteration [30164]: Loss = 0.7023760080337524
Iteration [30165]: Loss = 0.7021234035491943
Iteration [30166]: Loss = 0.7018588781356812
Iteration [30167]: Loss = 0.701583743095398
Iteration [30168]: Loss = 0.7012991905212402
Iteration [30169]: Loss = 0.7010060548782349
Iteration [30170]: Loss = 0.7007051706314087
Iteration [30171]: Loss = 0.7003974914550781
Iteration [30172]: Loss = 0.7000835537910461
Iteration [30173]: Loss = 0.6997640132904053
Iteration [30174]: Loss = 0.6994394659996033
Iteration [30175]: Loss = 0.6991106271743774
Iteration [30176]: Loss = 4.9522809982299805
Iteration [30177]: Loss = 0.6986715793609619
Iteration [30178]: Loss = 0.6985391974449158
Iteration [30179]: Loss = 0.6983833312988281
Iteration [30180]: Loss = 0.6982061862945557
Iteration [30181]: Loss = 0.698009729385376
Iteration [30182]: Loss = 4.957431316375732
Iteration [30183]: Loss = 0.6977974772453308
Iteration [30184]: Loss = 0.6977618932723999
Iteration [30185]: Loss = 0.6976930499076843
Iteration [30186]: Loss = 0.6975942850112915
Iteration [30187]: Loss = 4.9591546058654785
Iteration [30188]: Loss = 0.6975487470626831
Iteration [30189]: Loss = 4.9585466384887695
Iteration [30190]: Loss = 0.6978088617324829
Iteration [30191]: Loss = 0.6979745030403137
Iteration [30192]: Loss = 0.6980868577957153
Iteration [30193]: Loss = 0.6981513500213623
Iteration [30194]: Loss = 0.6981726884841919
Iteration [30195]: Loss = 0.6981549263000488
Iteration [30196]: Loss = 0.6981022357940674
Iteration [30197]: Loss = 4.956266403198242
Iteration [30198]: Loss = 0.698135256767273
Iteration [30199]: Loss = 0.6982040405273438
Iteration [30200]: Loss = 0.6982293128967285
Iteration [30201]: Loss = 0.6982151865959167
Iteration [30202]: Loss = 0.6981657147407532
Iteration [30203]: Loss = 0.6980842351913452
Iteration [30204]: Loss = 4.9564971923828125
Iteration [30205]: Loss = 0.6980683207511902
Iteration [30206]: Loss = 4.955750465393066
Iteration [30207]: Loss = 0.6983522772789001
Iteration [30208]: Loss = 0.6985280513763428
Iteration [30209]: Loss = 0.698649525642395
Iteration [30210]: Loss = 0.6987221240997314
Iteration [30211]: Loss = 0.6987506747245789
Iteration [30212]: Loss = 0.6987394094467163
Iteration [30213]: Loss = 4.9527268409729
Iteration [30214]: Loss = 0.6988433599472046
Iteration [30215]: Loss = 4.951417922973633
Iteration [30216]: Loss = 4.949942588806152
Iteration [30217]: Loss = 4.947610855102539
Iteration [30218]: Loss = 0.7002615928649902
Iteration [30219]: Loss = 0.7007584571838379
Iteration [30220]: Loss = 0.7011691331863403
Iteration [30221]: Loss = 0.7015023231506348
Iteration [30222]: Loss = 0.7017654776573181
Iteration [30223]: Loss = 0.7019655704498291
Iteration [30224]: Loss = 0.7021088600158691
Iteration [30225]: Loss = 0.7022007703781128
Iteration [30226]: Loss = 0.7022465467453003
Iteration [30227]: Loss = 0.7022507786750793
Iteration [30228]: Loss = 0.7022174596786499
Iteration [30229]: Loss = 0.7021505832672119
Iteration [30230]: Loss = 0.7020531296730042
Iteration [30231]: Loss = 0.701928436756134
Iteration [30232]: Loss = 0.7017789483070374
Iteration [30233]: Loss = 4.937493324279785
Iteration [30234]: Loss = 4.937292098999023
Iteration [30235]: Loss = 0.701873242855072
Iteration [30236]: Loss = 0.7020406723022461
Iteration [30237]: Loss = 0.7021544575691223
Iteration [30238]: Loss = 0.7022199630737305
Iteration [30239]: Loss = 0.7022418975830078
Iteration [30240]: Loss = 0.7022245526313782
Iteration [30241]: Loss = 0.7021719813346863
Iteration [30242]: Loss = 0.70208740234375
Iteration [30243]: Loss = 0.7019742727279663
Iteration [30244]: Loss = 4.936307430267334
Iteration [30245]: Loss = 4.9359540939331055
Iteration [30246]: Loss = 0.7021564841270447
Iteration [30247]: Loss = 4.9336419105529785
Iteration [30248]: Loss = 4.931751251220703
Iteration [30249]: Loss = 0.7032303810119629
Iteration [30250]: Loss = 0.7036608457565308
Iteration [30251]: Loss = 0.7040114998817444
Iteration [30252]: Loss = 0.7042902708053589
Iteration [30253]: Loss = 0.7045042514801025
Iteration [30254]: Loss = 0.7046598196029663
Iteration [30255]: Loss = 0.7047627568244934
Iteration [30256]: Loss = 0.7048182487487793
Iteration [30257]: Loss = 0.704831063747406
Iteration [30258]: Loss = 0.7048053741455078
Iteration [30259]: Loss = 0.7047449350357056
Iteration [30260]: Loss = 0.704653263092041
Iteration [30261]: Loss = 0.7045336365699768
Iteration [30262]: Loss = 0.7043886184692383
Iteration [30263]: Loss = 0.7042208313941956
Iteration [30264]: Loss = 0.7040325403213501
Iteration [30265]: Loss = 4.925970554351807
Iteration [30266]: Loss = 0.7038326263427734
Iteration [30267]: Loss = 0.703801691532135
Iteration [30268]: Loss = 4.926432132720947
Iteration [30269]: Loss = 4.925739288330078
Iteration [30270]: Loss = 0.7041828632354736
Iteration [30271]: Loss = 0.704427182674408
Iteration [30272]: Loss = 0.7046099901199341
Iteration [30273]: Loss = 0.7047374844551086
Iteration [30274]: Loss = 4.9208502769470215
Iteration [30275]: Loss = 0.7050768136978149
Iteration [30276]: Loss = 0.7052753567695618
Iteration [30277]: Loss = 0.7054169178009033
Iteration [30278]: Loss = 0.7055071592330933
Iteration [30279]: Loss = 0.7055510878562927
Iteration [30280]: Loss = 4.917037010192871
Iteration [30281]: Loss = 0.7057476043701172
Iteration [30282]: Loss = 0.7058851718902588
Iteration [30283]: Loss = 0.7059718370437622
Iteration [30284]: Loss = 0.7060125470161438
Iteration [30285]: Loss = 0.7060118317604065
Iteration [30286]: Loss = 0.7059738636016846
Iteration [30287]: Loss = 0.7059025168418884
Iteration [30288]: Loss = 0.7058007121086121
Iteration [30289]: Loss = 0.7056719064712524
Iteration [30290]: Loss = 0.7055184245109558
Iteration [30291]: Loss = 0.7053430080413818
Iteration [30292]: Loss = 0.7051476836204529
Iteration [30293]: Loss = 0.7049345374107361
Iteration [30294]: Loss = 0.7047052383422852
Iteration [30295]: Loss = 0.7044614553451538
Iteration [30296]: Loss = 0.704204797744751
Iteration [30297]: Loss = 0.7039363980293274
Iteration [30298]: Loss = 0.7036573886871338
Iteration [30299]: Loss = 0.703369140625
Iteration [30300]: Loss = 0.703072190284729
Iteration [30301]: Loss = 0.7027677297592163
Iteration [30302]: Loss = 0.7024562954902649
Iteration [30303]: Loss = 9.167319297790527
Iteration [30304]: Loss = 0.7022764682769775
Iteration [30305]: Loss = 4.933558940887451
Iteration [30306]: Loss = 0.7026333808898926
Iteration [30307]: Loss = 0.7028394341468811
Iteration [30308]: Loss = 0.7029882669448853
Iteration [30309]: Loss = 0.70308518409729
Iteration [30310]: Loss = 4.929549694061279
Iteration [30311]: Loss = 4.92832088470459
Iteration [30312]: Loss = 0.7037762403488159
Iteration [30313]: Loss = 0.7041031718254089
Iteration [30314]: Loss = 0.7043607831001282
Iteration [30315]: Loss = 0.7045556306838989
Iteration [30316]: Loss = 0.7046941518783569
Iteration [30317]: Loss = 0.7047819495201111
Iteration [30318]: Loss = 0.7048238515853882
Iteration [30319]: Loss = 0.7048245072364807
Iteration [30320]: Loss = 0.704788088798523
Iteration [30321]: Loss = 4.921352386474609
Iteration [30322]: Loss = 0.7048467397689819
Iteration [30323]: Loss = 0.7049254775047302
Iteration [30324]: Loss = 0.7049592733383179
Iteration [30325]: Loss = 0.7049526572227478
Iteration [30326]: Loss = 0.7049095630645752
Iteration [30327]: Loss = 0.7048336863517761
Iteration [30328]: Loss = 0.7047281861305237
Iteration [30329]: Loss = 0.7045961022377014
Iteration [30330]: Loss = 0.7044402360916138
Iteration [30331]: Loss = 0.7042626738548279
Iteration [30332]: Loss = 0.7040656805038452
Iteration [30333]: Loss = 0.7038511037826538
Iteration [30334]: Loss = 0.7036209106445312
Iteration [30335]: Loss = 0.7033765912055969
Iteration [30336]: Loss = 0.7031194567680359
Iteration [30337]: Loss = 0.7028509974479675
Iteration [30338]: Loss = 0.7025721669197083
Iteration [30339]: Loss = 0.7022840976715088
Iteration [30340]: Loss = 0.7019877433776855
Iteration [30341]: Loss = 0.7016839981079102
Iteration [30342]: Loss = 0.7013733386993408
Iteration [30343]: Loss = 0.7010567784309387
Iteration [30344]: Loss = 0.7007348537445068
Iteration [30345]: Loss = 0.7004079222679138
Iteration [30346]: Loss = 0.700076699256897
Iteration [30347]: Loss = 0.6997416019439697
Iteration [30348]: Loss = 0.699402928352356
Iteration [30349]: Loss = 0.6990611553192139
Iteration [30350]: Loss = 0.6987165212631226
Iteration [30351]: Loss = 0.6983693838119507
Iteration [30352]: Loss = 0.6980200409889221
Iteration [30353]: Loss = 0.697668731212616
Iteration [30354]: Loss = 0.6973156929016113
Iteration [30355]: Loss = 0.6969608068466187
Iteration [30356]: Loss = 4.963702201843262
Iteration [30357]: Loss = 0.696478545665741
Iteration [30358]: Loss = 4.965157508850098
Iteration [30359]: Loss = 0.6963871717453003
Iteration [30360]: Loss = 0.6964033246040344
Iteration [30361]: Loss = 0.6963812112808228
Iteration [30362]: Loss = 0.6963244080543518
Iteration [30363]: Loss = 0.6962366104125977
Iteration [30364]: Loss = 4.966254234313965
Iteration [30365]: Loss = 0.6962102055549622
Iteration [30366]: Loss = 0.6962541341781616
Iteration [30367]: Loss = 0.6962570548057556
Iteration [30368]: Loss = 0.6962226033210754
Iteration [30369]: Loss = 0.6961550712585449
Iteration [30370]: Loss = 0.6960573792457581
Iteration [30371]: Loss = 0.6959325671195984
Iteration [30372]: Loss = 0.6957834959030151
Iteration [30373]: Loss = 0.695612370967865
Iteration [30374]: Loss = 0.6954216361045837
Iteration [30375]: Loss = 0.6952131986618042
Iteration [30376]: Loss = 0.694988489151001
Iteration [30377]: Loss = 4.973498344421387
Iteration [30378]: Loss = 4.973605155944824
Iteration [30379]: Loss = 0.694905161857605
Iteration [30380]: Loss = 0.6950268745422363
Iteration [30381]: Loss = 0.6950995922088623
Iteration [30382]: Loss = 0.6951285004615784
Iteration [30383]: Loss = 0.6951176524162292
Iteration [30384]: Loss = 0.695071280002594
Iteration [30385]: Loss = 0.6949926614761353
Iteration [30386]: Loss = 4.972780704498291
Iteration [30387]: Loss = 0.6949827671051025
Iteration [30388]: Loss = 0.6950339078903198
Iteration [30389]: Loss = 0.6950433254241943
Iteration [30390]: Loss = 0.6950148940086365
Iteration [30391]: Loss = 0.6949525475502014
Iteration [30392]: Loss = 0.6948598027229309
Iteration [30393]: Loss = 0.6947392821311951
Iteration [30394]: Loss = 0.6945942640304565
Iteration [30395]: Loss = 0.6944266557693481
Iteration [30396]: Loss = 0.6942391395568848
Iteration [30397]: Loss = 0.6940335631370544
Iteration [30398]: Loss = 0.6938116550445557
Iteration [30399]: Loss = 0.6935751438140869
Iteration [30400]: Loss = 0.6933252811431885
Iteration [30401]: Loss = 0.6930638551712036
Iteration [30402]: Loss = 0.6927916407585144
Iteration [30403]: Loss = 0.6925100088119507
Iteration [30404]: Loss = 0.6922195553779602
Iteration [30405]: Loss = 0.6919214725494385
Iteration [30406]: Loss = 0.6916164755821228
Iteration [30407]: Loss = 0.6913049817085266
Iteration [30408]: Loss = 0.6909881830215454
Iteration [30409]: Loss = 0.6906663179397583
Iteration [30410]: Loss = 0.6903397440910339
Iteration [30411]: Loss = 0.6900092959403992
Iteration [30412]: Loss = 0.6896751523017883
Iteration [30413]: Loss = 0.6893376708030701
Iteration [30414]: Loss = 5.004149436950684
Iteration [30415]: Loss = 0.6888877749443054
Iteration [30416]: Loss = 0.6887527108192444
Iteration [30417]: Loss = 0.6885945200920105
Iteration [30418]: Loss = 0.6884154677391052
Iteration [30419]: Loss = 0.6882177591323853
Iteration [30420]: Loss = 0.6880032420158386
Iteration [30421]: Loss = 0.6877736449241638
Iteration [30422]: Loss = 0.6875302791595459
Iteration [30423]: Loss = 5.013409614562988
Iteration [30424]: Loss = 0.6872416138648987
Iteration [30425]: Loss = 5.013944625854492
Iteration [30426]: Loss = 0.687312126159668
Iteration [30427]: Loss = 0.6873986721038818
Iteration [30428]: Loss = 0.6874402165412903
Iteration [30429]: Loss = 0.6874411702156067
Iteration [30430]: Loss = 0.6874054074287415
Iteration [30431]: Loss = 0.6873369812965393
Iteration [30432]: Loss = 0.6872385740280151
Iteration [30433]: Loss = 0.6871137619018555
Iteration [30434]: Loss = 0.6869646310806274
Iteration [30435]: Loss = 0.686794102191925
Iteration [30436]: Loss = 0.6925209760665894
Iteration [30437]: Loss = 5.0181779861450195
Iteration [30438]: Loss = 0.6863952875137329
Iteration [30439]: Loss = 0.6863633394241333
Iteration [30440]: Loss = 0.6862978935241699
Iteration [30441]: Loss = 0.6862025856971741
Iteration [30442]: Loss = 0.6860803365707397
Iteration [30443]: Loss = 0.6859339475631714
Iteration [30444]: Loss = 0.6857655048370361
Iteration [30445]: Loss = 0.6855775117874146
Iteration [30446]: Loss = 0.6853717565536499
Iteration [30447]: Loss = 5.024882793426514
Iteration [30448]: Loss = 0.6851479411125183
Iteration [30449]: Loss = 0.6851096153259277
Iteration [30450]: Loss = 0.6850388050079346
Iteration [30451]: Loss = 0.6849386692047119
Iteration [30452]: Loss = 5.026714324951172
Iteration [30453]: Loss = 0.6848950982093811
Iteration [30454]: Loss = 0.6868060231208801
Iteration [30455]: Loss = 0.6868041753768921
Iteration [30456]: Loss = 0.6867659091949463
Iteration [30457]: Loss = 0.6866949796676636
Iteration [30458]: Loss = 0.6865944862365723
Iteration [30459]: Loss = 0.6864675283432007
Iteration [30460]: Loss = 0.6863166093826294
Iteration [30461]: Loss = 0.6861441135406494
Iteration [30462]: Loss = 0.6859524250030518
Iteration [30463]: Loss = 0.6857432126998901
Iteration [30464]: Loss = 0.6855183243751526
Iteration [30465]: Loss = 0.6852792501449585
Iteration [30466]: Loss = 0.685027539730072
Iteration [30467]: Loss = 5.02697229385376
Iteration [30468]: Loss = 0.6847257018089294
Iteration [30469]: Loss = 0.6846543550491333
Iteration [30470]: Loss = 0.6845537424087524
Iteration [30471]: Loss = 0.6844264268875122
Iteration [30472]: Loss = 0.6842755079269409
Iteration [30473]: Loss = 5.0305585861206055
Iteration [30474]: Loss = 0.6841460466384888
Iteration [30475]: Loss = 0.6841480731964111
Iteration [30476]: Loss = 0.6841135621070862
Iteration [30477]: Loss = 0.6840460300445557
Iteration [30478]: Loss = 0.6839486360549927
Iteration [30479]: Loss = 0.6838245987892151
Iteration [30480]: Loss = 0.683676540851593
Iteration [30481]: Loss = 5.0337982177734375
Iteration [30482]: Loss = 0.6835519075393677
Iteration [30483]: Loss = 0.6835562586784363
Iteration [30484]: Loss = 5.033705234527588
Iteration [30485]: Loss = 0.6836920380592346
Iteration [30486]: Loss = 0.6838074326515198
Iteration [30487]: Loss = 5.031798362731934
Iteration [30488]: Loss = 5.030397891998291
Iteration [30489]: Loss = 0.6845612525939941
Iteration [30490]: Loss = 0.6849110126495361
Iteration [30491]: Loss = 0.6851897239685059
Iteration [30492]: Loss = 0.6854043006896973
Iteration [30493]: Loss = 0.685560941696167
Iteration [30494]: Loss = 0.6856657266616821
Iteration [30495]: Loss = 0.6857234239578247
Iteration [30496]: Loss = 0.6857390403747559
Iteration [30497]: Loss = 0.6857163906097412
Iteration [30498]: Loss = 0.6856595277786255
Iteration [30499]: Loss = 0.6855717301368713
Iteration [30500]: Loss = 0.6854560971260071
Iteration [30501]: Loss = 0.6853154301643372
Iteration [30502]: Loss = 0.6851524114608765
Iteration [30503]: Loss = 0.6849689483642578
Iteration [30504]: Loss = 0.6847671866416931
Iteration [30505]: Loss = 0.68454909324646
Iteration [30506]: Loss = 0.6843160390853882
Iteration [30507]: Loss = 0.684069812297821
Iteration [30508]: Loss = 0.683811604976654
Iteration [30509]: Loss = 0.6835426092147827
Iteration [30510]: Loss = 0.683263897895813
Iteration [30511]: Loss = 0.6829766035079956
Iteration [30512]: Loss = 0.6826813817024231
Iteration [30513]: Loss = 0.6823791265487671
Iteration [30514]: Loss = 0.6820706129074097
Iteration [30515]: Loss = 0.6817563772201538
Iteration [30516]: Loss = 0.6814371347427368
Iteration [30517]: Loss = 0.6811132431030273
Iteration [30518]: Loss = 0.6807851791381836
Iteration [30519]: Loss = 0.6804535388946533
Iteration [30520]: Loss = 0.6801186800003052
Iteration [30521]: Loss = 0.6797807216644287
Iteration [30522]: Loss = 5.056005001068115
Iteration [30523]: Loss = 0.6793336868286133
Iteration [30524]: Loss = 0.6792015433311462
Iteration [30525]: Loss = 0.6790462732315063
Iteration [30526]: Loss = 0.6788700819015503
Iteration [30527]: Loss = 0.67867511510849
Iteration [30528]: Loss = 0.6784634590148926
Iteration [30529]: Loss = 0.6782790422439575
Iteration [30530]: Loss = 0.6780839562416077
Iteration [30531]: Loss = 0.6778790354728699
Iteration [30532]: Loss = 0.6776649951934814
Iteration [30533]: Loss = 0.6774429678916931
Iteration [30534]: Loss = 0.6772136688232422
Iteration [30535]: Loss = 0.6769776940345764
Iteration [30536]: Loss = 0.676736056804657
Iteration [30537]: Loss = 5.072256565093994
Iteration [30538]: Loss = 0.6764293909072876
Iteration [30539]: Loss = 0.6763463020324707
Iteration [30540]: Loss = 0.6762422323226929
Iteration [30541]: Loss = 0.6761191487312317
Iteration [30542]: Loss = 0.6759788990020752
Iteration [30543]: Loss = 0.6758233308792114
Iteration [30544]: Loss = 0.6756539940834045
Iteration [30545]: Loss = 0.6754720211029053
Iteration [30546]: Loss = 0.6752788424491882
Iteration [30547]: Loss = 0.6750755310058594
Iteration [30548]: Loss = 5.081257343292236
Iteration [30549]: Loss = 0.674835205078125
Iteration [30550]: Loss = 0.6747804880142212
Iteration [30551]: Loss = 0.6747021079063416
Iteration [30552]: Loss = 0.6746020913124084
Iteration [30553]: Loss = 0.6744827032089233
Iteration [30554]: Loss = 5.0841288566589355
Iteration [30555]: Loss = 5.0839080810546875
Iteration [30556]: Loss = 0.6745836138725281
Iteration [30557]: Loss = 0.6747326254844666
Iteration [30558]: Loss = 0.6748374700546265
Iteration [30559]: Loss = 0.6749027371406555
Iteration [30560]: Loss = 5.080874919891357
Iteration [30561]: Loss = 0.6751207113265991
Iteration [30562]: Loss = 5.079050064086914
Iteration [30563]: Loss = 0.675549328327179
Iteration [30564]: Loss = 0.6757797002792358
Iteration [30565]: Loss = 0.6759577393531799
Iteration [30566]: Loss = 5.074468612670898
Iteration [30567]: Loss = 0.6763681769371033
Iteration [30568]: Loss = 0.676590621471405
Iteration [30569]: Loss = 0.6767616868019104
Iteration [30570]: Loss = 0.6768862009048462
Iteration [30571]: Loss = 5.06960391998291
Iteration [30572]: Loss = 5.068301677703857
Iteration [30573]: Loss = 0.6775784492492676
Iteration [30574]: Loss = 0.6778854131698608
Iteration [30575]: Loss = 0.6781327128410339
Iteration [30576]: Loss = 0.6783259510993958
Iteration [30577]: Loss = 0.6784706115722656
Iteration [30578]: Loss = 0.6785715818405151
Iteration [30579]: Loss = 0.6786331534385681
Iteration [30580]: Loss = 5.060294151306152
Iteration [30581]: Loss = 0.6788437962532043
Iteration [30582]: Loss = 0.6789807081222534
Iteration [30583]: Loss = 0.6790745854377747
Iteration [30584]: Loss = 5.057708263397217
Iteration [30585]: Loss = 0.6793403625488281
Iteration [30586]: Loss = 0.6795008182525635
Iteration [30587]: Loss = 0.67961585521698
Iteration [30588]: Loss = 0.6796900033950806
Iteration [30589]: Loss = 0.6797273755073547
Iteration [30590]: Loss = 5.054406642913818
Iteration [30591]: Loss = 0.679896354675293
Iteration [30592]: Loss = 0.6800155639648438
Iteration [30593]: Loss = 5.052423477172852
Iteration [30594]: Loss = 0.6803240776062012
Iteration [30595]: Loss = 0.6805024743080139
Iteration [30596]: Loss = 0.6806337237358093
Iteration [30597]: Loss = 5.048978328704834
Iteration [30598]: Loss = 0.6809629797935486
Iteration [30599]: Loss = 0.6811500787734985
Iteration [30600]: Loss = 0.6812891960144043
Iteration [30601]: Loss = 0.6813850998878479
Iteration [30602]: Loss = 5.045046329498291
Iteration [30603]: Loss = 9.4061279296875
Iteration [30604]: Loss = 0.6821885704994202
Iteration [30605]: Loss = 0.6826414465904236
Iteration [30606]: Loss = 0.683020293712616
Iteration [30607]: Loss = 5.034746170043945
Iteration [30608]: Loss = 0.6837710738182068
Iteration [30609]: Loss = 0.684137225151062
Iteration [30610]: Loss = 0.6844378113746643
Iteration [30611]: Loss = 0.6846793293952942
Iteration [30612]: Loss = 0.6848673820495605
Iteration [30613]: Loss = 0.6850075125694275
Iteration [30614]: Loss = 0.6851043105125427
Iteration [30615]: Loss = 0.6851620078086853
Iteration [30616]: Loss = 0.6851845979690552
Iteration [30617]: Loss = 0.6851755976676941
Iteration [30618]: Loss = 0.6851382255554199
Iteration [30619]: Loss = 0.6850749850273132
Iteration [30620]: Loss = 0.6849886775016785
Iteration [30621]: Loss = 0.6848814487457275
Iteration [30622]: Loss = 0.6847555637359619
Iteration [30623]: Loss = 0.6846127510070801
Iteration [30624]: Loss = 0.6844547986984253
Iteration [30625]: Loss = 0.6842831373214722
Iteration [30626]: Loss = 0.6840991973876953
Iteration [30627]: Loss = 0.6839041113853455
Iteration [30628]: Loss = 0.6836989521980286
Iteration [30629]: Loss = 0.6834849715232849
Iteration [30630]: Loss = 0.6832629442214966
Iteration [30631]: Loss = 0.6830335855484009
Iteration [30632]: Loss = 0.6827977299690247
Iteration [30633]: Loss = 0.6825559139251709
Iteration [30634]: Loss = 0.6823088526725769
Iteration [30635]: Loss = 0.68205726146698
Iteration [30636]: Loss = 0.6818011999130249
Iteration [30637]: Loss = 0.6815411448478699
Iteration [30638]: Loss = 0.6812779307365417
Iteration [30639]: Loss = 0.681011438369751
Iteration [30640]: Loss = 0.6807422041893005
Iteration [30641]: Loss = 0.6804705858230591
Iteration [30642]: Loss = 0.6801965832710266
Iteration [30643]: Loss = 0.6799206733703613
Iteration [30644]: Loss = 0.679642915725708
Iteration [30645]: Loss = 0.679363489151001
Iteration [30646]: Loss = 0.6790826916694641
Iteration [30647]: Loss = 5.0595173835754395
Iteration [30648]: Loss = 0.6787081956863403
Iteration [30649]: Loss = 0.6785957217216492
Iteration [30650]: Loss = 0.6784650087356567
Iteration [30651]: Loss = 0.678318202495575
Iteration [30652]: Loss = 0.678156852722168
Iteration [30653]: Loss = 5.064019203186035
Iteration [30654]: Loss = 0.6779862642288208
Iteration [30655]: Loss = 0.6779607534408569
Iteration [30656]: Loss = 0.6779085397720337
Iteration [30657]: Loss = 5.064845561981201
Iteration [30658]: Loss = 0.6779244542121887
Iteration [30659]: Loss = 0.6779782772064209
Iteration [30660]: Loss = 0.6779976487159729
Iteration [30661]: Loss = 0.6779857873916626
Iteration [30662]: Loss = 0.6779457330703735
Iteration [30663]: Loss = 0.677880585193634
Iteration [30664]: Loss = 0.6777926683425903
Iteration [30665]: Loss = 0.6776842474937439
Iteration [30666]: Loss = 0.6775572896003723
Iteration [30667]: Loss = 0.6774137020111084
Iteration [30668]: Loss = 0.6772552132606506
Iteration [30669]: Loss = 0.6770832538604736
Iteration [30670]: Loss = 0.6768991947174072
Iteration [30671]: Loss = 0.6767042875289917
Iteration [30672]: Loss = 0.6764995455741882
Iteration [30673]: Loss = 5.073378562927246
Iteration [30674]: Loss = 0.676255464553833
Iteration [30675]: Loss = 0.6761989593505859
Iteration [30676]: Loss = 0.6761189103126526
Iteration [30677]: Loss = 0.6760175228118896
Iteration [30678]: Loss = 5.075530052185059
Iteration [30679]: Loss = 5.075235843658447
Iteration [30680]: Loss = 0.6761590242385864
Iteration [30681]: Loss = 0.6763179898262024
Iteration [30682]: Loss = 0.6764319539070129
Iteration [30683]: Loss = 0.6765053868293762
Iteration [30684]: Loss = 0.676542341709137
Iteration [30685]: Loss = 0.6765464544296265
Iteration [30686]: Loss = 5.072080612182617
Iteration [30687]: Loss = 0.6766588687896729
Iteration [30688]: Loss = 0.6767541766166687
Iteration [30689]: Loss = 0.6768106818199158
Iteration [30690]: Loss = 0.6768324375152588
Iteration [30691]: Loss = 0.6768227219581604
Iteration [30692]: Loss = 0.6767848134040833
Iteration [30693]: Loss = 5.070971965789795
Iteration [30694]: Loss = 0.6768256425857544
Iteration [30695]: Loss = 0.6768903136253357
Iteration [30696]: Loss = 0.6769192218780518
Iteration [30697]: Loss = 0.6769161224365234
Iteration [30698]: Loss = 0.6768840551376343
Iteration [30699]: Loss = 0.676826000213623
Iteration [30700]: Loss = 0.6767444014549255
Iteration [30701]: Loss = 0.6766416430473328
Iteration [30702]: Loss = 0.676520049571991
Iteration [30703]: Loss = 0.6763811707496643
Iteration [30704]: Loss = 0.6762269139289856
Iteration [30705]: Loss = 0.6760587692260742
Iteration [30706]: Loss = 0.67587810754776
Iteration [30707]: Loss = 0.6756862998008728
Iteration [30708]: Loss = 0.6754842400550842
Iteration [30709]: Loss = 0.6752732396125793
Iteration [30710]: Loss = 0.6750538349151611
Iteration [30711]: Loss = 0.6748272180557251
Iteration [30712]: Loss = 0.674593985080719
Iteration [30713]: Loss = 0.6743547320365906
Iteration [30714]: Loss = 0.6741100549697876
Iteration [30715]: Loss = 0.6738606095314026
Iteration [30716]: Loss = 0.6736068725585938
Iteration [30717]: Loss = 0.6733490824699402
Iteration [30718]: Loss = 0.6730879545211792
Iteration [30719]: Loss = 0.6728236079216003
Iteration [30720]: Loss = 0.672556459903717
Iteration [30721]: Loss = 0.6722866892814636
Iteration [30722]: Loss = 0.6720148921012878
Iteration [30723]: Loss = 0.6717407703399658
Iteration [30724]: Loss = 0.6714649796485901
Iteration [30725]: Loss = 5.101738452911377
Iteration [30726]: Loss = 0.6711013913154602
Iteration [30727]: Loss = 0.6709946393966675
Iteration [30728]: Loss = 0.6708694100379944
Iteration [30729]: Loss = 0.6707276105880737
Iteration [30730]: Loss = 0.6705707907676697
Iteration [30731]: Loss = 0.6704005599021912
Iteration [30732]: Loss = 5.107170104980469
Iteration [30733]: Loss = 5.107173919677734
Iteration [30734]: Loss = 0.6703793406486511
Iteration [30735]: Loss = 0.6704962849617004
Iteration [30736]: Loss = 0.6705723404884338
Iteration [30737]: Loss = 0.6706119775772095
Iteration [30738]: Loss = 0.67061847448349
Iteration [30739]: Loss = 5.1050543785095215
Iteration [30740]: Loss = 5.1042609214782715
Iteration [30741]: Loss = 0.6710267066955566
Iteration [30742]: Loss = 0.6712586283683777
Iteration [30743]: Loss = 0.671438455581665
Iteration [30744]: Loss = 0.6715712547302246
Iteration [30745]: Loss = 0.671661913394928
Iteration [30746]: Loss = 0.6717143654823303
Iteration [30747]: Loss = 0.6717325448989868
Iteration [30748]: Loss = 0.6717197299003601
Iteration [30749]: Loss = 0.6716791391372681
Iteration [30750]: Loss = 0.6716134548187256
Iteration [30751]: Loss = 0.6715251207351685
Iteration [30752]: Loss = 0.6714165806770325
Iteration [30753]: Loss = 5.101166248321533
Iteration [30754]: Loss = 5.100894451141357
Iteration [30755]: Loss = 0.6711524724960327
Iteration [30756]: Loss = 0.6713085770606995
Iteration [30757]: Loss = 0.671420156955719
Iteration [30758]: Loss = 0.6714915037155151
Iteration [30759]: Loss = 0.6715266704559326
Iteration [30760]: Loss = 0.6715292930603027
Iteration [30761]: Loss = 0.6715025901794434
Iteration [30762]: Loss = 0.6714494228363037
Iteration [30763]: Loss = 0.6713724732398987
Iteration [30764]: Loss = 0.6712741255760193
Iteration [30765]: Loss = 0.6711564064025879
Iteration [30766]: Loss = 0.6710212826728821
Iteration [30767]: Loss = 0.6708705425262451
Iteration [30768]: Loss = 0.6707056760787964
Iteration [30769]: Loss = 0.6705280542373657
Iteration [30770]: Loss = 0.6703391671180725
Iteration [30771]: Loss = 0.6701399683952332
Iteration [30772]: Loss = 0.6699314117431641
Iteration [30773]: Loss = 0.6697145700454712
Iteration [30774]: Loss = 0.6694903373718262
Iteration [30775]: Loss = 0.6692593693733215
Iteration [30776]: Loss = 0.6690223217010498
Iteration [30777]: Loss = 0.6687798500061035
Iteration [30778]: Loss = 5.116643905639648
Iteration [30779]: Loss = 0.6684738397598267
Iteration [30780]: Loss = 0.6683920621871948
Iteration [30781]: Loss = 0.6682895421981812
Iteration [30782]: Loss = 0.6681679487228394
Iteration [30783]: Loss = 0.6680294871330261
Iteration [30784]: Loss = 0.6678758263587952
Iteration [30785]: Loss = 0.6677083373069763
Iteration [30786]: Loss = 0.6675285696983337
Iteration [30787]: Loss = 5.123381614685059
Iteration [30788]: Loss = 0.6673300266265869
Iteration [30789]: Loss = 5.123628616333008
Iteration [30790]: Loss = 0.6674254536628723
Iteration [30791]: Loss = 0.6675145626068115
Iteration [30792]: Loss = 0.6675658822059631
Iteration [30793]: Loss = 0.667583167552948
Iteration [30794]: Loss = 0.6675696969032288
Iteration [30795]: Loss = 0.6675285696983337
Iteration [30796]: Loss = 0.6674624681472778
Iteration [30797]: Loss = 0.6673740148544312
Iteration [30798]: Loss = 0.6672652363777161
Iteration [30799]: Loss = 0.6671383380889893
Iteration [30800]: Loss = 0.6669950485229492
Iteration [30801]: Loss = 0.6668369770050049
Iteration [30802]: Loss = 0.6666656732559204
Iteration [30803]: Loss = 0.6664825677871704
Iteration [30804]: Loss = 5.129315376281738
Iteration [30805]: Loss = 0.6662783622741699
Iteration [30806]: Loss = 0.6662402153015137
Iteration [30807]: Loss = 0.666176974773407
Iteration [30808]: Loss = 5.130434513092041
Iteration [30809]: Loss = 0.6661776900291443
Iteration [30810]: Loss = 0.6662266254425049
Iteration [30811]: Loss = 0.6662420034408569
Iteration [30812]: Loss = 0.6662266254425049
Iteration [30813]: Loss = 0.6661840081214905
Iteration [30814]: Loss = 0.6661165356636047
Iteration [30815]: Loss = 0.6660268306732178
Iteration [30816]: Loss = 0.6659170389175415
Iteration [30817]: Loss = 0.6657891273498535
Iteration [30818]: Loss = 0.6656450033187866
Iteration [30819]: Loss = 0.6654863357543945
Iteration [30820]: Loss = 0.6653144359588623
Iteration [30821]: Loss = 0.665130615234375
Iteration [30822]: Loss = 0.6649362444877625
Iteration [30823]: Loss = 0.6647321581840515
Iteration [30824]: Loss = 0.6645194292068481
Iteration [30825]: Loss = 0.6642988920211792
Iteration [30826]: Loss = 14.097561836242676
Iteration [30827]: Loss = 0.6644096374511719
Iteration [30828]: Loss = 5.138406753540039
Iteration [30829]: Loss = 0.6650941967964172
Iteration [30830]: Loss = 0.6654335856437683
Iteration [30831]: Loss = 0.6657112240791321
Iteration [30832]: Loss = 0.6659328937530518
Iteration [30833]: Loss = 0.6661044359207153
Iteration [30834]: Loss = 0.6662305593490601
Iteration [30835]: Loss = 0.6663159132003784
Iteration [30836]: Loss = 0.6663644313812256
Iteration [30837]: Loss = 0.6663798093795776
Iteration [30838]: Loss = 0.6663653254508972
Iteration [30839]: Loss = 5.129115104675293
Iteration [30840]: Loss = 0.6664469838142395
Iteration [30841]: Loss = 0.6665293574333191
Iteration [30842]: Loss = 0.6665750741958618
Iteration [30843]: Loss = 0.6665881872177124
Iteration [30844]: Loss = 0.6665715575218201
Iteration [30845]: Loss = 0.6665282845497131
Iteration [30846]: Loss = 0.6664608120918274
Iteration [30847]: Loss = 0.6663718223571777
Iteration [30848]: Loss = 0.6662633419036865
Iteration [30849]: Loss = 5.1301727294921875
Iteration [30850]: Loss = 0.6661844849586487
Iteration [30851]: Loss = 0.6661984920501709
Iteration [30852]: Loss = 0.6661829352378845
Iteration [30853]: Loss = 0.6661405563354492
Iteration [30854]: Loss = 0.6660740375518799
Iteration [30855]: Loss = 0.6659858226776123
Iteration [30856]: Loss = 0.6658779978752136
Iteration [30857]: Loss = 0.6657524108886719
Iteration [30858]: Loss = 0.665611207485199
Iteration [30859]: Loss = 0.6654556393623352
Iteration [30860]: Loss = 0.6652872562408447
Iteration [30861]: Loss = 5.136013984680176
Iteration [30862]: Loss = 0.6651063561439514
Iteration [30863]: Loss = 0.6650771498680115
Iteration [30864]: Loss = 0.6650226712226868
Iteration [30865]: Loss = 0.6649452447891235
Iteration [30866]: Loss = 0.6648471355438232
Iteration [30867]: Loss = 0.6647304892539978
Iteration [30868]: Loss = 0.66459721326828
Iteration [30869]: Loss = 0.6644487380981445
Iteration [30870]: Loss = 0.6642869114875793
Iteration [30871]: Loss = 0.6641126871109009
Iteration [30872]: Loss = 5.142721652984619
Iteration [30873]: Loss = 0.6639223694801331
Iteration [30874]: Loss = 0.663889467716217
Iteration [30875]: Loss = 0.6638314723968506
Iteration [30876]: Loss = 0.6637510061264038
Iteration [30877]: Loss = 0.6636501550674438
Iteration [30878]: Loss = 0.6635311841964722
Iteration [30879]: Loss = 0.6633955836296082
Iteration [30880]: Loss = 0.6632452607154846
Iteration [30881]: Loss = 0.6630816459655762
Iteration [30882]: Loss = 9.634186744689941
Iteration [30883]: Loss = 0.6630972027778625
Iteration [30884]: Loss = 0.6632415652275085
Iteration [30885]: Loss = 5.146050930023193
Iteration [30886]: Loss = 0.6635945439338684
Iteration [30887]: Loss = 0.6637927293777466
Iteration [30888]: Loss = 5.142633438110352
Iteration [30889]: Loss = 0.6642374396324158
Iteration [30890]: Loss = 0.6644745469093323
Iteration [30891]: Loss = 0.6646601557731628
Iteration [30892]: Loss = 0.664799153804779
Iteration [30893]: Loss = 0.6634516716003418
Iteration [30894]: Loss = 0.6636608839035034
Iteration [30895]: Loss = 0.663478672504425
Iteration [30896]: Loss = 0.6631193161010742
Iteration [30897]: Loss = 0.6627320051193237
Iteration [30898]: Loss = 0.6622631549835205
Iteration [30899]: Loss = 0.6617244482040405
Iteration [30900]: Loss = 0.661125659942627
Iteration [30901]: Loss = 0.6604753732681274
Iteration [30902]: Loss = 0.6597809791564941
Iteration [30903]: Loss = 0.6590489745140076
Iteration [30904]: Loss = 0.6582850217819214
Iteration [30905]: Loss = 0.6574937701225281
Iteration [30906]: Loss = 5.184357643127441
Iteration [30907]: Loss = 0.6566236019134521
Iteration [30908]: Loss = 0.6602764129638672
Iteration [30909]: Loss = 0.6599835753440857
Iteration [30910]: Loss = 0.6601862907409668
Iteration [30911]: Loss = 0.6596759557723999
Iteration [30912]: Loss = 0.6592929363250732
Iteration [30913]: Loss = 5.16072416305542
Iteration [30914]: Loss = 0.6608668565750122
Iteration [30915]: Loss = 0.660875678062439
Iteration [30916]: Loss = 0.6608129739761353
Iteration [30917]: Loss = 0.6606863737106323
Iteration [30918]: Loss = 0.660502552986145
Iteration [30919]: Loss = 0.6602675318717957
Iteration [30920]: Loss = 0.6599867939949036
Iteration [30921]: Loss = 0.6596652269363403
Iteration [30922]: Loss = 0.6593071222305298
Iteration [30923]: Loss = 0.6589165329933167
Iteration [30924]: Loss = 0.6584967970848083
Iteration [30925]: Loss = 0.6580512523651123
Iteration [30926]: Loss = 5.179128646850586
Iteration [30927]: Loss = 0.6575599908828735
Iteration [30928]: Loss = 0.6575931310653687
Iteration [30929]: Loss = 0.6572243571281433
Iteration [30930]: Loss = 0.6587353944778442
Iteration [30931]: Loss = 0.6585076451301575
Iteration [30932]: Loss = 0.6582400798797607
Iteration [30933]: Loss = 0.6579371690750122
Iteration [30934]: Loss = 0.6576023101806641
Iteration [30935]: Loss = 0.6572389602661133
Iteration [30936]: Loss = 5.18336820602417
Iteration [30937]: Loss = 5.183306694030762
Iteration [30938]: Loss = 0.6571953296661377
Iteration [30939]: Loss = 5.17995548248291
Iteration [30940]: Loss = 0.657964825630188
Iteration [30941]: Loss = 0.6583830118179321
Iteration [30942]: Loss = 9.686591148376465
Iteration [30943]: Loss = 0.6595609188079834
Iteration [30944]: Loss = 0.6602836847305298
Iteration [30945]: Loss = 0.6608865857124329
Iteration [30946]: Loss = 0.6615228652954102
Iteration [30947]: Loss = 0.6663144826889038
Iteration [30948]: Loss = 0.6622234582901001
Iteration [30949]: Loss = 0.6624491214752197
Iteration [30950]: Loss = 5.1502790451049805
Iteration [30951]: Loss = 0.6630169153213501
Iteration [30952]: Loss = 0.663341224193573
Iteration [30953]: Loss = 0.6635841727256775
Iteration [30954]: Loss = 0.6637541055679321
Iteration [30955]: Loss = 0.6638579964637756
Iteration [30956]: Loss = 5.105076313018799
Iteration [30957]: Loss = 0.674057126045227
Iteration [30958]: Loss = 0.6727350950241089
Iteration [30959]: Loss = 0.662962794303894
Iteration [30960]: Loss = 0.6606404781341553
Iteration [30961]: Loss = 0.6549737453460693
Iteration [30962]: Loss = 0.6600949168205261
Iteration [30963]: Loss = 0.6533859968185425
Iteration [30964]: Loss = 9.906145095825195
Iteration [30965]: Loss = 0.6402266621589661
Iteration [30966]: Loss = 0.6698324680328369
Iteration [30967]: Loss = 5.214107036590576
Iteration [30968]: Loss = 0.6537833213806152
Iteration [30969]: Loss = 0.6692032814025879
Iteration [30970]: Loss = 0.6942143440246582
Iteration [30971]: Loss = 0.6689972877502441
Iteration [30972]: Loss = 0.6758008003234863
Iteration [30973]: Loss = 5.137227535247803
Iteration [30974]: Loss = 0.6569849848747253
Iteration [30975]: Loss = 0.6524391770362854
Iteration [30976]: Loss = 5.169793605804443
Iteration [30977]: Loss = 0.6658011078834534
Iteration [30978]: Loss = 0.6629587411880493
Iteration [30979]: Loss = 0.678066611289978
Iteration [30980]: Loss = 0.6751775145530701
Iteration [30981]: Loss = 0.6708544492721558
Iteration [30982]: Loss = 0.6694043874740601
Iteration [30983]: Loss = 0.6721796989440918
Iteration [30984]: Loss = 0.672487199306488
Iteration [30985]: Loss = 5.1142120361328125
Iteration [30986]: Loss = 0.696609377861023
Iteration [30987]: Loss = 5.117984294891357
Iteration [30988]: Loss = 0.6339682936668396
Iteration [30989]: Loss = 0.6406580209732056
Iteration [30990]: Loss = 0.647776186466217
Iteration [30991]: Loss = 5.276172161102295
Iteration [30992]: Loss = 0.6480982303619385
Iteration [30993]: Loss = 0.6584925651550293
Iteration [30994]: Loss = 0.6864485740661621
Iteration [30995]: Loss = 0.6778221130371094
Iteration [30996]: Loss = 0.6808344125747681
Iteration [30997]: Loss = 0.6563230752944946
Iteration [30998]: Loss = 0.658209502696991
Iteration [30999]: Loss = 0.6534236669540405
Iteration [31000]: Loss = 0.6481835842132568
Iteration [31001]: Loss = 0.6447588205337524
Iteration [31002]: Loss = 0.6508601307868958
Iteration [31003]: Loss = 0.6394270658493042
Iteration [31004]: Loss = 0.6438860297203064
Iteration [31005]: Loss = 0.6444997191429138
Iteration [31006]: Loss = 0.6418916583061218
Iteration [31007]: Loss = 0.6387749314308167
Iteration [31008]: Loss = 0.6421737670898438
Iteration [31009]: Loss = 0.6401224732398987
Iteration [31010]: Loss = 0.6380316615104675
Iteration [31011]: Loss = 0.6327678561210632
Iteration [31012]: Loss = 5.326350688934326
Iteration [31013]: Loss = 0.6290116906166077
Iteration [31014]: Loss = 0.6337888240814209
Iteration [31015]: Loss = 0.6305596828460693
Iteration [31016]: Loss = 5.311326503753662
Iteration [31017]: Loss = 0.6387335658073425
Iteration [31018]: Loss = 0.6575621366500854
Iteration [31019]: Loss = 0.6368448734283447
Iteration [31020]: Loss = 5.15269136428833
Iteration [31021]: Loss = 0.6712696552276611
Iteration [31022]: Loss = 0.6726933717727661
Iteration [31023]: Loss = 0.6871402263641357
Iteration [31024]: Loss = 0.6839806437492371
Iteration [31025]: Loss = 0.6594797372817993
Iteration [31026]: Loss = 0.6584336161613464
Iteration [31027]: Loss = 5.161493301391602
Iteration [31028]: Loss = 0.6574078798294067
Iteration [31029]: Loss = 0.6646996736526489
Iteration [31030]: Loss = 0.649420976638794
Iteration [31031]: Loss = 0.6546787619590759
Iteration [31032]: Loss = 5.179101943969727
Iteration [31033]: Loss = 5.2036967277526855
Iteration [31034]: Loss = 5.185671806335449
Iteration [31035]: Loss = 0.6582255363464355
Iteration [31036]: Loss = 0.6655279397964478
Iteration [31037]: Loss = 0.658070981502533
Iteration [31038]: Loss = 0.6625836491584778
Iteration [31039]: Loss = 0.6674518585205078
Iteration [31040]: Loss = 0.6680814027786255
Iteration [31041]: Loss = 0.6719115376472473
Iteration [31042]: Loss = 0.6720460653305054
Iteration [31043]: Loss = 0.6692990064620972
Iteration [31044]: Loss = 0.6690267324447632
Iteration [31045]: Loss = 0.6714176535606384
Iteration [31046]: Loss = 0.670927107334137
Iteration [31047]: Loss = 0.6724461317062378
Iteration [31048]: Loss = 0.6717987060546875
Iteration [31049]: Loss = 0.6613715887069702
Iteration [31050]: Loss = 0.6593712568283081
Iteration [31051]: Loss = 0.6584466695785522
Iteration [31052]: Loss = 0.6604699492454529
Iteration [31053]: Loss = 5.187757968902588
Iteration [31054]: Loss = 0.6562102437019348
Iteration [31055]: Loss = 0.6537307500839233
Iteration [31056]: Loss = 0.6548333168029785
Iteration [31057]: Loss = 0.6544604897499084
Iteration [31058]: Loss = 0.6539724469184875
Iteration [31059]: Loss = 0.650949239730835
Iteration [31060]: Loss = 0.6559052467346191
Iteration [31061]: Loss = 0.6551304459571838
Iteration [31062]: Loss = 0.6540647149085999
Iteration [31063]: Loss = 0.6531397700309753
Iteration [31064]: Loss = 0.6541458368301392
Iteration [31065]: Loss = 0.6522660255432129
Iteration [31066]: Loss = 0.6519434452056885
Iteration [31067]: Loss = 5.244224548339844
Iteration [31068]: Loss = 0.6486106514930725
Iteration [31069]: Loss = 0.6495336890220642
Iteration [31070]: Loss = 5.228053092956543
Iteration [31071]: Loss = 0.6488248109817505
Iteration [31072]: Loss = 0.6498896479606628
Iteration [31073]: Loss = 0.6501427888870239
Iteration [31074]: Loss = 5.22219181060791
Iteration [31075]: Loss = 0.6516785621643066
Iteration [31076]: Loss = 0.6524267196655273
Iteration [31077]: Loss = 0.6550773978233337
Iteration [31078]: Loss = 0.6553695201873779
Iteration [31079]: Loss = 0.6554664969444275
Iteration [31080]: Loss = 0.6553882360458374
Iteration [31081]: Loss = 0.6551522612571716
Iteration [31082]: Loss = 0.65477454662323
Iteration [31083]: Loss = 0.654269814491272
Iteration [31084]: Loss = 5.20197057723999
Iteration [31085]: Loss = 0.6540449261665344
Iteration [31086]: Loss = 0.6542391180992126
Iteration [31087]: Loss = 0.6542534828186035
Iteration [31088]: Loss = 0.6541060209274292
Iteration [31089]: Loss = 0.653813362121582
Iteration [31090]: Loss = 0.6533900499343872
Iteration [31091]: Loss = 0.6528496742248535
Iteration [31092]: Loss = 0.652204155921936
Iteration [31093]: Loss = 0.6514645218849182
Iteration [31094]: Loss = 0.650640606880188
Iteration [31095]: Loss = 0.6497414708137512
Iteration [31096]: Loss = 5.230601787567139
Iteration [31097]: Loss = 0.6475399136543274
Iteration [31098]: Loss = 0.6474422216415405
Iteration [31099]: Loss = 0.6472009420394897
Iteration [31100]: Loss = 0.6468306183815002
Iteration [31101]: Loss = 0.6463443040847778
Iteration [31102]: Loss = 0.6457541584968567
Iteration [31103]: Loss = 0.6450706720352173
Iteration [31104]: Loss = 0.6443036794662476
Iteration [31105]: Loss = 0.6434621214866638
Iteration [31106]: Loss = 0.6425537467002869
Iteration [31107]: Loss = 5.273439884185791
Iteration [31108]: Loss = 0.6416232585906982
Iteration [31109]: Loss = 0.6415092945098877
Iteration [31110]: Loss = 0.6412594318389893
Iteration [31111]: Loss = 0.6408871412277222
Iteration [31112]: Loss = 5.280545234680176
Iteration [31113]: Loss = 0.6408482789993286
Iteration [31114]: Loss = 0.6411031484603882
Iteration [31115]: Loss = 0.6411886215209961
Iteration [31116]: Loss = 5.276230812072754
Iteration [31117]: Loss = 0.6430217027664185
Iteration [31118]: Loss = 0.6435902714729309
Iteration [31119]: Loss = 0.6439605951309204
Iteration [31120]: Loss = 0.6441521644592285
Iteration [31121]: Loss = 5.257877826690674
Iteration [31122]: Loss = 5.252761363983154
Iteration [31123]: Loss = 0.6466132402420044
Iteration [31124]: Loss = 0.6478939056396484
Iteration [31125]: Loss = 5.229803085327148
Iteration [31126]: Loss = 0.6506096720695496
Iteration [31127]: Loss = 0.6520057320594788
Iteration [31128]: Loss = 0.6531275510787964
Iteration [31129]: Loss = 0.6540018320083618
Iteration [31130]: Loss = 0.6546523571014404
Iteration [31131]: Loss = 0.6551011800765991
Iteration [31132]: Loss = 0.6553682684898376
Iteration [31133]: Loss = 0.6554713845252991
Iteration [31134]: Loss = 0.6554270386695862
Iteration [31135]: Loss = 0.655250072479248
Iteration [31136]: Loss = 5.194377899169922
Iteration [31137]: Loss = 0.6554756760597229
Iteration [31138]: Loss = 0.6558106541633606
Iteration [31139]: Loss = 0.6559772491455078
Iteration [31140]: Loss = 0.6559922099113464
Iteration [31141]: Loss = 0.6558706164360046
Iteration [31142]: Loss = 0.6556261777877808
Iteration [31143]: Loss = 0.6552714705467224
Iteration [31144]: Loss = 0.654817521572113
Iteration [31145]: Loss = 0.654274582862854
Iteration [31146]: Loss = 0.6536517143249512
Iteration [31147]: Loss = 0.6529573202133179
Iteration [31148]: Loss = 0.6521989107131958
Iteration [31149]: Loss = 0.6513830423355103
Iteration [31150]: Loss = 0.6505157351493835
Iteration [31151]: Loss = 0.6496025323867798
Iteration [31152]: Loss = 0.6486485004425049
Iteration [31153]: Loss = 5.237209796905518
Iteration [31154]: Loss = 0.6475539803504944
Iteration [31155]: Loss = 0.6473298668861389
Iteration [31156]: Loss = 0.6469979882240295
Iteration [31157]: Loss = 0.6465691924095154
Iteration [31158]: Loss = 0.6460532546043396
Iteration [31159]: Loss = 0.6454592943191528
Iteration [31160]: Loss = 0.6447952389717102
Iteration [31161]: Loss = 0.6440683603286743
Iteration [31162]: Loss = 0.6432854533195496
Iteration [31163]: Loss = 0.6424521207809448
Iteration [31164]: Loss = 0.6415736675262451
Iteration [31165]: Loss = 0.6407340168952942
Iteration [31166]: Loss = 0.6398651599884033
Iteration [31167]: Loss = 0.6389670372009277
Iteration [31168]: Loss = 0.6380428671836853
Iteration [31169]: Loss = 5.3005781173706055
Iteration [31170]: Loss = 0.6369516849517822
Iteration [31171]: Loss = 0.6367079019546509
Iteration [31172]: Loss = 5.304965972900391
Iteration [31173]: Loss = 0.6367635726928711
Iteration [31174]: Loss = 0.6370015144348145
Iteration [31175]: Loss = 0.6371029615402222
Iteration [31176]: Loss = 0.6370816826820374
Iteration [31177]: Loss = 0.6369496583938599
Iteration [31178]: Loss = 5.302873134613037
Iteration [31179]: Loss = 0.6371886730194092
Iteration [31180]: Loss = 0.6375011205673218
Iteration [31181]: Loss = 0.6376710534095764
Iteration [31182]: Loss = 0.6377127170562744
Iteration [31183]: Loss = 0.6376389265060425
Iteration [31184]: Loss = 5.29835844039917
Iteration [31185]: Loss = 0.6379700899124146
Iteration [31186]: Loss = 5.280376434326172
Iteration [31187]: Loss = 0.6392838358879089
Iteration [31188]: Loss = 9.925395965576172
Iteration [31189]: Loss = 0.6420395374298096
Iteration [31190]: Loss = 5.260551452636719
Iteration [31191]: Loss = 0.6458635330200195
Iteration [31192]: Loss = 0.6476799845695496
Iteration [31193]: Loss = 0.6492142677307129
Iteration [31194]: Loss = 0.650493323802948
Iteration [31195]: Loss = 0.6515416502952576
Iteration [31196]: Loss = 0.6523816585540771
Iteration [31197]: Loss = 0.6530336141586304
Iteration [31198]: Loss = 5.202759265899658
Iteration [31199]: Loss = 0.6545534729957581
Iteration [31200]: Loss = 5.19187593460083
Iteration [31201]: Loss = 0.6567267179489136
Iteration [31202]: Loss = 0.6578330993652344
Iteration [31203]: Loss = 5.172526836395264
Iteration [31204]: Loss = 9.669051170349121
Iteration [31205]: Loss = 0.6624820232391357
Iteration [31206]: Loss = 0.6683416962623596
Iteration [31207]: Loss = 0.6700766086578369
Iteration [31208]: Loss = 5.099844455718994
Iteration [31209]: Loss = 0.6734635829925537
Iteration [31210]: Loss = 0.675095796585083
Iteration [31211]: Loss = 0.676452100276947
Iteration [31212]: Loss = 0.6775280833244324
Iteration [31213]: Loss = 0.6783717274665833
Iteration [31214]: Loss = 0.6790198087692261
Iteration [31215]: Loss = 0.6794912219047546
Iteration [31216]: Loss = 0.6798034310340881
Iteration [31217]: Loss = 0.6799722909927368
Iteration [31218]: Loss = 0.680011510848999
Iteration [31219]: Loss = 0.679934561252594
Iteration [31220]: Loss = 0.6797527074813843
Iteration [31221]: Loss = 0.6794766187667847
Iteration [31222]: Loss = 0.6791158318519592
Iteration [31223]: Loss = 0.6786788105964661
Iteration [31224]: Loss = 9.447759628295898
Iteration [31225]: Loss = 0.6790299415588379
Iteration [31226]: Loss = 0.6796940565109253
Iteration [31227]: Loss = 0.6801844835281372
Iteration [31228]: Loss = 0.6805181503295898
Iteration [31229]: Loss = 0.6807105541229248
Iteration [31230]: Loss = 0.6807757616043091
Iteration [31231]: Loss = 0.680726170539856
Iteration [31232]: Loss = 0.6805734634399414
Iteration [31233]: Loss = 0.6803279519081116
Iteration [31234]: Loss = 0.6799989938735962
Iteration [31235]: Loss = 0.6795949339866638
Iteration [31236]: Loss = 0.6791234016418457
Iteration [31237]: Loss = 0.6785913705825806
Iteration [31238]: Loss = 5.063893795013428
Iteration [31239]: Loss = 5.063538074493408
Iteration [31240]: Loss = 0.6787109971046448
Iteration [31241]: Loss = 0.6791824698448181
Iteration [31242]: Loss = 0.6795008182525635
Iteration [31243]: Loss = 0.6796811819076538
Iteration [31244]: Loss = 5.054375648498535
Iteration [31245]: Loss = 0.6803663969039917
Iteration [31246]: Loss = 0.6808273792266846
Iteration [31247]: Loss = 5.046713829040527
Iteration [31248]: Loss = 0.6819882988929749
Iteration [31249]: Loss = 0.682650089263916
Iteration [31250]: Loss = 0.6831405758857727
Iteration [31251]: Loss = 0.6834765672683716
Iteration [31252]: Loss = 0.6836732625961304
Iteration [31253]: Loss = 0.6837446689605713
Iteration [31254]: Loss = 0.6837029457092285
Iteration [31255]: Loss = 0.6835594177246094
Iteration [31256]: Loss = 0.6833242774009705
Iteration [31257]: Loss = 0.6830068826675415
Iteration [31258]: Loss = 0.6826155185699463
Iteration [31259]: Loss = 0.682157576084137
Iteration [31260]: Loss = 5.0439653396606445
Iteration [31261]: Loss = 0.6817495822906494
Iteration [31262]: Loss = 0.6817435622215271
Iteration [31263]: Loss = 0.6816332340240479
Iteration [31264]: Loss = 5.045115947723389
Iteration [31265]: Loss = 0.6818152070045471
Iteration [31266]: Loss = 0.6820586919784546
Iteration [31267]: Loss = 0.6821736693382263
Iteration [31268]: Loss = 0.6821727752685547
Iteration [31269]: Loss = 5.041630744934082
Iteration [31270]: Loss = 0.6825388669967651
Iteration [31271]: Loss = 5.037317752838135
Iteration [31272]: Loss = 0.6837074756622314
Iteration [31273]: Loss = 0.6843681335449219
Iteration [31274]: Loss = 5.026454925537109
Iteration [31275]: Loss = 0.6858572959899902
Iteration [31276]: Loss = 0.6866530179977417
Iteration [31277]: Loss = 0.68726646900177
Iteration [31278]: Loss = 0.6877154111862183
Iteration [31279]: Loss = 5.009419918060303
Iteration [31280]: Loss = 0.6887198090553284
Iteration [31281]: Loss = 0.6892315149307251
Iteration [31282]: Loss = 0.6896097660064697
Iteration [31283]: Loss = 0.6898673176765442
Iteration [31284]: Loss = 0.6900162100791931
Iteration [31285]: Loss = 0.6900672912597656
Iteration [31286]: Loss = 0.6900302171707153
Iteration [31287]: Loss = 0.6899135708808899
Iteration [31288]: Loss = 5.000246524810791
Iteration [31289]: Loss = 0.6899998188018799
Iteration [31290]: Loss = 0.6901641488075256
Iteration [31291]: Loss = 0.6902292370796204
Iteration [31292]: Loss = 0.6902050375938416
Iteration [31293]: Loss = 0.6901006102561951
Iteration [31294]: Loss = 0.6899236440658569
Iteration [31295]: Loss = 0.6896816492080688
Iteration [31296]: Loss = 0.6893810629844666
Iteration [31297]: Loss = 0.6890277862548828
Iteration [31298]: Loss = 0.6886271238327026
Iteration [31299]: Loss = 0.6881840229034424
Iteration [31300]: Loss = 0.6877026557922363
Iteration [31301]: Loss = 0.6871870756149292
Iteration [31302]: Loss = 0.686640739440918
Iteration [31303]: Loss = 5.01992654800415
Iteration [31304]: Loss = 0.6859952807426453
Iteration [31305]: Loss = 0.685849130153656
Iteration [31306]: Loss = 0.6856357455253601
Iteration [31307]: Loss = 0.6853618025779724
Iteration [31308]: Loss = 0.6850336194038391
Iteration [31309]: Loss = 0.6846562027931213
Iteration [31310]: Loss = 0.684235155582428
Iteration [31311]: Loss = 5.032342433929443
Iteration [31312]: Loss = 5.032186508178711
Iteration [31313]: Loss = 0.6842672824859619
Iteration [31314]: Loss = 9.37106990814209
Iteration [31315]: Loss = 5.021181106567383
Iteration [31316]: Loss = 0.6873627305030823
Iteration [31317]: Loss = 0.6886619329452515
Iteration [31318]: Loss = 0.6897538900375366
Iteration [31319]: Loss = 0.690658450126648
Iteration [31320]: Loss = 4.991327285766602
Iteration [31321]: Loss = 0.6924769878387451
Iteration [31322]: Loss = 0.6933732032775879
Iteration [31323]: Loss = 0.6941013336181641
Iteration [31324]: Loss = 0.6946772336959839
Iteration [31325]: Loss = 4.971560001373291
Iteration [31326]: Loss = 0.6959309577941895
Iteration [31327]: Loss = 0.6965852379798889
Iteration [31328]: Loss = 0.697094738483429
Iteration [31329]: Loss = 0.6974734663963318
Iteration [31330]: Loss = 0.6969847083091736
Iteration [31331]: Loss = 0.6971388459205627
Iteration [31332]: Loss = 0.6971975564956665
Iteration [31333]: Loss = 0.6971701383590698
Iteration [31334]: Loss = 0.6970651745796204
Iteration [31335]: Loss = 0.6968905329704285
Iteration [31336]: Loss = 0.6966529488563538
Iteration [31337]: Loss = 0.6963590383529663
Iteration [31338]: Loss = 0.6960144639015198
Iteration [31339]: Loss = 0.6956241726875305
Iteration [31340]: Loss = 0.6951927542686462
Iteration [31341]: Loss = 4.973631381988525
Iteration [31342]: Loss = 0.6947267651557922
Iteration [31343]: Loss = 4.974031448364258
Iteration [31344]: Loss = 4.972179889678955
Iteration [31345]: Loss = 0.695730447769165
Iteration [31346]: Loss = 0.69631028175354
Iteration [31347]: Loss = 4.962917804718018
Iteration [31348]: Loss = 0.6975667476654053
Iteration [31349]: Loss = 0.6982204914093018
Iteration [31350]: Loss = 0.6987301707267761
Iteration [31351]: Loss = 0.6991097927093506
Iteration [31352]: Loss = 0.6993721723556519
Iteration [31353]: Loss = 0.6995289921760559
Iteration [31354]: Loss = 0.6995905637741089
Iteration [31355]: Loss = 0.6995663642883301
Iteration [31356]: Loss = 0.6994650363922119
Iteration [31357]: Loss = 0.6992940902709961
Iteration [31358]: Loss = 4.9507975578308105
Iteration [31359]: Loss = 0.6992666125297546
Iteration [31360]: Loss = 4.949162006378174
Iteration [31361]: Loss = 0.6998817920684814
Iteration [31362]: Loss = 0.700261116027832
Iteration [31363]: Loss = 0.700523316860199
Iteration [31364]: Loss = 0.7006803154945374
Iteration [31365]: Loss = 4.9420037269592285
Iteration [31366]: Loss = 0.7012102603912354
Iteration [31367]: Loss = 0.7015525102615356
Iteration [31368]: Loss = 4.936586856842041
Iteration [31369]: Loss = 4.933381080627441
Iteration [31370]: Loss = 0.7033594846725464
Iteration [31371]: Loss = 0.7041472792625427
Iteration [31372]: Loss = 0.7047780752182007
Iteration [31373]: Loss = 0.7052671909332275
Iteration [31374]: Loss = 0.7056284546852112
Iteration [31375]: Loss = 4.91538143157959
Iteration [31376]: Loss = 0.7065027952194214
Iteration [31377]: Loss = 4.909639358520508
Iteration [31378]: Loss = 0.7078323364257812
Iteration [31379]: Loss = 0.708512544631958
Iteration [31380]: Loss = 4.8990864753723145
Iteration [31381]: Loss = 4.894570827484131
Iteration [31382]: Loss = 4.888471603393555
Iteration [31383]: Loss = 0.7126002311706543
Iteration [31384]: Loss = 0.7138509154319763
Iteration [31385]: Loss = 0.7148990631103516
Iteration [31386]: Loss = 0.7157642245292664
Iteration [31387]: Loss = 0.7164639830589294
Iteration [31388]: Loss = 0.717014729976654
Iteration [31389]: Loss = 4.856586933135986
Iteration [31390]: Loss = 0.7182040810585022
Iteration [31391]: Loss = 0.7188209295272827
Iteration [31392]: Loss = 0.7192966938018799
Iteration [31393]: Loss = 4.845500946044922
Iteration [31394]: Loss = 0.7203563451766968
Iteration [31395]: Loss = 0.7209173440933228
Iteration [31396]: Loss = 0.7213423252105713
Iteration [31397]: Loss = 0.7216449975967407
Iteration [31398]: Loss = 0.7218372225761414
Iteration [31399]: Loss = 0.7219300866127014
Iteration [31400]: Loss = 0.7219333052635193
Iteration [31401]: Loss = 4.834488391876221
Iteration [31402]: Loss = 0.7221842408180237
Iteration [31403]: Loss = 0.7223997712135315
Iteration [31404]: Loss = 0.7225136756896973
Iteration [31405]: Loss = 0.722536027431488
Iteration [31406]: Loss = 0.7224758863449097
Iteration [31407]: Loss = 0.7223411798477173
Iteration [31408]: Loss = 0.722139835357666
Iteration [31409]: Loss = 0.7218783497810364
Iteration [31410]: Loss = 0.7215626239776611
Iteration [31411]: Loss = 0.7211982607841492
Iteration [31412]: Loss = 0.7207900881767273
Iteration [31413]: Loss = 0.7203426361083984
Iteration [31414]: Loss = 0.7198600172996521
Iteration [31415]: Loss = 0.7193456888198853
Iteration [31416]: Loss = 0.7188027501106262
Iteration [31417]: Loss = 0.7182343006134033
Iteration [31418]: Loss = 0.7176430225372314
Iteration [31419]: Loss = 0.7170311808586121
Iteration [31420]: Loss = 0.7164010405540466
Iteration [31421]: Loss = 0.7157545685768127
Iteration [31422]: Loss = 0.7150934338569641
Iteration [31423]: Loss = 0.7144190669059753
Iteration [31424]: Loss = 0.7137330174446106
Iteration [31425]: Loss = 0.7130365967750549
Iteration [31426]: Loss = 0.7123307585716248
Iteration [31427]: Loss = 0.7116168737411499
Iteration [31428]: Loss = 4.889641761779785
Iteration [31429]: Loss = 0.7106497883796692
Iteration [31430]: Loss = 0.7103499174118042
Iteration [31431]: Loss = 4.89420223236084
Iteration [31432]: Loss = 0.7100887298583984
Iteration [31433]: Loss = 0.710088849067688
Iteration [31434]: Loss = 0.7100107669830322
Iteration [31435]: Loss = 0.7098622918128967
Iteration [31436]: Loss = 0.7096502780914307
Iteration [31437]: Loss = 0.7093811631202698
Iteration [31438]: Loss = 0.7090606093406677
Iteration [31439]: Loss = 0.7086940407752991
Iteration [31440]: Loss = 0.7082859873771667
Iteration [31441]: Loss = 0.7078404426574707
Iteration [31442]: Loss = 0.70736163854599
Iteration [31443]: Loss = 4.920498847961426
Iteration [31444]: Loss = 0.7048285007476807
Iteration [31445]: Loss = 0.7047021389007568
Iteration [31446]: Loss = 0.7045108675956726
Iteration [31447]: Loss = 0.704261302947998
Iteration [31448]: Loss = 0.7039594054222107
Iteration [31449]: Loss = 4.92708683013916
Iteration [31450]: Loss = 0.703696608543396
Iteration [31451]: Loss = 0.7036972045898438
Iteration [31452]: Loss = 0.7036207318305969
Iteration [31453]: Loss = 0.7034748792648315
Iteration [31454]: Loss = 0.7032662630081177
Iteration [31455]: Loss = 0.7030016183853149
Iteration [31456]: Loss = 0.7026863694190979
Iteration [31457]: Loss = 0.7023256421089172
Iteration [31458]: Loss = 0.7019240260124207
Iteration [31459]: Loss = 0.7014857530593872
Iteration [31460]: Loss = 0.7010142803192139
Iteration [31461]: Loss = 0.7005133628845215
Iteration [31462]: Loss = 0.699985682964325
Iteration [31463]: Loss = 0.6994343400001526
Iteration [31464]: Loss = 0.6988615393638611
Iteration [31465]: Loss = 0.6982696056365967
Iteration [31466]: Loss = 0.697660505771637
Iteration [31467]: Loss = 0.69703608751297
Iteration [31468]: Loss = 0.6963978409767151
Iteration [31469]: Loss = 0.6957473158836365
Iteration [31470]: Loss = 0.6950860023498535
Iteration [31471]: Loss = 4.975270748138428
Iteration [31472]: Loss = 0.6942147016525269
Iteration [31473]: Loss = 0.6939586400985718
Iteration [31474]: Loss = 4.979311943054199
Iteration [31475]: Loss = 0.6937780380249023
Iteration [31476]: Loss = 0.6938158273696899
Iteration [31477]: Loss = 0.6937741637229919
Iteration [31478]: Loss = 9.264869689941406
Iteration [31479]: Loss = 0.6944209337234497
Iteration [31480]: Loss = 0.6950310468673706
Iteration [31481]: Loss = 0.6955063939094543
Iteration [31482]: Loss = 0.6958603858947754
Iteration [31483]: Loss = 4.966339111328125
Iteration [31484]: Loss = 0.6967151761054993
Iteration [31485]: Loss = 0.6971909403800964
Iteration [31486]: Loss = 0.6975449323654175
Iteration [31487]: Loss = 4.957468032836914
Iteration [31488]: Loss = 0.6983988881111145
Iteration [31489]: Loss = 0.6988736987113953
Iteration [31490]: Loss = 0.6992266774177551
Iteration [31491]: Loss = 0.6994701623916626
Iteration [31492]: Loss = 4.9478960037231445
Iteration [31493]: Loss = 0.7001338601112366
Iteration [31494]: Loss = 0.7005267143249512
Iteration [31495]: Loss = 0.700214147567749
Iteration [31496]: Loss = 0.7003905177116394
Iteration [31497]: Loss = 0.7004747986793518
Iteration [31498]: Loss = 0.7004758715629578
Iteration [31499]: Loss = 0.7004022598266602
Iteration [31500]: Loss = 4.944515705108643
Iteration [31501]: Loss = 0.7005236744880676
Iteration [31502]: Loss = 4.942300319671631
Iteration [31503]: Loss = 0.7012180685997009
Iteration [31504]: Loss = 0.7016236186027527
Iteration [31505]: Loss = 4.935895919799805
Iteration [31506]: Loss = 0.7025614380836487
Iteration [31507]: Loss = 0.7030702233314514
Iteration [31508]: Loss = 0.7034540176391602
Iteration [31509]: Loss = 4.926492214202881
Iteration [31510]: Loss = 0.7043535709381104
Iteration [31511]: Loss = 0.7048454284667969
Iteration [31512]: Loss = 0.7052136659622192
Iteration [31513]: Loss = 0.705470860004425
Iteration [31514]: Loss = 0.7056277394294739
Iteration [31515]: Loss = 0.7056941390037537
Iteration [31516]: Loss = 0.705679178237915
Iteration [31517]: Loss = 0.7055908441543579
Iteration [31518]: Loss = 0.7054365873336792
Iteration [31519]: Loss = 0.7052228450775146
Iteration [31520]: Loss = 0.7049557566642761
Iteration [31521]: Loss = 0.7046403884887695
Iteration [31522]: Loss = 0.7042818069458008
Iteration [31523]: Loss = 0.7038846015930176
Iteration [31524]: Loss = 0.7034522294998169
Iteration [31525]: Loss = 0.7029885053634644
Iteration [31526]: Loss = 0.7024967074394226
Iteration [31527]: Loss = 0.701979398727417
Iteration [31528]: Loss = 0.7014395594596863
Iteration [31529]: Loss = 0.7008794546127319
Iteration [31530]: Loss = 0.7003010511398315
Iteration [31531]: Loss = 0.6997063159942627
Iteration [31532]: Loss = 0.6990969181060791
Iteration [31533]: Loss = 4.953869819641113
Iteration [31534]: Loss = 0.6983039379119873
Iteration [31535]: Loss = 0.6980764269828796
Iteration [31536]: Loss = 0.697797954082489
Iteration [31537]: Loss = 4.959127902984619
Iteration [31538]: Loss = 4.958625793457031
Iteration [31539]: Loss = 0.6980401873588562
Iteration [31540]: Loss = 4.954308986663818
Iteration [31541]: Loss = 0.6990900039672852
Iteration [31542]: Loss = 0.6996464729309082
Iteration [31543]: Loss = 0.7000741958618164
Iteration [31544]: Loss = 0.7003859281539917
Iteration [31545]: Loss = 0.700593113899231
Iteration [31546]: Loss = 0.7007060050964355
Iteration [31547]: Loss = 0.70073401927948
Iteration [31548]: Loss = 0.700685441493988
Iteration [31549]: Loss = 0.7005680203437805
Iteration [31550]: Loss = 0.7003886103630066
Iteration [31551]: Loss = 0.7001534104347229
Iteration [31552]: Loss = 4.946571350097656
Iteration [31553]: Loss = 0.6999959349632263
Iteration [31554]: Loss = 0.7000376582145691
Iteration [31555]: Loss = 0.7000017762184143
Iteration [31556]: Loss = 0.699895977973938
Iteration [31557]: Loss = 4.94730806350708
Iteration [31558]: Loss = 0.6999590396881104
Iteration [31559]: Loss = 0.7000945806503296
Iteration [31560]: Loss = 0.7001432180404663
Iteration [31561]: Loss = 0.7001135349273682
Iteration [31562]: Loss = 9.191608428955078
Iteration [31563]: Loss = 0.700751543045044
Iteration [31564]: Loss = 0.7013440132141113
Iteration [31565]: Loss = 0.7018055319786072
Iteration [31566]: Loss = 0.7021486759185791
Iteration [31567]: Loss = 0.7023850679397583
Iteration [31568]: Loss = 0.7025254964828491
Iteration [31569]: Loss = 0.7025790214538574
Iteration [31570]: Loss = 4.932566165924072
Iteration [31571]: Loss = 0.702909529209137
Iteration [31572]: Loss = 0.7031564712524414
Iteration [31573]: Loss = 0.7033061385154724
Iteration [31574]: Loss = 0.7033683657646179
Iteration [31575]: Loss = 0.7033516764640808
Iteration [31576]: Loss = 4.9288835525512695
Iteration [31577]: Loss = 0.7035612463951111
Iteration [31578]: Loss = 0.7037562727928162
Iteration [31579]: Loss = 0.7038595080375671
Iteration [31580]: Loss = 0.7038797736167908
Iteration [31581]: Loss = 0.7038252949714661
Iteration [31582]: Loss = 0.7037036418914795
Iteration [31583]: Loss = 0.7035213708877563
Iteration [31584]: Loss = 4.928775787353516
Iteration [31585]: Loss = 0.7034481167793274
Iteration [31586]: Loss = 0.703522801399231
Iteration [31587]: Loss = 0.7035174369812012
Iteration [31588]: Loss = 4.927968978881836
Iteration [31589]: Loss = 0.7037457823753357
Iteration [31590]: Loss = 0.7039485573768616
Iteration [31591]: Loss = 0.704058825969696
Iteration [31592]: Loss = 0.7040855884552002
Iteration [31593]: Loss = 0.7040372490882874
Iteration [31594]: Loss = 0.7039210796356201
Iteration [31595]: Loss = 0.703744113445282
Iteration [31596]: Loss = 0.7035121917724609
Iteration [31597]: Loss = 0.7032309770584106
Iteration [31598]: Loss = 0.7029052972793579
Iteration [31599]: Loss = 0.7025398015975952
Iteration [31600]: Loss = 0.7021383047103882
Iteration [31601]: Loss = 4.93698787689209
Iteration [31602]: Loss = 0.7016913294792175
Iteration [31603]: Loss = 0.7016070485115051
Iteration [31604]: Loss = 0.7014591693878174
Iteration [31605]: Loss = 0.7012537717819214
Iteration [31606]: Loss = 0.7009967565536499
Iteration [31607]: Loss = 4.942260265350342
Iteration [31608]: Loss = 0.7007962465286255
Iteration [31609]: Loss = 0.7008169889450073
Iteration [31610]: Loss = 0.7007637619972229
Iteration [31611]: Loss = 0.70064377784729
Iteration [31612]: Loss = 0.7004640102386475
Iteration [31613]: Loss = 0.7002300024032593
Iteration [31614]: Loss = 0.6999475359916687
Iteration [31615]: Loss = 0.6996213793754578
Iteration [31616]: Loss = 4.949775218963623
Iteration [31617]: Loss = 0.6993032693862915
Iteration [31618]: Loss = 0.6992741823196411
Iteration [31619]: Loss = 0.6991764307022095
Iteration [31620]: Loss = 0.6990165710449219
Iteration [31621]: Loss = 0.6988011598587036
Iteration [31622]: Loss = 0.6985354423522949
Iteration [31623]: Loss = 0.698224663734436
Iteration [31624]: Loss = 0.6978732943534851
Iteration [31625]: Loss = 4.9590654373168945
Iteration [31626]: Loss = 0.6975127458572388
Iteration [31627]: Loss = 0.6974658966064453
Iteration [31628]: Loss = 0.697352409362793
Iteration [31629]: Loss = 0.697178840637207
Iteration [31630]: Loss = 0.696951150894165
Iteration [31631]: Loss = 0.6966749429702759
Iteration [31632]: Loss = 0.696354866027832
Iteration [31633]: Loss = 0.6959954500198364
Iteration [31634]: Loss = 0.6956006288528442
Iteration [31635]: Loss = 0.695173978805542
Iteration [31636]: Loss = 0.6947190165519714
Iteration [31637]: Loss = 0.6942381858825684
Iteration [31638]: Loss = 0.6937344074249268
Iteration [31639]: Loss = 4.981661319732666
Iteration [31640]: Loss = 9.271208763122559
Iteration [31641]: Loss = 0.6938420534133911
Iteration [31642]: Loss = 0.6944266557693481
Iteration [31643]: Loss = 0.694883406162262
Iteration [31644]: Loss = 4.97098445892334
Iteration [31645]: Loss = 0.6959004402160645
Iteration [31646]: Loss = 0.6964392066001892
Iteration [31647]: Loss = 0.6968543529510498
Iteration [31648]: Loss = 0.6971582770347595
Iteration [31649]: Loss = 4.959715843200684
Iteration [31650]: Loss = 0.6979126930236816
Iteration [31651]: Loss = 0.6983388662338257
Iteration [31652]: Loss = 0.6986525058746338
Iteration [31653]: Loss = 0.6988646984100342
Iteration [31654]: Loss = 4.951191425323486
Iteration [31655]: Loss = 4.948698997497559
Iteration [31656]: Loss = 0.7002553343772888
Iteration [31657]: Loss = 0.7009004950523376
Iteration [31658]: Loss = 0.7014114260673523
Iteration [31659]: Loss = 0.7018013000488281
Iteration [31660]: Loss = 0.7020820379257202
Iteration [31661]: Loss = 0.7022642493247986
Iteration [31662]: Loss = 0.702357828617096
Iteration [31663]: Loss = 4.933518409729004
Iteration [31664]: Loss = 0.7027496695518494
Iteration [31665]: Loss = 0.703019917011261
Iteration [31666]: Loss = 0.7031927108764648
Iteration [31667]: Loss = 0.7032777070999146
Iteration [31668]: Loss = 0.7032836079597473
Iteration [31669]: Loss = 0.7032181024551392
Iteration [31670]: Loss = 0.703088641166687
Iteration [31671]: Loss = 0.7029013633728027
Iteration [31672]: Loss = 0.7026620507240295
Iteration [31673]: Loss = 0.7023760080337524
Iteration [31674]: Loss = 0.7020479440689087
Iteration [31675]: Loss = 0.701681911945343
Iteration [31676]: Loss = 0.7012820243835449
Iteration [31677]: Loss = 0.7008515000343323
Iteration [31678]: Loss = 0.7003936171531677
Iteration [31679]: Loss = 0.6999110579490662
Iteration [31680]: Loss = 0.6994063854217529
Iteration [31681]: Loss = 0.6988818049430847
Iteration [31682]: Loss = 0.698339581489563
Iteration [31683]: Loss = 0.6977812051773071
Iteration [31684]: Loss = 0.6972086429595947
Iteration [31685]: Loss = 4.963603496551514
Iteration [31686]: Loss = 0.6964665651321411
Iteration [31687]: Loss = 0.696255624294281
Iteration [31688]: Loss = 0.6959958076477051
Iteration [31689]: Loss = 0.6956920623779297
Iteration [31690]: Loss = 0.6953489184379578
Iteration [31691]: Loss = 0.6949702501296997
Iteration [31692]: Loss = 0.694559633731842
Iteration [31693]: Loss = 0.6941204071044922
Iteration [31694]: Loss = 0.6936553716659546
Iteration [31695]: Loss = 0.6931673288345337
Iteration [31696]: Loss = 0.692658543586731
Iteration [31697]: Loss = 0.6921311616897583
Iteration [31698]: Loss = 0.6915869116783142
Iteration [31699]: Loss = 0.6910279989242554
Iteration [31700]: Loss = 0.6904553771018982
Iteration [31701]: Loss = 0.6898710131645203
Iteration [31702]: Loss = 0.6892759203910828
Iteration [31703]: Loss = 0.6886711120605469
Iteration [31704]: Loss = 0.6880579590797424
Iteration [31705]: Loss = 0.6874371767044067
Iteration [31706]: Loss = 0.6868095397949219
Iteration [31707]: Loss = 0.6861759424209595
Iteration [31708]: Loss = 0.6855369806289673
Iteration [31709]: Loss = 0.6848931312561035
Iteration [31710]: Loss = 0.6842452883720398
Iteration [31711]: Loss = 0.6835935711860657
Iteration [31712]: Loss = 0.6829386949539185
Iteration [31713]: Loss = 0.682280957698822
Iteration [31714]: Loss = 0.6816205978393555
Iteration [31715]: Loss = 0.6809582710266113
Iteration [31716]: Loss = 0.6802939176559448
Iteration [31717]: Loss = 0.6796280741691589
Iteration [31718]: Loss = 0.6789606809616089
Iteration [31719]: Loss = 5.062312126159668
Iteration [31720]: Loss = 0.6780660152435303
Iteration [31721]: Loss = 0.677794337272644
Iteration [31722]: Loss = 5.066773414611816
Iteration [31723]: Loss = 5.0662641525268555
Iteration [31724]: Loss = 0.6780286431312561
Iteration [31725]: Loss = 0.6783702969551086
Iteration [31726]: Loss = 0.6786103248596191
Iteration [31727]: Loss = 0.6787590980529785
Iteration [31728]: Loss = 0.678825318813324
Iteration [31729]: Loss = 0.6788173317909241
Iteration [31730]: Loss = 0.6787424683570862
Iteration [31731]: Loss = 5.060577869415283
Iteration [31732]: Loss = 0.6788570880889893
Iteration [31733]: Loss = 0.6790145039558411
Iteration [31734]: Loss = 0.6790886521339417
Iteration [31735]: Loss = 0.67908775806427
Iteration [31736]: Loss = 0.6790193915367126
Iteration [31737]: Loss = 5.059023857116699
Iteration [31738]: Loss = 0.6791447401046753
Iteration [31739]: Loss = 0.6793064475059509
Iteration [31740]: Loss = 0.6793845891952515
Iteration [31741]: Loss = 0.6793874502182007
Iteration [31742]: Loss = 0.6793222427368164
Iteration [31743]: Loss = 0.6791960597038269
Iteration [31744]: Loss = 5.058339595794678
Iteration [31745]: Loss = 0.6792223453521729
Iteration [31746]: Loss = 0.6793419122695923
Iteration [31747]: Loss = 0.6793819069862366
Iteration [31748]: Loss = 0.6793504953384399
Iteration [31749]: Loss = 0.6792548298835754
Iteration [31750]: Loss = 5.05786657333374
Iteration [31751]: Loss = 0.6793326139450073
Iteration [31752]: Loss = 0.679473876953125
Iteration [31753]: Loss = 0.679533839225769
Iteration [31754]: Loss = 0.6795200705528259
Iteration [31755]: Loss = 5.056003093719482
Iteration [31756]: Loss = 0.67973792552948
Iteration [31757]: Loss = 5.053271293640137
Iteration [31758]: Loss = 0.6804865002632141
Iteration [31759]: Loss = 0.6809129118919373
Iteration [31760]: Loss = 0.6812296509742737
Iteration [31761]: Loss = 0.6814475059509277
Iteration [31762]: Loss = 5.044312477111816
Iteration [31763]: Loss = 0.6820590496063232
Iteration [31764]: Loss = 0.6824265718460083
Iteration [31765]: Loss = 0.6826902627944946
Iteration [31766]: Loss = 0.6828601360321045
Iteration [31767]: Loss = 0.6829456090927124
Iteration [31768]: Loss = 0.6829548478126526
Iteration [31769]: Loss = 5.037120342254639
Iteration [31770]: Loss = 5.035412788391113
Iteration [31771]: Loss = 0.6838567852973938
Iteration [31772]: Loss = 0.68437260389328
Iteration [31773]: Loss = 0.6847698092460632
Iteration [31774]: Loss = 0.6850600838661194
Iteration [31775]: Loss = 0.6852538585662842
Iteration [31776]: Loss = 0.6853606104850769
Iteration [31777]: Loss = 0.6853891611099243
Iteration [31778]: Loss = 0.6853471398353577
Iteration [31779]: Loss = 5.024388313293457
Iteration [31780]: Loss = 0.6855122447013855
Iteration [31781]: Loss = 0.6856884360313416
Iteration [31782]: Loss = 0.6857795715332031
Iteration [31783]: Loss = 5.021399974822998
Iteration [31784]: Loss = 0.6861715912818909
Iteration [31785]: Loss = 0.6864440441131592
Iteration [31786]: Loss = 0.686621904373169
Iteration [31787]: Loss = 0.6867143511772156
Iteration [31788]: Loss = 0.6867300271987915
Iteration [31789]: Loss = 0.6866762638092041
Iteration [31790]: Loss = 0.6865600943565369
Iteration [31791]: Loss = 0.686387836933136
Iteration [31792]: Loss = 0.6861647963523865
Iteration [31793]: Loss = 0.6858965754508972
Iteration [31794]: Loss = 0.6855873465538025
Iteration [31795]: Loss = 0.685241162776947
Iteration [31796]: Loss = 0.6848620176315308
Iteration [31797]: Loss = 0.6844531297683716
Iteration [31798]: Loss = 0.6840174794197083
Iteration [31799]: Loss = 0.6835579872131348
Iteration [31800]: Loss = 0.6830768585205078
Iteration [31801]: Loss = 0.6825764179229736
Iteration [31802]: Loss = 5.041680812835693
Iteration [31803]: Loss = 0.6819606423377991
Iteration [31804]: Loss = 0.6818052530288696
Iteration [31805]: Loss = 0.6815980076789856
Iteration [31806]: Loss = 0.6813443899154663
Iteration [31807]: Loss = 0.6810489296913147
Iteration [31808]: Loss = 0.6807159185409546
Iteration [31809]: Loss = 5.051023006439209
Iteration [31810]: Loss = 5.0508198738098145
Iteration [31811]: Loss = 0.6807847023010254
Iteration [31812]: Loss = 0.6810769438743591
Iteration [31813]: Loss = 0.6812732219696045
Iteration [31814]: Loss = 0.6813831329345703
Iteration [31815]: Loss = 0.6814150214195251
Iteration [31816]: Loss = 0.6813768744468689
Iteration [31817]: Loss = 0.6812755465507507
Iteration [31818]: Loss = 0.6811172366142273
Iteration [31819]: Loss = 0.6809078454971313
Iteration [31820]: Loss = 0.6806523203849792
Iteration [31821]: Loss = 0.6803553104400635
Iteration [31822]: Loss = 0.6800210475921631
Iteration [31823]: Loss = 0.6796532273292542
Iteration [31824]: Loss = 0.679255485534668
Iteration [31825]: Loss = 0.6788303852081299
Iteration [31826]: Loss = 0.6783811450004578
Iteration [31827]: Loss = 0.6779100298881531
Iteration [31828]: Loss = 0.6774193048477173
Iteration [31829]: Loss = 0.676910936832428
Iteration [31830]: Loss = 0.6763869524002075
Iteration [31831]: Loss = 0.6758488416671753
Iteration [31832]: Loss = 0.6752978563308716
Iteration [31833]: Loss = 0.6747357845306396
Iteration [31834]: Loss = 9.49612045288086
Iteration [31835]: Loss = 0.6744481921195984
Iteration [31836]: Loss = 0.6746392846107483
Iteration [31837]: Loss = 0.6747459173202515
Iteration [31838]: Loss = 0.6747763156890869
Iteration [31839]: Loss = 0.674738347530365
Iteration [31840]: Loss = 0.674638569355011
Iteration [31841]: Loss = 0.6744832992553711
Iteration [31842]: Loss = 5.084506988525391
Iteration [31843]: Loss = 0.6745072603225708
Iteration [31844]: Loss = 5.093687534332275
Iteration [31845]: Loss = 0.6772899031639099
Iteration [31846]: Loss = 0.6797620058059692
Iteration [31847]: Loss = 0.6687200665473938
Iteration [31848]: Loss = 0.6668519973754883
Iteration [31849]: Loss = 0.6744194030761719
Iteration [31850]: Loss = 0.6766877174377441
Iteration [31851]: Loss = 0.6784694194793701
Iteration [31852]: Loss = 0.6765254735946655
Iteration [31853]: Loss = 0.6784694790840149
Iteration [31854]: Loss = 0.674567699432373
Iteration [31855]: Loss = 0.6697359085083008
Iteration [31856]: Loss = 0.6662213802337646
Iteration [31857]: Loss = 5.132217884063721
Iteration [31858]: Loss = 0.6659142971038818
Iteration [31859]: Loss = 0.6637946367263794
Iteration [31860]: Loss = 0.6751858592033386
Iteration [31861]: Loss = 0.6717401146888733
Iteration [31862]: Loss = 0.6734877824783325
Iteration [31863]: Loss = 0.6729635000228882
Iteration [31864]: Loss = 0.6725977659225464
Iteration [31865]: Loss = 0.6549828052520752
Iteration [31866]: Loss = 5.149496078491211
Iteration [31867]: Loss = 0.6611824631690979
Iteration [31868]: Loss = 0.6617835760116577
Iteration [31869]: Loss = 5.155411243438721
Iteration [31870]: Loss = 5.168307304382324
Iteration [31871]: Loss = 0.6645803451538086
Iteration [31872]: Loss = 0.6695968508720398
Iteration [31873]: Loss = 0.6700328588485718
Iteration [31874]: Loss = 5.072037220001221
Iteration [31875]: Loss = 0.6817371249198914
Iteration [31876]: Loss = 0.6827664971351624
Iteration [31877]: Loss = 0.6831526160240173
Iteration [31878]: Loss = 0.6834979057312012
Iteration [31879]: Loss = 0.6837196350097656
Iteration [31880]: Loss = 0.6838359832763672
Iteration [31881]: Loss = 0.6838542819023132
Iteration [31882]: Loss = 0.6837843060493469
Iteration [31883]: Loss = 0.6836345195770264
Iteration [31884]: Loss = 0.6834133863449097
Iteration [31885]: Loss = 0.683137059211731
Iteration [31886]: Loss = 5.037656784057617
Iteration [31887]: Loss = 5.03657865524292
Iteration [31888]: Loss = 0.6958906054496765
Iteration [31889]: Loss = 0.7150677442550659
Iteration [31890]: Loss = 0.7081959247589111
Iteration [31891]: Loss = 0.7183074951171875
Iteration [31892]: Loss = 0.7342230081558228
Iteration [31893]: Loss = 0.7184467315673828
Iteration [31894]: Loss = 0.691722571849823
Iteration [31895]: Loss = 0.6843001842498779
Iteration [31896]: Loss = 0.6698029637336731
Iteration [31897]: Loss = 0.659354031085968
Iteration [31898]: Loss = 9.542987823486328
Iteration [31899]: Loss = 0.6703238487243652
Iteration [31900]: Loss = 0.6728708744049072
Iteration [31901]: Loss = 5.071178913116455
Iteration [31902]: Loss = 0.6933599710464478
Iteration [31903]: Loss = 5.169204235076904
Iteration [31904]: Loss = 5.129332542419434
Iteration [31905]: Loss = 0.6626468896865845
Iteration [31906]: Loss = 5.099277973175049
Iteration [31907]: Loss = 0.6722511053085327
Iteration [31908]: Loss = 0.6661872863769531
Iteration [31909]: Loss = 0.6697106957435608
Iteration [31910]: Loss = 0.6690245866775513
Iteration [31911]: Loss = 0.6656363010406494
Iteration [31912]: Loss = 0.6677440404891968
Iteration [31913]: Loss = 0.6573889255523682
Iteration [31914]: Loss = 0.6543753743171692
Iteration [31915]: Loss = 5.197235584259033
Iteration [31916]: Loss = 0.6552236080169678
Iteration [31917]: Loss = 5.189512729644775
Iteration [31918]: Loss = 0.6569540500640869
Iteration [31919]: Loss = 0.6570363640785217
Iteration [31920]: Loss = 0.6635143756866455
Iteration [31921]: Loss = 0.6640455722808838
Iteration [31922]: Loss = 0.6644074320793152
Iteration [31923]: Loss = 0.6646167039871216
Iteration [31924]: Loss = 0.6646883487701416
Iteration [31925]: Loss = 5.138687610626221
Iteration [31926]: Loss = 5.135269641876221
Iteration [31927]: Loss = 0.6664023399353027
Iteration [31928]: Loss = 0.6673393845558167
Iteration [31929]: Loss = 0.6680712103843689
Iteration [31930]: Loss = 0.6697329878807068
Iteration [31931]: Loss = 0.6701124906539917
Iteration [31932]: Loss = 0.6703414916992188
Iteration [31933]: Loss = 5.105952739715576
Iteration [31934]: Loss = 0.6711370944976807
Iteration [31935]: Loss = 0.6716587543487549
Iteration [31936]: Loss = 5.097097396850586
Iteration [31937]: Loss = 0.6729435324668884
Iteration [31938]: Loss = 0.6736683249473572
Iteration [31939]: Loss = 0.6742118000984192
Iteration [31940]: Loss = 0.6745917201042175
Iteration [31941]: Loss = 5.081472873687744
Iteration [31942]: Loss = 5.077018737792969
Iteration [31943]: Loss = 0.6769293546676636
Iteration [31944]: Loss = 0.6779953837394714
Iteration [31945]: Loss = 0.6788490414619446
Iteration [31946]: Loss = 0.6795109510421753
Iteration [31947]: Loss = 0.6799999475479126
Iteration [31948]: Loss = 0.6803330183029175
Iteration [31949]: Loss = 0.6805257201194763
Iteration [31950]: Loss = 0.6805918216705322
Iteration [31951]: Loss = 0.6805440783500671
Iteration [31952]: Loss = 0.6803939342498779
Iteration [31953]: Loss = 0.6801517009735107
Iteration [31954]: Loss = 0.6798264384269714
Iteration [31955]: Loss = 0.6794268488883972
Iteration [31956]: Loss = 0.6789605021476746
Iteration [31957]: Loss = 0.6784340143203735
Iteration [31958]: Loss = 0.6778540015220642
Iteration [31959]: Loss = 0.6772254705429077
Iteration [31960]: Loss = 0.6765539646148682
Iteration [31961]: Loss = 5.075823783874512
Iteration [31962]: Loss = 0.6757930517196655
Iteration [31963]: Loss = 0.6756427884101868
Iteration [31964]: Loss = 0.6754029989242554
Iteration [31965]: Loss = 0.6750826835632324
Iteration [31966]: Loss = 5.082217693328857
Iteration [31967]: Loss = 0.674913227558136
Iteration [31968]: Loss = 5.080438137054443
Iteration [31969]: Loss = 0.6756619215011597
Iteration [31970]: Loss = 0.6761462688446045
Iteration [31971]: Loss = 0.6764804720878601
Iteration [31972]: Loss = 0.6766793131828308
Iteration [31973]: Loss = 0.6767563223838806
Iteration [31974]: Loss = 0.6767235398292542
Iteration [31975]: Loss = 0.6765918731689453
Iteration [31976]: Loss = 0.6763714551925659
Iteration [31977]: Loss = 0.6760709285736084
Iteration [31978]: Loss = 5.076626777648926
Iteration [31979]: Loss = 0.6759250164031982
Iteration [31980]: Loss = 0.6760281324386597
Iteration [31981]: Loss = 0.6760202050209045
Iteration [31982]: Loss = 0.6759122610092163
Iteration [31983]: Loss = 0.6757145524024963
Iteration [31984]: Loss = 0.6754359602928162
Iteration [31985]: Loss = 0.6750847101211548
Iteration [31986]: Loss = 0.6746681332588196
Iteration [31987]: Loss = 0.6741929054260254
Iteration [31988]: Loss = 0.6736651062965393
Iteration [31989]: Loss = 0.6730899810791016
Iteration [31990]: Loss = 0.6724724769592285
Iteration [31991]: Loss = 0.6718171834945679
Iteration [31992]: Loss = 0.6711276769638062
Iteration [31993]: Loss = 0.6704080700874329
Iteration [31994]: Loss = 5.105423450469971
Iteration [31995]: Loss = 0.6704182028770447
Iteration [31996]: Loss = 0.6702196002006531
Iteration [31997]: Loss = 0.6699424386024475
Iteration [31998]: Loss = 0.6695947051048279
Iteration [31999]: Loss = 0.669183611869812
Iteration [32000]: Loss = 0.6687154173851013
Iteration [32001]: Loss = 0.6681962609291077
Iteration [32002]: Loss = 0.6676310896873474
Iteration [32003]: Loss = 0.6670247316360474
Iteration [32004]: Loss = 5.12878942489624
Iteration [32005]: Loss = 0.6663563251495361
Iteration [32006]: Loss = 0.6662369966506958
Iteration [32007]: Loss = 0.6660330891609192
Iteration [32008]: Loss = 5.132349491119385
Iteration [32009]: Loss = 0.6660449504852295
Iteration [32010]: Loss = 5.1297478675842285
Iteration [32011]: Loss = 0.6668964624404907
Iteration [32012]: Loss = 0.6670031547546387
Iteration [32013]: Loss = 0.6673771739006042
Iteration [32014]: Loss = 0.6676191091537476
Iteration [32015]: Loss = 5.12109899520874
Iteration [32016]: Loss = 0.6683813333511353
Iteration [32017]: Loss = 0.66886305809021
Iteration [32018]: Loss = 0.6692028641700745
Iteration [32019]: Loss = 0.6694145798683167
Iteration [32020]: Loss = 0.6695109009742737
Iteration [32021]: Loss = 0.6695035696029663
Iteration [32022]: Loss = 0.6694023609161377
Iteration [32023]: Loss = 0.6692174077033997
Iteration [32024]: Loss = 5.114256858825684
Iteration [32025]: Loss = 0.6692487597465515
Iteration [32026]: Loss = 0.6694186329841614
Iteration [32027]: Loss = 5.111324787139893
Iteration [32028]: Loss = 5.108108043670654
Iteration [32029]: Loss = 0.671076774597168
Iteration [32030]: Loss = 0.6713237166404724
Iteration [32031]: Loss = 0.6719797849655151
Iteration [32032]: Loss = 0.6724784970283508
Iteration [32033]: Loss = 5.09253454208374
Iteration [32034]: Loss = 0.6736639142036438
Iteration [32035]: Loss = 0.6743187308311462
Iteration [32036]: Loss = 0.6748167276382446
Iteration [32037]: Loss = 0.6751731634140015
Iteration [32038]: Loss = 0.6754022240638733
Iteration [32039]: Loss = 0.6755163073539734
Iteration [32040]: Loss = 0.6755269765853882
Iteration [32041]: Loss = 0.6754444241523743
Iteration [32042]: Loss = 0.6752781271934509
Iteration [32043]: Loss = 0.6750363111495972
Iteration [32044]: Loss = 0.6747267842292786
Iteration [32045]: Loss = 5.084072113037109
Iteration [32046]: Loss = 0.6745318174362183
Iteration [32047]: Loss = 0.674598753452301
Iteration [32048]: Loss = 0.6745677590370178
Iteration [32049]: Loss = 0.6744486689567566
Iteration [32050]: Loss = 0.6742502450942993
Iteration [32051]: Loss = 0.6739804744720459
Iteration [32052]: Loss = 0.6736466288566589
Iteration [32053]: Loss = 0.6732549667358398
Iteration [32054]: Loss = 5.092667102813721
Iteration [32055]: Loss = 5.092067718505859
Iteration [32056]: Loss = 0.6748083829879761
Iteration [32057]: Loss = 0.6752538084983826
Iteration [32058]: Loss = 0.6749053001403809
Iteration [32059]: Loss = 0.6757552623748779
Iteration [32060]: Loss = 5.075863361358643
Iteration [32061]: Loss = 0.6764038801193237
Iteration [32062]: Loss = 0.6768252849578857
Iteration [32063]: Loss = 5.068797588348389
Iteration [32064]: Loss = 0.6778651475906372
Iteration [32065]: Loss = 0.678451418876648
Iteration [32066]: Loss = 5.059023380279541
Iteration [32067]: Loss = 0.67976975440979
Iteration [32068]: Loss = 0.6804730892181396
Iteration [32069]: Loss = 0.6810177564620972
Iteration [32070]: Loss = 5.045170307159424
Iteration [32071]: Loss = 0.68226158618927
Iteration [32072]: Loss = 0.6829316020011902
Iteration [32073]: Loss = 0.6834205985069275
Iteration [32074]: Loss = 0.6837725043296814
Iteration [32075]: Loss = 0.6840055584907532
Iteration [32076]: Loss = 0.684131920337677
Iteration [32077]: Loss = 0.6841620206832886
Iteration [32078]: Loss = 0.6841055750846863
Iteration [32079]: Loss = 0.6839709281921387
Iteration [32080]: Loss = 0.68376624584198
Iteration [32081]: Loss = 0.6834982633590698
Iteration [32082]: Loss = 0.6831735372543335
Iteration [32083]: Loss = 0.6827977299690247
Iteration [32084]: Loss = 0.6823761463165283
Iteration [32085]: Loss = 0.6819133162498474
Iteration [32086]: Loss = 0.6814134120941162
Iteration [32087]: Loss = 0.6808804869651794
Iteration [32088]: Loss = 0.6803176999092102
Iteration [32089]: Loss = 0.679728090763092
Iteration [32090]: Loss = 0.6791146993637085
Iteration [32091]: Loss = 0.6784799098968506
Iteration [32092]: Loss = 0.677825927734375
Iteration [32093]: Loss = 5.068579196929932
Iteration [32094]: Loss = 0.6770085692405701
Iteration [32095]: Loss = 0.6767947673797607
Iteration [32096]: Loss = 0.6765203475952148
Iteration [32097]: Loss = 0.6761913299560547
Iteration [32098]: Loss = 0.6758132576942444
Iteration [32099]: Loss = 9.481269836425781
Iteration [32100]: Loss = 0.675979733467102
Iteration [32101]: Loss = 0.6764305830001831
Iteration [32102]: Loss = 0.6767573356628418
Iteration [32103]: Loss = 0.6769722700119019
Iteration [32104]: Loss = 0.6778196096420288
Iteration [32105]: Loss = 0.6778426170349121
Iteration [32106]: Loss = 0.6777839064598083
Iteration [32107]: Loss = 0.6776512861251831
Iteration [32108]: Loss = 0.6774523854255676
Iteration [32109]: Loss = 0.6771937608718872
Iteration [32110]: Loss = 0.6768814325332642
Iteration [32111]: Loss = 0.6765210628509521
Iteration [32112]: Loss = 0.6761171221733093
Iteration [32113]: Loss = 0.675674319267273
Iteration [32114]: Loss = 5.079409122467041
Iteration [32115]: Loss = 5.0793561935424805
Iteration [32116]: Loss = 0.67564857006073
Iteration [32117]: Loss = 0.6759688854217529
Iteration [32118]: Loss = 0.6761786937713623
Iteration [32119]: Loss = 0.6762892007827759
Iteration [32120]: Loss = 0.6763100624084473
Iteration [32121]: Loss = 5.073574542999268
Iteration [32122]: Loss = 0.676628589630127
Iteration [32123]: Loss = 0.6768909692764282
Iteration [32124]: Loss = 0.6770492196083069
Iteration [32125]: Loss = 0.6771132349967957
Iteration [32126]: Loss = 9.460750579833984
Iteration [32127]: Loss = 0.6779888868331909
Iteration [32128]: Loss = 0.6787200570106506
Iteration [32129]: Loss = 0.6793026924133301
Iteration [32130]: Loss = 0.6797512173652649
Iteration [32131]: Loss = 0.6800785660743713
Iteration [32132]: Loss = 0.6802968978881836
Iteration [32133]: Loss = 0.6804169416427612
Iteration [32134]: Loss = 0.6804484128952026
Iteration [32135]: Loss = 0.6804002523422241
Iteration [32136]: Loss = 0.680280327796936
Iteration [32137]: Loss = 0.6800954937934875
Iteration [32138]: Loss = 0.6798526644706726
Iteration [32139]: Loss = 0.6795574426651001
Iteration [32140]: Loss = 0.6792152523994446
Iteration [32141]: Loss = 0.6788308024406433
Iteration [32142]: Loss = 5.061674118041992
Iteration [32143]: Loss = 0.6784483790397644
Iteration [32144]: Loss = 0.6784084439277649
Iteration [32145]: Loss = 5.062288284301758
Iteration [32146]: Loss = 0.6786124110221863
Iteration [32147]: Loss = 0.6788210868835449
Iteration [32148]: Loss = 0.678933322429657
Iteration [32149]: Loss = 0.6789585947990417
Iteration [32150]: Loss = 5.058940410614014
Iteration [32151]: Loss = 0.6792721152305603
Iteration [32152]: Loss = 5.05552864074707
Iteration [32153]: Loss = 5.052019119262695
Iteration [32154]: Loss = 5.046640872955322
Iteration [32155]: Loss = 0.6824389100074768
Iteration [32156]: Loss = 0.6835256814956665
Iteration [32157]: Loss = 0.6844303607940674
Iteration [32158]: Loss = 5.024774074554443
Iteration [32159]: Loss = 5.019367694854736
Iteration [32160]: Loss = 0.6873627305030823
Iteration [32161]: Loss = 0.6883722543716431
Iteration [32162]: Loss = 0.689136803150177
Iteration [32163]: Loss = 0.6897546648979187
Iteration [32164]: Loss = 0.6902526021003723
Iteration [32165]: Loss = 4.995353698730469
Iteration [32166]: Loss = 0.6912907958030701
Iteration [32167]: Loss = 0.691819429397583
Iteration [32168]: Loss = 0.6922376751899719
Iteration [32169]: Loss = 0.6925566792488098
Iteration [32170]: Loss = 0.692785918712616
Iteration [32171]: Loss = 0.6929345726966858
Iteration [32172]: Loss = 4.98272180557251
Iteration [32173]: Loss = 0.6933850049972534
Iteration [32174]: Loss = 0.6936647891998291
Iteration [32175]: Loss = 0.6938588619232178
Iteration [32176]: Loss = 0.6939756870269775
Iteration [32177]: Loss = 0.6940228939056396
Iteration [32178]: Loss = 0.6940075159072876
Iteration [32179]: Loss = 0.6939358115196228
Iteration [32180]: Loss = 0.6938133239746094
Iteration [32181]: Loss = 4.979351997375488
Iteration [32182]: Loss = 0.6938003301620483
Iteration [32183]: Loss = 0.6938825249671936
Iteration [32184]: Loss = 0.693898618221283
Iteration [32185]: Loss = 0.6938554048538208
Iteration [32186]: Loss = 0.6937587857246399
Iteration [32187]: Loss = 0.6936140060424805
Iteration [32188]: Loss = 0.6934258341789246
Iteration [32189]: Loss = 0.6931986808776855
Iteration [32190]: Loss = 4.983114719390869
Iteration [32191]: Loss = 0.693007230758667
Iteration [32192]: Loss = 4.982707500457764
Iteration [32193]: Loss = 4.98106050491333
Iteration [32194]: Loss = 0.6939041614532471
Iteration [32195]: Loss = 0.694370448589325
Iteration [32196]: Loss = 0.6947329640388489
Iteration [32197]: Loss = 4.972161769866943
Iteration [32198]: Loss = 4.969287872314453
Iteration [32199]: Loss = 0.6963344216346741
Iteration [32200]: Loss = 0.6969878673553467
Iteration [32201]: Loss = 4.958887577056885
Iteration [32202]: Loss = 0.6982958316802979
Iteration [32203]: Loss = 0.6989268064498901
Iteration [32204]: Loss = 0.6994290351867676
Iteration [32205]: Loss = 0.6998263001441956
Iteration [32206]: Loss = 0.7001287937164307
Iteration [32207]: Loss = 0.7003459930419922
Iteration [32208]: Loss = 0.7004860043525696
Iteration [32209]: Loss = 0.7005568146705627
Iteration [32210]: Loss = 0.7005650997161865
Iteration [32211]: Loss = 0.7005172371864319
Iteration [32212]: Loss = 9.186968803405762
Iteration [32213]: Loss = 0.7009533643722534
Iteration [32214]: Loss = 4.9386749267578125
Iteration [32215]: Loss = 4.935206890106201
Iteration [32216]: Loss = 0.7029263973236084
Iteration [32217]: Loss = 0.7036646604537964
Iteration [32218]: Loss = 0.7042754888534546
Iteration [32219]: Loss = 0.7047713398933411
Iteration [32220]: Loss = 0.7051633596420288
Iteration [32221]: Loss = 0.7054619193077087
Iteration [32222]: Loss = 4.916404724121094
Iteration [32223]: Loss = 0.7061493396759033
Iteration [32224]: Loss = 0.7065211534500122
Iteration [32225]: Loss = 0.7068013548851013
Iteration [32226]: Loss = 0.7069989442825317
Iteration [32227]: Loss = 0.7071221470832825
Iteration [32228]: Loss = 0.7071783542633057
Iteration [32229]: Loss = 0.7071741223335266
Iteration [32230]: Loss = 0.7071154713630676
Iteration [32231]: Loss = 0.707007884979248
Iteration [32232]: Loss = 0.7068561911582947
Iteration [32233]: Loss = 0.7066649198532104
Iteration [32234]: Loss = 0.7064377665519714
Iteration [32235]: Loss = 0.7061786651611328
Iteration [32236]: Loss = 0.7058906555175781
Iteration [32237]: Loss = 0.7055766582489014
Iteration [32238]: Loss = 0.7052392959594727
Iteration [32239]: Loss = 4.9205098152160645
Iteration [32240]: Loss = 0.7048414349555969
Iteration [32241]: Loss = 0.704751193523407
Iteration [32242]: Loss = 4.921882152557373
Iteration [32243]: Loss = 0.7047747373580933
Iteration [32244]: Loss = 0.7048637270927429
Iteration [32245]: Loss = 0.7048895359039307
Iteration [32246]: Loss = 0.7048583030700684
Iteration [32247]: Loss = 0.7047758102416992
Iteration [32248]: Loss = 0.7046471238136292
Iteration [32249]: Loss = 0.7044770121574402
Iteration [32250]: Loss = 0.7042694091796875
Iteration [32251]: Loss = 0.7040281295776367
Iteration [32252]: Loss = 0.7037566900253296
Iteration [32253]: Loss = 0.7034579515457153
Iteration [32254]: Loss = 0.7031346559524536
Iteration [32255]: Loss = 0.7027894854545593
Iteration [32256]: Loss = 0.7024246454238892
Iteration [32257]: Loss = 0.7020419836044312
Iteration [32258]: Loss = 0.7016433477401733
Iteration [32259]: Loss = 0.7012304067611694
Iteration [32260]: Loss = 0.7008046507835388
Iteration [32261]: Loss = 0.7003674507141113
Iteration [32262]: Loss = 0.6999199390411377
Iteration [32263]: Loss = 0.6994631290435791
Iteration [32264]: Loss = 0.6989981532096863
Iteration [32265]: Loss = 0.6985256671905518
Iteration [32266]: Loss = 0.6980466246604919
Iteration [32267]: Loss = 4.958664417266846
Iteration [32268]: Loss = 0.6974091529846191
Iteration [32269]: Loss = 0.697218120098114
Iteration [32270]: Loss = 0.6969925165176392
Iteration [32271]: Loss = 4.963010787963867
Iteration [32272]: Loss = 0.6967871189117432
Iteration [32273]: Loss = 0.6967799067497253
Iteration [32274]: Loss = 0.6967198252677917
Iteration [32275]: Loss = 0.6966124176979065
Iteration [32276]: Loss = 0.6964621543884277
Iteration [32277]: Loss = 0.6962734460830688
Iteration [32278]: Loss = 4.966626167297363
Iteration [32279]: Loss = 0.6961309313774109
Iteration [32280]: Loss = 0.6961503028869629
Iteration [32281]: Loss = 0.6961144208908081
Iteration [32282]: Loss = 0.6960289478302002
Iteration [32283]: Loss = 4.96742582321167
Iteration [32284]: Loss = 0.6960620284080505
Iteration [32285]: Loss = 4.966066837310791
Iteration [32286]: Loss = 0.6965199112892151
Iteration [32287]: Loss = 0.6967945694923401
Iteration [32288]: Loss = 0.6969889402389526
Iteration [32289]: Loss = 0.697110652923584
Iteration [32290]: Loss = 0.6971670985221863
Iteration [32291]: Loss = 4.960752010345459
Iteration [32292]: Loss = 0.697441577911377
Iteration [32293]: Loss = 0.6976379752159119
Iteration [32294]: Loss = 0.6977615356445312
Iteration [32295]: Loss = 0.6978197693824768
Iteration [32296]: Loss = 0.69781893491745
Iteration [32297]: Loss = 4.957595348358154
Iteration [32298]: Loss = 0.6979952454566956
Iteration [32299]: Loss = 0.698149561882019
Iteration [32300]: Loss = 0.6982353329658508
Iteration [32301]: Loss = 0.6982595324516296
Iteration [32302]: Loss = 0.698228120803833
Iteration [32303]: Loss = 0.6981467604637146
Iteration [32304]: Loss = 0.6980203986167908
Iteration [32305]: Loss = 0.6978535652160645
Iteration [32306]: Loss = 0.6976503133773804
Iteration [32307]: Loss = 0.6974141001701355
Iteration [32308]: Loss = 0.6971484422683716
Iteration [32309]: Loss = 0.6968563199043274
Iteration [32310]: Loss = 0.6965402364730835
Iteration [32311]: Loss = 0.6962027549743652
Iteration [32312]: Loss = 0.6958460211753845
Iteration [32313]: Loss = 0.6954719424247742
Iteration [32314]: Loss = 0.6950822472572327
Iteration [32315]: Loss = 0.694678783416748
Iteration [32316]: Loss = 0.6942626237869263
Iteration [32317]: Loss = 0.6938353776931763
Iteration [32318]: Loss = 0.6933980584144592
Iteration [32319]: Loss = 0.692951500415802
Iteration [32320]: Loss = 0.6924970149993896
Iteration [32321]: Loss = 0.6920352578163147
Iteration [32322]: Loss = 0.6915671229362488
Iteration [32323]: Loss = 0.6910929679870605
Iteration [32324]: Loss = 0.690613865852356
Iteration [32325]: Loss = 0.6901301145553589
Iteration [32326]: Loss = 0.6896423697471619
Iteration [32327]: Loss = 0.6891508102416992
Iteration [32328]: Loss = 0.6886559724807739
Iteration [32329]: Loss = 0.6881584525108337
Iteration [32330]: Loss = 0.6876583099365234
Iteration [32331]: Loss = 5.014049530029297
Iteration [32332]: Loss = 0.6869864463806152
Iteration [32333]: Loss = 0.6867817640304565
Iteration [32334]: Loss = 0.6865453124046326
Iteration [32335]: Loss = 0.6862806081771851
Iteration [32336]: Loss = 0.6859901547431946
Iteration [32337]: Loss = 0.685676634311676
Iteration [32338]: Loss = 0.6853424310684204
Iteration [32339]: Loss = 0.684989869594574
Iteration [32340]: Loss = 0.6846203207969666
Iteration [32341]: Loss = 5.029837608337402
Iteration [32342]: Loss = 0.6841719150543213
Iteration [32343]: Loss = 0.6840626001358032
Iteration [32344]: Loss = 0.6839125156402588
Iteration [32345]: Loss = 0.6837256550788879
Iteration [32346]: Loss = 0.6835055351257324
Iteration [32347]: Loss = 0.6832557320594788
Iteration [32348]: Loss = 0.6829791069030762
Iteration [32349]: Loss = 0.6826785206794739
Iteration [32350]: Loss = 0.6823561787605286
Iteration [32351]: Loss = 9.401826858520508
Iteration [32352]: Loss = 0.6823163628578186
Iteration [32353]: Loss = 0.6825374960899353
Iteration [32354]: Loss = 5.038262367248535
Iteration [32355]: Loss = 0.6830945611000061
Iteration [32356]: Loss = 0.6834120154380798
Iteration [32357]: Loss = 0.6836472749710083
Iteration [32358]: Loss = 0.6838083863258362
Iteration [32359]: Loss = 0.6839025020599365
Iteration [32360]: Loss = 0.683936357498169
Iteration [32361]: Loss = 0.6839161515235901
Iteration [32362]: Loss = 0.6838468909263611
Iteration [32363]: Loss = 0.6837337613105774
Iteration [32364]: Loss = 0.6835810542106628
Iteration [32365]: Loss = 0.6833927035331726
Iteration [32366]: Loss = 0.6831722259521484
Iteration [32367]: Loss = 0.6829228401184082
Iteration [32368]: Loss = 0.6826475262641907
Iteration [32369]: Loss = 0.6823490262031555
Iteration [32370]: Loss = 5.041840076446533
Iteration [32371]: Loss = 0.6820189952850342
Iteration [32372]: Loss = 5.042224407196045
Iteration [32373]: Loss = 0.6821804046630859
Iteration [32374]: Loss = 0.6823294162750244
Iteration [32375]: Loss = 0.6824129223823547
Iteration [32376]: Loss = 5.039614677429199
Iteration [32377]: Loss = 5.037998199462891
Iteration [32378]: Loss = 0.6832743883132935
Iteration [32379]: Loss = 5.032689094543457
Iteration [32380]: Loss = 5.029083251953125
Iteration [32381]: Loss = 0.6852432489395142
Iteration [32382]: Loss = 0.6859754920005798
Iteration [32383]: Loss = 0.6865850687026978
Iteration [32384]: Loss = 9.341795921325684
Iteration [32385]: Loss = 0.6881095767021179
Iteration [32386]: Loss = 0.6889844536781311
Iteration [32387]: Loss = 0.689723014831543
Iteration [32388]: Loss = 0.6903385519981384
Iteration [32389]: Loss = 0.6908429861068726
Iteration [32390]: Loss = 0.6912471652030945
Iteration [32391]: Loss = 9.289313316345215
Iteration [32392]: Loss = 0.6924155354499817
Iteration [32393]: Loss = 0.6931359767913818
Iteration [32394]: Loss = 4.978872299194336
Iteration [32395]: Loss = 0.694536566734314
Iteration [32396]: Loss = 0.6952089071273804
Iteration [32397]: Loss = 0.6957648396492004
Iteration [32398]: Loss = 0.6975765228271484
Iteration [32399]: Loss = 0.6979219317436218
Iteration [32400]: Loss = 0.6981735229492188
Iteration [32401]: Loss = 4.954451560974121
Iteration [32402]: Loss = 0.6988033056259155
Iteration [32403]: Loss = 0.6991479992866516
Iteration [32404]: Loss = 0.6994071006774902
Iteration [32405]: Loss = 0.6995890736579895
Iteration [32406]: Loss = 4.947442054748535
Iteration [32407]: Loss = 0.698736310005188
Iteration [32408]: Loss = 0.6990141868591309
Iteration [32409]: Loss = 0.6992145776748657
Iteration [32410]: Loss = 0.6993447542190552
Iteration [32411]: Loss = 4.948957920074463
Iteration [32412]: Loss = 0.6997339129447937
Iteration [32413]: Loss = 0.6999738216400146
Iteration [32414]: Loss = 0.7001397013664246
Iteration [32415]: Loss = 0.7002391219139099
Iteration [32416]: Loss = 0.7002785205841064
Iteration [32417]: Loss = 0.7002637386322021
Iteration [32418]: Loss = 0.700200080871582
Iteration [32419]: Loss = 0.7000927925109863
Iteration [32420]: Loss = 0.6999459862709045
Iteration [32421]: Loss = 0.6997635364532471
Iteration [32422]: Loss = 0.69954913854599
Iteration [32423]: Loss = 0.6993060111999512
Iteration [32424]: Loss = 0.6990369558334351
Iteration [32425]: Loss = 0.6987446546554565
Iteration [32426]: Loss = 0.6984314918518066
Iteration [32427]: Loss = 0.6980993151664734
Iteration [32428]: Loss = 0.6977502703666687
Iteration [32429]: Loss = 0.6973862051963806
Iteration [32430]: Loss = 0.6970084309577942
Iteration [32431]: Loss = 0.6966182589530945
Iteration [32432]: Loss = 0.6962172389030457
Iteration [32433]: Loss = 0.6958063244819641
Iteration [32434]: Loss = 0.695386528968811
Iteration [32435]: Loss = 0.6949589252471924
Iteration [32436]: Loss = 0.6945241689682007
Iteration [32437]: Loss = 0.6940829753875732
Iteration [32438]: Loss = 0.6936361789703369
Iteration [32439]: Loss = 0.6931843757629395
Iteration [32440]: Loss = 0.6927279233932495
Iteration [32441]: Loss = 0.6922673583030701
Iteration [32442]: Loss = 0.6918033361434937
Iteration [32443]: Loss = 0.6913360953330994
Iteration [32444]: Loss = 0.6908659934997559
Iteration [32445]: Loss = 4.996672630310059
Iteration [32446]: Loss = 0.690233588218689
Iteration [32447]: Loss = 0.6900404691696167
Iteration [32448]: Loss = 0.6898170709609985
Iteration [32449]: Loss = 0.6895666718482971
Iteration [32450]: Loss = 5.002569675445557
Iteration [32451]: Loss = 0.6893094182014465
Iteration [32452]: Loss = 0.6892756819725037
Iteration [32453]: Loss = 0.6891962885856628
Iteration [32454]: Loss = 0.6890754103660583
Iteration [32455]: Loss = 0.688917338848114
Iteration [32456]: Loss = 0.6887258291244507
Iteration [32457]: Loss = 0.6885040998458862
Iteration [32458]: Loss = 0.6882553100585938
Iteration [32459]: Loss = 0.6879820823669434
Iteration [32460]: Loss = 0.68768709897995
Iteration [32461]: Loss = 0.6873722076416016
Iteration [32462]: Loss = 0.6870397329330444
Iteration [32463]: Loss = 0.686691164970398
Iteration [32464]: Loss = 0.6863284111022949
Iteration [32465]: Loss = 5.020542144775391
Iteration [32466]: Loss = 0.6858803033828735
Iteration [32467]: Loss = 0.6857661008834839
Iteration [32468]: Loss = 0.6856143474578857
Iteration [32469]: Loss = 0.6854288578033447
Iteration [32470]: Loss = 0.6852128505706787
Iteration [32471]: Loss = 5.025860786437988
Iteration [32472]: Loss = 5.025611877441406
Iteration [32473]: Loss = 0.6853200793266296
Iteration [32474]: Loss = 0.685545802116394
Iteration [32475]: Loss = 0.6857004165649414
Iteration [32476]: Loss = 0.6857907772064209
Iteration [32477]: Loss = 5.021239757537842
Iteration [32478]: Loss = 5.0196614265441895
Iteration [32479]: Loss = 5.016828536987305
Iteration [32480]: Loss = 0.687373161315918
Iteration [32481]: Loss = 0.6879847049713135
Iteration [32482]: Loss = 0.68848717212677
Iteration [32483]: Loss = 0.6888908743858337
Iteration [32484]: Loss = 0.6892058253288269
Iteration [32485]: Loss = 0.6894406676292419
Iteration [32486]: Loss = 0.6896031498908997
Iteration [32487]: Loss = 0.6897006630897522
Iteration [32488]: Loss = 0.6897393465042114
Iteration [32489]: Loss = 0.689725399017334
Iteration [32490]: Loss = 0.6896637082099915
Iteration [32491]: Loss = 0.6895592212677002
Iteration [32492]: Loss = 0.6894161701202393
Iteration [32493]: Loss = 0.6892383098602295
Iteration [32494]: Loss = 0.6890293955802917
Iteration [32495]: Loss = 0.6887922286987305
Iteration [32496]: Loss = 0.6885297298431396
Iteration [32497]: Loss = 0.688244640827179
Iteration [32498]: Loss = 0.6879390478134155
Iteration [32499]: Loss = 0.687614917755127
Iteration [32500]: Loss = 0.6872743964195251
Iteration [32501]: Loss = 0.6869190335273743
Iteration [32502]: Loss = 5.01731538772583
Iteration [32503]: Loss = 0.6864821910858154
Iteration [32504]: Loss = 0.6863724589347839
Iteration [32505]: Loss = 0.6862246990203857
Iteration [32506]: Loss = 9.35406494140625
Iteration [32507]: Loss = 0.6864482164382935
Iteration [32508]: Loss = 0.6867650747299194
Iteration [32509]: Loss = 0.6870023012161255
Iteration [32510]: Loss = 0.6871680617332458
Iteration [32511]: Loss = 0.6872690320014954
Iteration [32512]: Loss = 5.013209342956543
Iteration [32513]: Loss = 5.01161003112793
Iteration [32514]: Loss = 0.6881337761878967
Iteration [32515]: Loss = 0.6885584592819214
Iteration [32516]: Loss = 0.6888929605484009
Iteration [32517]: Loss = 0.689146101474762
Iteration [32518]: Loss = 0.6893259286880493
Iteration [32519]: Loss = 0.6894396543502808
Iteration [32520]: Loss = 0.6894937753677368
Iteration [32521]: Loss = 0.689494252204895
Iteration [32522]: Loss = 0.6894465684890747
Iteration [32523]: Loss = 0.6893551349639893
Iteration [32524]: Loss = 5.002930641174316
Iteration [32525]: Loss = 0.6893656253814697
Iteration [32526]: Loss = 0.6894444823265076
Iteration [32527]: Loss = 0.6894672513008118
Iteration [32528]: Loss = 0.6894394755363464
Iteration [32529]: Loss = 0.6893662214279175
Iteration [32530]: Loss = 5.002782821655273
Iteration [32531]: Loss = 5.001948833465576
Iteration [32532]: Loss = 0.6898044943809509
Iteration [32533]: Loss = 0.6901137828826904
Iteration [32534]: Loss = 4.99693489074707
Iteration [32535]: Loss = 4.994457244873047
Iteration [32536]: Loss = 0.6914803981781006
Iteration [32537]: Loss = 0.6920382380485535
Iteration [32538]: Loss = 0.692492663860321
Iteration [32539]: Loss = 0.6928538084030151
Iteration [32540]: Loss = 0.6931308507919312
Iteration [32541]: Loss = 0.6933320760726929
Iteration [32542]: Loss = 0.6934650540351868
Iteration [32543]: Loss = 4.979928016662598
Iteration [32544]: Loss = 4.978230953216553
Iteration [32545]: Loss = 0.6943989396095276
Iteration [32546]: Loss = 0.6948394775390625
Iteration [32547]: Loss = 4.971179485321045
Iteration [32548]: Loss = 0.6957557797431946
Iteration [32549]: Loss = 0.6962189078330994
Iteration [32550]: Loss = 0.6965877413749695
Iteration [32551]: Loss = 0.6968715190887451
Iteration [32552]: Loss = 0.6970789432525635
Iteration [32553]: Loss = 0.6972170472145081
Iteration [32554]: Loss = 0.6972930431365967
Iteration [32555]: Loss = 0.6973127722740173
Iteration [32556]: Loss = 0.6972821354866028
Iteration [32557]: Loss = 0.6972060203552246
Iteration [32558]: Loss = 0.6970889568328857
Iteration [32559]: Loss = 4.9619622230529785
Iteration [32560]: Loss = 0.6970517635345459
Iteration [32561]: Loss = 0.6971084475517273
Iteration [32562]: Loss = 0.6971110105514526
Iteration [32563]: Loss = 0.6970648169517517
Iteration [32564]: Loss = 0.6969746947288513
Iteration [32565]: Loss = 4.962435722351074
Iteration [32566]: Loss = 0.6969835162162781
Iteration [32567]: Loss = 0.6970596313476562
Iteration [32568]: Loss = 0.6970800161361694
Iteration [32569]: Loss = 0.6970497369766235
Iteration [32570]: Loss = 4.961757183074951
Iteration [32571]: Loss = 4.9607744216918945
Iteration [32572]: Loss = 0.6975818276405334
Iteration [32573]: Loss = 4.956818103790283
Iteration [32574]: Loss = 0.6984637379646301
Iteration [32575]: Loss = 0.6989115476608276
Iteration [32576]: Loss = 0.6992664933204651
Iteration [32577]: Loss = 4.948298931121826
Iteration [32578]: Loss = 4.945702075958252
Iteration [32579]: Loss = 0.7007326483726501
Iteration [32580]: Loss = 0.7013133764266968
Iteration [32581]: Loss = 0.7017882466316223
Iteration [32582]: Loss = 4.934579849243164
Iteration [32583]: Loss = 0.7027596831321716
Iteration [32584]: Loss = 0.7032448053359985
Iteration [32585]: Loss = 0.7036333680152893
Iteration [32586]: Loss = 0.7039346098899841
Iteration [32587]: Loss = 0.704157292842865
Iteration [32588]: Loss = 0.7043091654777527
Iteration [32589]: Loss = 4.923012733459473
Iteration [32590]: Loss = 0.7047277092933655
Iteration [32591]: Loss = 0.7049768567085266
Iteration [32592]: Loss = 0.7051523923873901
Iteration [32593]: Loss = 0.7052618265151978
Iteration [32594]: Loss = 0.7053114175796509
Iteration [32595]: Loss = 4.918307304382324
Iteration [32596]: Loss = 0.7055550813674927
Iteration [32597]: Loss = 0.7057294845581055
Iteration [32598]: Loss = 4.9155707359313965
Iteration [32599]: Loss = 0.706186056137085
Iteration [32600]: Loss = 0.7064509391784668
Iteration [32601]: Loss = 0.7066407799720764
Iteration [32602]: Loss = 0.7067627906799316
Iteration [32603]: Loss = 0.7060110569000244
Iteration [32604]: Loss = 0.7060171365737915
Iteration [32605]: Loss = 0.705973744392395
Iteration [32606]: Loss = 0.7058860063552856
Iteration [32607]: Loss = 4.915981292724609
Iteration [32608]: Loss = 0.7058942914009094
Iteration [32609]: Loss = 0.70596843957901
Iteration [32610]: Loss = 0.7059863209724426
Iteration [32611]: Loss = 0.7059535980224609
Iteration [32612]: Loss = 0.7058754563331604
Iteration [32613]: Loss = 0.7057563066482544
Iteration [32614]: Loss = 0.7056002616882324
Iteration [32615]: Loss = 4.9177727699279785
Iteration [32616]: Loss = 0.7054921984672546
Iteration [32617]: Loss = 0.7055166959762573
Iteration [32618]: Loss = 0.7054901719093323
Iteration [32619]: Loss = 0.7054173946380615
Iteration [32620]: Loss = 0.7053031325340271
Iteration [32621]: Loss = 0.7051515579223633
Iteration [32622]: Loss = 0.7049664855003357
Iteration [32623]: Loss = 4.921181678771973
Iteration [32624]: Loss = 0.7048089504241943
Iteration [32625]: Loss = 0.7048124670982361
Iteration [32626]: Loss = 0.7047668695449829
Iteration [32627]: Loss = 0.7046773433685303
Iteration [32628]: Loss = 4.922231674194336
Iteration [32629]: Loss = 0.7046829462051392
Iteration [32630]: Loss = 0.7047559022903442
Iteration [32631]: Loss = 0.7047728896141052
Iteration [32632]: Loss = 0.7047397494316101
Iteration [32633]: Loss = 4.921646595001221
Iteration [32634]: Loss = 0.7048414349555969
Iteration [32635]: Loss = 0.7049551606178284
Iteration [32636]: Loss = 0.7050091028213501
Iteration [32637]: Loss = 0.7050091028213501
Iteration [32638]: Loss = 0.7049603462219238
Iteration [32639]: Loss = 4.920577526092529
Iteration [32640]: Loss = 0.7050356268882751
Iteration [32641]: Loss = 0.7051380276679993
Iteration [32642]: Loss = 0.7051817178726196
Iteration [32643]: Loss = 0.7051724195480347
Iteration [32644]: Loss = 0.7051156163215637
Iteration [32645]: Loss = 0.7050157189369202
Iteration [32646]: Loss = 0.7048772573471069
Iteration [32647]: Loss = 0.7047039270401001
Iteration [32648]: Loss = 4.922482967376709
Iteration [32649]: Loss = 0.704566478729248
Iteration [32650]: Loss = 0.7045785188674927
Iteration [32651]: Loss = 0.7045406699180603
Iteration [32652]: Loss = 0.7044580578804016
Iteration [32653]: Loss = 0.7043352127075195
Iteration [32654]: Loss = 0.7041760683059692
Iteration [32655]: Loss = 0.703984260559082
Iteration [32656]: Loss = 0.7037631273269653
Iteration [32657]: Loss = 0.7035154700279236
Iteration [32658]: Loss = 0.7032440900802612
Iteration [32659]: Loss = 0.7029513120651245
Iteration [32660]: Loss = 0.7026392817497253
Iteration [32661]: Loss = 4.933837890625
Iteration [32662]: Loss = 0.7022656798362732
Iteration [32663]: Loss = 0.7021775245666504
Iteration [32664]: Loss = 0.702049732208252
Iteration [32665]: Loss = 0.7018864750862122
Iteration [32666]: Loss = 0.7016909718513489
Iteration [32667]: Loss = 0.7014667391777039
Iteration [32668]: Loss = 0.7012166380882263
Iteration [32669]: Loss = 4.9409565925598145
Iteration [32670]: Loss = 0.7009488940238953
Iteration [32671]: Loss = 0.700905978679657
Iteration [32672]: Loss = 0.7008191347122192
Iteration [32673]: Loss = 0.7006926536560059
Iteration [32674]: Loss = 4.943109512329102
Iteration [32675]: Loss = 0.7006363272666931
Iteration [32676]: Loss = 0.7006832957267761
Iteration [32677]: Loss = 0.7006775140762329
Iteration [32678]: Loss = 4.942621231079102
Iteration [32679]: Loss = 4.941562175750732
Iteration [32680]: Loss = 0.701259434223175
Iteration [32681]: Loss = 4.937528610229492
Iteration [32682]: Loss = 0.7021573185920715
Iteration [32683]: Loss = 0.7026104927062988
Iteration [32684]: Loss = 0.7029706835746765
Iteration [32685]: Loss = 4.928971767425537
Iteration [32686]: Loss = 0.7037443518638611
Iteration [32687]: Loss = 0.704144299030304
Iteration [32688]: Loss = 0.7044563889503479
Iteration [32689]: Loss = 0.7046892046928406
Iteration [32690]: Loss = 0.7048506140708923
Iteration [32691]: Loss = 0.7049475908279419
Iteration [32692]: Loss = 0.7049866318702698
Iteration [32693]: Loss = 0.7049733996391296
Iteration [32694]: Loss = 0.7049130797386169
Iteration [32695]: Loss = 4.920875072479248
Iteration [32696]: Loss = 0.7049676775932312
Iteration [32697]: Loss = 0.7050610780715942
Iteration [32698]: Loss = 0.7050969004631042
Iteration [32699]: Loss = 0.7050807476043701
Iteration [32700]: Loss = 0.7050177454948425
Iteration [32701]: Loss = 4.920346260070801
Iteration [32702]: Loss = 0.7050678133964539
Iteration [32703]: Loss = 0.7051591873168945
Iteration [32704]: Loss = 0.705193042755127
Iteration [32705]: Loss = 0.7051753401756287
Iteration [32706]: Loss = 4.9193220138549805
Iteration [32707]: Loss = 0.7053022384643555
Iteration [32708]: Loss = 0.7054263353347778
Iteration [32709]: Loss = 0.7054898142814636
Iteration [32710]: Loss = 0.7054985761642456
Iteration [32711]: Loss = 0.7054581642150879
Iteration [32712]: Loss = 0.7053733468055725
Iteration [32713]: Loss = 4.918610095977783
Iteration [32714]: Loss = 4.917902946472168
Iteration [32715]: Loss = 0.7057574391365051
Iteration [32716]: Loss = 0.7060440182685852
Iteration [32717]: Loss = 0.7062539458274841
Iteration [32718]: Loss = 0.7063946723937988
Iteration [32719]: Loss = 0.7064729928970337
Iteration [32720]: Loss = 0.7064952850341797
Iteration [32721]: Loss = 0.706466794013977
Iteration [32722]: Loss = 4.9127092361450195
Iteration [32723]: Loss = 0.7065751552581787
Iteration [32724]: Loss = 4.911175727844238
Iteration [32725]: Loss = 0.707042932510376
Iteration [32726]: Loss = 4.907982349395752
Iteration [32727]: Loss = 0.7078009247779846
Iteration [32728]: Loss = 4.903457164764404
Iteration [32729]: Loss = 0.7087926268577576
Iteration [32730]: Loss = 4.897867679595947
Iteration [32731]: Loss = 0.7099729776382446
Iteration [32732]: Loss = 0.7105449438095093
Iteration [32733]: Loss = 0.7110119462013245
Iteration [32734]: Loss = 0.711384117603302
Iteration [32735]: Loss = 0.7116709351539612
Iteration [32736]: Loss = 0.7118805646896362
Iteration [32737]: Loss = 0.7120208144187927
Iteration [32738]: Loss = 4.883519649505615
Iteration [32739]: Loss = 0.7124147415161133
Iteration [32740]: Loss = 0.7126510143280029
Iteration [32741]: Loss = 0.7128152847290039
Iteration [32742]: Loss = 0.7129144668579102
Iteration [32743]: Loss = 0.7129552364349365
Iteration [32744]: Loss = 0.7129430770874023
Iteration [32745]: Loss = 4.879533767700195
Iteration [32746]: Loss = 0.7130765914916992
Iteration [32747]: Loss = 0.7132017016410828
Iteration [32748]: Loss = 0.7132658362388611
Iteration [32749]: Loss = 0.7132748365402222
Iteration [32750]: Loss = 0.7132341861724854
Iteration [32751]: Loss = 0.713148832321167
Iteration [32752]: Loss = 0.7130231857299805
Iteration [32753]: Loss = 0.7128613591194153
Iteration [32754]: Loss = 0.7126671075820923
Iteration [32755]: Loss = 0.7124432921409607
Iteration [32756]: Loss = 0.7121933698654175
Iteration [32757]: Loss = 0.7119195461273193
Iteration [32758]: Loss = 4.885930061340332
Iteration [32759]: Loss = 0.7116065621376038
Iteration [32760]: Loss = 0.7115418314933777
Iteration [32761]: Loss = 0.7114351391792297
Iteration [32762]: Loss = 0.7112902998924255
Iteration [32763]: Loss = 0.7111113667488098
Iteration [32764]: Loss = 0.7109017968177795
Iteration [32765]: Loss = 0.7106644511222839
Iteration [32766]: Loss = 0.7104023098945618
Iteration [32767]: Loss = 0.7101176977157593
Iteration [32768]: Loss = 0.7098129391670227
Iteration [32769]: Loss = 0.709490180015564
Iteration [32770]: Loss = 0.7091510891914368
Iteration [32771]: Loss = 0.7087975740432739
Iteration [32772]: Loss = 0.7084307670593262
Iteration [32773]: Loss = 0.7080521583557129
Iteration [32774]: Loss = 0.7076629996299744
Iteration [32775]: Loss = 0.7072644233703613
Iteration [32776]: Loss = 0.7068573236465454
Iteration [32777]: Loss = 0.7064424753189087
Iteration [32778]: Loss = 4.9146270751953125
Iteration [32779]: Loss = 0.7058908343315125
Iteration [32780]: Loss = 0.7057256698608398
Iteration [32781]: Loss = 4.9171648025512695
Iteration [32782]: Loss = 0.7055999636650085
Iteration [32783]: Loss = 0.7056160569190979
Iteration [32784]: Loss = 0.7055824995040894
Iteration [32785]: Loss = 0.7055040597915649
Iteration [32786]: Loss = 0.7053852677345276
Iteration [32787]: Loss = 0.7052302360534668
Iteration [32788]: Loss = 0.7050424814224243
Iteration [32789]: Loss = 0.7048255205154419
Iteration [32790]: Loss = 0.7045819163322449
Iteration [32791]: Loss = 0.7043145895004272
Iteration [32792]: Loss = 0.70402592420578
Iteration [32793]: Loss = 0.7037179470062256
Iteration [32794]: Loss = 0.70599764585495
Iteration [32795]: Loss = 0.7030519247055054
Iteration [32796]: Loss = 0.7026970982551575
Iteration [32797]: Loss = 0.7023298144340515
Iteration [32798]: Loss = 0.7019511461257935
Iteration [32799]: Loss = 0.7015625238418579
Iteration [32800]: Loss = 0.701164722442627
Iteration [32801]: Loss = 0.7007588744163513
Iteration [32802]: Loss = 0.7003456354141235
Iteration [32803]: Loss = 0.6999258399009705
Iteration [32804]: Loss = 0.699500322341919
Iteration [32805]: Loss = 0.6990694999694824
Iteration [32806]: Loss = 4.953033447265625
Iteration [32807]: Loss = 0.6984929442405701
Iteration [32808]: Loss = 0.6983184814453125
Iteration [32809]: Loss = 0.698113739490509
Iteration [32810]: Loss = 4.956982612609863
Iteration [32811]: Loss = 0.6979231238365173
Iteration [32812]: Loss = 0.6979128122329712
Iteration [32813]: Loss = 0.697856068611145
Iteration [32814]: Loss = 0.697757363319397
Iteration [32815]: Loss = 4.958353042602539
Iteration [32816]: Loss = 0.6977477669715881
Iteration [32817]: Loss = 0.6978145837783813
Iteration [32818]: Loss = 0.6978272795677185
Iteration [32819]: Loss = 9.217126846313477
Iteration [32820]: Loss = 0.6982985734939575
Iteration [32821]: Loss = 0.6987088322639465
Iteration [32822]: Loss = 0.6990312337875366
Iteration [32823]: Loss = 0.6992745399475098
Iteration [32824]: Loss = 0.6994466781616211
Iteration [32825]: Loss = 0.699554443359375
Iteration [32826]: Loss = 0.699604332447052
Iteration [32827]: Loss = 0.6996021866798401
Iteration [32828]: Loss = 4.948220252990723
Iteration [32829]: Loss = 0.6997550129890442
Iteration [32830]: Loss = 0.6998900771141052
Iteration [32831]: Loss = 0.6999645829200745
Iteration [32832]: Loss = 0.6999842524528503
Iteration [32833]: Loss = 0.6999549865722656
Iteration [32834]: Loss = 4.946502685546875
Iteration [32835]: Loss = 0.7000614404678345
Iteration [32836]: Loss = 0.700176477432251
Iteration [32837]: Loss = 0.7002328634262085
Iteration [32838]: Loss = 0.7002366185188293
Iteration [32839]: Loss = 0.7001926302909851
Iteration [32840]: Loss = 4.945327281951904
Iteration [32841]: Loss = 0.7002741694450378
Iteration [32842]: Loss = 0.7003785371780396
Iteration [32843]: Loss = 0.700425386428833
Iteration [32844]: Loss = 0.7004204392433167
Iteration [32845]: Loss = 0.7003686428070068
Iteration [32846]: Loss = 0.7002748847007751
Iteration [32847]: Loss = 0.7001433372497559
Iteration [32848]: Loss = 0.6999775171279907
Iteration [32849]: Loss = 0.6997811794281006
Iteration [32850]: Loss = 0.6995570659637451
Iteration [32851]: Loss = 0.6993082761764526
Iteration [32852]: Loss = 0.6990370750427246
Iteration [32853]: Loss = 0.698745608329773
Iteration [32854]: Loss = 0.6984362602233887
Iteration [32855]: Loss = 0.6981106996536255
Iteration [32856]: Loss = 0.6977704167366028
Iteration [32857]: Loss = 0.6974170804023743
Iteration [32858]: Loss = 4.96134614944458
Iteration [32859]: Loss = 4.961770057678223
Iteration [32860]: Loss = 0.697145938873291
Iteration [32861]: Loss = 0.6972561478614807
Iteration [32862]: Loss = 0.6973084807395935
Iteration [32863]: Loss = 4.959995746612549
Iteration [32864]: Loss = 0.6975552439689636
Iteration [32865]: Loss = 0.697730302810669
Iteration [32866]: Loss = 0.6978411078453064
Iteration [32867]: Loss = 0.6978939175605774
Iteration [32868]: Loss = 0.6978945136070251
Iteration [32869]: Loss = 0.6978481411933899
Iteration [32870]: Loss = 0.6977592706680298
Iteration [32871]: Loss = 0.6976323127746582
Iteration [32872]: Loss = 0.6974709630012512
Iteration [32873]: Loss = 0.6972787976264954
Iteration [32874]: Loss = 0.6970587968826294
Iteration [32875]: Loss = 9.228387832641602
Iteration [32876]: Loss = 0.6971309781074524
Iteration [32877]: Loss = 0.6973701119422913
Iteration [32878]: Loss = 0.697539210319519
Iteration [32879]: Loss = 0.6976447701454163
Iteration [32880]: Loss = 0.6976935267448425
Iteration [32881]: Loss = 0.6976907849311829
Iteration [32882]: Loss = 0.6976416707038879
Iteration [32883]: Loss = 0.697550892829895
Iteration [32884]: Loss = 0.6974227428436279
Iteration [32885]: Loss = 4.96024751663208
Iteration [32886]: Loss = 0.6973597407341003
Iteration [32887]: Loss = 0.6974023580551147
Iteration [32888]: Loss = 4.959545612335205
Iteration [32889]: Loss = 0.6976310014724731
Iteration [32890]: Loss = 0.6977978348731995
Iteration [32891]: Loss = 0.6979015469551086
Iteration [32892]: Loss = 0.6979485154151917
Iteration [32893]: Loss = 0.6979441046714783
Iteration [32894]: Loss = 4.956920146942139
Iteration [32895]: Loss = 0.6980924010276794
Iteration [32896]: Loss = 4.955181121826172
Iteration [32897]: Loss = 0.6985872983932495
Iteration [32898]: Loss = 0.6988673210144043
Iteration [32899]: Loss = 0.699073076248169
Iteration [32900]: Loss = 0.699211835861206
Iteration [32901]: Loss = 0.6992901563644409
Iteration [32902]: Loss = 0.6993141174316406
Iteration [32903]: Loss = 0.6992892026901245
Iteration [32904]: Loss = 0.6992200016975403
Iteration [32905]: Loss = 0.6991111040115356
Iteration [32906]: Loss = 0.6989665031433105
Iteration [32907]: Loss = 0.6987895965576172
Iteration [32908]: Loss = 0.6985836625099182
Iteration [32909]: Loss = 0.6983518004417419
Iteration [32910]: Loss = 0.6980963945388794
Iteration [32911]: Loss = 0.6978200078010559
Iteration [32912]: Loss = 0.6975244283676147
Iteration [32913]: Loss = 0.6972119808197021
Iteration [32914]: Loss = 0.6968840956687927
Iteration [32915]: Loss = 0.6965425610542297
Iteration [32916]: Loss = 0.6961885690689087
Iteration [32917]: Loss = 4.967823505401611
Iteration [32918]: Loss = 0.6957404613494873
Iteration [32919]: Loss = 4.968899726867676
Iteration [32920]: Loss = 0.6957551836967468
Iteration [32921]: Loss = 0.6958311796188354
Iteration [32922]: Loss = 0.6958531737327576
Iteration [32923]: Loss = 0.6958267688751221
Iteration [32924]: Loss = 4.968175888061523
Iteration [32925]: Loss = 4.967219829559326
Iteration [32926]: Loss = 0.6963441371917725
Iteration [32927]: Loss = 0.6966640949249268
Iteration [32928]: Loss = 0.6969058513641357
Iteration [32929]: Loss = 0.697077214717865
Iteration [32930]: Loss = 0.6971853375434875
Iteration [32931]: Loss = 0.697236180305481
Iteration [32932]: Loss = 0.6972355842590332
Iteration [32933]: Loss = 0.6971885561943054
Iteration [32934]: Loss = 0.6970998644828796
Iteration [32935]: Loss = 0.6969735026359558
Iteration [32936]: Loss = 0.6968134045600891
Iteration [32937]: Loss = 0.6966227293014526
Iteration [32938]: Loss = 0.6964046359062195
Iteration [32939]: Loss = 0.6961619853973389
Iteration [32940]: Loss = 0.6958970427513123
Iteration [32941]: Loss = 0.6956122517585754
Iteration [32942]: Loss = 0.6953093409538269
Iteration [32943]: Loss = 0.6949903964996338
Iteration [32944]: Loss = 0.694657027721405
Iteration [32945]: Loss = 0.6943104863166809
Iteration [32946]: Loss = 4.97772216796875
Iteration [32947]: Loss = 0.693875789642334
Iteration [32948]: Loss = 0.6937608122825623
Iteration [32949]: Loss = 0.6936110258102417
Iteration [32950]: Loss = 0.6934299468994141
Iteration [32951]: Loss = 0.6932206153869629
Iteration [32952]: Loss = 0.692986011505127
Iteration [32953]: Loss = 4.984219074249268
Iteration [32954]: Loss = 0.6927428245544434
Iteration [32955]: Loss = 0.6927093267440796
Iteration [32956]: Loss = 0.6926330327987671
Iteration [32957]: Loss = 0.6925183534622192
Iteration [32958]: Loss = 0.6923689246177673
Iteration [32959]: Loss = 0.6921882033348083
Iteration [32960]: Loss = 0.6919794082641602
Iteration [32961]: Loss = 9.287164688110352
Iteration [32962]: Loss = 4.987735271453857
Iteration [32963]: Loss = 0.6926002502441406
Iteration [32964]: Loss = 4.982596397399902
Iteration [32965]: Loss = 0.6936652660369873
Iteration [32966]: Loss = 4.976469993591309
Iteration [32967]: Loss = 0.6948997974395752
Iteration [32968]: Loss = 0.6954950094223022
Iteration [32969]: Loss = 0.6959856748580933
Iteration [32970]: Loss = 0.6963818073272705
Iteration [32971]: Loss = 0.6966928839683533
Iteration [32972]: Loss = 0.6969273090362549
Iteration [32973]: Loss = 0.6970925331115723
Iteration [32974]: Loss = 0.6971953511238098
Iteration [32975]: Loss = 0.697242021560669
Iteration [32976]: Loss = 0.6972380876541138
Iteration [32977]: Loss = 4.960626602172852
Iteration [32978]: Loss = 4.959591865539551
Iteration [32979]: Loss = 0.6978031396865845
Iteration [32980]: Loss = 0.6981335878372192
Iteration [32981]: Loss = 0.6983852386474609
Iteration [32982]: Loss = 0.6985659599304199
Iteration [32983]: Loss = 4.952778339385986
Iteration [32984]: Loss = 0.6990281343460083
Iteration [32985]: Loss = 0.6992933750152588
Iteration [32986]: Loss = 0.699486255645752
Iteration [32987]: Loss = 4.947900295257568
Iteration [32988]: Loss = 0.6999689340591431
Iteration [32989]: Loss = 0.7002426385879517
Iteration [32990]: Loss = 0.7004432082176208
Iteration [32991]: Loss = 0.7005776166915894
Iteration [32992]: Loss = 0.7006527781486511
Iteration [32993]: Loss = 0.7006741762161255
Iteration [32994]: Loss = 0.7006472945213318
Iteration [32995]: Loss = 0.7005770206451416
Iteration [32996]: Loss = 0.7004674673080444
Iteration [32997]: Loss = 4.944194793701172
Iteration [32998]: Loss = 0.7004333734512329
Iteration [32999]: Loss = 0.700486958026886
Iteration [33000]: Loss = 0.7004891037940979
Iteration [33001]: Loss = 4.943557262420654
Iteration [33002]: Loss = 4.942509651184082
Iteration [33003]: Loss = 0.7010655999183655
Iteration [33004]: Loss = 0.7013980150222778
Iteration [33005]: Loss = 0.7016511559486389
Iteration [33006]: Loss = 0.7018332481384277
Iteration [33007]: Loss = 0.7019509077072144
Iteration [33008]: Loss = 0.7020108103752136
Iteration [33009]: Loss = 0.7020184993743896
Iteration [33010]: Loss = 0.7019792795181274
Iteration [33011]: Loss = 4.935983180999756
Iteration [33012]: Loss = 0.7020644545555115
Iteration [33013]: Loss = 0.7021685242652893
Iteration [33014]: Loss = 0.7022160291671753
Iteration [33015]: Loss = 0.7022125124931335
Iteration [33016]: Loss = 0.7021632194519043
Iteration [33017]: Loss = 0.7020725011825562
Iteration [33018]: Loss = 0.7019446492195129
Iteration [33019]: Loss = 4.936577320098877
Iteration [33020]: Loss = 0.7018787860870361
Iteration [33021]: Loss = 0.7019183039665222
Iteration [33022]: Loss = 0.7019078731536865
Iteration [33023]: Loss = 0.7018522024154663
Iteration [33024]: Loss = 0.7017560005187988
Iteration [33025]: Loss = 4.937411785125732
Iteration [33026]: Loss = 0.7017438411712646
Iteration [33027]: Loss = 0.701806366443634
Iteration [33028]: Loss = 0.7018166780471802
Iteration [33029]: Loss = 0.7017795443534851
Iteration [33030]: Loss = 0.7017000913619995
Iteration [33031]: Loss = 0.7015823721885681
Iteration [33032]: Loss = 0.7014302015304565
Iteration [33033]: Loss = 0.7012470364570618
Iteration [33034]: Loss = 0.7010359168052673
Iteration [33035]: Loss = 4.941704273223877
Iteration [33036]: Loss = 0.700827956199646
Iteration [33037]: Loss = 0.7008073925971985
Iteration [33038]: Loss = 0.700742781162262
Iteration [33039]: Loss = 0.7006384134292603
Iteration [33040]: Loss = 0.7004983425140381
Iteration [33041]: Loss = 4.944177627563477
Iteration [33042]: Loss = 0.7004117965698242
Iteration [33043]: Loss = 0.7004429697990417
Iteration [33044]: Loss = 0.7004249691963196
Iteration [33045]: Loss = 4.952976226806641
Iteration [33046]: Loss = 0.6988295316696167
Iteration [33047]: Loss = 0.698949933052063
Iteration [33048]: Loss = 0.6990123987197876
Iteration [33049]: Loss = 0.6990228295326233
Iteration [33050]: Loss = 0.6989862322807312
Iteration [33051]: Loss = 0.6989072561264038
Iteration [33052]: Loss = 0.6987902522087097
Iteration [33053]: Loss = 0.6986389756202698
Iteration [33054]: Loss = 0.6984567642211914
Iteration [33055]: Loss = 0.6982468366622925
Iteration [33056]: Loss = 4.956298828125
Iteration [33057]: Loss = 0.6980417370796204
Iteration [33058]: Loss = 4.956242084503174
Iteration [33059]: Loss = 0.6982460021972656
Iteration [33060]: Loss = 0.6984012126922607
Iteration [33061]: Loss = 0.6984952688217163
Iteration [33062]: Loss = 0.6985340714454651
Iteration [33063]: Loss = 0.6985230445861816
Iteration [33064]: Loss = 0.6984671950340271
Iteration [33065]: Loss = 0.6983711123466492
Iteration [33066]: Loss = 0.6982385516166687
Iteration [33067]: Loss = 0.6980734467506409
Iteration [33068]: Loss = 4.956997394561768
Iteration [33069]: Loss = 0.697944700717926
Iteration [33070]: Loss = 0.69795823097229
Iteration [33071]: Loss = 4.956757068634033
Iteration [33072]: Loss = 0.6981347799301147
Iteration [33073]: Loss = 0.6982781887054443
Iteration [33074]: Loss = 0.6983615159988403
Iteration [33075]: Loss = 0.6983906030654907
Iteration [33076]: Loss = 0.6983711123466492
Iteration [33077]: Loss = 0.698307454586029
Iteration [33078]: Loss = 0.6982043981552124
Iteration [33079]: Loss = 4.9560160636901855
Iteration [33080]: Loss = 0.6981816291809082
Iteration [33081]: Loss = 0.6982401013374329
Iteration [33082]: Loss = 0.6982470750808716
Iteration [33083]: Loss = 0.6982073783874512
Iteration [33084]: Loss = 4.955700397491455
Iteration [33085]: Loss = 0.6982928514480591
Iteration [33086]: Loss = 4.954274654388428
Iteration [33087]: Loss = 0.6987313628196716
Iteration [33088]: Loss = 0.6989862322807312
Iteration [33089]: Loss = 0.6991699934005737
Iteration [33090]: Loss = 0.6992896795272827
Iteration [33091]: Loss = 0.6993515491485596
Iteration [33092]: Loss = 4.949223041534424
Iteration [33093]: Loss = 0.6996099948883057
Iteration [33094]: Loss = 0.6997880339622498
Iteration [33095]: Loss = 0.6999025344848633
Iteration [33096]: Loss = 4.946091651916504
Iteration [33097]: Loss = 0.7002503871917725
Iteration [33098]: Loss = 0.700466513633728
Iteration [33099]: Loss = 0.7006152272224426
Iteration [33100]: Loss = 0.7007032632827759
Iteration [33101]: Loss = 0.7007365226745605
Iteration [33102]: Loss = 0.7007204294204712
Iteration [33103]: Loss = 4.942434787750244
Iteration [33104]: Loss = 0.7008452415466309
Iteration [33105]: Loss = 0.7009662389755249
Iteration [33106]: Loss = 0.7010290622711182
Iteration [33107]: Loss = 0.701039731502533
Iteration [33108]: Loss = 0.7010033130645752
Iteration [33109]: Loss = 4.9410529136657715
Iteration [33110]: Loss = 0.701093316078186
Iteration [33111]: Loss = 0.7011992931365967
Iteration [33112]: Loss = 0.701248824596405
Iteration [33113]: Loss = 4.939370155334473
Iteration [33114]: Loss = 0.7014853954315186
Iteration [33115]: Loss = 0.7016536593437195
Iteration [33116]: Loss = 0.7017593383789062
Iteration [33117]: Loss = 0.7018085718154907
Iteration [33118]: Loss = 0.7018066048622131
Iteration [33119]: Loss = 0.7017589807510376
Iteration [33120]: Loss = 0.7016700506210327
Iteration [33121]: Loss = 0.7015438675880432
Iteration [33122]: Loss = 0.7013841867446899
Iteration [33123]: Loss = 0.7011944055557251
Iteration [33124]: Loss = 4.940777778625488
Iteration [33125]: Loss = 0.7010223269462585
Iteration [33126]: Loss = 0.7010167837142944
Iteration [33127]: Loss = 0.7009658217430115
Iteration [33128]: Loss = 0.7008739709854126
Iteration [33129]: Loss = 0.7007452249526978
Iteration [33130]: Loss = 0.700583279132843
Iteration [33131]: Loss = 0.7003914713859558
Iteration [33132]: Loss = 0.7001728415489197
Iteration [33133]: Loss = 0.6999301314353943
Iteration [33134]: Loss = 0.6996655464172363
Iteration [33135]: Loss = 0.699381411075592
Iteration [33136]: Loss = 0.699079692363739
Iteration [33137]: Loss = 0.6987622976303101
Iteration [33138]: Loss = 0.6984305381774902
Iteration [33139]: Loss = 0.6980860233306885
Iteration [33140]: Loss = 0.6977300643920898
Iteration [33141]: Loss = 0.6973637938499451
Iteration [33142]: Loss = 0.6969883441925049
Iteration [33143]: Loss = 0.6966044902801514
Iteration [33144]: Loss = 0.6962131857872009
Iteration [33145]: Loss = 0.6958152055740356
Iteration [33146]: Loss = 0.6954113841056824
Iteration [33147]: Loss = 0.6950020790100098
Iteration [33148]: Loss = 0.6945878863334656
Iteration [33149]: Loss = 0.6941695809364319
Iteration [33150]: Loss = 0.6937474012374878
Iteration [33151]: Loss = 0.693321704864502
Iteration [33152]: Loss = 0.6928931474685669
Iteration [33153]: Loss = 0.6924617290496826
Iteration [33154]: Loss = 0.6920278072357178
Iteration [33155]: Loss = 4.990273475646973
Iteration [33156]: Loss = 0.6914426684379578
Iteration [33157]: Loss = 4.9920268058776855
Iteration [33158]: Loss = 0.6913434267044067
Iteration [33159]: Loss = 0.6913706660270691
Iteration [33160]: Loss = 9.291781425476074
Iteration [33161]: Loss = 0.6918538808822632
Iteration [33162]: Loss = 0.692263126373291
Iteration [33163]: Loss = 0.6925868988037109
Iteration [33164]: Loss = 0.6928334832191467
Iteration [33165]: Loss = 0.6930105686187744
Iteration [33166]: Loss = 0.6931250095367432
Iteration [33167]: Loss = 4.981805324554443
Iteration [33168]: Loss = 0.6934739947319031
Iteration [33169]: Loss = 0.6936908960342407
Iteration [33170]: Loss = 0.6938413381576538
Iteration [33171]: Loss = 0.6939316987991333
Iteration [33172]: Loss = 0.6939680576324463
Iteration [33173]: Loss = 0.6939553618431091
Iteration [33174]: Loss = 0.6938990950584412
Iteration [33175]: Loss = 0.693803071975708
Iteration [33176]: Loss = 0.693671464920044
Iteration [33177]: Loss = 0.6935078501701355
Iteration [33178]: Loss = 0.6933152675628662
Iteration [33179]: Loss = 4.98226261138916
Iteration [33180]: Loss = 0.6931402683258057
Iteration [33181]: Loss = 0.693134069442749
Iteration [33182]: Loss = 0.6930835247039795
Iteration [33183]: Loss = 0.6929928064346313
Iteration [33184]: Loss = 0.6928660869598389
Iteration [33185]: Loss = 0.6927068829536438
Iteration [33186]: Loss = 0.6925183534622192
Iteration [33187]: Loss = 0.6923036575317383
Iteration [33188]: Loss = 0.6920652389526367
Iteration [33189]: Loss = 0.6918054223060608
Iteration [33190]: Loss = 0.6915265321731567
Iteration [33191]: Loss = 0.6912305951118469
Iteration [33192]: Loss = 0.6909188032150269
Iteration [33193]: Loss = 0.6905933022499084
Iteration [33194]: Loss = 0.690255343914032
Iteration [33195]: Loss = 0.6899059414863586
Iteration [33196]: Loss = 0.6895465850830078
Iteration [33197]: Loss = 0.6891781091690063
Iteration [33198]: Loss = 0.6888017058372498
Iteration [33199]: Loss = 5.007260799407959
Iteration [33200]: Loss = 0.6883139610290527
Iteration [33201]: Loss = 0.6881757378578186
Iteration [33202]: Loss = 0.6880065202713013
Iteration [33203]: Loss = 0.6878091096878052
Iteration [33204]: Loss = 0.6875868439674377
Iteration [33205]: Loss = 0.6873418688774109
Iteration [33206]: Loss = 0.6870765686035156
Iteration [33207]: Loss = 0.6867927312850952
Iteration [33208]: Loss = 0.6864927411079407
Iteration [33209]: Loss = 0.6861776113510132
Iteration [33210]: Loss = 0.6858496069908142
Iteration [33211]: Loss = 0.6855093836784363
Iteration [33212]: Loss = 0.6851584315299988
Iteration [33213]: Loss = 0.6847977638244629
Iteration [33214]: Loss = 0.6844285726547241
Iteration [33215]: Loss = 0.6840516328811646
Iteration [33216]: Loss = 0.6836676001548767
Iteration [33217]: Loss = 0.6832773089408875
Iteration [33218]: Loss = 0.6828815937042236
Iteration [33219]: Loss = 0.6824806928634644
Iteration [33220]: Loss = 5.041589736938477
Iteration [33221]: Loss = 5.042251110076904
Iteration [33222]: Loss = 0.6820867657661438
Iteration [33223]: Loss = 0.6821621656417847
Iteration [33224]: Loss = 0.6821854710578918
Iteration [33225]: Loss = 0.6821621656417847
Iteration [33226]: Loss = 0.6820966601371765
Iteration [33227]: Loss = 0.6819933652877808
Iteration [33228]: Loss = 0.6818557977676392
Iteration [33229]: Loss = 0.6816876530647278
Iteration [33230]: Loss = 0.6814916729927063
Iteration [33231]: Loss = 0.6812708377838135
Iteration [33232]: Loss = 0.6810276508331299
Iteration [33233]: Loss = 0.680764377117157
Iteration [33234]: Loss = 9.420096397399902
Iteration [33235]: Loss = 5.048791408538818
Iteration [33236]: Loss = 0.6812421083450317
Iteration [33237]: Loss = 5.043989658355713
Iteration [33238]: Loss = 0.6822276711463928
Iteration [33239]: Loss = 0.6827175617218018
Iteration [33240]: Loss = 0.683114767074585
Iteration [33241]: Loss = 0.6834287047386169
Iteration [33242]: Loss = 0.6836674809455872
Iteration [33243]: Loss = 5.0319952964782715
Iteration [33244]: Loss = 0.684230625629425
Iteration [33245]: Loss = 0.6845399141311646
Iteration [33246]: Loss = 0.6847745180130005
Iteration [33247]: Loss = 0.6849414110183716
Iteration [33248]: Loss = 0.6850478053092957
Iteration [33249]: Loss = 0.6850994229316711
Iteration [33250]: Loss = 5.025145053863525
Iteration [33251]: Loss = 5.023841857910156
Iteration [33252]: Loss = 0.685796856880188
Iteration [33253]: Loss = 0.6861621141433716
Iteration [33254]: Loss = 0.6864469051361084
Iteration [33255]: Loss = 0.6866593956947327
Iteration [33256]: Loss = 0.6868064999580383
Iteration [33257]: Loss = 0.6868947148323059
Iteration [33258]: Loss = 5.015268325805664
Iteration [33259]: Loss = 0.6871994733810425
Iteration [33260]: Loss = 0.6873981356620789
Iteration [33261]: Loss = 5.012019157409668
Iteration [33262]: Loss = 0.6878914833068848
Iteration [33263]: Loss = 5.008590221405029
Iteration [33264]: Loss = 0.6886583566665649
Iteration [33265]: Loss = 0.6868518590927124
Iteration [33266]: Loss = 0.6871481537818909
Iteration [33267]: Loss = 0.687362015247345
Iteration [33268]: Loss = 0.6866186261177063
Iteration [33269]: Loss = 0.6884623765945435
Iteration [33270]: Loss = 0.6885144114494324
Iteration [33271]: Loss = 5.00672721862793
Iteration [33272]: Loss = 0.6887569427490234
Iteration [33273]: Loss = 0.6889287233352661
Iteration [33274]: Loss = 5.003925323486328
Iteration [33275]: Loss = 0.6893755793571472
Iteration [33276]: Loss = 0.6896344423294067
Iteration [33277]: Loss = 0.6898232698440552
Iteration [33278]: Loss = 0.6899487376213074
Iteration [33279]: Loss = 0.6900174021720886
Iteration [33280]: Loss = 0.6900349259376526
Iteration [33281]: Loss = 0.6900061368942261
Iteration [33282]: Loss = 4.999121189117432
Iteration [33283]: Loss = 0.6901099681854248
Iteration [33284]: Loss = 0.6902225017547607
Iteration [33285]: Loss = 0.690279483795166
Iteration [33286]: Loss = 0.6902862191200256
Iteration [33287]: Loss = 0.6902478337287903
Iteration [33288]: Loss = 0.6901688575744629
Iteration [33289]: Loss = 0.6900533437728882
Iteration [33290]: Loss = 0.6899046897888184
Iteration [33291]: Loss = 0.6897264719009399
Iteration [33292]: Loss = 5.001338958740234
Iteration [33293]: Loss = 0.6895753741264343
Iteration [33294]: Loss = 0.6895793676376343
Iteration [33295]: Loss = 0.6895385384559631
Iteration [33296]: Loss = 0.6894574165344238
Iteration [33297]: Loss = 0.689339816570282
Iteration [33298]: Loss = 0.6891897320747375
Iteration [33299]: Loss = 0.6890100240707397
Iteration [33300]: Loss = 0.6888037323951721
Iteration [33301]: Loss = 0.6885737180709839
Iteration [33302]: Loss = 0.6883221864700317
Iteration [33303]: Loss = 0.6880513429641724
Iteration [33304]: Loss = 0.6877632141113281
Iteration [33305]: Loss = 0.687459409236908
Iteration [33306]: Loss = 0.687141478061676
Iteration [33307]: Loss = 5.0159077644348145
Iteration [33308]: Loss = 0.6867532134056091
Iteration [33309]: Loss = 0.6866565942764282
Iteration [33310]: Loss = 0.6865254640579224
Iteration [33311]: Loss = 0.6863631010055542
Iteration [33312]: Loss = 0.6861727833747864
Iteration [33313]: Loss = 0.6859570145606995
Iteration [33314]: Loss = 0.6857185363769531
Iteration [33315]: Loss = 0.6854596138000488
Iteration [33316]: Loss = 0.6851823925971985
Iteration [33317]: Loss = 0.6848885416984558
Iteration [33318]: Loss = 0.6845797300338745
Iteration [33319]: Loss = 0.6842576861381531
Iteration [33320]: Loss = 0.683923602104187
Iteration [33321]: Loss = 0.6835787296295166
Iteration [33322]: Loss = 0.683224081993103
Iteration [33323]: Loss = 0.682860791683197
Iteration [33324]: Loss = 0.6824895739555359
Iteration [33325]: Loss = 0.682111382484436
Iteration [33326]: Loss = 0.68172687292099
Iteration [33327]: Loss = 5.045619964599609
Iteration [33328]: Loss = 0.6812267899513245
Iteration [33329]: Loss = 0.6810837984085083
Iteration [33330]: Loss = 0.6809110641479492
Iteration [33331]: Loss = 0.6807116866111755
Iteration [33332]: Loss = 0.680488109588623
Iteration [33333]: Loss = 0.6802428960800171
Iteration [33334]: Loss = 0.6799784302711487
Iteration [33335]: Loss = 0.6796963214874268
Iteration [33336]: Loss = 0.6793983578681946
Iteration [33337]: Loss = 0.6790863275527954
Iteration [33338]: Loss = 0.6787616014480591
Iteration [33339]: Loss = 0.6784253716468811
Iteration [33340]: Loss = 0.6780788898468018
Iteration [33341]: Loss = 5.065445899963379
Iteration [33342]: Loss = 0.6776448488235474
Iteration [33343]: Loss = 5.066506385803223
Iteration [33344]: Loss = 0.6776686310768127
Iteration [33345]: Loss = 0.6777492761611938
Iteration [33346]: Loss = 0.6777781248092651
Iteration [33347]: Loss = 0.6777604222297668
Iteration [33348]: Loss = 0.6777007579803467
Iteration [33349]: Loss = 0.6776032447814941
Iteration [33350]: Loss = 0.6774718165397644
Iteration [33351]: Loss = 0.6773096323013306
Iteration [33352]: Loss = 0.6771199107170105
Iteration [33353]: Loss = 0.6769055128097534
Iteration [33354]: Loss = 5.071263313293457
Iteration [33355]: Loss = 0.6766970157623291
Iteration [33356]: Loss = 0.6766788959503174
Iteration [33357]: Loss = 0.6766188740730286
Iteration [33358]: Loss = 0.6765213012695312
Iteration [33359]: Loss = 0.6763895750045776
Iteration [33360]: Loss = 0.6762273907661438
Iteration [33361]: Loss = 0.6760379076004028
Iteration [33362]: Loss = 0.6758233308792114
Iteration [33363]: Loss = 0.6755865812301636
Iteration [33364]: Loss = 0.6753299236297607
Iteration [33365]: Loss = 0.6750551462173462
Iteration [33366]: Loss = 0.6747642755508423
Iteration [33367]: Loss = 0.6744588017463684
Iteration [33368]: Loss = 0.674140214920044
Iteration [33369]: Loss = 0.6738097667694092
Iteration [33370]: Loss = 0.6734687685966492
Iteration [33371]: Loss = 0.6731183528900146
Iteration [33372]: Loss = 0.6727592945098877
Iteration [33373]: Loss = 0.6723926067352295
Iteration [33374]: Loss = 0.6720189452171326
Iteration [33375]: Loss = 5.099210262298584
Iteration [33376]: Loss = 5.099759578704834
Iteration [33377]: Loss = 0.671694815158844
Iteration [33378]: Loss = 0.6717900633811951
Iteration [33379]: Loss = 0.6718323230743408
Iteration [33380]: Loss = 0.6718271970748901
Iteration [33381]: Loss = 5.098429203033447
Iteration [33382]: Loss = 0.6719778776168823
Iteration [33383]: Loss = 0.672113299369812
Iteration [33384]: Loss = 9.52005386352539
Iteration [33385]: Loss = 0.6727825403213501
Iteration [33386]: Loss = 0.6732715964317322
Iteration [33387]: Loss = 0.6736693382263184
Iteration [33388]: Loss = 0.6739845275878906
Iteration [33389]: Loss = 0.674225389957428
Iteration [33390]: Loss = 0.6743992567062378
Iteration [33391]: Loss = 0.6745127439498901
Iteration [33392]: Loss = 0.6745718717575073
Iteration [33393]: Loss = 0.6745818853378296
Iteration [33394]: Loss = 0.6745477914810181
Iteration [33395]: Loss = 0.6744738817214966
Iteration [33396]: Loss = 0.6743643283843994
Iteration [33397]: Loss = 0.6742223501205444
Iteration [33398]: Loss = 0.6740515232086182
Iteration [33399]: Loss = 0.6738544702529907
Iteration [33400]: Loss = 0.6736339330673218
Iteration [33401]: Loss = 0.673392117023468
Iteration [33402]: Loss = 5.090884208679199
Iteration [33403]: Loss = 5.090851783752441
Iteration [33404]: Loss = 0.6733816266059875
Iteration [33405]: Loss = 0.6735588312149048
Iteration [33406]: Loss = 0.6736752986907959
Iteration [33407]: Loss = 0.673737108707428
Iteration [33408]: Loss = 0.6737498044967651
Iteration [33409]: Loss = 5.087618827819824
Iteration [33410]: Loss = 0.6739286184310913
Iteration [33411]: Loss = 0.6740753054618835
Iteration [33412]: Loss = 0.6741642951965332
Iteration [33413]: Loss = 0.6742014288902283
Iteration [33414]: Loss = 0.6741916537284851
Iteration [33415]: Loss = 0.6741397976875305
Iteration [33416]: Loss = 0.6740499138832092
Iteration [33417]: Loss = 0.6739258170127869
Iteration [33418]: Loss = 0.6737711429595947
Iteration [33419]: Loss = 0.6735885739326477
Iteration [33420]: Loss = 0.6733811497688293
Iteration [33421]: Loss = 5.090773105621338
Iteration [33422]: Loss = 0.6731845736503601
Iteration [33423]: Loss = 0.6744653582572937
Iteration [33424]: Loss = 0.674410343170166
Iteration [33425]: Loss = 0.6743178367614746
Iteration [33426]: Loss = 0.6741912961006165
Iteration [33427]: Loss = 0.6740341186523438
Iteration [33428]: Loss = 0.6738494634628296
Iteration [33429]: Loss = 0.6736401319503784
Iteration [33430]: Loss = 0.6734085083007812
Iteration [33431]: Loss = 0.67315673828125
Iteration [33432]: Loss = 5.092246055603027
Iteration [33433]: Loss = 5.092257499694824
Iteration [33434]: Loss = 0.6731222867965698
Iteration [33435]: Loss = 0.6732931733131409
Iteration [33436]: Loss = 5.089366436004639
Iteration [33437]: Loss = 5.08748197555542
Iteration [33438]: Loss = 0.6742851734161377
Iteration [33439]: Loss = 0.6747310757637024
Iteration [33440]: Loss = 5.080001354217529
Iteration [33441]: Loss = 0.6756500005722046
Iteration [33442]: Loss = 0.6761116981506348
Iteration [33443]: Loss = 5.072279930114746
Iteration [33444]: Loss = 0.677057147026062
Iteration [33445]: Loss = 0.67753005027771
Iteration [33446]: Loss = 5.064401149749756
Iteration [33447]: Loss = 0.678493857383728
Iteration [33448]: Loss = 5.058563232421875
Iteration [33449]: Loss = 0.6796427369117737
Iteration [33450]: Loss = 5.051828384399414
Iteration [33451]: Loss = 0.6809404492378235
Iteration [33452]: Loss = 0.6815628409385681
Iteration [33453]: Loss = 0.6820802688598633
Iteration [33454]: Loss = 5.0392584800720215
Iteration [33455]: Loss = 0.6831188201904297
Iteration [33456]: Loss = 5.033126354217529
Iteration [33457]: Loss = 9.374382019042969
Iteration [33458]: Loss = 5.023248195648193
Iteration [33459]: Loss = 0.686697781085968
Iteration [33460]: Loss = 0.6877776980400085
Iteration [33461]: Loss = 0.6887079477310181
Iteration [33462]: Loss = 9.313374519348145
Iteration [33463]: Loss = 0.6907130479812622
Iteration [33464]: Loss = 0.6917610168457031
Iteration [33465]: Loss = 0.6926624774932861
Iteration [33466]: Loss = 0.6934316754341125
Iteration [33467]: Loss = 0.6940813660621643
Iteration [33468]: Loss = 0.6946234703063965
Iteration [33469]: Loss = 0.6950684189796448
Iteration [33470]: Loss = 0.6954256296157837
Iteration [33471]: Loss = 0.69570392370224
Iteration [33472]: Loss = 0.6959109306335449
Iteration [33473]: Loss = 0.6960535645484924
Iteration [33474]: Loss = 0.6961385607719421
Iteration [33475]: Loss = 0.696171224117279
Iteration [33476]: Loss = 0.6961570978164673
Iteration [33477]: Loss = 0.6961005330085754
Iteration [33478]: Loss = 0.6960059404373169
Iteration [33479]: Loss = 0.6958770751953125
Iteration [33480]: Loss = 4.968382358551025
Iteration [33481]: Loss = 0.6958042979240417
Iteration [33482]: Loss = 0.6958388686180115
Iteration [33483]: Loss = 0.6958264112472534
Iteration [33484]: Loss = 0.6957714557647705
Iteration [33485]: Loss = 0.6956782341003418
Iteration [33486]: Loss = 0.6955505609512329
Iteration [33487]: Loss = 0.6953920125961304
Iteration [33488]: Loss = 0.695205569267273
Iteration [33489]: Loss = 0.6949940323829651
Iteration [33490]: Loss = 4.973444938659668
Iteration [33491]: Loss = 0.6947802305221558
Iteration [33492]: Loss = 4.9734697341918945
Iteration [33493]: Loss = 0.6949629783630371
Iteration [33494]: Loss = 0.6951065063476562
Iteration [33495]: Loss = 0.6951922178268433
Iteration [33496]: Loss = 0.695225715637207
Iteration [33497]: Loss = 0.6952123641967773
Iteration [33498]: Loss = 0.695156455039978
Iteration [33499]: Loss = 0.6950625777244568
Iteration [33500]: Loss = 0.6949343085289001
Iteration [33501]: Loss = 0.6947751045227051
Iteration [33502]: Loss = 0.6945881247520447
Iteration [33503]: Loss = 0.6943762898445129
Iteration [33504]: Loss = 0.6941416263580322
Iteration [33505]: Loss = 0.693886935710907
Iteration [33506]: Loss = 0.6936138868331909
Iteration [33507]: Loss = 0.6933245658874512
Iteration [33508]: Loss = 0.6930203437805176
Iteration [33509]: Loss = 0.6927030682563782
Iteration [33510]: Loss = 0.6923736929893494
Iteration [33511]: Loss = 0.6920337080955505
Iteration [33512]: Loss = 0.6916841268539429
Iteration [33513]: Loss = 0.6913260221481323
Iteration [33514]: Loss = 4.993644714355469
Iteration [33515]: Loss = 0.6908634901046753
Iteration [33516]: Loss = 0.690733015537262
Iteration [33517]: Loss = 0.6905722618103027
Iteration [33518]: Loss = 0.6903839707374573
Iteration [33519]: Loss = 0.69017094373703
Iteration [33520]: Loss = 0.6899358630180359
Iteration [33521]: Loss = 0.689680814743042
Iteration [33522]: Loss = 9.31449031829834
Iteration [33523]: Loss = 0.6896678805351257
Iteration [33524]: Loss = 0.68985915184021
Iteration [33525]: Loss = 0.689988374710083
Iteration [33526]: Loss = 0.6900618672370911
Iteration [33527]: Loss = 0.6900847554206848
Iteration [33528]: Loss = 4.99844217300415
Iteration [33529]: Loss = 0.6902724504470825
Iteration [33530]: Loss = 0.690418541431427
Iteration [33531]: Loss = 0.6905069947242737
Iteration [33532]: Loss = 0.6905435919761658
Iteration [33533]: Loss = 0.6905333995819092
Iteration [33534]: Loss = 0.6904811859130859
Iteration [33535]: Loss = 0.6903910636901855
Iteration [33536]: Loss = 0.6902667284011841
Iteration [33537]: Loss = 0.6901116967201233
Iteration [33538]: Loss = 0.6899288892745972
Iteration [33539]: Loss = 5.000268459320068
Iteration [33540]: Loss = 0.6897653937339783
Iteration [33541]: Loss = 0.6897619962692261
Iteration [33542]: Loss = 0.6897158622741699
Iteration [33543]: Loss = 5.00075101852417
Iteration [33544]: Loss = 0.6897855997085571
Iteration [33545]: Loss = 0.689881443977356
Iteration [33546]: Loss = 0.6899245977401733
Iteration [33547]: Loss = 0.6899206042289734
Iteration [33548]: Loss = 0.6898738741874695
Iteration [33549]: Loss = 4.999908447265625
Iteration [33550]: Loss = 0.6899425387382507
Iteration [33551]: Loss = 0.6900379657745361
Iteration [33552]: Loss = 0.6900807619094849
Iteration [33553]: Loss = 0.6900762319564819
Iteration [33554]: Loss = 0.6900292634963989
Iteration [33555]: Loss = 0.6899435520172119
Iteration [33556]: Loss = 0.6898235082626343
Iteration [33557]: Loss = 0.6896721720695496
Iteration [33558]: Loss = 0.6894928216934204
Iteration [33559]: Loss = 0.6892884373664856
Iteration [33560]: Loss = 0.6890610456466675
Iteration [33561]: Loss = 0.6888134479522705
Iteration [33562]: Loss = 0.6885473728179932
Iteration [33563]: Loss = 5.008082866668701
Iteration [33564]: Loss = 0.6882420778274536
Iteration [33565]: Loss = 0.6881785988807678
Iteration [33566]: Loss = 0.6880785822868347
Iteration [33567]: Loss = 0.6879453659057617
Iteration [33568]: Loss = 0.6877824068069458
Iteration [33569]: Loss = 0.6875927448272705
Iteration [33570]: Loss = 0.6873790621757507
Iteration [33571]: Loss = 0.6871435046195984
Iteration [33572]: Loss = 0.686888575553894
Iteration [33573]: Loss = 5.016960620880127
Iteration [33574]: Loss = 0.6866028308868408
Iteration [33575]: Loss = 0.6865478754043579
Iteration [33576]: Loss = 5.017826080322266
Iteration [33577]: Loss = 0.6866040229797363
Iteration [33578]: Loss = 0.6866947412490845
Iteration [33579]: Loss = 0.6867334246635437
Iteration [33580]: Loss = 0.686725378036499
Iteration [33581]: Loss = 0.6866751909255981
Iteration [33582]: Loss = 0.6865872144699097
Iteration [33583]: Loss = 0.686464786529541
Iteration [33584]: Loss = 0.6863118410110474
Iteration [33585]: Loss = 0.6861311197280884
Iteration [33586]: Loss = 0.6859254837036133
Iteration [33587]: Loss = 0.6856974363327026
Iteration [33588]: Loss = 0.6854491233825684
Iteration [33589]: Loss = 0.6851828694343567
Iteration [33590]: Loss = 0.6849000453948975
Iteration [33591]: Loss = 0.6846027374267578
Iteration [33592]: Loss = 0.6842921376228333
Iteration [33593]: Loss = 0.6839697360992432
Iteration [33594]: Loss = 0.6836366653442383
Iteration [33595]: Loss = 0.6832939386367798
Iteration [33596]: Loss = 0.6829426288604736
Iteration [33597]: Loss = 0.6825836300849915
Iteration [33598]: Loss = 0.6822177767753601
Iteration [33599]: Loss = 0.6818456053733826
Iteration [33600]: Loss = 5.04490327835083
Iteration [33601]: Loss = 0.6813619136810303
Iteration [33602]: Loss = 0.6812236309051514
Iteration [33603]: Loss = 0.6810564994812012
Iteration [33604]: Loss = 0.6808634996414185
Iteration [33605]: Loss = 0.6806470155715942
Iteration [33606]: Loss = 0.6804094314575195
Iteration [33607]: Loss = 0.6801530718803406
Iteration [33608]: Loss = 0.6798794269561768
Iteration [33609]: Loss = 9.430768013000488
Iteration [33610]: Loss = 0.6798380613327026
Iteration [33611]: Loss = 0.6800187230110168
Iteration [33612]: Loss = 0.6801393032073975
Iteration [33613]: Loss = 0.6802055239677429
Iteration [33614]: Loss = 5.051712989807129
Iteration [33615]: Loss = 0.6804695129394531
Iteration [33616]: Loss = 0.68064945936203
Iteration [33617]: Loss = 0.6807692050933838
Iteration [33618]: Loss = 0.6808347702026367
Iteration [33619]: Loss = 0.6808515191078186
Iteration [33620]: Loss = 0.680824339389801
Iteration [33621]: Loss = 0.6807575821876526
Iteration [33622]: Loss = 0.6806550025939941
Iteration [33623]: Loss = 0.6805204749107361
Iteration [33624]: Loss = 5.0509796142578125
Iteration [33625]: Loss = 0.6804413795471191
Iteration [33626]: Loss = 5.050332069396973
Iteration [33627]: Loss = 0.6807364821434021
Iteration [33628]: Loss = 0.68092942237854
Iteration [33629]: Loss = 0.6810610890388489
Iteration [33630]: Loss = 0.681137204170227
Iteration [33631]: Loss = 0.6811636090278625
Iteration [33632]: Loss = 0.6811450123786926
Iteration [33633]: Loss = 0.6810859441757202
Iteration [33634]: Loss = 0.6809903383255005
Iteration [33635]: Loss = 0.6808618903160095
Iteration [33636]: Loss = 0.68070387840271
Iteration [33637]: Loss = 9.419661521911621
Iteration [33638]: Loss = 0.6808552145957947
Iteration [33639]: Loss = 0.6811160445213318
Iteration [33640]: Loss = 0.6813087463378906
Iteration [33641]: Loss = 0.6814403533935547
Iteration [33642]: Loss = 0.6815170049667358
Iteration [33643]: Loss = 0.6815438270568848
Iteration [33644]: Loss = 5.044587135314941
Iteration [33645]: Loss = 5.043424129486084
Iteration [33646]: Loss = 0.6821593642234802
Iteration [33647]: Loss = 0.6824958324432373
Iteration [33648]: Loss = 0.6827570199966431
Iteration [33649]: Loss = 0.6829500198364258
Iteration [33650]: Loss = 0.6830819249153137
Iteration [33651]: Loss = 0.6831585168838501
Iteration [33652]: Loss = 0.683185338973999
Iteration [33653]: Loss = 0.6831673383712769
Iteration [33654]: Loss = 0.6831088662147522
Iteration [33655]: Loss = 0.6830142736434937
Iteration [33656]: Loss = 0.6828866600990295
Iteration [33657]: Loss = 5.038023471832275
Iteration [33658]: Loss = 0.6828180551528931
Iteration [33659]: Loss = 0.682855486869812
Iteration [33660]: Loss = 0.6828469038009644
Iteration [33661]: Loss = 5.037657260894775
Iteration [33662]: Loss = 0.6829813718795776
Iteration [33663]: Loss = 0.6831051707267761
Iteration [33664]: Loss = 0.6831745505332947
Iteration [33665]: Loss = 0.6831948161125183
Iteration [33666]: Loss = 0.6831709146499634
Iteration [33667]: Loss = 0.6831072568893433
Iteration [33668]: Loss = 0.6830076575279236
Iteration [33669]: Loss = 0.6828758716583252
Iteration [33670]: Loss = 0.6827149987220764
Iteration [33671]: Loss = 0.6825278997421265
Iteration [33672]: Loss = 0.6823173761367798
Iteration [33673]: Loss = 0.6820856332778931
Iteration [33674]: Loss = 0.6818348169326782
Iteration [33675]: Loss = 0.6815669536590576
Iteration [33676]: Loss = 0.6812835335731506
Iteration [33677]: Loss = 0.6809863448143005
Iteration [33678]: Loss = 0.6806766390800476
Iteration [33679]: Loss = 0.6803557276725769
Iteration [33680]: Loss = 0.6800247430801392
Iteration [33681]: Loss = 0.6796846985816956
Iteration [33682]: Loss = 0.6793366074562073
Iteration [33683]: Loss = 0.6789812445640564
Iteration [33684]: Loss = 0.6786192059516907
Iteration [33685]: Loss = 5.062536716461182
Iteration [33686]: Loss = 0.6781519651412964
Iteration [33687]: Loss = 0.6780204176902771
Iteration [33688]: Loss = 5.064691066741943
Iteration [33689]: Loss = 0.6779468655586243
Iteration [33690]: Loss = 0.6779828667640686
Iteration [33691]: Loss = 0.6779735088348389
Iteration [33692]: Loss = 0.6779232025146484
Iteration [33693]: Loss = 0.6778359413146973
Iteration [33694]: Loss = 0.6777154207229614
Iteration [33695]: Loss = 0.677564799785614
Iteration [33696]: Loss = 5.067295551300049
Iteration [33697]: Loss = 0.6774589419364929
Iteration [33698]: Loss = 0.6774814128875732
Iteration [33699]: Loss = 0.6774597764015198
Iteration [33700]: Loss = 0.6773983836174011
Iteration [33701]: Loss = 0.6773011684417725
Iteration [33702]: Loss = 0.6771717071533203
Iteration [33703]: Loss = 9.461705207824707
Iteration [33704]: Loss = 0.6773711442947388
Iteration [33705]: Loss = 0.6776519417762756
Iteration [33706]: Loss = 5.06467342376709
Iteration [33707]: Loss = 5.062371730804443
Iteration [33708]: Loss = 0.6788852214813232
Iteration [33709]: Loss = 0.679387629032135
Iteration [33710]: Loss = 0.6797987818717957
Iteration [33711]: Loss = 0.6801273822784424
Iteration [33712]: Loss = 0.6803818941116333
Iteration [33713]: Loss = 0.6805692315101624
Iteration [33714]: Loss = 0.6806963086128235
Iteration [33715]: Loss = 0.6807689666748047
Iteration [33716]: Loss = 0.680792510509491
Iteration [33717]: Loss = 0.680772066116333
Iteration [33718]: Loss = 0.6807119250297546
Iteration [33719]: Loss = 5.049562454223633
Iteration [33720]: Loss = 0.6807578206062317
Iteration [33721]: Loss = 0.6808439493179321
Iteration [33722]: Loss = 0.6808798313140869
Iteration [33723]: Loss = 0.6808702945709229
Iteration [33724]: Loss = 0.6808198690414429
Iteration [33725]: Loss = 0.6807325482368469
Iteration [33726]: Loss = 0.6806122660636902
Iteration [33727]: Loss = 0.6804621815681458
Iteration [33728]: Loss = 0.6802850961685181
Iteration [33729]: Loss = 5.052475452423096
Iteration [33730]: Loss = 0.6801319122314453
Iteration [33731]: Loss = 0.6801333427429199
Iteration [33732]: Loss = 0.6800928711891174
Iteration [33733]: Loss = 0.6800146102905273
Iteration [33734]: Loss = 0.6799023747444153
Iteration [33735]: Loss = 5.0542521476745605
Iteration [33736]: Loss = 0.67985999584198
Iteration [33737]: Loss = 0.679908812046051
Iteration [33738]: Loss = 0.6799108386039734
Iteration [33739]: Loss = 0.6798709630966187
Iteration [33740]: Loss = 0.6797932386398315
Iteration [33741]: Loss = 0.6796814203262329
Iteration [33742]: Loss = 0.6795390248298645
Iteration [33743]: Loss = 5.056394577026367
Iteration [33744]: Loss = 5.055976390838623
Iteration [33745]: Loss = 0.6797422766685486
Iteration [33746]: Loss = 0.679967999458313
Iteration [33747]: Loss = 0.6801297068595886
Iteration [33748]: Loss = 0.6802335381507874
Iteration [33749]: Loss = 0.6802850961685181
Iteration [33750]: Loss = 0.6802898049354553
Iteration [33751]: Loss = 0.6802523136138916
Iteration [33752]: Loss = 0.6801766157150269
Iteration [33753]: Loss = 0.6800667643547058
Iteration [33754]: Loss = 0.6799259781837463
Iteration [33755]: Loss = 0.6797574162483215
Iteration [33756]: Loss = 0.6795637607574463
Iteration [33757]: Loss = 0.6793476343154907
Iteration [33758]: Loss = 0.6791112422943115
Iteration [33759]: Loss = 0.6788567900657654
Iteration [33760]: Loss = 0.6785857677459717
Iteration [33761]: Loss = 0.6783000230789185
Iteration [33762]: Loss = 0.6780010461807251
Iteration [33763]: Loss = 0.6776901483535767
Iteration [33764]: Loss = 0.6773685812950134
Iteration [33765]: Loss = 5.06922721862793
Iteration [33766]: Loss = 0.6769698262214661
Iteration [33767]: Loss = 0.6768673658370972
Iteration [33768]: Loss = 0.6767334938049316
Iteration [33769]: Loss = 0.6765713095664978
Iteration [33770]: Loss = 0.6763836145401001
Iteration [33771]: Loss = 0.6761729121208191
Iteration [33772]: Loss = 9.47462272644043
Iteration [33773]: Loss = 0.6762328743934631
Iteration [33774]: Loss = 0.6764537692070007
Iteration [33775]: Loss = 0.6766114830970764
Iteration [33776]: Loss = 0.6767122745513916
Iteration [33777]: Loss = 0.6767618060112
Iteration [33778]: Loss = 0.676764965057373
Iteration [33779]: Loss = 0.6767264604568481
Iteration [33780]: Loss = 0.6766505241394043
Iteration [33781]: Loss = 0.6765406131744385
Iteration [33782]: Loss = 0.6764004826545715
Iteration [33783]: Loss = 0.6762328743934631
Iteration [33784]: Loss = 0.6760405898094177
Iteration [33785]: Loss = 0.6758260726928711
Iteration [33786]: Loss = 0.6755917072296143
Iteration [33787]: Loss = 5.078617572784424
Iteration [33788]: Loss = 0.6753414273262024
Iteration [33789]: Loss = 0.6753019094467163
Iteration [33790]: Loss = 5.079250335693359
Iteration [33791]: Loss = 0.6753845810890198
Iteration [33792]: Loss = 0.6754869818687439
Iteration [33793]: Loss = 0.6755378246307373
Iteration [33794]: Loss = 5.077493190765381
Iteration [33795]: Loss = 0.6757744550704956
Iteration [33796]: Loss = 0.6759424805641174
Iteration [33797]: Loss = 0.676052451133728
Iteration [33798]: Loss = 5.074350357055664
Iteration [33799]: Loss = 0.6763900518417358
Iteration [33800]: Loss = 5.0716376304626465
Iteration [33801]: Loss = 0.6770178079605103
Iteration [33802]: Loss = 0.6773521304130554
Iteration [33803]: Loss = 0.6776120066642761
Iteration [33804]: Loss = 0.6778045892715454
Iteration [33805]: Loss = 0.677936851978302
Iteration [33806]: Loss = 0.6780143976211548
Iteration [33807]: Loss = 5.063685417175293
Iteration [33808]: Loss = 0.6782959699630737
Iteration [33809]: Loss = 0.6784825921058655
Iteration [33810]: Loss = 0.678609311580658
Iteration [33811]: Loss = 0.6786818504333496
Iteration [33812]: Loss = 0.6787056922912598
Iteration [33813]: Loss = 0.6786858439445496
Iteration [33814]: Loss = 5.060474872589111
Iteration [33815]: Loss = 0.678800642490387
Iteration [33816]: Loss = 0.6789162158966064
Iteration [33817]: Loss = 0.678978681564331
Iteration [33818]: Loss = 0.6789933443069458
Iteration [33819]: Loss = 0.6789652705192566
Iteration [33820]: Loss = 0.6788983345031738
Iteration [33821]: Loss = 0.6787965893745422
Iteration [33822]: Loss = 0.6786633729934692
Iteration [33823]: Loss = 0.6785019636154175
Iteration [33824]: Loss = 0.6783150434494019
Iteration [33825]: Loss = 0.6781052947044373
Iteration [33826]: Loss = 0.6778749227523804
Iteration [33827]: Loss = 0.6776259541511536
Iteration [33828]: Loss = 0.6773603558540344
Iteration [33829]: Loss = 5.068994045257568
Iteration [33830]: Loss = 0.6770562529563904
Iteration [33831]: Loss = 5.069467544555664
Iteration [33832]: Loss = 0.6771659255027771
Iteration [33833]: Loss = 0.677279531955719
Iteration [33834]: Loss = 0.6773404479026794
Iteration [33835]: Loss = 0.6773539185523987
Iteration [33836]: Loss = 0.6773245334625244
Iteration [33837]: Loss = 0.6772565841674805
Iteration [33838]: Loss = 0.677154004573822
Iteration [33839]: Loss = 0.6770201921463013
Iteration [33840]: Loss = 0.6768580675125122
Iteration [33841]: Loss = 0.6766707301139832
Iteration [33842]: Loss = 0.6764607429504395
Iteration [33843]: Loss = 0.6762300729751587
Iteration [33844]: Loss = 0.6759810447692871
Iteration [33845]: Loss = 0.6757152676582336
Iteration [33846]: Loss = 0.6754347085952759
Iteration [33847]: Loss = 0.6751406788825989
Iteration [33848]: Loss = 0.6748344898223877
Iteration [33849]: Loss = 0.6745176315307617
Iteration [33850]: Loss = 0.674190878868103
Iteration [33851]: Loss = 0.6738554239273071
Iteration [33852]: Loss = 0.6735121607780457
Iteration [33853]: Loss = 0.6731618642807007
Iteration [33854]: Loss = 0.67280513048172
Iteration [33855]: Loss = 5.094723701477051
Iteration [33856]: Loss = 5.095255374908447
Iteration [33857]: Loss = 0.6724915504455566
Iteration [33858]: Loss = 0.6725800633430481
Iteration [33859]: Loss = 0.672618567943573
Iteration [33860]: Loss = 5.093779563903809
Iteration [33861]: Loss = 5.092532634735107
Iteration [33862]: Loss = 0.6732653379440308
Iteration [33863]: Loss = 5.088212013244629
Iteration [33864]: Loss = 5.085212707519531
Iteration [33865]: Loss = 5.081254482269287
Iteration [33866]: Loss = 0.6757321953773499
Iteration [33867]: Loss = 0.6764737963676453
Iteration [33868]: Loss = 0.6771007776260376
Iteration [33869]: Loss = 0.6776242256164551
Iteration [33870]: Loss = 0.6780545711517334
Iteration [33871]: Loss = 0.6784006953239441
Iteration [33872]: Loss = 0.6786712408065796
Iteration [33873]: Loss = 0.6788732409477234
Iteration [33874]: Loss = 0.679013729095459
Iteration [33875]: Loss = 0.6790985465049744
Iteration [33876]: Loss = 0.679133415222168
Iteration [33877]: Loss = 0.6791234016418457
Iteration [33878]: Loss = 0.6790725588798523
Iteration [33879]: Loss = 5.058503150939941
Iteration [33880]: Loss = 5.057680606842041
Iteration [33881]: Loss = 5.055691719055176
Iteration [33882]: Loss = 0.6800496578216553
Iteration [33883]: Loss = 0.6805061101913452
Iteration [33884]: Loss = 0.6808756589889526
Iteration [33885]: Loss = 0.6811671257019043
Iteration [33886]: Loss = 5.045342445373535
Iteration [33887]: Loss = 0.6818131804466248
Iteration [33888]: Loss = 5.04115629196167
Iteration [33889]: Loss = 5.038249492645264
Iteration [33890]: Loss = 0.683394193649292
Iteration [33891]: Loss = 5.031179904937744
Iteration [33892]: Loss = 5.027056694030762
Iteration [33893]: Loss = 5.0221381187438965
Iteration [33894]: Loss = 0.6866997480392456
Iteration [33895]: Loss = 0.6875975131988525
Iteration [33896]: Loss = 0.6883646845817566
Iteration [33897]: Loss = 0.6890140175819397
Iteration [33898]: Loss = 0.6895571947097778
Iteration [33899]: Loss = 0.6900044679641724
Iteration [33900]: Loss = 4.996822834014893
Iteration [33901]: Loss = 0.6909142732620239
Iteration [33902]: Loss = 0.6913669109344482
Iteration [33903]: Loss = 0.6917323470115662
Iteration [33904]: Loss = 4.987995147705078
Iteration [33905]: Loss = 0.6925019025802612
Iteration [33906]: Loss = 0.6928943395614624
Iteration [33907]: Loss = 4.981685161590576
Iteration [33908]: Loss = 0.6937097907066345
Iteration [33909]: Loss = 0.6941215991973877
Iteration [33910]: Loss = 0.6944501399993896
Iteration [33911]: Loss = 0.6947036981582642
Iteration [33912]: Loss = 0.694889485836029
Iteration [33913]: Loss = 0.6950144171714783
Iteration [33914]: Loss = 0.6950843930244446
Iteration [33915]: Loss = 4.971619129180908
Iteration [33916]: Loss = 0.6953477263450623
Iteration [33917]: Loss = 0.6955240368843079
Iteration [33918]: Loss = 0.6956402063369751
Iteration [33919]: Loss = 0.6957022547721863
Iteration [33920]: Loss = 0.6957155466079712
Iteration [33921]: Loss = 0.6956849098205566
Iteration [33922]: Loss = 0.6956146359443665
Iteration [33923]: Loss = 0.6955088376998901
Iteration [33924]: Loss = 4.970212936401367
Iteration [33925]: Loss = 4.969679832458496
Iteration [33926]: Loss = 0.6957870721817017
Iteration [33927]: Loss = 0.696028470993042
Iteration [33928]: Loss = 0.6962032318115234
Iteration [33929]: Loss = 0.6963181495666504
Iteration [33930]: Loss = 0.6963788270950317
Iteration [33931]: Loss = 0.6963908672332764
Iteration [33932]: Loss = 0.6963590383529663
Iteration [33933]: Loss = 4.9653730392456055
Iteration [33934]: Loss = 4.964527130126953
Iteration [33935]: Loss = 0.6968168616294861
Iteration [33936]: Loss = 4.961060523986816
Iteration [33937]: Loss = 0.6975902915000916
Iteration [33938]: Loss = 0.6979837417602539
Iteration [33939]: Loss = 0.6982954740524292
Iteration [33940]: Loss = 0.6985334753990173
Iteration [33941]: Loss = 0.6987050175666809
Iteration [33942]: Loss = 0.6988167762756348
Iteration [33943]: Loss = 0.6988746523857117
Iteration [33944]: Loss = 0.6988838911056519
Iteration [33945]: Loss = 0.6988493204116821
Iteration [33946]: Loss = 4.9522929191589355
Iteration [33947]: Loss = 0.6989331245422363
Iteration [33948]: Loss = 4.9509453773498535
Iteration [33949]: Loss = 0.6993457078933716
Iteration [33950]: Loss = 0.6995850205421448
Iteration [33951]: Loss = 0.6997576951980591
Iteration [33952]: Loss = 0.6998703479766846
Iteration [33953]: Loss = 0.6999289393424988
Iteration [33954]: Loss = 0.6999387741088867
Iteration [33955]: Loss = 0.6999045610427856
Iteration [33956]: Loss = 0.6998308897018433
Iteration [33957]: Loss = 0.6997215747833252
Iteration [33958]: Loss = 0.699580192565918
Iteration [33959]: Loss = 0.6994099617004395
Iteration [33960]: Loss = 0.6992137432098389
Iteration [33961]: Loss = 0.6989941596984863
Iteration [33962]: Loss = 0.6987535357475281
Iteration [33963]: Loss = 0.698494017124176
Iteration [33964]: Loss = 4.955219745635986
Iteration [33965]: Loss = 0.6981940269470215
Iteration [33966]: Loss = 0.6981300115585327
Iteration [33967]: Loss = 0.6980295181274414
Iteration [33968]: Loss = 0.6978961825370789
Iteration [33969]: Loss = 4.957762241363525
Iteration [33970]: Loss = 4.957350254058838
Iteration [33971]: Loss = 0.6981068849563599
Iteration [33972]: Loss = 0.6983299851417542
Iteration [33973]: Loss = 0.6984879970550537
Iteration [33974]: Loss = 0.6985874176025391
Iteration [33975]: Loss = 4.953032970428467
Iteration [33976]: Loss = 4.95163631439209
Iteration [33977]: Loss = 0.6993640661239624
Iteration [33978]: Loss = 0.6997387409210205
Iteration [33979]: Loss = 0.7000333666801453
Iteration [33980]: Loss = 0.700255811214447
Iteration [33981]: Loss = 0.7004132270812988
Iteration [33982]: Loss = 0.7005119323730469
Iteration [33983]: Loss = 0.7005578279495239
Iteration [33984]: Loss = 0.7005561590194702
Iteration [33985]: Loss = 0.7005115747451782
Iteration [33986]: Loss = 0.7004283666610718
Iteration [33987]: Loss = 0.7003104090690613
Iteration [33988]: Loss = 0.7001612186431885
Iteration [33989]: Loss = 0.6999837756156921
Iteration [33990]: Loss = 0.699781060218811
Iteration [33991]: Loss = 0.699555516242981
Iteration [33992]: Loss = 0.6993093490600586
Iteration [33993]: Loss = 0.6990447640419006
Iteration [33994]: Loss = 4.9523539543151855
Iteration [33995]: Loss = 0.6987361907958984
Iteration [33996]: Loss = 0.6986684203147888
Iteration [33997]: Loss = 0.6985646486282349
Iteration [33998]: Loss = 4.954113483428955
Iteration [33999]: Loss = 0.6985306143760681
Iteration [34000]: Loss = 4.953317642211914
Iteration [34001]: Loss = 0.6988489627838135
Iteration [34002]: Loss = 0.6990483999252319
Iteration [34003]: Loss = 0.6991849541664124
Iteration [34004]: Loss = 0.6992650628089905
Iteration [34005]: Loss = 0.6992942094802856
Iteration [34006]: Loss = 0.6992774605751038
Iteration [34007]: Loss = 0.6992194056510925
Iteration [34008]: Loss = 0.6991240382194519
Iteration [34009]: Loss = 0.6989952325820923
Iteration [34010]: Loss = 0.6988361477851868
Iteration [34011]: Loss = 0.6986500024795532
Iteration [34012]: Loss = 0.6984394192695618
Iteration [34013]: Loss = 0.6982067823410034
Iteration [34014]: Loss = 0.6979544162750244
Iteration [34015]: Loss = 0.6976841688156128
Iteration [34016]: Loss = 0.6973978877067566
Iteration [34017]: Loss = 0.6970973610877991
Iteration [34018]: Loss = 0.6967838406562805
Iteration [34019]: Loss = 0.6964585781097412
Iteration [34020]: Loss = 0.6961230039596558
Iteration [34021]: Loss = 0.6957780122756958
Iteration [34022]: Loss = 0.695424497127533
Iteration [34023]: Loss = 0.6950636506080627
Iteration [34024]: Loss = 4.973783016204834
Iteration [34025]: Loss = 0.6945918798446655
Iteration [34026]: Loss = 0.694455623626709
Iteration [34027]: Loss = 0.6942902207374573
Iteration [34028]: Loss = 0.6940984725952148
Iteration [34029]: Loss = 0.6938831210136414
Iteration [34030]: Loss = 4.979345321655273
Iteration [34031]: Loss = 0.6936602592468262
Iteration [34032]: Loss = 0.6936300992965698
Iteration [34033]: Loss = 0.6935601830482483
Iteration [34034]: Loss = 0.6934546232223511
Iteration [34035]: Loss = 0.6933168172836304
Iteration [34036]: Loss = 0.6931500434875488
Iteration [34037]: Loss = 0.6929571032524109
Iteration [34038]: Loss = 0.6927406787872314
Iteration [34039]: Loss = 0.6925032138824463
Iteration [34040]: Loss = 0.6922467350959778
Iteration [34041]: Loss = 0.6919731497764587
Iteration [34042]: Loss = 0.6916841268539429
Iteration [34043]: Loss = 0.6913813352584839
Iteration [34044]: Loss = 0.6910661458969116
Iteration [34045]: Loss = 4.994820594787598
Iteration [34046]: Loss = 0.6906741857528687
Iteration [34047]: Loss = 0.6905725002288818
Iteration [34048]: Loss = 0.6904383897781372
Iteration [34049]: Loss = 0.6902749538421631
Iteration [34050]: Loss = 0.6900853514671326
Iteration [34051]: Loss = 4.999461650848389
Iteration [34052]: Loss = 0.689907968044281
Iteration [34053]: Loss = 4.999324321746826
Iteration [34054]: Loss = 0.6901156902313232
Iteration [34055]: Loss = 0.6902695894241333
Iteration [34056]: Loss = 0.6903655529022217
Iteration [34057]: Loss = 0.6904094815254211
Iteration [34058]: Loss = 0.6904065608978271
Iteration [34059]: Loss = 4.9968438148498535
Iteration [34060]: Loss = 0.6905478835105896
Iteration [34061]: Loss = 0.6906732320785522
Iteration [34062]: Loss = 0.6907436847686768
Iteration [34063]: Loss = 0.6907646656036377
Iteration [34064]: Loss = 0.6907407641410828
Iteration [34065]: Loss = 0.6906768083572388
Iteration [34066]: Loss = 4.995693683624268
Iteration [34067]: Loss = 0.6907137632369995
Iteration [34068]: Loss = 0.6907946467399597
Iteration [34069]: Loss = 0.6908249855041504
Iteration [34070]: Loss = 9.298084259033203
Iteration [34071]: Loss = 0.691288411617279
Iteration [34072]: Loss = 9.287959098815918
Iteration [34073]: Loss = 0.6925109624862671
Iteration [34074]: Loss = 0.6932202577590942
Iteration [34075]: Loss = 4.9784369468688965
Iteration [34076]: Loss = 0.6945766806602478
Iteration [34077]: Loss = 0.6936874389648438
Iteration [34078]: Loss = 0.6942002177238464
Iteration [34079]: Loss = 0.6945983171463013
Iteration [34080]: Loss = 4.9727396965026855
Iteration [34081]: Loss = 0.6954940557479858
Iteration [34082]: Loss = 0.6959722638130188
Iteration [34083]: Loss = 0.6963394284248352
Iteration [34084]: Loss = 0.6966065168380737
Iteration [34085]: Loss = 0.6967834830284119
Iteration [34086]: Loss = 0.6968792080879211
Iteration [34087]: Loss = 4.962137222290039
Iteration [34088]: Loss = 0.6972556710243225
Iteration [34089]: Loss = 0.6975113153457642
Iteration [34090]: Loss = 0.6992888450622559
Iteration [34091]: Loss = 0.6992484331130981
Iteration [34092]: Loss = 0.6991823315620422
Iteration [34093]: Loss = 0.6991320848464966
Iteration [34094]: Loss = 0.6990233063697815
Iteration [34095]: Loss = 0.6988620162010193
Iteration [34096]: Loss = 0.6986534595489502
Iteration [34097]: Loss = 0.6984021067619324
Iteration [34098]: Loss = 4.961610794067383
Iteration [34099]: Loss = 0.6979399919509888
Iteration [34100]: Loss = 0.697959303855896
Iteration [34101]: Loss = 0.6979342699050903
Iteration [34102]: Loss = 0.6978692412376404
Iteration [34103]: Loss = 0.6977682709693909
Iteration [34104]: Loss = 9.218925476074219
Iteration [34105]: Loss = 9.214722633361816
Iteration [34106]: Loss = 0.6988043785095215
Iteration [34107]: Loss = 0.6994876265525818
Iteration [34108]: Loss = 0.7000614404678345
Iteration [34109]: Loss = 0.70053631067276
Iteration [34110]: Loss = 0.7009223699569702
Iteration [34111]: Loss = 0.7012280225753784
Iteration [34112]: Loss = 0.7014611959457397
Iteration [34113]: Loss = 0.7016291618347168
Iteration [34114]: Loss = 4.934715270996094
Iteration [34115]: Loss = 0.707258403301239
Iteration [34116]: Loss = 0.690061628818512
Iteration [34117]: Loss = 5.006967544555664
Iteration [34118]: Loss = 0.6889485120773315
Iteration [34119]: Loss = 0.6749292612075806
Iteration [34120]: Loss = 0.6816567778587341
Iteration [34121]: Loss = 0.6534256935119629
Iteration [34122]: Loss = 0.6662301421165466
Iteration [34123]: Loss = 0.6658542156219482
Iteration [34124]: Loss = 0.6801620125770569
Iteration [34125]: Loss = 0.6574575304985046
Iteration [34126]: Loss = 0.6637421250343323
Iteration [34127]: Loss = 0.6595174074172974
Iteration [34128]: Loss = 0.6631485223770142
Iteration [34129]: Loss = 9.532144546508789
Iteration [34130]: Loss = 5.066507339477539
Iteration [34131]: Loss = 5.051274299621582
Iteration [34132]: Loss = 0.6868268847465515
Iteration [34133]: Loss = 0.6892727613449097
Iteration [34134]: Loss = 0.6852954626083374
Iteration [34135]: Loss = 0.6869415044784546
Iteration [34136]: Loss = 0.6820929646492004
Iteration [34137]: Loss = 0.6847812533378601
Iteration [34138]: Loss = 0.6932903528213501
Iteration [34139]: Loss = 0.6842597723007202
Iteration [34140]: Loss = 0.6850506067276001
Iteration [34141]: Loss = 0.6847209930419922
Iteration [34142]: Loss = 0.6891283988952637
Iteration [34143]: Loss = 0.691993236541748
Iteration [34144]: Loss = 0.6973066926002502
Iteration [34145]: Loss = 0.6908739805221558
Iteration [34146]: Loss = 0.6873158812522888
Iteration [34147]: Loss = 0.6840862035751343
Iteration [34148]: Loss = 5.038942813873291
Iteration [34149]: Loss = 13.726530075073242
Iteration [34150]: Loss = 0.6897859573364258
Iteration [34151]: Loss = 0.6883936524391174
Iteration [34152]: Loss = 0.689478874206543
Iteration [34153]: Loss = 0.6904510259628296
Iteration [34154]: Loss = 0.6848125457763672
Iteration [34155]: Loss = 0.6858192682266235
Iteration [34156]: Loss = 0.6863300204277039
Iteration [34157]: Loss = 0.6866545081138611
Iteration [34158]: Loss = 5.016074180603027
Iteration [34159]: Loss = 0.687771737575531
Iteration [34160]: Loss = 5.001941204071045
Iteration [34161]: Loss = 0.6899996995925903
Iteration [34162]: Loss = 0.6910838484764099
Iteration [34163]: Loss = 0.6918960809707642
Iteration [34164]: Loss = 0.6924633979797363
Iteration [34165]: Loss = 0.6928099393844604
Iteration [34166]: Loss = 0.6909597516059875
Iteration [34167]: Loss = 0.6909552216529846
Iteration [34168]: Loss = 0.6908074617385864
Iteration [34169]: Loss = 0.69053053855896
Iteration [34170]: Loss = 0.6901381611824036
Iteration [34171]: Loss = 0.6896416544914246
Iteration [34172]: Loss = 0.6890519261360168
Iteration [34173]: Loss = 0.688388466835022
Iteration [34174]: Loss = 5.010758399963379
Iteration [34175]: Loss = 0.6878719329833984
Iteration [34176]: Loss = 0.6878450512886047
Iteration [34177]: Loss = 5.0111212730407715
Iteration [34178]: Loss = 0.6882113218307495
Iteration [34179]: Loss = 9.324515342712402
Iteration [34180]: Loss = 0.6896409392356873
Iteration [34181]: Loss = 0.6908663511276245
Iteration [34182]: Loss = 0.6918649673461914
Iteration [34183]: Loss = 0.6926589012145996
Iteration [34184]: Loss = 0.6932681798934937
Iteration [34185]: Loss = 4.979002475738525
Iteration [34186]: Loss = 0.6946586966514587
Iteration [34187]: Loss = 0.6954075694084167
Iteration [34188]: Loss = 0.6959772706031799
Iteration [34189]: Loss = 0.6963851451873779
Iteration [34190]: Loss = 0.6966474652290344
Iteration [34191]: Loss = 0.6967785358428955
Iteration [34192]: Loss = 0.696791410446167
Iteration [34193]: Loss = 0.6966978311538696
Iteration [34194]: Loss = 0.6965087056159973
Iteration [34195]: Loss = 0.6962335109710693
Iteration [34196]: Loss = 4.967518329620361
Iteration [34197]: Loss = 0.696114182472229
Iteration [34198]: Loss = 0.6962205767631531
Iteration [34199]: Loss = 0.6962128281593323
Iteration [34200]: Loss = 0.6961023211479187
Iteration [34201]: Loss = 0.6958994269371033
Iteration [34202]: Loss = 0.6956133246421814
Iteration [34203]: Loss = 0.6952525973320007
Iteration [34204]: Loss = 0.6948248147964478
Iteration [34205]: Loss = 0.6943366527557373
Iteration [34206]: Loss = 0.6937946081161499
Iteration [34207]: Loss = 0.6932039260864258
Iteration [34208]: Loss = 4.98506498336792
Iteration [34209]: Loss = 0.6925461888313293
Iteration [34210]: Loss = 0.6924236416816711
Iteration [34211]: Loss = 0.6922119855880737
Iteration [34212]: Loss = 0.6919201612472534
Iteration [34213]: Loss = 0.6915562152862549
Iteration [34214]: Loss = 0.691127598285675
Iteration [34215]: Loss = 0.6906408667564392
Iteration [34216]: Loss = 0.6901020407676697
Iteration [34217]: Loss = 0.6895164251327515
Iteration [34218]: Loss = 0.6888889670372009
Iteration [34219]: Loss = 0.6882237792015076
Iteration [34220]: Loss = 0.6875249147415161
Iteration [34221]: Loss = 0.6867961883544922
Iteration [34222]: Loss = 0.6860403418540955
Iteration [34223]: Loss = 0.6852604746818542
Iteration [34224]: Loss = 0.6844590902328491
Iteration [34225]: Loss = 0.6836386322975159
Iteration [34226]: Loss = 0.6828011274337769
Iteration [34227]: Loss = 0.6819484233856201
Iteration [34228]: Loss = 0.6810821294784546
Iteration [34229]: Loss = 0.680203914642334
Iteration [34230]: Loss = 0.6793152689933777
Iteration [34231]: Loss = 0.6784171462059021
Iteration [34232]: Loss = 0.677510678768158
Iteration [34233]: Loss = 0.6765970587730408
Iteration [34234]: Loss = 0.6756770014762878
Iteration [34235]: Loss = 5.081876754760742
Iteration [34236]: Loss = 0.6744670867919922
Iteration [34237]: Loss = 0.6741145849227905
Iteration [34238]: Loss = 0.6737005710601807
Iteration [34239]: Loss = 0.6732314229011536
Iteration [34240]: Loss = 0.672713041305542
Iteration [34241]: Loss = 0.6721500158309937
Iteration [34242]: Loss = 5.09972620010376
Iteration [34243]: Loss = 0.6715433597564697
Iteration [34244]: Loss = 0.6714449524879456
Iteration [34245]: Loss = 9.531392097473145
Iteration [34246]: Loss = 0.6721987724304199
Iteration [34247]: Loss = 0.672953724861145
Iteration [34248]: Loss = 5.088590145111084
Iteration [34249]: Loss = 5.082911014556885
Iteration [34250]: Loss = 0.6759674549102783
Iteration [34251]: Loss = 0.6771424412727356
Iteration [34252]: Loss = 0.6781122088432312
Iteration [34253]: Loss = 0.6788967847824097
Iteration [34254]: Loss = 5.055597305297852
Iteration [34255]: Loss = 0.6805500984191895
Iteration [34256]: Loss = 0.6813948154449463
Iteration [34257]: Loss = 0.6820666790008545
Iteration [34258]: Loss = 0.6825830936431885
Iteration [34259]: Loss = 0.6829590797424316
Iteration [34260]: Loss = 0.6832085847854614
Iteration [34261]: Loss = 0.6833441853523254
Iteration [34262]: Loss = 5.034501552581787
Iteration [34263]: Loss = 0.6838865280151367
Iteration [34264]: Loss = 0.6842568516731262
Iteration [34265]: Loss = 5.02839469909668
Iteration [34266]: Loss = 0.6851959228515625
Iteration [34267]: Loss = 5.021728038787842
Iteration [34268]: Loss = 0.6866841912269592
Iteration [34269]: Loss = 5.012447834014893
Iteration [34270]: Loss = 5.006241798400879
Iteration [34271]: Loss = 0.6901015639305115
Iteration [34272]: Loss = 0.6913619637489319
Iteration [34273]: Loss = 4.985910415649414
Iteration [34274]: Loss = 0.6938072443008423
Iteration [34275]: Loss = 0.6949793100357056
Iteration [34276]: Loss = 0.6959487199783325
Iteration [34277]: Loss = 0.6967355012893677
Iteration [34278]: Loss = 0.6973569393157959
Iteration [34279]: Loss = 0.6978297233581543
Iteration [34280]: Loss = 0.6981682181358337
Iteration [34281]: Loss = 0.6983857154846191
Iteration [34282]: Loss = 0.6984941363334656
Iteration [34283]: Loss = 0.6985044479370117
Iteration [34284]: Loss = 0.6984263062477112
Iteration [34285]: Loss = 0.6982686519622803
Iteration [34286]: Loss = 0.6980392932891846
Iteration [34287]: Loss = 0.6977457404136658
Iteration [34288]: Loss = 0.6973942518234253
Iteration [34289]: Loss = 0.6969907283782959
Iteration [34290]: Loss = 0.6965405941009521
Iteration [34291]: Loss = 0.6960485577583313
Iteration [34292]: Loss = 0.6955187916755676
Iteration [34293]: Loss = 0.6949551701545715
Iteration [34294]: Loss = 0.6943614482879639
Iteration [34295]: Loss = 0.6937406659126282
Iteration [34296]: Loss = 0.6930955648422241
Iteration [34297]: Loss = 9.279202461242676
Iteration [34298]: Loss = 0.6928195357322693
Iteration [34299]: Loss = 4.982308387756348
Iteration [34300]: Loss = 0.6937677264213562
Iteration [34301]: Loss = 4.975895404815674
Iteration [34302]: Loss = 0.6952061653137207
Iteration [34303]: Loss = 4.967191696166992
Iteration [34304]: Loss = 4.9614362716674805
Iteration [34305]: Loss = 0.6984420418739319
Iteration [34306]: Loss = 0.6996285915374756
Iteration [34307]: Loss = 0.7006158232688904
Iteration [34308]: Loss = 0.7014229893684387
Iteration [34309]: Loss = 0.7020677328109741
Iteration [34310]: Loss = 0.7025657892227173
Iteration [34311]: Loss = 0.7029316425323486
Iteration [34312]: Loss = 0.703178346157074
Iteration [34313]: Loss = 0.7033177018165588
Iteration [34314]: Loss = 0.7033603191375732
Iteration [34315]: Loss = 0.7033157348632812
Iteration [34316]: Loss = 0.7031928300857544
Iteration [34317]: Loss = 0.7029991149902344
Iteration [34318]: Loss = 4.93159294128418
Iteration [34319]: Loss = 0.7029396295547485
Iteration [34320]: Loss = 0.7030351758003235
Iteration [34321]: Loss = 0.7030389308929443
Iteration [34322]: Loss = 0.7029597163200378
Iteration [34323]: Loss = 4.9312591552734375
Iteration [34324]: Loss = 4.929765224456787
Iteration [34325]: Loss = 4.926242351531982
Iteration [34326]: Loss = 0.7048012614250183
Iteration [34327]: Loss = 0.7056459784507751
Iteration [34328]: Loss = 0.7063248157501221
Iteration [34329]: Loss = 0.7068551182746887
Iteration [34330]: Loss = 0.707251250743866
Iteration [34331]: Loss = 0.707526445388794
Iteration [34332]: Loss = 0.7076926231384277
Iteration [34333]: Loss = 0.707760751247406
Iteration [34334]: Loss = 0.707740306854248
Iteration [34335]: Loss = 0.7076404094696045
Iteration [34336]: Loss = 0.7058224678039551
Iteration [34337]: Loss = 0.7072327733039856
Iteration [34338]: Loss = 0.7047256231307983
Iteration [34339]: Loss = 0.7043067812919617
Iteration [34340]: Loss = 0.7039156556129456
Iteration [34341]: Loss = 4.919250011444092
Iteration [34342]: Loss = 0.7035115957260132
Iteration [34343]: Loss = 0.7034571766853333
Iteration [34344]: Loss = 0.7033272981643677
Iteration [34345]: Loss = 0.7031300663948059
Iteration [34346]: Loss = 0.7028719782829285
Iteration [34347]: Loss = 0.7025590538978577
Iteration [34348]: Loss = 0.7021971344947815
Iteration [34349]: Loss = 0.7017908692359924
Iteration [34350]: Loss = 0.7013450860977173
Iteration [34351]: Loss = 0.7008634805679321
Iteration [34352]: Loss = 0.7003500461578369
Iteration [34353]: Loss = 0.6998078227043152
Iteration [34354]: Loss = 0.6992400288581848
Iteration [34355]: Loss = 0.698648989200592
Iteration [34356]: Loss = 0.6980375051498413
Iteration [34357]: Loss = 0.6974074840545654
Iteration [34358]: Loss = 0.6967609524726868
Iteration [34359]: Loss = 0.6960996985435486
Iteration [34360]: Loss = 0.695425271987915
Iteration [34361]: Loss = 0.694739043712616
Iteration [34362]: Loss = 0.6940423846244812
Iteration [34363]: Loss = 0.6933363676071167
Iteration [34364]: Loss = 0.6926221251487732
Iteration [34365]: Loss = 0.6919006705284119
Iteration [34366]: Loss = 0.6911726593971252
Iteration [34367]: Loss = 0.6904388666152954
Iteration [34368]: Loss = 5.000381946563721
Iteration [34369]: Loss = 0.6894584894180298
Iteration [34370]: Loss = 0.6891629695892334
Iteration [34371]: Loss = 0.6888188123703003
Iteration [34372]: Loss = 0.6884312629699707
Iteration [34373]: Loss = 0.6880042552947998
Iteration [34374]: Loss = 0.6875422596931458
Iteration [34375]: Loss = 0.687048614025116
Iteration [34376]: Loss = 0.6865266561508179
Iteration [34377]: Loss = 0.6859790682792664
Iteration [34378]: Loss = 0.6854088306427002
Iteration [34379]: Loss = 9.368542671203613
Iteration [34380]: Loss = 5.024652481079102
Iteration [34381]: Loss = 0.6859323978424072
Iteration [34382]: Loss = 0.6865240931510925
Iteration [34383]: Loss = 0.6869817972183228
Iteration [34384]: Loss = 9.339020729064941
Iteration [34385]: Loss = 0.6890050172805786
Iteration [34386]: Loss = 0.6906249523162842
Iteration [34387]: Loss = 0.691420316696167
Iteration [34388]: Loss = 0.6920632123947144
Iteration [34389]: Loss = 4.988527774810791
Iteration [34390]: Loss = 5.021989822387695
Iteration [34391]: Loss = 0.69643235206604
Iteration [34392]: Loss = 0.6973205804824829
Iteration [34393]: Loss = 0.684451699256897
Iteration [34394]: Loss = 0.672285258769989
Iteration [34395]: Loss = 0.6712183952331543
Iteration [34396]: Loss = 0.6909757852554321
Iteration [34397]: Loss = 0.6734631061553955
Iteration [34398]: Loss = 0.6718930006027222
Iteration [34399]: Loss = 0.678358793258667
Iteration [34400]: Loss = 0.6695472598075867
Iteration [34401]: Loss = 0.6673271656036377
Iteration [34402]: Loss = 0.6830390095710754
Iteration [34403]: Loss = 0.6772814989089966
Iteration [34404]: Loss = 0.676699161529541
Iteration [34405]: Loss = 0.6725627183914185
Iteration [34406]: Loss = 0.6759627461433411
Iteration [34407]: Loss = 0.6666232347488403
Iteration [34408]: Loss = 5.153787612915039
Iteration [34409]: Loss = 0.6714272499084473
Iteration [34410]: Loss = 0.6783353686332703
Iteration [34411]: Loss = 0.6786486506462097
Iteration [34412]: Loss = 0.6755741834640503
Iteration [34413]: Loss = 0.6775831580162048
Iteration [34414]: Loss = 0.6740715503692627
Iteration [34415]: Loss = 5.065240383148193
Iteration [34416]: Loss = 0.6777839064598083
Iteration [34417]: Loss = 0.6711807250976562
Iteration [34418]: Loss = 0.6743521690368652
Iteration [34419]: Loss = 5.106104850769043
Iteration [34420]: Loss = 0.6739539504051208
Iteration [34421]: Loss = 0.6716679334640503
Iteration [34422]: Loss = 5.084714412689209
Iteration [34423]: Loss = 0.6745714545249939
Iteration [34424]: Loss = 0.6789760589599609
Iteration [34425]: Loss = 5.060338020324707
Iteration [34426]: Loss = 0.6814026832580566
Iteration [34427]: Loss = 0.6787826418876648
Iteration [34428]: Loss = 0.6792090535163879
Iteration [34429]: Loss = 0.6794804930686951
Iteration [34430]: Loss = 0.6796125173568726
Iteration [34431]: Loss = 0.6796191334724426
Iteration [34432]: Loss = 0.679513156414032
Iteration [34433]: Loss = 0.6793060898780823
Iteration [34434]: Loss = 0.6792702078819275
Iteration [34435]: Loss = 0.6789097785949707
Iteration [34436]: Loss = 0.6784688830375671
Iteration [34437]: Loss = 0.6782678365707397
Iteration [34438]: Loss = 0.6776976585388184
Iteration [34439]: Loss = 5.069054126739502
Iteration [34440]: Loss = 9.460160255432129
Iteration [34441]: Loss = 0.67840576171875
Iteration [34442]: Loss = 0.6802730560302734
Iteration [34443]: Loss = 5.047696113586426
Iteration [34444]: Loss = 0.6820800304412842
Iteration [34445]: Loss = 0.6812648177146912
Iteration [34446]: Loss = 0.6819921135902405
Iteration [34447]: Loss = 0.6825518608093262
Iteration [34448]: Loss = 0.6829606294631958
Iteration [34449]: Loss = 0.6748241186141968
Iteration [34450]: Loss = 0.6735442280769348
Iteration [34451]: Loss = 0.671605110168457
Iteration [34452]: Loss = 0.6731094121932983
Iteration [34453]: Loss = 0.6755321025848389
Iteration [34454]: Loss = 0.6752803325653076
Iteration [34455]: Loss = 0.6749547719955444
Iteration [34456]: Loss = 13.899640083312988
Iteration [34457]: Loss = 5.075802803039551
Iteration [34458]: Loss = 0.6774601936340332
Iteration [34459]: Loss = 0.6762514114379883
Iteration [34460]: Loss = 0.6773740649223328
Iteration [34461]: Loss = 0.678274929523468
Iteration [34462]: Loss = 0.6789755821228027
Iteration [34463]: Loss = 0.6794889569282532
Iteration [34464]: Loss = 0.679840087890625
Iteration [34465]: Loss = 0.6823902130126953
Iteration [34466]: Loss = 0.6824508905410767
Iteration [34467]: Loss = 0.6824363470077515
Iteration [34468]: Loss = 0.6848291158676147
Iteration [34469]: Loss = 0.6846097111701965
Iteration [34470]: Loss = 0.6842998266220093
Iteration [34471]: Loss = 0.6839082837104797
Iteration [34472]: Loss = 0.6834437251091003
Iteration [34473]: Loss = 0.6836164593696594
Iteration [34474]: Loss = 0.6831070184707642
Iteration [34475]: Loss = 0.682551920413971
Iteration [34476]: Loss = 0.6819555759429932
Iteration [34477]: Loss = 0.6813226938247681
Iteration [34478]: Loss = 0.6806566715240479
Iteration [34479]: Loss = 0.6799612641334534
Iteration [34480]: Loss = 0.6792394518852234
Iteration [34481]: Loss = 0.6784940958023071
Iteration [34482]: Loss = 0.6777276992797852
Iteration [34483]: Loss = 0.6769424080848694
Iteration [34484]: Loss = 0.6761399507522583
Iteration [34485]: Loss = 0.6753554344177246
Iteration [34486]: Loss = 0.6745526194572449
Iteration [34487]: Loss = 0.6737320423126221
Iteration [34488]: Loss = 0.6728954911231995
Iteration [34489]: Loss = 0.6720446944236755
Iteration [34490]: Loss = 0.6711814403533936
Iteration [34491]: Loss = 0.6703070402145386
Iteration [34492]: Loss = 0.6694228053092957
Iteration [34493]: Loss = 5.1166582107543945
Iteration [34494]: Loss = 0.6682791113853455
Iteration [34495]: Loss = 0.6679571866989136
Iteration [34496]: Loss = 0.6675708889961243
Iteration [34497]: Loss = 0.6671271324157715
Iteration [34498]: Loss = 0.6666314601898193
Iteration [34499]: Loss = 0.6660894155502319
Iteration [34500]: Loss = 0.6655056476593018
Iteration [34501]: Loss = 0.6648843884468079
Iteration [34502]: Loss = 5.1410017013549805
Iteration [34503]: Loss = 0.6641864776611328
Iteration [34504]: Loss = 0.6640527844429016
Iteration [34505]: Loss = 0.6638375520706177
Iteration [34506]: Loss = 0.6635491251945496
Iteration [34507]: Loss = 5.1468963623046875
Iteration [34508]: Loss = 0.6641412973403931
Iteration [34509]: Loss = 0.6642431020736694
Iteration [34510]: Loss = 0.6642419695854187
Iteration [34511]: Loss = 0.6641480922698975
Iteration [34512]: Loss = 0.6639707684516907
Iteration [34513]: Loss = 0.6637184023857117
Iteration [34514]: Loss = 0.6633984446525574
Iteration [34515]: Loss = 5.147907257080078
Iteration [34516]: Loss = 0.6632024049758911
Iteration [34517]: Loss = 5.146430015563965
Iteration [34518]: Loss = 0.6623445749282837
Iteration [34519]: Loss = 0.662778377532959
Iteration [34520]: Loss = 0.663077175617218
Iteration [34521]: Loss = 0.6632541418075562
Iteration [34522]: Loss = 5.146175861358643
Iteration [34523]: Loss = 0.6639015674591064
Iteration [34524]: Loss = 0.6643327474594116
Iteration [34525]: Loss = 0.6646295189857483
Iteration [34526]: Loss = 0.6648053526878357
Iteration [34527]: Loss = 5.137348651885986
Iteration [34528]: Loss = 0.6654471158981323
Iteration [34529]: Loss = 0.665874183177948
Iteration [34530]: Loss = 0.6661677360534668
Iteration [34531]: Loss = 0.6663410663604736
Iteration [34532]: Loss = 0.6664060354232788
Iteration [34533]: Loss = 0.6663735508918762
Iteration [34534]: Loss = 0.6662532091140747
Iteration [34535]: Loss = 5.130646228790283
Iteration [34536]: Loss = 0.6663872003555298
Iteration [34537]: Loss = 0.6665970683097839
Iteration [34538]: Loss = 0.6666955947875977
Iteration [34539]: Loss = 5.127020359039307
Iteration [34540]: Loss = 0.6671997904777527
Iteration [34541]: Loss = 0.6675654053688049
Iteration [34542]: Loss = 0.6678047180175781
Iteration [34543]: Loss = 0.6679304242134094
Iteration [34544]: Loss = 5.135838031768799
Iteration [34545]: Loss = 0.6656436920166016
Iteration [34546]: Loss = 0.666013240814209
Iteration [34547]: Loss = 0.6662600040435791
Iteration [34548]: Loss = 0.6663960814476013
Iteration [34549]: Loss = 0.6664325594902039
Iteration [34550]: Loss = 0.6663792729377747
Iteration [34551]: Loss = 5.129560470581055
Iteration [34552]: Loss = 0.6666090488433838
Iteration [34553]: Loss = 0.666851282119751
Iteration [34554]: Loss = 5.125381946563721
Iteration [34555]: Loss = 0.6675816178321838
Iteration [34556]: Loss = 0.6680352687835693
Iteration [34557]: Loss = 0.6683586239814758
Iteration [34558]: Loss = 0.6685647368431091
Iteration [34559]: Loss = 5.115895748138428
Iteration [34560]: Loss = 0.6692306995391846
Iteration [34561]: Loss = 9.550999641418457
Iteration [34562]: Loss = 5.102661609649658
Iteration [34563]: Loss = 0.6727011799812317
Iteration [34564]: Loss = 0.6747510433197021
Iteration [34565]: Loss = 0.6759442090988159
Iteration [34566]: Loss = 0.6769229769706726
Iteration [34567]: Loss = 0.6777080297470093
Iteration [34568]: Loss = 0.6783183217048645
Iteration [34569]: Loss = 0.678770899772644
Iteration [34570]: Loss = 0.6790813207626343
Iteration [34571]: Loss = 0.6792634725570679
Iteration [34572]: Loss = 0.6776682734489441
Iteration [34573]: Loss = 0.6776311993598938
Iteration [34574]: Loss = 5.066671371459961
Iteration [34575]: Loss = 0.6779153347015381
Iteration [34576]: Loss = 0.6781923770904541
Iteration [34577]: Loss = 0.6783453226089478
Iteration [34578]: Loss = 5.061792850494385
Iteration [34579]: Loss = 5.058691024780273
Iteration [34580]: Loss = 0.6799764037132263
Iteration [34581]: Loss = 0.6807993650436401
Iteration [34582]: Loss = 0.6814462542533875
Iteration [34583]: Loss = 5.042360782623291
Iteration [34584]: Loss = 0.6828850507736206
Iteration [34585]: Loss = 0.6836364269256592
Iteration [34586]: Loss = 0.6842018365859985
Iteration [34587]: Loss = 0.6864058375358582
Iteration [34588]: Loss = 0.6849105954170227
Iteration [34589]: Loss = 0.6850810050964355
Iteration [34590]: Loss = 0.6851450800895691
Iteration [34591]: Loss = 5.025084018707275
Iteration [34592]: Loss = 0.6855665445327759
Iteration [34593]: Loss = 5.020903587341309
Iteration [34594]: Loss = 0.6866509914398193
Iteration [34595]: Loss = 0.6872515678405762
Iteration [34596]: Loss = 0.6877034902572632
Iteration [34597]: Loss = 0.6880213022232056
Iteration [34598]: Loss = 0.6882184743881226
Iteration [34599]: Loss = 0.6883066892623901
Iteration [34600]: Loss = 0.6882968544960022
Iteration [34601]: Loss = 0.6881986260414124
Iteration [34602]: Loss = 0.6880208253860474
Iteration [34603]: Loss = 0.6877716183662415
Iteration [34604]: Loss = 0.6874580979347229
Iteration [34605]: Loss = 0.6870867609977722
Iteration [34606]: Loss = 0.6866633892059326
Iteration [34607]: Loss = 0.6861933469772339
Iteration [34608]: Loss = 0.6856812238693237
Iteration [34609]: Loss = 0.6851314902305603
Iteration [34610]: Loss = 0.6845481395721436
Iteration [34611]: Loss = 0.6839345097541809
Iteration [34612]: Loss = 0.6832935214042664
Iteration [34613]: Loss = 0.682628333568573
Iteration [34614]: Loss = 0.6819415092468262
Iteration [34615]: Loss = 0.6812352538108826
Iteration [34616]: Loss = 0.6805116534233093
Iteration [34617]: Loss = 0.6797724962234497
Iteration [34618]: Loss = 0.6790193915367126
Iteration [34619]: Loss = 0.6782541871070862
Iteration [34620]: Loss = 0.6774779558181763
Iteration [34621]: Loss = 0.676692008972168
Iteration [34622]: Loss = 0.6758975386619568
Iteration [34623]: Loss = 0.6750953197479248
Iteration [34624]: Loss = 0.6742865443229675
Iteration [34625]: Loss = 0.6734717488288879
Iteration [34626]: Loss = 0.6726518869400024
Iteration [34627]: Loss = 5.098160266876221
Iteration [34628]: Loss = 0.6715726256370544
Iteration [34629]: Loss = 0.6712570190429688
Iteration [34630]: Loss = 0.6708868741989136
Iteration [34631]: Loss = 0.6704675555229187
Iteration [34632]: Loss = 0.6700040698051453
Iteration [34633]: Loss = 0.6749451160430908
Iteration [34634]: Loss = 0.6744367480278015
Iteration [34635]: Loss = 0.6738893985748291
Iteration [34636]: Loss = 0.6729210615158081
Iteration [34637]: Loss = 5.09545373916626
Iteration [34638]: Loss = 0.6756213903427124
Iteration [34639]: Loss = 0.677943229675293
Iteration [34640]: Loss = 0.6776835322380066
Iteration [34641]: Loss = 0.6779409646987915
Iteration [34642]: Loss = 0.6775924563407898
Iteration [34643]: Loss = 0.6834717392921448
Iteration [34644]: Loss = 0.6848068237304688
Iteration [34645]: Loss = 0.6845017075538635
Iteration [34646]: Loss = 5.030186653137207
Iteration [34647]: Loss = 0.6841748952865601
Iteration [34648]: Loss = 0.6841228008270264
Iteration [34649]: Loss = 0.6839919090270996
Iteration [34650]: Loss = 0.683804988861084
Iteration [34651]: Loss = 0.6835706830024719
Iteration [34652]: Loss = 0.6832938194274902
Iteration [34653]: Loss = 0.6829786896705627
Iteration [34654]: Loss = 0.6826290488243103
Iteration [34655]: Loss = 0.6822484731674194
Iteration [34656]: Loss = 0.681840181350708
Iteration [34657]: Loss = 0.6814069151878357
Iteration [34658]: Loss = 5.047727584838867
Iteration [34659]: Loss = 0.6809011697769165
Iteration [34660]: Loss = 0.6807906627655029
Iteration [34661]: Loss = 0.680625855922699
Iteration [34662]: Loss = 5.0506768226623535
Iteration [34663]: Loss = 0.6805765628814697
Iteration [34664]: Loss = 0.6806595921516418
Iteration [34665]: Loss = 0.6806694269180298
Iteration [34666]: Loss = 0.6806131601333618
Iteration [34667]: Loss = 0.6804975271224976
Iteration [34668]: Loss = 5.051135063171387
Iteration [34669]: Loss = 0.6805310249328613
Iteration [34670]: Loss = 0.6806488037109375
Iteration [34671]: Loss = 0.6806899905204773
Iteration [34672]: Loss = 0.6806625723838806
Iteration [34673]: Loss = 0.680573046207428
Iteration [34674]: Loss = 0.6804277896881104
Iteration [34675]: Loss = 0.6802322268486023
Iteration [34676]: Loss = 0.679991602897644
Iteration [34677]: Loss = 0.679710328578949
Iteration [34678]: Loss = 0.6793926358222961
Iteration [34679]: Loss = 0.6790420413017273
Iteration [34680]: Loss = 0.6786619424819946
Iteration [34681]: Loss = 5.0625152587890625
Iteration [34682]: Loss = 0.6782445907592773
Iteration [34683]: Loss = 0.6781707406044006
Iteration [34684]: Loss = 0.678040087223053
Iteration [34685]: Loss = 0.6778584122657776
Iteration [34686]: Loss = 0.6776307821273804
Iteration [34687]: Loss = 0.677361786365509
Iteration [34688]: Loss = 0.6770555973052979
Iteration [34689]: Loss = 5.07100248336792
Iteration [34690]: Loss = 0.6767637133598328
Iteration [34691]: Loss = 0.6767430901527405
Iteration [34692]: Loss = 9.465953826904297
Iteration [34693]: Loss = 0.675493061542511
Iteration [34694]: Loss = 5.074763298034668
Iteration [34695]: Loss = 0.6768612861633301
Iteration [34696]: Loss = 0.6775436401367188
Iteration [34697]: Loss = 0.6780968308448792
Iteration [34698]: Loss = 0.6785331964492798
Iteration [34699]: Loss = 5.0591654777526855
Iteration [34700]: Loss = 0.6794995069503784
Iteration [34701]: Loss = 0.6800097823143005
Iteration [34702]: Loss = 0.6804075837135315
Iteration [34703]: Loss = 0.6807041764259338
Iteration [34704]: Loss = 5.047956466674805
Iteration [34705]: Loss = 0.6814297437667847
Iteration [34706]: Loss = 0.6818369030952454
Iteration [34707]: Loss = 0.682141900062561
Iteration [34708]: Loss = 5.040066719055176
Iteration [34709]: Loss = 0.6828804016113281
Iteration [34710]: Loss = 5.041314601898193
Iteration [34711]: Loss = 5.037547588348389
Iteration [34712]: Loss = 0.683763861656189
Iteration [34713]: Loss = 0.6845570206642151
Iteration [34714]: Loss = 0.6852109432220459
Iteration [34715]: Loss = 0.6857396960258484
Iteration [34716]: Loss = 0.6861554980278015
Iteration [34717]: Loss = 0.6864693760871887
Iteration [34718]: Loss = 0.686691403388977
Iteration [34719]: Loss = 0.6868305802345276
Iteration [34720]: Loss = 5.0154547691345215
Iteration [34721]: Loss = 5.013387203216553
Iteration [34722]: Loss = 0.6879470944404602
Iteration [34723]: Loss = 0.6884754300117493
Iteration [34724]: Loss = 0.6888395547866821
Iteration [34725]: Loss = 5.003513336181641
Iteration [34726]: Loss = 5.000709056854248
Iteration [34727]: Loss = 4.99673318862915
Iteration [34728]: Loss = 0.6913213729858398
Iteration [34729]: Loss = 0.6921167373657227
Iteration [34730]: Loss = 0.6927821040153503
Iteration [34731]: Loss = 0.6948676705360413
Iteration [34732]: Loss = 0.695309579372406
Iteration [34733]: Loss = 4.9687066078186035
Iteration [34734]: Loss = 0.6962385177612305
Iteration [34735]: Loss = 0.6967116594314575
Iteration [34736]: Loss = 0.6970862150192261
Iteration [34737]: Loss = 0.6973718404769897
Iteration [34738]: Loss = 9.219588279724121
Iteration [34739]: Loss = 0.6983417272567749
Iteration [34740]: Loss = 0.6989797949790955
Iteration [34741]: Loss = 0.6995037794113159
Iteration [34742]: Loss = 0.6999247074127197
Iteration [34743]: Loss = 0.7002529501914978
Iteration [34744]: Loss = 0.7004975080490112
Iteration [34745]: Loss = 0.700666606426239
Iteration [34746]: Loss = 0.7007677555084229
Iteration [34747]: Loss = 0.7008076310157776
Iteration [34748]: Loss = 0.7007923722267151
Iteration [34749]: Loss = 4.942081451416016
Iteration [34750]: Loss = 0.7009353041648865
Iteration [34751]: Loss = 0.7010714411735535
Iteration [34752]: Loss = 0.7011430859565735
Iteration [34753]: Loss = 0.7011564373970032
Iteration [34754]: Loss = 0.701117217540741
Iteration [34755]: Loss = 0.701030969619751
Iteration [34756]: Loss = 0.7009021639823914
Iteration [34757]: Loss = 4.942041397094727
Iteration [34758]: Loss = 0.7008510231971741
Iteration [34759]: Loss = 0.7009044289588928
Iteration [34760]: Loss = 0.7009016275405884
Iteration [34761]: Loss = 0.7008479833602905
Iteration [34762]: Loss = 0.7007489204406738
Iteration [34763]: Loss = 0.7006086111068726
Iteration [34764]: Loss = 0.7004314661026001
Iteration [34765]: Loss = 0.7002210021018982
Iteration [34766]: Loss = 0.6999805569648743
Iteration [34767]: Loss = 0.6997132301330566
Iteration [34768]: Loss = 0.699421763420105
Iteration [34769]: Loss = 0.6991084814071655
Iteration [34770]: Loss = 0.698775589466095
Iteration [34771]: Loss = 0.6984252333641052
Iteration [34772]: Loss = 0.69805908203125
Iteration [34773]: Loss = 0.697678804397583
Iteration [34774]: Loss = 0.6972855925559998
Iteration [34775]: Loss = 0.6968812346458435
Iteration [34776]: Loss = 0.6964665651321411
Iteration [34777]: Loss = 0.6960426568984985
Iteration [34778]: Loss = 0.6956107020378113
Iteration [34779]: Loss = 0.6951712369918823
Iteration [34780]: Loss = 0.6947253346443176
Iteration [34781]: Loss = 4.976020336151123
Iteration [34782]: Loss = 4.976753234863281
Iteration [34783]: Loss = 0.6942766308784485
Iteration [34784]: Loss = 0.7013079524040222
Iteration [34785]: Loss = 4.975533962249756
Iteration [34786]: Loss = 0.6946399807929993
Iteration [34787]: Loss = 0.6948374509811401
Iteration [34788]: Loss = 0.697165310382843
Iteration [34789]: Loss = 0.6972302198410034
Iteration [34790]: Loss = 0.6972380876541138
Iteration [34791]: Loss = 4.960593223571777
Iteration [34792]: Loss = 0.6974201798439026
Iteration [34793]: Loss = 4.958605766296387
Iteration [34794]: Loss = 0.6979724764823914
Iteration [34795]: Loss = 0.6982825398445129
Iteration [34796]: Loss = 0.69851154088974
Iteration [34797]: Loss = 0.698667585849762
Iteration [34798]: Loss = 4.952383995056152
Iteration [34799]: Loss = 0.6991012692451477
Iteration [34800]: Loss = 0.6993603706359863
Iteration [34801]: Loss = 0.6995435953140259
Iteration [34802]: Loss = 0.6996583342552185
Iteration [34803]: Loss = 0.6997116208076477
Iteration [34804]: Loss = 0.6997092962265015
Iteration [34805]: Loss = 0.6996570229530334
Iteration [34806]: Loss = 0.6995596885681152
Iteration [34807]: Loss = 0.699421763420105
Iteration [34808]: Loss = 0.6992474794387817
Iteration [34809]: Loss = 0.6990403532981873
Iteration [34810]: Loss = 0.6988036632537842
Iteration [34811]: Loss = 0.698540449142456
Iteration [34812]: Loss = 4.955031394958496
Iteration [34813]: Loss = 4.9550042152404785
Iteration [34814]: Loss = 0.6985242366790771
Iteration [34815]: Loss = 0.6987138390541077
Iteration [34816]: Loss = 0.6988347172737122
Iteration [34817]: Loss = 0.6988935470581055
Iteration [34818]: Loss = 0.6988967061042786
Iteration [34819]: Loss = 4.951903343200684
Iteration [34820]: Loss = 0.6990680694580078
Iteration [34821]: Loss = 0.6992150545120239
Iteration [34822]: Loss = 0.6992976069450378
Iteration [34823]: Loss = 0.6993220448493958
Iteration [34824]: Loss = 4.9495744705200195
Iteration [34825]: Loss = 0.6995294094085693
Iteration [34826]: Loss = 4.9474945068359375
Iteration [34827]: Loss = 0.7000963687896729
Iteration [34828]: Loss = 0.7004112005233765
Iteration [34829]: Loss = 0.7006452083587646
Iteration [34830]: Loss = 0.7008060812950134
Iteration [34831]: Loss = 0.700901210308075
Iteration [34832]: Loss = 0.7009371519088745
Iteration [34833]: Loss = 0.7009195685386658
Iteration [34834]: Loss = 9.181988716125488
Iteration [34835]: Loss = 0.70135498046875
Iteration [34836]: Loss = 0.7017574310302734
Iteration [34837]: Loss = 0.7020708322525024
Iteration [34838]: Loss = 4.933868885040283
Iteration [34839]: Loss = 4.931459426879883
Iteration [34840]: Loss = 0.7034372687339783
Iteration [34841]: Loss = 0.703991711139679
Iteration [34842]: Loss = 0.7044421434402466
Iteration [34843]: Loss = 0.7047989368438721
Iteration [34844]: Loss = 0.7050710916519165
Iteration [34845]: Loss = 4.918516159057617
Iteration [34846]: Loss = 0.7056958079338074
Iteration [34847]: Loss = 0.7060331702232361
Iteration [34848]: Loss = 0.7062877416610718
Iteration [34849]: Loss = 0.7064679861068726
Iteration [34850]: Loss = 4.911742210388184
Iteration [34851]: Loss = 0.7069348692893982
Iteration [34852]: Loss = 0.7072044610977173
Iteration [34853]: Loss = 0.7073981761932373
Iteration [34854]: Loss = 0.7075232863426208
Iteration [34855]: Loss = 0.7075868248939514
Iteration [34856]: Loss = 0.7075946927070618
Iteration [34857]: Loss = 0.7075525522232056
Iteration [34858]: Loss = 0.7074652910232544
Iteration [34859]: Loss = 0.7073373794555664
Iteration [34860]: Loss = 0.7071730494499207
Iteration [34861]: Loss = 0.7069758772850037
Iteration [34862]: Loss = 0.7067490220069885
Iteration [34863]: Loss = 0.7064956426620483
Iteration [34864]: Loss = 0.7062181830406189
Iteration [34865]: Loss = 0.7059193253517151
Iteration [34866]: Loss = 0.7056010961532593
Iteration [34867]: Loss = 0.7052655816078186
Iteration [34868]: Loss = 0.704914391040802
Iteration [34869]: Loss = 0.7045490741729736
Iteration [34870]: Loss = 0.7041712999343872
Iteration [34871]: Loss = 0.7037821412086487
Iteration [34872]: Loss = 4.928266525268555
Iteration [34873]: Loss = 4.928808212280273
Iteration [34874]: Loss = 0.703437328338623
Iteration [34875]: Loss = 0.7035316824913025
Iteration [34876]: Loss = 0.7035679817199707
Iteration [34877]: Loss = 0.7035518288612366
Iteration [34878]: Loss = 0.7034884691238403
Iteration [34879]: Loss = 0.7033827304840088
Iteration [34880]: Loss = 0.7032385468482971
Iteration [34881]: Loss = 0.7030600309371948
Iteration [34882]: Loss = 0.7028506398200989
Iteration [34883]: Loss = 0.7026132941246033
Iteration [34884]: Loss = 4.933626174926758
Iteration [34885]: Loss = 0.7023680806159973
Iteration [34886]: Loss = 0.7018439769744873
Iteration [34887]: Loss = 0.7017655968666077
Iteration [34888]: Loss = 0.7016466856002808
Iteration [34889]: Loss = 0.701982319355011
Iteration [34890]: Loss = 0.7013022899627686
Iteration [34891]: Loss = 4.940221786499023
Iteration [34892]: Loss = 0.7011404037475586
Iteration [34893]: Loss = 0.7011428475379944
Iteration [34894]: Loss = 0.7010966539382935
Iteration [34895]: Loss = 0.7010065913200378
Iteration [34896]: Loss = 0.7008770704269409
Iteration [34897]: Loss = 0.7007119059562683
Iteration [34898]: Loss = 0.7005149126052856
Iteration [34899]: Loss = 4.944370746612549
Iteration [34900]: Loss = 4.944110870361328
Iteration [34901]: Loss = 0.7006345391273499
Iteration [34902]: Loss = 4.941427230834961
Iteration [34903]: Loss = 4.939098834991455
Iteration [34904]: Loss = 4.935710906982422
Iteration [34905]: Loss = 4.931379318237305
Iteration [34906]: Loss = 0.7037795186042786
Iteration [34907]: Loss = 0.70462965965271
Iteration [34908]: Loss = 0.7053478956222534
Iteration [34909]: Loss = 0.705946683883667
Iteration [34910]: Loss = 0.7064380049705505
Iteration [34911]: Loss = 0.7068322896957397
Iteration [34912]: Loss = 0.7071391940116882
Iteration [34913]: Loss = 0.7073670625686646
Iteration [34914]: Loss = 0.7075239419937134
Iteration [34915]: Loss = 0.7076166868209839
Iteration [34916]: Loss = 0.7076517343521118
Iteration [34917]: Loss = 0.7076348066329956
Iteration [34918]: Loss = 0.7075709700584412
Iteration [34919]: Loss = 0.7074651718139648
Iteration [34920]: Loss = 0.7073212265968323
Iteration [34921]: Loss = 0.7071431875228882
Iteration [34922]: Loss = 4.9099225997924805
Iteration [34923]: Loss = 0.7069956660270691
Iteration [34924]: Loss = 4.909571647644043
Iteration [34925]: Loss = 0.7072569131851196
Iteration [34926]: Loss = 0.7074375748634338
Iteration [34927]: Loss = 0.7075519561767578
Iteration [34928]: Loss = 4.906467437744141
Iteration [34929]: Loss = 0.707903265953064
Iteration [34930]: Loss = 4.903822898864746
Iteration [34931]: Loss = 4.901549339294434
Iteration [34932]: Loss = 0.7092093825340271
Iteration [34933]: Loss = 0.7097415328025818
Iteration [34934]: Loss = 0.7101727724075317
Iteration [34935]: Loss = 0.7105129361152649
Iteration [34936]: Loss = 0.7107709646224976
Iteration [34937]: Loss = 0.7109549045562744
Iteration [34938]: Loss = 4.888741493225098
Iteration [34939]: Loss = 0.7114233374595642
Iteration [34940]: Loss = 0.7116914391517639
Iteration [34941]: Loss = 0.7118843197822571
Iteration [34942]: Loss = 0.7120096683502197
Iteration [34943]: Loss = 4.88364315032959
Iteration [34944]: Loss = 0.7123773097991943
Iteration [34945]: Loss = 0.7126021981239319
Iteration [34946]: Loss = 0.7127562761306763
Iteration [34947]: Loss = 0.7128465175628662
Iteration [34948]: Loss = 0.7128793597221375
Iteration [34949]: Loss = 0.7128605246543884
Iteration [34950]: Loss = 0.712795078754425
Iteration [34951]: Loss = 0.7126874923706055
Iteration [34952]: Loss = 4.881264686584473
Iteration [34953]: Loss = 0.7126574516296387
Iteration [34954]: Loss = 0.7127126455307007
Iteration [34955]: Loss = 4.880393028259277
Iteration [34956]: Loss = 0.7129601836204529
Iteration [34957]: Loss = 0.7131336331367493
Iteration [34958]: Loss = 0.7132413983345032
Iteration [34959]: Loss = 0.7132900357246399
Iteration [34960]: Loss = 0.7132853865623474
Iteration [34961]: Loss = 0.7132328748703003
Iteration [34962]: Loss = 0.7131372690200806
Iteration [34963]: Loss = 0.7130027413368225
Iteration [34964]: Loss = 4.879788398742676
Iteration [34965]: Loss = 0.7129260301589966
Iteration [34966]: Loss = 0.7129611968994141
Iteration [34967]: Loss = 0.712944507598877
Iteration [34968]: Loss = 0.7128812670707703
Iteration [34969]: Loss = 0.7127760052680969
Iteration [34970]: Loss = 0.712632954120636
Iteration [34971]: Loss = 4.881704807281494
Iteration [34972]: Loss = 4.881269931793213
Iteration [34973]: Loss = 0.7128623127937317
Iteration [34974]: Loss = 0.7131031155586243
Iteration [34975]: Loss = 4.877564430236816
Iteration [34976]: Loss = 0.7136666774749756
Iteration [34977]: Loss = 4.874007701873779
Iteration [34978]: Loss = 0.7144930958747864
Iteration [34979]: Loss = 0.7149125933647156
Iteration [34980]: Loss = 0.7152422070503235
Iteration [34981]: Loss = 0.7154908776283264
Iteration [34982]: Loss = 0.715666651725769
Iteration [34983]: Loss = 0.7157766819000244
Iteration [34984]: Loss = 0.7158275246620178
Iteration [34985]: Loss = 0.7158249616622925
Iteration [34986]: Loss = 0.7157743573188782
Iteration [34987]: Loss = 0.7156804800033569
Iteration [34988]: Loss = 0.7155475616455078
Iteration [34989]: Loss = 0.7153797149658203
Iteration [34990]: Loss = 0.7151802182197571
Iteration [34991]: Loss = 9.023174285888672
Iteration [34992]: Loss = 0.715278148651123
Iteration [34993]: Loss = 4.866179466247559
Iteration [34994]: Loss = 0.7159842252731323
Iteration [34995]: Loss = 0.7163511514663696
Iteration [34996]: Loss = 0.7166340947151184
Iteration [34997]: Loss = 0.7168412208557129
Iteration [34998]: Loss = 0.7169800400733948
Iteration [34999]: Loss = 0.7170573472976685
Iteration [35000]: Loss = 0.7170790433883667
Iteration [35001]: Loss = 0.7170508503913879
Iteration [35002]: Loss = 0.7169777154922485
Iteration [35003]: Loss = 0.7168640494346619
Iteration [35004]: Loss = 0.7167138457298279
Iteration [35005]: Loss = 0.7165308594703674
Iteration [35006]: Loss = 0.7163183093070984
Iteration [35007]: Loss = 0.7160793542861938
Iteration [35008]: Loss = 0.7158163785934448
Iteration [35009]: Loss = 0.7155318260192871
Iteration [35010]: Loss = 0.7152280807495117
Iteration [35011]: Loss = 0.7149069905281067
Iteration [35012]: Loss = 4.870993614196777
Iteration [35013]: Loss = 0.7145083546638489
Iteration [35014]: Loss = 0.7144051790237427
Iteration [35015]: Loss = 0.7142646908760071
Iteration [35016]: Loss = 9.032747268676758
Iteration [35017]: Loss = 0.7144571542739868
Iteration [35018]: Loss = 0.7147404551506042
Iteration [35019]: Loss = 4.869082927703857
Iteration [35020]: Loss = 0.7153719067573547
Iteration [35021]: Loss = 0.7157064080238342
Iteration [35022]: Loss = 0.7159606218338013
Iteration [35023]: Loss = 4.863062381744385
Iteration [35024]: Loss = 4.8610520362854
Iteration [35025]: Loss = 0.717136561870575
Iteration [35026]: Loss = 0.7176252007484436
Iteration [35027]: Loss = 0.7180182933807373
Iteration [35028]: Loss = 0.7183253765106201
Iteration [35029]: Loss = 0.7185548543930054
Iteration [35030]: Loss = 0.7187144160270691
Iteration [35031]: Loss = 0.7188109159469604
Iteration [35032]: Loss = 0.7188505530357361
Iteration [35033]: Loss = 0.7188390493392944
Iteration [35034]: Loss = 4.849817276000977
Iteration [35035]: Loss = 0.7189655303955078
Iteration [35036]: Loss = 0.7190840840339661
Iteration [35037]: Loss = 0.7191436290740967
Iteration [35038]: Loss = 0.7191500067710876
Iteration [35039]: Loss = 4.848180294036865
Iteration [35040]: Loss = 0.719307005405426
Iteration [35041]: Loss = 0.7194383144378662
Iteration [35042]: Loss = 0.7195096611976624
Iteration [35043]: Loss = 0.7195264101028442
Iteration [35044]: Loss = 0.7194944620132446
Iteration [35045]: Loss = 0.7194185853004456
Iteration [35046]: Loss = 4.847209930419922
Iteration [35047]: Loss = 4.84655237197876
Iteration [35048]: Loss = 0.7197874188423157
Iteration [35049]: Loss = 0.7200581431388855
Iteration [35050]: Loss = 4.842457294464111
Iteration [35051]: Loss = 4.840408802032471
Iteration [35052]: Loss = 0.7212686538696289
Iteration [35053]: Loss = 0.72176194190979
Iteration [35054]: Loss = 0.7221482992172241
Iteration [35055]: Loss = 0.7224505543708801
Iteration [35056]: Loss = 0.7226775884628296
Iteration [35057]: Loss = 0.7228360772132874
Iteration [35058]: Loss = 0.7229333519935608
Iteration [35059]: Loss = 0.7229751348495483
Iteration [35060]: Loss = 0.7229671478271484
Iteration [35061]: Loss = 0.7229142189025879
Iteration [35062]: Loss = 0.7228208780288696
Iteration [35063]: Loss = 0.7226910591125488
Iteration [35064]: Loss = 0.7225285172462463
Iteration [35065]: Loss = 0.7223364114761353
Iteration [35066]: Loss = 0.7221178412437439
Iteration [35067]: Loss = 0.7218753695487976
Iteration [35068]: Loss = 4.835702896118164
Iteration [35069]: Loss = 4.835754871368408
Iteration [35070]: Loss = 0.7218177318572998
Iteration [35071]: Loss = 0.7219672799110413
Iteration [35072]: Loss = 0.72205650806427
Iteration [35073]: Loss = 4.833319664001465
Iteration [35074]: Loss = 0.7223480939865112
Iteration [35075]: Loss = 0.7225339412689209
Iteration [35076]: Loss = 0.722655713558197
Iteration [35077]: Loss = 4.830199718475342
Iteration [35078]: Loss = 4.828797340393066
Iteration [35079]: Loss = 0.7234817743301392
Iteration [35080]: Loss = 0.723867654800415
Iteration [35081]: Loss = 0.7241698503494263
Iteration [35082]: Loss = 0.7243964076042175
Iteration [35083]: Loss = 0.7245549559593201
Iteration [35084]: Loss = 0.7246519923210144
Iteration [35085]: Loss = 0.7246938347816467
Iteration [35086]: Loss = 0.7246858477592468
Iteration [35087]: Loss = 4.82073450088501
Iteration [35088]: Loss = 0.7248102426528931
Iteration [35089]: Loss = 0.7249244451522827
Iteration [35090]: Loss = 0.7249816656112671
Iteration [35091]: Loss = 4.8189849853515625
Iteration [35092]: Loss = 0.7252172231674194
Iteration [35093]: Loss = 0.7253787517547607
Iteration [35094]: Loss = 4.816565036773682
Iteration [35095]: Loss = 4.815018653869629
Iteration [35096]: Loss = 0.7262977361679077
Iteration [35097]: Loss = 0.7267075777053833
Iteration [35098]: Loss = 0.7270312905311584
Iteration [35099]: Loss = 0.7272771000862122
Iteration [35100]: Loss = 4.806858539581299
Iteration [35101]: Loss = 0.727834165096283
Iteration [35102]: Loss = 0.7281320095062256
Iteration [35103]: Loss = 0.7283546328544617
Iteration [35104]: Loss = 0.7285093069076538
Iteration [35105]: Loss = 0.7286028861999512
Iteration [35106]: Loss = 0.7286413908004761
Iteration [35107]: Loss = 4.801091194152832
Iteration [35108]: Loss = 0.7288437485694885
Iteration [35109]: Loss = 0.7289902567863464
Iteration [35110]: Loss = 0.7290763854980469
Iteration [35111]: Loss = 0.7291082143783569
Iteration [35112]: Loss = 4.798838138580322
Iteration [35113]: Loss = 0.729299008846283
Iteration [35114]: Loss = 0.7294403910636902
Iteration [35115]: Loss = 0.7295219898223877
Iteration [35116]: Loss = 0.7295496463775635
Iteration [35117]: Loss = 0.7295287847518921
Iteration [35118]: Loss = 0.7294641137123108
Iteration [35119]: Loss = 0.7293601632118225
Iteration [35120]: Loss = 0.7292207479476929
Iteration [35121]: Loss = 4.799042701721191
Iteration [35122]: Loss = 0.7291189432144165
Iteration [35123]: Loss = 0.7291358709335327
Iteration [35124]: Loss = 0.7291051745414734
Iteration [35125]: Loss = 4.79912805557251
Iteration [35126]: Loss = 0.7291892170906067
Iteration [35127]: Loss = 0.7292851209640503
Iteration [35128]: Loss = 0.7293259501457214
Iteration [35129]: Loss = 0.7293168902397156
Iteration [35130]: Loss = 8.86673641204834
Iteration [35131]: Loss = 0.7297009229660034
Iteration [35132]: Loss = 4.794156551361084
Iteration [35133]: Loss = 0.7305843830108643
Iteration [35134]: Loss = 0.7310200929641724
Iteration [35135]: Loss = 4.787744998931885
Iteration [35136]: Loss = 0.7318991422653198
Iteration [35137]: Loss = 0.7323328256607056
Iteration [35138]: Loss = 4.781383514404297
Iteration [35139]: Loss = 0.7332078814506531
Iteration [35140]: Loss = 0.7336395978927612
Iteration [35141]: Loss = 0.7339831590652466
Iteration [35142]: Loss = 0.734247088432312
Iteration [35143]: Loss = 4.772866249084473
Iteration [35144]: Loss = 0.7348311543464661
Iteration [35145]: Loss = 0.7351387143135071
Iteration [35146]: Loss = 0.7353702187538147
Iteration [35147]: Loss = 0.7355329990386963
Iteration [35148]: Loss = 0.7356339693069458
Iteration [35149]: Loss = 8.798100471496582
Iteration [35150]: Loss = 4.764393329620361
Iteration [35151]: Loss = 0.7368813157081604
Iteration [35152]: Loss = 0.7374514937400818
Iteration [35153]: Loss = 0.7379201650619507
Iteration [35154]: Loss = 0.7382968664169312
Iteration [35155]: Loss = 0.7385909557342529
Iteration [35156]: Loss = 0.7388104200363159
Iteration [35157]: Loss = 0.7389626502990723
Iteration [35158]: Loss = 0.7390543818473816
Iteration [35159]: Loss = 4.7505316734313965
Iteration [35160]: Loss = 0.7393413782119751
Iteration [35161]: Loss = 0.7395210266113281
Iteration [35162]: Loss = 0.7396374344825745
Iteration [35163]: Loss = 0.739696741104126
Iteration [35164]: Loss = 0.7397047281265259
Iteration [35165]: Loss = 4.747787952423096
Iteration [35166]: Loss = 4.746920108795166
Iteration [35167]: Loss = 0.7402280569076538
Iteration [35168]: Loss = 0.7405247688293457
Iteration [35169]: Loss = 0.7407463788986206
Iteration [35170]: Loss = 0.7409005165100098
Iteration [35171]: Loss = 4.741466999053955
Iteration [35172]: Loss = 4.740041732788086
Iteration [35173]: Loss = 0.7417786121368408
Iteration [35174]: Loss = 0.742169976234436
Iteration [35175]: Loss = 0.7424770593643188
Iteration [35176]: Loss = 0.7427079677581787
Iteration [35177]: Loss = 0.7428704500198364
Iteration [35178]: Loss = 0.7429712414741516
Iteration [35179]: Loss = 0.7430161833763123
Iteration [35180]: Loss = 0.743010938167572
Iteration [35181]: Loss = 0.7429606914520264
Iteration [35182]: Loss = 0.7428696155548096
Iteration [35183]: Loss = 0.7427420616149902
Iteration [35184]: Loss = 8.7252836227417
Iteration [35185]: Loss = 4.7323689460754395
Iteration [35186]: Loss = 0.7434214949607849
Iteration [35187]: Loss = 0.7438358068466187
Iteration [35188]: Loss = 0.7441636323928833
Iteration [35189]: Loss = 0.7444136738777161
Iteration [35190]: Loss = 4.724422931671143
Iteration [35191]: Loss = 0.744968593120575
Iteration [35192]: Loss = 0.7452610731124878
Iteration [35193]: Loss = 4.720251083374023
Iteration [35194]: Loss = 0.7458880543708801
Iteration [35195]: Loss = 0.746211051940918
Iteration [35196]: Loss = 0.7464567422866821
Iteration [35197]: Loss = 0.7466323971748352
Iteration [35198]: Loss = 0.746745228767395
Iteration [35199]: Loss = 0.7468011975288391
Iteration [35200]: Loss = 0.7468062043190002
Iteration [35201]: Loss = 0.7467650771141052
Iteration [35202]: Loss = 0.7466825842857361
Iteration [35203]: Loss = 0.7465627193450928
Iteration [35204]: Loss = 0.7464092969894409
Iteration [35205]: Loss = 4.716740131378174
Iteration [35206]: Loss = 0.7462742924690247
Iteration [35207]: Loss = 0.7462725043296814
Iteration [35208]: Loss = 0.7462255358695984
Iteration [35209]: Loss = 0.7461376190185547
Iteration [35210]: Loss = 0.7460131049156189
Iteration [35211]: Loss = 0.7458555102348328
Iteration [35212]: Loss = 0.7456680536270142
Iteration [35213]: Loss = 0.7454538345336914
Iteration [35214]: Loss = 0.7452155947685242
Iteration [35215]: Loss = 8.70047664642334
Iteration [35216]: Loss = 8.698005676269531
Iteration [35217]: Loss = 0.7458667159080505
Iteration [35218]: Loss = 0.7464295625686646
Iteration [35219]: Loss = 0.746891975402832
Iteration [35220]: Loss = 4.711867809295654
Iteration [35221]: Loss = 0.7478072643280029
Iteration [35222]: Loss = 0.7482520937919617
Iteration [35223]: Loss = 4.705578327178955
Iteration [35224]: Loss = 0.7491368651390076
Iteration [35225]: Loss = 0.749568521976471
Iteration [35226]: Loss = 0.7499123811721802
Iteration [35227]: Loss = 0.750177264213562
Iteration [35228]: Loss = 0.7503708600997925
Iteration [35229]: Loss = 0.7505001425743103
Iteration [35230]: Loss = 0.7505717277526855
Iteration [35231]: Loss = 0.7505909204483032
Iteration [35232]: Loss = 0.750563383102417
Iteration [35233]: Loss = 0.7504933476448059
Iteration [35234]: Loss = 0.7503852844238281
Iteration [35235]: Loss = 0.7502430081367493
Iteration [35236]: Loss = 0.7500697374343872
Iteration [35237]: Loss = 0.7498688697814941
Iteration [35238]: Loss = 0.7496427893638611
Iteration [35239]: Loss = 0.7493943572044373
Iteration [35240]: Loss = 0.7491256594657898
Iteration [35241]: Loss = 0.7488387227058411
Iteration [35242]: Loss = 0.7485353946685791
Iteration [35243]: Loss = 0.7482175827026367
Iteration [35244]: Loss = 0.7478864789009094
Iteration [35245]: Loss = 0.747543454170227
Iteration [35246]: Loss = 0.7471897602081299
Iteration [35247]: Loss = 4.713918685913086
Iteration [35248]: Loss = 0.7467107176780701
Iteration [35249]: Loss = 0.7465615272521973
Iteration [35250]: Loss = 4.71600341796875
Iteration [35251]: Loss = 0.7464315891265869
Iteration [35252]: Loss = 0.7464311718940735
Iteration [35253]: Loss = 0.7463860511779785
Iteration [35254]: Loss = 0.7463005781173706
Iteration [35255]: Loss = 0.7461788654327393
Iteration [35256]: Loss = 0.7460246682167053
Iteration [35257]: Loss = 0.7458409070968628
Iteration [35258]: Loss = 0.7456307411193848
Iteration [35259]: Loss = 0.7453969717025757
Iteration [35260]: Loss = 0.7451415061950684
Iteration [35261]: Loss = 0.7448670268058777
Iteration [35262]: Loss = 0.7445752024650574
Iteration [35263]: Loss = 0.7442677617073059
Iteration [35264]: Loss = 0.743946373462677
Iteration [35265]: Loss = 0.7436125874519348
Iteration [35266]: Loss = 0.7432673573493958
Iteration [35267]: Loss = 0.7429119348526001
Iteration [35268]: Loss = 4.734093189239502
Iteration [35269]: Loss = 0.7424312233924866
Iteration [35270]: Loss = 0.7422819137573242
Iteration [35271]: Loss = 0.7421030402183533
Iteration [35272]: Loss = 0.741897463798523
Iteration [35273]: Loss = 0.7416679263114929
Iteration [35274]: Loss = 0.7414168119430542
Iteration [35275]: Loss = 0.7411465048789978
Iteration [35276]: Loss = 4.7421112060546875
Iteration [35277]: Loss = 0.7408109903335571
Iteration [35278]: Loss = 0.740723729133606
Iteration [35279]: Loss = 0.7406010031700134
Iteration [35280]: Loss = 0.7404459714889526
Iteration [35281]: Loss = 0.7402620315551758
Iteration [35282]: Loss = 4.745949745178223
Iteration [35283]: Loss = 0.7400745153427124
Iteration [35284]: Loss = 4.74595832824707
Iteration [35285]: Loss = 0.7402394413948059
Iteration [35286]: Loss = 0.7403653860092163
Iteration [35287]: Loss = 4.7441277503967285
Iteration [35288]: Loss = 0.7407072186470032
Iteration [35289]: Loss = 4.741873264312744
Iteration [35290]: Loss = 0.7412993907928467
Iteration [35291]: Loss = 4.738552570343018
Iteration [35292]: Loss = 0.7420937418937683
Iteration [35293]: Loss = 0.7424877882003784
Iteration [35294]: Loss = 0.7427984476089478
Iteration [35295]: Loss = 0.743033766746521
Iteration [35296]: Loss = 0.7432013154029846
Iteration [35297]: Loss = 4.730494022369385
Iteration [35298]: Loss = 0.7436131834983826
Iteration [35299]: Loss = 0.7438439130783081
Iteration [35300]: Loss = 0.7440072298049927
Iteration [35301]: Loss = 0.7441098093986511
Iteration [35302]: Loss = 4.7264790534973145
Iteration [35303]: Loss = 0.7444104552268982
Iteration [35304]: Loss = 4.724422931671143
Iteration [35305]: Loss = 0.7449674606323242
Iteration [35306]: Loss = 4.721282958984375
Iteration [35307]: Loss = 0.7457317113876343
Iteration [35308]: Loss = 0.7461122870445251
Iteration [35309]: Loss = 0.7464105486869812
Iteration [35310]: Loss = 0.7466346025466919
Iteration [35311]: Loss = 0.7467917203903198
Iteration [35312]: Loss = 0.7468884587287903
Iteration [35313]: Loss = 0.7469310760498047
Iteration [35314]: Loss = 0.7469245791435242
Iteration [35315]: Loss = 0.7468741536140442
Iteration [35316]: Loss = 4.7141194343566895
Iteration [35317]: Loss = 4.7135162353515625
Iteration [35318]: Loss = 0.7472368478775024
Iteration [35319]: Loss = 0.7474845051765442
Iteration [35320]: Loss = 0.7476627826690674
Iteration [35321]: Loss = 0.7477787137031555
Iteration [35322]: Loss = 0.7478382587432861
Iteration [35323]: Loss = 0.747847318649292
Iteration [35324]: Loss = 0.7478105425834656
Iteration [35325]: Loss = 0.7477327585220337
Iteration [35326]: Loss = 0.7476179599761963
Iteration [35327]: Loss = 0.7474697828292847
Iteration [35328]: Loss = 0.7472915649414062
Iteration [35329]: Loss = 4.712700366973877
Iteration [35330]: Loss = 0.7471116185188293
Iteration [35331]: Loss = 0.7470896244049072
Iteration [35332]: Loss = 0.747025191783905
Iteration [35333]: Loss = 0.7469224333763123
Iteration [35334]: Loss = 0.7467851638793945
Iteration [35335]: Loss = 0.746616780757904
Iteration [35336]: Loss = 0.7464205026626587
Iteration [35337]: Loss = 0.7461992502212524
Iteration [35338]: Loss = 0.7459551692008972
Iteration [35339]: Loss = 4.719254016876221
Iteration [35340]: Loss = 0.7456634044647217
Iteration [35341]: Loss = 0.7455939054489136
Iteration [35342]: Loss = 0.7454867362976074
Iteration [35343]: Loss = 0.7453457713127136
Iteration [35344]: Loss = 0.7451741695404053
Iteration [35345]: Loss = 0.7449750304222107
Iteration [35346]: Loss = 4.723679065704346
Iteration [35347]: Loss = 0.7447599768638611
Iteration [35348]: Loss = 0.7447233200073242
Iteration [35349]: Loss = 0.7446458339691162
Iteration [35350]: Loss = 0.744531512260437
Iteration [35351]: Loss = 0.7443839311599731
Iteration [35352]: Loss = 0.7442066669464111
Iteration [35353]: Loss = 0.7440025806427002
Iteration [35354]: Loss = 0.7437741756439209
Iteration [35355]: Loss = 0.7435240745544434
Iteration [35356]: Loss = 0.7432544231414795
Iteration [35357]: Loss = 0.7429671883583069
Iteration [35358]: Loss = 0.7426640391349792
Iteration [35359]: Loss = 0.7423468232154846
Iteration [35360]: Loss = 0.7420169115066528
Iteration [35361]: Loss = 0.7416753172874451
Iteration [35362]: Loss = 0.7413235306739807
Iteration [35363]: Loss = 0.7409624457359314
Iteration [35364]: Loss = 0.7405931353569031
Iteration [35365]: Loss = 0.7402163147926331
Iteration [35366]: Loss = 4.746994495391846
Iteration [35367]: Loss = 0.7396994829177856
Iteration [35368]: Loss = 0.7395351529121399
Iteration [35369]: Loss = 0.7393430471420288
Iteration [35370]: Loss = 0.7391257882118225
Iteration [35371]: Loss = 4.751512050628662
Iteration [35372]: Loss = 0.7388817071914673
Iteration [35373]: Loss = 0.738833487033844
Iteration [35374]: Loss = 4.752182960510254
Iteration [35375]: Loss = 0.7388779520988464
Iteration [35376]: Loss = 0.7389526963233948
Iteration [35377]: Loss = 0.7389758825302124
Iteration [35378]: Loss = 0.7389526963233948
Iteration [35379]: Loss = 0.7388875484466553
Iteration [35380]: Loss = 0.7387847304344177
Iteration [35381]: Loss = 0.7386481165885925
Iteration [35382]: Loss = 4.7534499168396
Iteration [35383]: Loss = 0.738541305065155
Iteration [35384]: Loss = 0.7385517954826355
Iteration [35385]: Loss = 0.7385171055793762
Iteration [35386]: Loss = 4.753636360168457
Iteration [35387]: Loss = 4.752954006195068
Iteration [35388]: Loss = 0.7389231324195862
Iteration [35389]: Loss = 4.750089645385742
Iteration [35390]: Loss = 0.7396283149719238
Iteration [35391]: Loss = 0.7399846315383911
Iteration [35392]: Loss = 0.740261435508728
Iteration [35393]: Loss = 4.74397611618042
Iteration [35394]: Loss = 4.742101192474365
Iteration [35395]: Loss = 0.7414239645004272
Iteration [35396]: Loss = 0.7418875694274902
Iteration [35397]: Loss = 0.7422610521316528
Iteration [35398]: Loss = 0.742553174495697
Iteration [35399]: Loss = 0.7427719831466675
Iteration [35400]: Loss = 0.7429248690605164
Iteration [35401]: Loss = 0.7430180907249451
Iteration [35402]: Loss = 0.7430576682090759
Iteration [35403]: Loss = 0.7430490255355835
Iteration [35404]: Loss = 0.7429969310760498
Iteration [35405]: Loss = 0.7429054379463196
Iteration [35406]: Loss = 0.7427787780761719
Iteration [35407]: Loss = 4.733747959136963
Iteration [35408]: Loss = 0.7426879405975342
Iteration [35409]: Loss = 0.7427045106887817
Iteration [35410]: Loss = 0.7426750659942627
Iteration [35411]: Loss = 0.74260413646698
Iteration [35412]: Loss = 0.7424960136413574
Iteration [35413]: Loss = 0.742354154586792
Iteration [35414]: Loss = 4.7358245849609375
Iteration [35415]: Loss = 4.735561370849609
Iteration [35416]: Loss = 0.7424970865249634
Iteration [35417]: Loss = 4.73343563079834
Iteration [35418]: Loss = 0.7430658340454102
Iteration [35419]: Loss = 0.7433632612228394
Iteration [35420]: Loss = 0.7435868978500366
Iteration [35421]: Loss = 4.7284321784973145
Iteration [35422]: Loss = 0.7440942525863647
Iteration [35423]: Loss = 0.744365394115448
Iteration [35424]: Loss = 0.7445651888847351
Iteration [35425]: Loss = 0.7447008490562439
Iteration [35426]: Loss = 0.7447785139083862
Iteration [35427]: Loss = 4.723430156707764
Iteration [35428]: Loss = 0.7450360059738159
Iteration [35429]: Loss = 0.7452006340026855
Iteration [35430]: Loss = 0.7453042268753052
Iteration [35431]: Loss = 0.7453532218933105
Iteration [35432]: Loss = 0.7453528642654419
Iteration [35433]: Loss = 0.7453079223632812
Iteration [35434]: Loss = 0.7452229857444763
Iteration [35435]: Loss = 0.745102047920227
Iteration [35436]: Loss = 0.7449486255645752
Iteration [35437]: Loss = 0.7447659969329834
Iteration [35438]: Loss = 0.7445571422576904
Iteration [35439]: Loss = 0.7443245053291321
Iteration [35440]: Loss = 0.7440707087516785
Iteration [35441]: Loss = 4.728178024291992
Iteration [35442]: Loss = 0.7437623143196106
Iteration [35443]: Loss = 0.7436859011650085
Iteration [35444]: Loss = 0.7435729503631592
Iteration [35445]: Loss = 0.7434266805648804
Iteration [35446]: Loss = 0.7432505488395691
Iteration [35447]: Loss = 0.7430476546287537
Iteration [35448]: Loss = 4.732799530029297
Iteration [35449]: Loss = 0.742826521396637
Iteration [35450]: Loss = 0.7427874207496643
Iteration [35451]: Loss = 0.7427078485488892
Iteration [35452]: Loss = 0.7425921559333801
Iteration [35453]: Loss = 0.742443323135376
Iteration [35454]: Loss = 0.7422652244567871
Iteration [35455]: Loss = 0.7420604825019836
Iteration [35456]: Loss = 0.7418317794799805
Iteration [35457]: Loss = 4.738673686981201
Iteration [35458]: Loss = 4.738744258880615
Iteration [35459]: Loss = 4.73781156539917
Iteration [35460]: Loss = 0.7421493530273438
Iteration [35461]: Loss = 4.734543323516846
Iteration [35462]: Loss = 4.732262134552002
Iteration [35463]: Loss = 0.7435756921768188
Iteration [35464]: Loss = 0.7441094517707825
Iteration [35465]: Loss = 0.744546115398407
Iteration [35466]: Loss = 0.7448951601982117
Iteration [35467]: Loss = 0.745165228843689
Iteration [35468]: Loss = 4.720791816711426
Iteration [35469]: Loss = 4.71897029876709
Iteration [35470]: Loss = 0.7463076114654541
Iteration [35471]: Loss = 0.7467643022537231
Iteration [35472]: Loss = 0.7471314072608948
Iteration [35473]: Loss = 0.7474175691604614
Iteration [35474]: Loss = 0.747630774974823
Iteration [35475]: Loss = 0.7477782964706421
Iteration [35476]: Loss = 0.7478664517402649
Iteration [35477]: Loss = 0.7479013204574585
Iteration [35478]: Loss = 0.7478880882263184
Iteration [35479]: Loss = 0.7478314638137817
Iteration [35480]: Loss = 8.671578407287598
Iteration [35481]: Loss = 0.7481085062026978
Iteration [35482]: Loss = 0.7483997344970703
Iteration [35483]: Loss = 4.705532550811768
Iteration [35484]: Loss = 0.7490203976631165
Iteration [35485]: Loss = 0.7493387460708618
Iteration [35486]: Loss = 4.7010369300842285
Iteration [35487]: Loss = 0.7500051259994507
Iteration [35488]: Loss = 0.750342845916748
Iteration [35489]: Loss = 0.7506027221679688
Iteration [35490]: Loss = 0.7507923245429993
Iteration [35491]: Loss = 4.694809913635254
Iteration [35492]: Loss = 0.7512384653091431
Iteration [35493]: Loss = 0.7514455318450928
Iteration [35494]: Loss = 0.7515897750854492
Iteration [35495]: Loss = 0.7516828775405884
Iteration [35496]: Loss = 0.7517300248146057
Iteration [35497]: Loss = 0.7517356276512146
Iteration [35498]: Loss = 0.7517040967941284
Iteration [35499]: Loss = 0.7516388893127441
Iteration [35500]: Loss = 0.751543402671814
Iteration [35501]: Loss = 0.751420795917511
Iteration [35502]: Loss = 0.7512735724449158
Iteration [35503]: Loss = 0.7511041760444641
Iteration [35504]: Loss = 0.7509150505065918
Iteration [35505]: Loss = 0.7507081031799316
Iteration [35506]: Loss = 0.7504850029945374
Iteration [35507]: Loss = 0.7502474188804626
Iteration [35508]: Loss = 4.699098110198975
Iteration [35509]: Loss = 0.7499425411224365
Iteration [35510]: Loss = 0.7498570084571838
Iteration [35511]: Loss = 0.7497433423995972
Iteration [35512]: Loss = 0.749604344367981
Iteration [35513]: Loss = 0.7494425177574158
Iteration [35514]: Loss = 0.7492601871490479
Iteration [35515]: Loss = 0.7490593194961548
Iteration [35516]: Loss = 0.7488420009613037
Iteration [35517]: Loss = 0.7486096620559692
Iteration [35518]: Loss = 0.7483639717102051
Iteration [35519]: Loss = 0.7481061220169067
Iteration [35520]: Loss = 0.7478373646736145
Iteration [35521]: Loss = 0.7475588917732239
Iteration [35522]: Loss = 0.747271716594696
Iteration [35523]: Loss = 0.7469766139984131
Iteration [35524]: Loss = 0.7466745376586914
Iteration [35525]: Loss = 0.7463659644126892
Iteration [35526]: Loss = 0.7460517883300781
Iteration [35527]: Loss = 0.7457323670387268
Iteration [35528]: Loss = 0.7454084753990173
Iteration [35529]: Loss = 0.7450805902481079
Iteration [35530]: Loss = 0.7447488903999329
Iteration [35531]: Loss = 0.7444139719009399
Iteration [35532]: Loss = 0.7440760731697083
Iteration [35533]: Loss = 0.7437356114387512
Iteration [35534]: Loss = 0.7433927059173584
Iteration [35535]: Loss = 0.7430476546287537
Iteration [35536]: Loss = 0.7427008748054504
Iteration [35537]: Loss = 4.735018253326416
Iteration [35538]: Loss = 0.7422113418579102
Iteration [35539]: Loss = 0.7420480847358704
Iteration [35540]: Loss = 0.741864800453186
Iteration [35541]: Loss = 0.7416635751724243
Iteration [35542]: Loss = 4.739316940307617
Iteration [35543]: Loss = 0.7414228320121765
Iteration [35544]: Loss = 0.7413655519485474
Iteration [35545]: Loss = 0.7412778735160828
Iteration [35546]: Loss = 0.7411626577377319
Iteration [35547]: Loss = 0.7410227060317993
Iteration [35548]: Loss = 0.740860641002655
Iteration [35549]: Loss = 0.7406785488128662
Iteration [35550]: Loss = 0.7404783964157104
Iteration [35551]: Loss = 0.7402620315551758
Iteration [35552]: Loss = 0.7400311231613159
Iteration [35553]: Loss = 0.7397870421409607
Iteration [35554]: Loss = 0.7395312786102295
Iteration [35555]: Loss = 0.7392648458480835
Iteration [35556]: Loss = 0.7389888763427734
Iteration [35557]: Loss = 0.7387043833732605
Iteration [35558]: Loss = 0.7384123206138611
Iteration [35559]: Loss = 0.7381131649017334
Iteration [35560]: Loss = 0.7378079295158386
Iteration [35561]: Loss = 4.758159160614014
Iteration [35562]: Loss = 0.7373905777931213
Iteration [35563]: Loss = 0.7372584939002991
Iteration [35564]: Loss = 0.7371037602424622
Iteration [35565]: Loss = 0.736928403377533
Iteration [35566]: Loss = 0.737005889415741
Iteration [35567]: Loss = 4.76171350479126
Iteration [35568]: Loss = 4.761129856109619
Iteration [35569]: Loss = 0.7372369766235352
Iteration [35570]: Loss = 0.7375002503395081
Iteration [35571]: Loss = 0.7376769781112671
Iteration [35572]: Loss = 0.7377759218215942
Iteration [35573]: Loss = 0.7377855181694031
Iteration [35574]: Loss = 0.737737774848938
Iteration [35575]: Loss = 0.7376507520675659
Iteration [35576]: Loss = 0.7375286221504211
Iteration [35577]: Loss = 0.7373747825622559
Iteration [35578]: Loss = 0.7371925115585327
Iteration [35579]: Loss = 0.7369843125343323
Iteration [35580]: Loss = 0.7367531657218933
Iteration [35581]: Loss = 0.7365012168884277
Iteration [35582]: Loss = 0.7362304329872131
Iteration [35583]: Loss = 0.7359430193901062
Iteration [35584]: Loss = 4.767077922821045
Iteration [35585]: Loss = 4.767371654510498
Iteration [35586]: Loss = 0.735734224319458
Iteration [35587]: Loss = 0.7358304262161255
Iteration [35588]: Loss = 0.7358731031417847
Iteration [35589]: Loss = 0.735867977142334
Iteration [35590]: Loss = 0.7358194589614868
Iteration [35591]: Loss = 0.7357320785522461
Iteration [35592]: Loss = 0.7356095910072327
Iteration [35593]: Loss = 0.7354556322097778
Iteration [35594]: Loss = 0.7352733612060547
Iteration [35595]: Loss = 0.7350653409957886
Iteration [35596]: Loss = 0.7348343729972839
Iteration [35597]: Loss = 4.772173881530762
Iteration [35598]: Loss = 4.772248268127441
Iteration [35599]: Loss = 0.7347639203071594
Iteration [35600]: Loss = 0.7348971366882324
Iteration [35601]: Loss = 0.7349734902381897
Iteration [35602]: Loss = 0.7349985837936401
Iteration [35603]: Loss = 0.7349776029586792
Iteration [35604]: Loss = 0.7349149584770203
Iteration [35605]: Loss = 0.7348147630691528
Iteration [35606]: Loss = 0.7346808910369873
Iteration [35607]: Loss = 0.7345167994499207
Iteration [35608]: Loss = 0.7343253493309021
Iteration [35609]: Loss = 0.7341093420982361
Iteration [35610]: Loss = 0.7338711619377136
Iteration [35611]: Loss = 0.7336130738258362
Iteration [35612]: Loss = 0.7333371639251709
Iteration [35613]: Loss = 0.7330451011657715
Iteration [35614]: Loss = 0.7327385544776917
Iteration [35615]: Loss = 0.7324190139770508
Iteration [35616]: Loss = 0.7320877909660339
Iteration [35617]: Loss = 0.7317461371421814
Iteration [35618]: Loss = 0.7313950061798096
Iteration [35619]: Loss = 0.7310354113578796
Iteration [35620]: Loss = 0.7306682467460632
Iteration [35621]: Loss = 0.7302943468093872
Iteration [35622]: Loss = 0.7299143075942993
Iteration [35623]: Loss = 0.7295286655426025
Iteration [35624]: Loss = 0.7291383147239685
Iteration [35625]: Loss = 0.7287434339523315
Iteration [35626]: Loss = 0.7283447980880737
Iteration [35627]: Loss = 0.7279425263404846
Iteration [35628]: Loss = 0.7275371551513672
Iteration [35629]: Loss = 4.808447360992432
Iteration [35630]: Loss = 0.7269747257232666
Iteration [35631]: Loss = 0.7267926931381226
Iteration [35632]: Loss = 0.7265856266021729
Iteration [35633]: Loss = 0.7263559103012085
Iteration [35634]: Loss = 0.7261058688163757
Iteration [35635]: Loss = 0.7258377075195312
Iteration [35636]: Loss = 0.7255532145500183
Iteration [35637]: Loss = 0.7252537608146667
Iteration [35638]: Loss = 0.7249413132667542
Iteration [35639]: Loss = 0.7246167063713074
Iteration [35640]: Loss = 0.7242815494537354
Iteration [35641]: Loss = 0.7239367365837097
Iteration [35642]: Loss = 0.7235832810401917
Iteration [35643]: Loss = 0.7232221364974976
Iteration [35644]: Loss = 0.7228540182113647
Iteration [35645]: Loss = 0.7224796414375305
Iteration [35646]: Loss = 0.722099781036377
Iteration [35647]: Loss = 4.835188865661621
Iteration [35648]: Loss = 0.7215824723243713
Iteration [35649]: Loss = 0.7214203476905823
Iteration [35650]: Loss = 0.7212315201759338
Iteration [35651]: Loss = 4.838651657104492
Iteration [35652]: Loss = 0.7210404872894287
Iteration [35653]: Loss = 0.7210174798965454
Iteration [35654]: Loss = 0.7209537029266357
Iteration [35655]: Loss = 8.958093643188477
Iteration [35656]: Loss = 4.837608814239502
Iteration [35657]: Loss = 0.7217752933502197
Iteration [35658]: Loss = 0.7222256064414978
Iteration [35659]: Loss = 0.7225889563560486
Iteration [35660]: Loss = 0.7228736877441406
Iteration [35661]: Loss = 0.723087728023529
Iteration [35662]: Loss = 0.7232379913330078
Iteration [35663]: Loss = 0.7233307361602783
Iteration [35664]: Loss = 0.723371684551239
Iteration [35665]: Loss = 0.7233659029006958
Iteration [35666]: Loss = 0.7233180999755859
Iteration [35667]: Loss = 0.7232324481010437
Iteration [35668]: Loss = 0.7231127023696899
Iteration [35669]: Loss = 0.7229623198509216
Iteration [35670]: Loss = 0.7227843999862671
Iteration [35671]: Loss = 0.7225814461708069
Iteration [35672]: Loss = 0.7223563194274902
Iteration [35673]: Loss = 0.7221109867095947
Iteration [35674]: Loss = 0.721847414970398
Iteration [35675]: Loss = 0.7215677499771118
Iteration [35676]: Loss = 0.7212733030319214
Iteration [35677]: Loss = 4.8389153480529785
Iteration [35678]: Loss = 0.7209011316299438
Iteration [35679]: Loss = 0.7208003997802734
Iteration [35680]: Loss = 0.72066730260849
Iteration [35681]: Loss = 0.7205049991607666
Iteration [35682]: Loss = 0.7203162908554077
Iteration [35683]: Loss = 0.7201040387153625
Iteration [35684]: Loss = 0.7198705673217773
Iteration [35685]: Loss = 0.7196177244186401
Iteration [35686]: Loss = 0.7193479537963867
Iteration [35687]: Loss = 0.7190625071525574
Iteration [35688]: Loss = 0.7187632322311401
Iteration [35689]: Loss = 0.7184513807296753
Iteration [35690]: Loss = 0.7181283235549927
Iteration [35691]: Loss = 0.717795193195343
Iteration [35692]: Loss = 4.856475830078125
Iteration [35693]: Loss = 0.717357873916626
Iteration [35694]: Loss = 0.717229962348938
Iteration [35695]: Loss = 0.7170724868774414
Iteration [35696]: Loss = 0.7168886065483093
Iteration [35697]: Loss = 0.7166807651519775
Iteration [35698]: Loss = 0.7164513468742371
Iteration [35699]: Loss = 4.862761497497559
Iteration [35700]: Loss = 0.7161913514137268
Iteration [35701]: Loss = 0.7161392569541931
Iteration [35702]: Loss = 0.7160499691963196
Iteration [35703]: Loss = 0.7159276008605957
Iteration [35704]: Loss = 0.7157750725746155
Iteration [35705]: Loss = 0.7155957221984863
Iteration [35706]: Loss = 4.866846084594727
Iteration [35707]: Loss = 0.7154213786125183
Iteration [35708]: Loss = 0.7154056429862976
Iteration [35709]: Loss = 0.7153494954109192
Iteration [35710]: Loss = 0.7152566313743591
Iteration [35711]: Loss = 4.868161678314209
Iteration [35712]: Loss = 0.7152303457260132
Iteration [35713]: Loss = 0.7152777910232544
Iteration [35714]: Loss = 0.7152782678604126
Iteration [35715]: Loss = 0.7152366638183594
Iteration [35716]: Loss = 0.715157151222229
Iteration [35717]: Loss = 0.7150434851646423
Iteration [35718]: Loss = 4.869333744049072
Iteration [35719]: Loss = 4.868916988372803
Iteration [35720]: Loss = 0.7152670621871948
Iteration [35721]: Loss = 0.7154824733734131
Iteration [35722]: Loss = 0.7156344652175903
Iteration [35723]: Loss = 0.7157292366027832
Iteration [35724]: Loss = 0.7157725095748901
Iteration [35725]: Loss = 0.715769350528717
Iteration [35726]: Loss = 4.865169525146484
Iteration [35727]: Loss = 0.7158957719802856
Iteration [35728]: Loss = 0.7160081267356873
Iteration [35729]: Loss = 0.7160671353340149
Iteration [35730]: Loss = 0.7160782814025879
Iteration [35731]: Loss = 4.86354923248291
Iteration [35732]: Loss = 0.7162287831306458
Iteration [35733]: Loss = 0.7163512706756592
Iteration [35734]: Loss = 0.7164195775985718
Iteration [35735]: Loss = 0.716438889503479
Iteration [35736]: Loss = 0.7164140939712524
Iteration [35737]: Loss = 0.7163497805595398
Iteration [35738]: Loss = 0.7162495255470276
Iteration [35739]: Loss = 0.716117262840271
Iteration [35740]: Loss = 0.7159560322761536
Iteration [35741]: Loss = 0.715768575668335
Iteration [35742]: Loss = 0.7155578136444092
Iteration [35743]: Loss = 0.7153258323669434
Iteration [35744]: Loss = 0.715074896812439
Iteration [35745]: Loss = 0.7148069739341736
Iteration [35746]: Loss = 0.7145236730575562
Iteration [35747]: Loss = 0.7142264246940613
Iteration [35748]: Loss = 0.7139168977737427
Iteration [35749]: Loss = 0.7135961055755615
Iteration [35750]: Loss = 0.7132654786109924
Iteration [35751]: Loss = 0.7129256725311279
Iteration [35752]: Loss = 0.7125778794288635
Iteration [35753]: Loss = 0.712222695350647
Iteration [35754]: Loss = 0.7118611335754395
Iteration [35755]: Loss = 0.711493730545044
Iteration [35756]: Loss = 0.7111210823059082
Iteration [35757]: Loss = 0.7107436656951904
Iteration [35758]: Loss = 4.892361640930176
Iteration [35759]: Loss = 0.7102330327033997
Iteration [35760]: Loss = 0.7100749015808105
Iteration [35761]: Loss = 0.7098907828330994
Iteration [35762]: Loss = 0.7096832394599915
Iteration [35763]: Loss = 9.084541320800781
Iteration [35764]: Loss = 0.7097150087356567
Iteration [35765]: Loss = 0.709908127784729
Iteration [35766]: Loss = 0.7100407481193542
Iteration [35767]: Loss = 0.7101187109947205
Iteration [35768]: Loss = 0.7101474404335022
Iteration [35769]: Loss = 0.7101320028305054
Iteration [35770]: Loss = 4.893819332122803
Iteration [35771]: Loss = 0.710237979888916
Iteration [35772]: Loss = 0.7103420495986938
Iteration [35773]: Loss = 0.7103942036628723
Iteration [35774]: Loss = 0.7103998064994812
Iteration [35775]: Loss = 0.7103632688522339
Iteration [35776]: Loss = 0.7102890610694885
Iteration [35777]: Loss = 0.7101807594299316
Iteration [35778]: Loss = 0.7100417017936707
Iteration [35779]: Loss = 0.7098751068115234
Iteration [35780]: Loss = 0.7096837162971497
Iteration [35781]: Loss = 0.7094698548316956
Iteration [35782]: Loss = 4.898115634918213
Iteration [35783]: Loss = 0.7092375755310059
Iteration [35784]: Loss = 0.7091976404190063
Iteration [35785]: Loss = 0.7091202139854431
Iteration [35786]: Loss = 0.7090091109275818
Iteration [35787]: Loss = 0.7088676691055298
Iteration [35788]: Loss = 0.7086990475654602
Iteration [35789]: Loss = 0.7085058093070984
Iteration [35790]: Loss = 0.7082904577255249
Iteration [35791]: Loss = 0.7080551981925964
Iteration [35792]: Loss = 0.7078021168708801
Iteration [35793]: Loss = 0.7075328826904297
Iteration [35794]: Loss = 0.7072490453720093
Iteration [35795]: Loss = 0.7069523930549622
Iteration [35796]: Loss = 0.7066438794136047
Iteration [35797]: Loss = 0.7063249349594116
Iteration [35798]: Loss = 0.705996572971344
Iteration [35799]: Loss = 0.7056596279144287
Iteration [35800]: Loss = 0.7053150534629822
Iteration [35801]: Loss = 0.704963743686676
Iteration [35802]: Loss = 0.7046062350273132
Iteration [35803]: Loss = 9.1433744430542
Iteration [35804]: Loss = 0.7043829560279846
Iteration [35805]: Loss = 0.7044679522514343
Iteration [35806]: Loss = 0.7045037746429443
Iteration [35807]: Loss = 0.7044951915740967
Iteration [35808]: Loss = 0.7044466733932495
Iteration [35809]: Loss = 0.7043622136116028
Iteration [35810]: Loss = 0.704245388507843
Iteration [35811]: Loss = 0.7040993571281433
Iteration [35812]: Loss = 0.7039269804954529
Iteration [35813]: Loss = 0.7037310600280762
Iteration [35814]: Loss = 0.7035138607025146
Iteration [35815]: Loss = 0.703277587890625
Iteration [35816]: Loss = 0.7030240297317505
Iteration [35817]: Loss = 0.7027550935745239
Iteration [35818]: Loss = 0.7024720311164856
Iteration [35819]: Loss = 4.9345316886901855
Iteration [35820]: Loss = 4.934810161590576
Iteration [35821]: Loss = 0.702285885810852
Iteration [35822]: Loss = 0.702392041683197
Iteration [35823]: Loss = 0.7024468779563904
Iteration [35824]: Loss = 0.7024556994438171
Iteration [35825]: Loss = 0.7046399116516113
Iteration [35826]: Loss = 0.7045519351959229
Iteration [35827]: Loss = 0.7044143080711365
Iteration [35828]: Loss = 0.7042320370674133
Iteration [35829]: Loss = 0.7040096521377563
Iteration [35830]: Loss = 4.926357269287109
Iteration [35831]: Loss = 0.7038204669952393
Iteration [35832]: Loss = 0.7038246989250183
Iteration [35833]: Loss = 0.7037704586982727
Iteration [35834]: Loss = 0.7036637663841248
Iteration [35835]: Loss = 0.7035094499588013
Iteration [35836]: Loss = 0.7033123970031738
Iteration [35837]: Loss = 0.7025425434112549
Iteration [35838]: Loss = 0.7028073072433472
Iteration [35839]: Loss = 0.7025064826011658
Iteration [35840]: Loss = 0.7021777629852295
Iteration [35841]: Loss = 0.7018239498138428
Iteration [35842]: Loss = 0.7014473676681519
Iteration [35843]: Loss = 0.7010508179664612
Iteration [35844]: Loss = 0.7006357312202454
Iteration [35845]: Loss = 0.7002045512199402
Iteration [35846]: Loss = 4.947143077850342
Iteration [35847]: Loss = 0.6996603608131409
Iteration [35848]: Loss = 0.6995144486427307
Iteration [35849]: Loss = 4.9494099617004395
Iteration [35850]: Loss = 0.6994557976722717
Iteration [35851]: Loss = 0.6995159387588501
Iteration [35852]: Loss = 0.699512779712677
Iteration [35853]: Loss = 0.6994525790214539
Iteration [35854]: Loss = 0.6993412375450134
Iteration [35855]: Loss = 0.6991838812828064
Iteration [35856]: Loss = 0.6989848613739014
Iteration [35857]: Loss = 0.6987485289573669
Iteration [35858]: Loss = 0.6984784603118896
Iteration [35859]: Loss = 0.6981782913208008
Iteration [35860]: Loss = 0.6978510022163391
Iteration [35861]: Loss = 0.6974992156028748
Iteration [35862]: Loss = 0.6971254944801331
Iteration [35863]: Loss = 0.6967320442199707
Iteration [35864]: Loss = 0.6963208913803101
Iteration [35865]: Loss = 0.6958938241004944
Iteration [35866]: Loss = 0.6954525113105774
Iteration [35867]: Loss = 0.694998562335968
Iteration [35868]: Loss = 4.974645614624023
Iteration [35869]: Loss = 4.975265026092529
Iteration [35870]: Loss = 4.974240779876709
Iteration [35871]: Loss = 4.9717512130737305
Iteration [35872]: Loss = 0.6957967877388
Iteration [35873]: Loss = 0.6963865756988525
Iteration [35874]: Loss = 4.96234655380249
Iteration [35875]: Loss = 0.6975820660591125
Iteration [35876]: Loss = 0.6981748342514038
Iteration [35877]: Loss = 0.6986526250839233
Iteration [35878]: Loss = 0.6990270614624023
Iteration [35879]: Loss = 4.949501037597656
Iteration [35880]: Loss = 0.699852705001831
Iteration [35881]: Loss = 0.700287401676178
Iteration [35882]: Loss = 0.7006227970123291
Iteration [35883]: Loss = 0.7008686065673828
Iteration [35884]: Loss = 0.7010338306427002
Iteration [35885]: Loss = 0.7011265158653259
Iteration [35886]: Loss = 0.7011535167694092
Iteration [35887]: Loss = 0.7011218070983887
Iteration [35888]: Loss = 0.7010369896888733
Iteration [35889]: Loss = 0.7009041905403137
Iteration [35890]: Loss = 0.7007285356521606
Iteration [35891]: Loss = 0.7005141973495483
Iteration [35892]: Loss = 0.7002649307250977
Iteration [35893]: Loss = 0.6999843716621399
Iteration [35894]: Loss = 0.6996757388114929
Iteration [35895]: Loss = 0.6993415951728821
Iteration [35896]: Loss = 0.6989849209785461
Iteration [35897]: Loss = 0.6986076235771179
Iteration [35898]: Loss = 4.955246925354004
Iteration [35899]: Loss = 0.6981507539749146
Iteration [35900]: Loss = 0.6980397701263428
Iteration [35901]: Loss = 0.6978840827941895
Iteration [35902]: Loss = 0.6976880431175232
Iteration [35903]: Loss = 0.6974557638168335
Iteration [35904]: Loss = 0.6971908807754517
Iteration [35905]: Loss = 0.6968966722488403
Iteration [35906]: Loss = 0.6965760588645935
Iteration [35907]: Loss = 0.6962317228317261
Iteration [35908]: Loss = 0.6958662271499634
Iteration [35909]: Loss = 0.6954814195632935
Iteration [35910]: Loss = 0.6950793862342834
Iteration [35911]: Loss = 0.6946620345115662
Iteration [35912]: Loss = 0.6942307949066162
Iteration [35913]: Loss = 0.6937870383262634
Iteration [35914]: Loss = 0.6933321952819824
Iteration [35915]: Loss = 0.6928673982620239
Iteration [35916]: Loss = 0.6923937201499939
Iteration [35917]: Loss = 0.6919118762016296
Iteration [35918]: Loss = 4.991174221038818
Iteration [35919]: Loss = 0.6912791728973389
Iteration [35920]: Loss = 0.6910945177078247
Iteration [35921]: Loss = 4.994107723236084
Iteration [35922]: Loss = 0.6909680366516113
Iteration [35923]: Loss = 0.6909984946250916
Iteration [35924]: Loss = 0.6909710168838501
Iteration [35925]: Loss = 0.6908913254737854
Iteration [35926]: Loss = 0.6907646656036377
Iteration [35927]: Loss = 0.690595805644989
Iteration [35928]: Loss = 0.6903886795043945
Iteration [35929]: Loss = 0.6901476383209229
Iteration [35930]: Loss = 0.6898755431175232
Iteration [35931]: Loss = 0.6895758509635925
Iteration [35932]: Loss = 0.689251184463501
Iteration [35933]: Loss = 0.6889041662216187
Iteration [35934]: Loss = 0.688537061214447
Iteration [35935]: Loss = 0.6881518959999084
Iteration [35936]: Loss = 0.6877502799034119
Iteration [35937]: Loss = 0.6873342990875244
Iteration [35938]: Loss = 0.6869052648544312
Iteration [35939]: Loss = 0.6864641904830933
Iteration [35940]: Loss = 0.686012864112854
Iteration [35941]: Loss = 5.022706985473633
Iteration [35942]: Loss = 0.6854332685470581
Iteration [35943]: Loss = 0.6852719187736511
Iteration [35944]: Loss = 5.025302886962891
Iteration [35945]: Loss = 0.6851865649223328
Iteration [35946]: Loss = 0.6852351427078247
Iteration [35947]: Loss = 9.36373233795166
Iteration [35948]: Loss = 0.6858421564102173
Iteration [35949]: Loss = 0.6863449811935425
Iteration [35950]: Loss = 0.6867449283599854
Iteration [35951]: Loss = 0.6870518326759338
Iteration [35952]: Loss = 0.6872751116752625
Iteration [35953]: Loss = 0.6874228119850159
Iteration [35954]: Loss = 0.6875026822090149
Iteration [35955]: Loss = 0.6875210404396057
Iteration [35956]: Loss = 0.6874843835830688
Iteration [35957]: Loss = 0.6873978972434998
Iteration [35958]: Loss = 0.6872668266296387
Iteration [35959]: Loss = 0.6870954036712646
Iteration [35960]: Loss = 0.6868876814842224
Iteration [35961]: Loss = 0.6866474747657776
Iteration [35962]: Loss = 5.018245697021484
Iteration [35963]: Loss = 0.6864228844642639
Iteration [35964]: Loss = 5.018070220947266
Iteration [35965]: Loss = 0.686684787273407
Iteration [35966]: Loss = 0.6868788003921509
Iteration [35967]: Loss = 0.6870007514953613
Iteration [35968]: Loss = 0.687057375907898
Iteration [35969]: Loss = 0.687055230140686
Iteration [35970]: Loss = 5.014887809753418
Iteration [35971]: Loss = 0.6872360110282898
Iteration [35972]: Loss = 0.6873953342437744
Iteration [35973]: Loss = 9.337059020996094
Iteration [35974]: Loss = 9.328934669494629
Iteration [35975]: Loss = 0.6893874406814575
Iteration [35976]: Loss = 0.6904274225234985
Iteration [35977]: Loss = 0.6913134455680847
Iteration [35978]: Loss = 0.6920603513717651
Iteration [35979]: Loss = 0.6926817893981934
Iteration [35980]: Loss = 0.6931899785995483
Iteration [35981]: Loss = 0.6935961246490479
Iteration [35982]: Loss = 0.6939101815223694
Iteration [35983]: Loss = 0.694141149520874
Iteration [35984]: Loss = 4.975893020629883
Iteration [35985]: Loss = 0.6947113871574402
Iteration [35986]: Loss = 0.6950324773788452
Iteration [35987]: Loss = 0.6952698230743408
Iteration [35988]: Loss = 0.6954318284988403
Iteration [35989]: Loss = 0.6955257058143616
Iteration [35990]: Loss = 4.969221591949463
Iteration [35991]: Loss = 0.6958609819412231
Iteration [35992]: Loss = 0.6960817575454712
Iteration [35993]: Loss = 0.6962287425994873
Iteration [35994]: Loss = 0.6963090896606445
Iteration [35995]: Loss = 0.6963297724723816
Iteration [35996]: Loss = 0.6962963938713074
Iteration [35997]: Loss = 4.965758800506592
Iteration [35998]: Loss = 0.6964138150215149
Iteration [35999]: Loss = 0.6965416073799133
Iteration [36000]: Loss = 0.6966047286987305
Iteration [36001]: Loss = 0.6966098546981812
Iteration [36002]: Loss = 0.696562647819519
Iteration [36003]: Loss = 4.964421272277832
Iteration [36004]: Loss = 4.9634318351745605
Iteration [36005]: Loss = 0.7039498090744019
Iteration [36006]: Loss = 0.7042704820632935
Iteration [36007]: Loss = 4.922543048858643
Iteration [36008]: Loss = 0.7050508260726929
Iteration [36009]: Loss = 0.7054867744445801
Iteration [36010]: Loss = 4.9157233238220215
Iteration [36011]: Loss = 0.7064615488052368
Iteration [36012]: Loss = 0.7069791555404663
Iteration [36013]: Loss = 0.7073348760604858
Iteration [36014]: Loss = 4.9065423011779785
Iteration [36015]: Loss = 0.7081005573272705
Iteration [36016]: Loss = 4.901861667633057
Iteration [36017]: Loss = 0.7091436386108398
Iteration [36018]: Loss = 0.7096576690673828
Iteration [36019]: Loss = 0.7100637555122375
Iteration [36020]: Loss = 0.7103769779205322
Iteration [36021]: Loss = 0.7106064558029175
Iteration [36022]: Loss = 4.890329837799072
Iteration [36023]: Loss = 0.7111664414405823
Iteration [36024]: Loss = 0.7114795446395874
Iteration [36025]: Loss = 0.7117087841033936
Iteration [36026]: Loss = 0.7118625640869141
Iteration [36027]: Loss = 0.7119484543800354
Iteration [36028]: Loss = 0.7119729518890381
Iteration [36029]: Loss = 0.7119423747062683
Iteration [36030]: Loss = 0.7118619680404663
Iteration [36031]: Loss = 4.88535737991333
Iteration [36032]: Loss = 0.711892306804657
Iteration [36033]: Loss = 0.7119793891906738
Iteration [36034]: Loss = 4.883993625640869
Iteration [36035]: Loss = 4.882518291473389
Iteration [36036]: Loss = 0.7128223180770874
Iteration [36037]: Loss = 0.7132444381713867
Iteration [36038]: Loss = 0.7135720252990723
Iteration [36039]: Loss = 0.713814377784729
Iteration [36040]: Loss = 4.873978137969971
Iteration [36041]: Loss = 0.7143945693969727
Iteration [36042]: Loss = 0.7147152423858643
Iteration [36043]: Loss = 0.7149515748023987
Iteration [36044]: Loss = 0.7151116132736206
Iteration [36045]: Loss = 0.715201735496521
Iteration [36046]: Loss = 0.7152244448661804
Iteration [36047]: Loss = 0.7152042984962463
Iteration [36048]: Loss = 0.7151457071304321
Iteration [36049]: Loss = 0.7150523662567139
Iteration [36050]: Loss = 0.7149277329444885
Iteration [36051]: Loss = 0.7147749662399292
Iteration [36052]: Loss = 0.7145968675613403
Iteration [36053]: Loss = 0.7143959999084473
Iteration [36054]: Loss = 0.7141745686531067
Iteration [36055]: Loss = 0.7139347791671753
Iteration [36056]: Loss = 0.713678240776062
Iteration [36057]: Loss = 0.713407039642334
Iteration [36058]: Loss = 0.7131221890449524
Iteration [36059]: Loss = 4.879828453063965
Iteration [36060]: Loss = 0.7127638459205627
Iteration [36061]: Loss = 0.7126680612564087
Iteration [36062]: Loss = 0.712541401386261
Iteration [36063]: Loss = 0.7123869061470032
Iteration [36064]: Loss = 0.7122074365615845
Iteration [36065]: Loss = 4.883993148803711
Iteration [36066]: Loss = 0.7120290994644165
Iteration [36067]: Loss = 0.7120100259780884
Iteration [36068]: Loss = 0.7119525671005249
Iteration [36069]: Loss = 0.7118603587150574
Iteration [36070]: Loss = 0.7117369771003723
Iteration [36071]: Loss = 9.06067180633545
Iteration [36072]: Loss = 0.7118971347808838
Iteration [36073]: Loss = 0.7121378183364868
Iteration [36074]: Loss = 0.7123144865036011
Iteration [36075]: Loss = 0.7124335765838623
Iteration [36076]: Loss = 0.7125006914138794
Iteration [36077]: Loss = 0.7125210762023926
Iteration [36078]: Loss = 0.7124993205070496
Iteration [36079]: Loss = 0.7124395370483398
Iteration [36080]: Loss = 0.7123457193374634
Iteration [36081]: Loss = 0.7122209668159485
Iteration [36082]: Loss = 0.7120685577392578
Iteration [36083]: Loss = 4.884572982788086
Iteration [36084]: Loss = 0.7119355797767639
Iteration [36085]: Loss = 0.7119355797767639
Iteration [36086]: Loss = 0.7118953466415405
Iteration [36087]: Loss = 4.8849406242370605
Iteration [36088]: Loss = 0.7119541764259338
Iteration [36089]: Loss = 0.7120356559753418
Iteration [36090]: Loss = 0.7120689749717712
Iteration [36091]: Loss = 0.7120588421821594
Iteration [36092]: Loss = 4.883971214294434
Iteration [36093]: Loss = 0.7121690511703491
Iteration [36094]: Loss = 0.7122724652290344
Iteration [36095]: Loss = 0.7123254537582397
Iteration [36096]: Loss = 0.712333083152771
Iteration [36097]: Loss = 0.7122999429702759
Iteration [36098]: Loss = 4.882852554321289
Iteration [36099]: Loss = 4.882138252258301
Iteration [36100]: Loss = 0.7126997709274292
Iteration [36101]: Loss = 0.7129565477371216
Iteration [36102]: Loss = 0.7131475806236267
Iteration [36103]: Loss = 4.877525806427002
Iteration [36104]: Loss = 0.7136012315750122
Iteration [36105]: Loss = 0.7138506770133972
Iteration [36106]: Loss = 0.7140353322029114
Iteration [36107]: Loss = 0.7141614556312561
Iteration [36108]: Loss = 0.7142347097396851
Iteration [36109]: Loss = 0.7142605185508728
Iteration [36110]: Loss = 0.714243471622467
Iteration [36111]: Loss = 0.7141879796981812
Iteration [36112]: Loss = 0.7140977382659912
Iteration [36113]: Loss = 0.713976263999939
Iteration [36114]: Loss = 0.7138265371322632
Iteration [36115]: Loss = 0.7136515974998474
Iteration [36116]: Loss = 0.7134537696838379
Iteration [36117]: Loss = 0.7132354378700256
Iteration [36118]: Loss = 0.712998628616333
Iteration [36119]: Loss = 4.8802361488342285
Iteration [36120]: Loss = 0.7127214074134827
Iteration [36121]: Loss = 0.7126598358154297
Iteration [36122]: Loss = 0.71256422996521
Iteration [36123]: Loss = 4.8817949295043945
Iteration [36124]: Loss = 0.7125282883644104
Iteration [36125]: Loss = 0.7125693559646606
Iteration [36126]: Loss = 0.7125662565231323
Iteration [36127]: Loss = 0.7125232815742493
Iteration [36128]: Loss = 0.7124444246292114
Iteration [36129]: Loss = 4.882327079772949
Iteration [36130]: Loss = 0.7124369740486145
Iteration [36131]: Loss = 0.7124904990196228
Iteration [36132]: Loss = 4.88148832321167
Iteration [36133]: Loss = 0.7127088904380798
Iteration [36134]: Loss = 0.7128584384918213
Iteration [36135]: Loss = 0.7129529118537903
Iteration [36136]: Loss = 0.7129979133605957
Iteration [36137]: Loss = 0.7129981517791748
Iteration [36138]: Loss = 0.7129582762718201
Iteration [36139]: Loss = 0.7128820419311523
Iteration [36140]: Loss = 0.7127732038497925
Iteration [36141]: Loss = 0.7126350998878479
Iteration [36142]: Loss = 0.712470531463623
Iteration [36143]: Loss = 0.7122821807861328
Iteration [36144]: Loss = 0.7120723724365234
Iteration [36145]: Loss = 0.7118432521820068
Iteration [36146]: Loss = 0.7115968465805054
Iteration [36147]: Loss = 0.7113349437713623
Iteration [36148]: Loss = 0.7110587954521179
Iteration [36149]: Loss = 0.7107702493667603
Iteration [36150]: Loss = 0.7104702591896057
Iteration [36151]: Loss = 0.7101601362228394
Iteration [36152]: Loss = 4.895023822784424
Iteration [36153]: Loss = 0.7097587585449219
Iteration [36154]: Loss = 0.7096447944641113
Iteration [36155]: Loss = 0.709502100944519
Iteration [36156]: Loss = 0.7093335390090942
Iteration [36157]: Loss = 0.7091417908668518
Iteration [36158]: Loss = 0.7089290618896484
Iteration [36159]: Loss = 0.7086976766586304
Iteration [36160]: Loss = 0.708449125289917
Iteration [36161]: Loss = 0.7081855535507202
Iteration [36162]: Loss = 0.7079082131385803
Iteration [36163]: Loss = 0.7076184749603271
Iteration [36164]: Loss = 4.907951354980469
Iteration [36165]: Loss = 0.7072528004646301
Iteration [36166]: Loss = 0.7071545124053955
Iteration [36167]: Loss = 0.7070258855819702
Iteration [36168]: Loss = 0.7068703174591064
Iteration [36169]: Loss = 4.9111785888671875
Iteration [36170]: Loss = 0.7067336440086365
Iteration [36171]: Loss = 0.7067329287528992
Iteration [36172]: Loss = 0.7066923379898071
Iteration [36173]: Loss = 4.911561489105225
Iteration [36174]: Loss = 0.7067521810531616
Iteration [36175]: Loss = 4.910433292388916
Iteration [36176]: Loss = 0.7071141600608826
Iteration [36177]: Loss = 0.7073256969451904
Iteration [36178]: Loss = 0.7074763774871826
Iteration [36179]: Loss = 0.7075720429420471
Iteration [36180]: Loss = 0.7076183557510376
Iteration [36181]: Loss = 0.7076202630996704
Iteration [36182]: Loss = 0.7075819969177246
Iteration [36183]: Loss = 0.7075076103210449
Iteration [36184]: Loss = 0.7074005603790283
Iteration [36185]: Loss = 0.7072643637657166
Iteration [36186]: Loss = 0.7071017026901245
Iteration [36187]: Loss = 0.7069153189659119
Iteration [36188]: Loss = 0.7067075967788696
Iteration [36189]: Loss = 0.7064806818962097
Iteration [36190]: Loss = 0.7062364220619202
Iteration [36191]: Loss = 0.705976665019989
Iteration [36192]: Loss = 0.7057029604911804
Iteration [36193]: Loss = 4.917743682861328
Iteration [36194]: Loss = 0.705365002155304
Iteration [36195]: Loss = 0.7052788734436035
Iteration [36196]: Loss = 0.7051613330841064
Iteration [36197]: Loss = 0.7050157189369202
Iteration [36198]: Loss = 0.7048447728157043
Iteration [36199]: Loss = 0.7046511173248291
Iteration [36200]: Loss = 0.7044367790222168
Iteration [36201]: Loss = 0.7042040824890137
Iteration [36202]: Loss = 0.703954815864563
Iteration [36203]: Loss = 0.7036905884742737
Iteration [36204]: Loss = 4.928110122680664
Iteration [36205]: Loss = 0.7033696174621582
Iteration [36206]: Loss = 0.7032908201217651
Iteration [36207]: Loss = 0.7031803131103516
Iteration [36208]: Loss = 0.7030408382415771
Iteration [36209]: Loss = 4.930898666381836
Iteration [36210]: Loss = 4.930599212646484
Iteration [36211]: Loss = 4.929263591766357
Iteration [36212]: Loss = 0.7036271095275879
Iteration [36213]: Loss = 4.925168514251709
Iteration [36214]: Loss = 4.922463893890381
Iteration [36215]: Loss = 0.7051771283149719
Iteration [36216]: Loss = 0.7057448625564575
Iteration [36217]: Loss = 0.7062166333198547
Iteration [36218]: Loss = 0.7066019773483276
Iteration [36219]: Loss = 0.7069091200828552
Iteration [36220]: Loss = 0.7071460485458374
Iteration [36221]: Loss = 4.907941818237305
Iteration [36222]: Loss = 0.7076799273490906
Iteration [36223]: Loss = 0.7079647183418274
Iteration [36224]: Loss = 0.7081813216209412
Iteration [36225]: Loss = 0.7083364725112915
Iteration [36226]: Loss = 4.902211666107178
Iteration [36227]: Loss = 0.7087301015853882
Iteration [36228]: Loss = 4.8995537757873535
Iteration [36229]: Loss = 0.7093611359596252
Iteration [36230]: Loss = 0.7096868753433228
Iteration [36231]: Loss = 0.709940493106842
Iteration [36232]: Loss = 0.7101288437843323
Iteration [36233]: Loss = 0.7102583646774292
Iteration [36234]: Loss = 0.7103350162506104
Iteration [36235]: Loss = 0.7103639841079712
Iteration [36236]: Loss = 0.7103499174118042
Iteration [36237]: Loss = 0.7102972865104675
Iteration [36238]: Loss = 0.7102097272872925
Iteration [36239]: Loss = 0.7100908160209656
Iteration [36240]: Loss = 0.7099435925483704
Iteration [36241]: Loss = 4.89538049697876
Iteration [36242]: Loss = 0.7098203897476196
Iteration [36243]: Loss = 0.7098249197006226
Iteration [36244]: Loss = 0.7097889184951782
Iteration [36245]: Loss = 0.7097164392471313
Iteration [36246]: Loss = 0.7096111178398132
Iteration [36247]: Loss = 0.7094761729240417
Iteration [36248]: Loss = 0.7093145251274109
Iteration [36249]: Loss = 0.7091290354728699
Iteration [36250]: Loss = 0.7089219093322754
Iteration [36251]: Loss = 4.900882720947266
Iteration [36252]: Loss = 0.7086968421936035
Iteration [36253]: Loss = 0.7086580991744995
Iteration [36254]: Loss = 0.7085831165313721
Iteration [36255]: Loss = 0.7084758877754211
Iteration [36256]: Loss = 0.7083390951156616
Iteration [36257]: Loss = 0.7081758379936218
Iteration [36258]: Loss = 4.904504776000977
Iteration [36259]: Loss = 0.7080260515213013
Iteration [36260]: Loss = 0.7080196142196655
Iteration [36261]: Loss = 0.7079736590385437
Iteration [36262]: Loss = 0.7078923583030701
Iteration [36263]: Loss = 0.7077792286872864
Iteration [36264]: Loss = 0.7047274708747864
Iteration [36265]: Loss = 0.7045576572418213
Iteration [36266]: Loss = 0.7043623328208923
Iteration [36267]: Loss = 0.7041438221931458
Iteration [36268]: Loss = 0.7039045691490173
Iteration [36269]: Loss = 0.7036467790603638
Iteration [36270]: Loss = 0.7033720016479492
Iteration [36271]: Loss = 0.7030821442604065
Iteration [36272]: Loss = 0.702778697013855
Iteration [36273]: Loss = 4.933042049407959
Iteration [36274]: Loss = 0.7024002075195312
Iteration [36275]: Loss = 0.7023012042045593
Iteration [36276]: Loss = 0.7021695971488953
Iteration [36277]: Loss = 0.7020086646080017
Iteration [36278]: Loss = 9.170938491821289
Iteration [36279]: Loss = 0.7021326422691345
Iteration [36280]: Loss = 0.7023711204528809
Iteration [36281]: Loss = 0.7025437355041504
Iteration [36282]: Loss = 0.7026573419570923
Iteration [36283]: Loss = 0.702717661857605
Iteration [36284]: Loss = 0.7027300596237183
Iteration [36285]: Loss = 4.9318156242370605
Iteration [36286]: Loss = 0.702889084815979
Iteration [36287]: Loss = 0.7030181288719177
Iteration [36288]: Loss = 4.929773330688477
Iteration [36289]: Loss = 0.7033765912055969
Iteration [36290]: Loss = 0.7035905122756958
Iteration [36291]: Loss = 0.703741192817688
Iteration [36292]: Loss = 4.925922393798828
Iteration [36293]: Loss = 0.7041361927986145
Iteration [36294]: Loss = 0.7043654918670654
Iteration [36295]: Loss = 0.7045301795005798
Iteration [36296]: Loss = 0.70463627576828
Iteration [36297]: Loss = 0.7046898007392883
Iteration [36298]: Loss = 4.921466827392578
Iteration [36299]: Loss = 0.704918622970581
Iteration [36300]: Loss = 0.7050769925117493
Iteration [36301]: Loss = 4.9189772605896
Iteration [36302]: Loss = 0.705483615398407
Iteration [36303]: Loss = 0.7057035565376282
Iteration [36304]: Loss = 0.7058621644973755
Iteration [36305]: Loss = 0.7059656381607056
Iteration [36306]: Loss = 0.7060191631317139
Iteration [36307]: Loss = 0.7060279846191406
Iteration [36308]: Loss = 0.7059962153434753
Iteration [36309]: Loss = 0.7059280872344971
Iteration [36310]: Loss = 0.7058272957801819
Iteration [36311]: Loss = 0.7056970596313477
Iteration [36312]: Loss = 0.705540120601654
Iteration [36313]: Loss = 0.7053593397140503
Iteration [36314]: Loss = 0.7051569819450378
Iteration [36315]: Loss = 0.7049353718757629
Iteration [36316]: Loss = 0.7046962380409241
Iteration [36317]: Loss = 0.7044414281845093
Iteration [36318]: Loss = 0.7041726112365723
Iteration [36319]: Loss = 0.7038910984992981
Iteration [36320]: Loss = 0.7035980820655823
Iteration [36321]: Loss = 0.7032950520515442
Iteration [36322]: Loss = 0.7029826045036316
Iteration [36323]: Loss = 0.70266193151474
Iteration [36324]: Loss = 0.702333927154541
Iteration [36325]: Loss = 4.935454368591309
Iteration [36326]: Loss = 0.7019034028053284
Iteration [36327]: Loss = 0.7017777562141418
Iteration [36328]: Loss = 0.701625406742096
Iteration [36329]: Loss = 0.7014488577842712
Iteration [36330]: Loss = 0.7012503743171692
Iteration [36331]: Loss = 0.7010325193405151
Iteration [36332]: Loss = 0.7007969617843628
Iteration [36333]: Loss = 0.7005455493927002
Iteration [36334]: Loss = 0.7002800703048706
Iteration [36335]: Loss = 0.7000016570091248
Iteration [36336]: Loss = 0.6997117400169373
Iteration [36337]: Loss = 0.6994113922119141
Iteration [36338]: Loss = 0.6991018652915955
Iteration [36339]: Loss = 4.9522480964660645
Iteration [36340]: Loss = 0.698703944683075
Iteration [36341]: Loss = 0.6985926628112793
Iteration [36342]: Loss = 0.6984533071517944
Iteration [36343]: Loss = 0.69828861951828
Iteration [36344]: Loss = 0.698101282119751
Iteration [36345]: Loss = 0.6978933215141296
Iteration [36346]: Loss = 0.6976669430732727
Iteration [36347]: Loss = 0.6974238753318787
Iteration [36348]: Loss = 0.6971659064292908
Iteration [36349]: Loss = 0.696894645690918
Iteration [36350]: Loss = 4.963667392730713
Iteration [36351]: Loss = 0.696562647819519
Iteration [36352]: Loss = 0.696479856967926
Iteration [36353]: Loss = 0.6963661313056946
Iteration [36354]: Loss = 0.6962247490882874
Iteration [36355]: Loss = 0.6960583329200745
Iteration [36356]: Loss = 0.6958693265914917
Iteration [36357]: Loss = 0.6956601738929749
Iteration [36358]: Loss = 0.6954327821731567
Iteration [36359]: Loss = 4.971174716949463
Iteration [36360]: Loss = 4.971241474151611
Iteration [36361]: Loss = 0.695370614528656
Iteration [36362]: Loss = 0.695506751537323
Iteration [36363]: Loss = 0.6955904960632324
Iteration [36364]: Loss = 0.6956267356872559
Iteration [36365]: Loss = 0.6956203579902649
Iteration [36366]: Loss = 0.6955755352973938
Iteration [36367]: Loss = 0.6954962015151978
Iteration [36368]: Loss = 4.97013521194458
Iteration [36369]: Loss = 0.6954923868179321
Iteration [36370]: Loss = 0.6955493688583374
Iteration [36371]: Loss = 0.6955618262290955
Iteration [36372]: Loss = 0.6955339908599854
Iteration [36373]: Loss = 0.6954697966575623
Iteration [36374]: Loss = 0.6953729391098022
Iteration [36375]: Loss = 0.6952467560768127
Iteration [36376]: Loss = 4.971676349639893
Iteration [36377]: Loss = 0.6951630115509033
Iteration [36378]: Loss = 0.695186197757721
Iteration [36379]: Loss = 4.971285343170166
Iteration [36380]: Loss = 0.6953575015068054
Iteration [36381]: Loss = 0.6954891681671143
Iteration [36382]: Loss = 0.6955687403678894
Iteration [36383]: Loss = 0.6956014633178711
Iteration [36384]: Loss = 0.6955918073654175
Iteration [36385]: Loss = 0.6955441236495972
Iteration [36386]: Loss = 0.695462167263031
Iteration [36387]: Loss = 0.6953491568565369
Iteration [36388]: Loss = 0.6952084302902222
Iteration [36389]: Loss = 0.6950427293777466
Iteration [36390]: Loss = 0.6948543787002563
Iteration [36391]: Loss = 0.6946459412574768
Iteration [36392]: Loss = 0.6944191455841064
Iteration [36393]: Loss = 0.6941757798194885
Iteration [36394]: Loss = 0.6939178109169006
Iteration [36395]: Loss = 0.6936465501785278
Iteration [36396]: Loss = 4.980847358703613
Iteration [36397]: Loss = 0.6933157444000244
Iteration [36398]: Loss = 0.6932340860366821
Iteration [36399]: Loss = 0.6931215524673462
Iteration [36400]: Loss = 4.982876777648926
Iteration [36401]: Loss = 0.6930618286132812
Iteration [36402]: Loss = 0.6930956840515137
Iteration [36403]: Loss = 0.693087100982666
Iteration [36404]: Loss = 0.6930403709411621
Iteration [36405]: Loss = 4.982993125915527
Iteration [36406]: Loss = 0.6930932998657227
Iteration [36407]: Loss = 0.6931749582290649
Iteration [36408]: Loss = 0.6932095289230347
Iteration [36409]: Loss = 0.6932017803192139
Iteration [36410]: Loss = 0.6931558847427368
Iteration [36411]: Loss = 0.6930755376815796
Iteration [36412]: Loss = 0.6929642558097839
Iteration [36413]: Loss = 0.6928251385688782
Iteration [36414]: Loss = 0.692660927772522
Iteration [36415]: Loss = 0.6924741268157959
Iteration [36416]: Loss = 0.6950409412384033
Iteration [36417]: Loss = 4.973152160644531
Iteration [36418]: Loss = 0.6948192119598389
Iteration [36419]: Loss = 0.6947838068008423
Iteration [36420]: Loss = 4.973693370819092
Iteration [36421]: Loss = 0.6948556900024414
Iteration [36422]: Loss = 4.972463130950928
Iteration [36423]: Loss = 0.6952319145202637
Iteration [36424]: Loss = 0.6954512596130371
Iteration [36425]: Loss = 0.6956096291542053
Iteration [36426]: Loss = 0.6957131028175354
Iteration [36427]: Loss = 0.6957671642303467
Iteration [36428]: Loss = 0.6957767009735107
Iteration [36429]: Loss = 0.695746123790741
Iteration [36430]: Loss = 9.241484642028809
Iteration [36431]: Loss = 0.6960676312446594
Iteration [36432]: Loss = 0.6963787078857422
Iteration [36433]: Loss = 0.6966198086738586
Iteration [36434]: Loss = 0.6967983245849609
Iteration [36435]: Loss = 4.962040424346924
Iteration [36436]: Loss = 0.6972337961196899
Iteration [36437]: Loss = 0.6974775195121765
Iteration [36438]: Loss = 0.6976581811904907
Iteration [36439]: Loss = 4.95750617980957
Iteration [36440]: Loss = 0.698097288608551
Iteration [36441]: Loss = 4.954563617706299
Iteration [36442]: Loss = 0.6987662315368652
Iteration [36443]: Loss = 0.6991094350814819
Iteration [36444]: Loss = 0.6993793845176697
Iteration [36445]: Loss = 0.6995836496353149
Iteration [36446]: Loss = 4.947300434112549
Iteration [36447]: Loss = 0.7000625133514404
Iteration [36448]: Loss = 0.7003242373466492
Iteration [36449]: Loss = 0.700520932674408
Iteration [36450]: Loss = 0.7006590366363525
Iteration [36451]: Loss = 0.7014737129211426
Iteration [36452]: Loss = 0.7015112042427063
Iteration [36453]: Loss = 0.7015057802200317
Iteration [36454]: Loss = 0.701461672782898
Iteration [36455]: Loss = 0.7013828158378601
Iteration [36456]: Loss = 0.7012726068496704
Iteration [36457]: Loss = 0.701134204864502
Iteration [36458]: Loss = 0.7009702920913696
Iteration [36459]: Loss = 0.7007836103439331
Iteration [36460]: Loss = 4.94287109375
Iteration [36461]: Loss = 0.7005943059921265
Iteration [36462]: Loss = 9.185218811035156
Iteration [36463]: Loss = 0.7009941935539246
Iteration [36464]: Loss = 0.7013359665870667
Iteration [36465]: Loss = 4.937505722045898
Iteration [36466]: Loss = 4.9351959228515625
Iteration [36467]: Loss = 0.7026491761207581
Iteration [36468]: Loss = 0.7031512260437012
Iteration [36469]: Loss = 0.7035645842552185
Iteration [36470]: Loss = 0.7038980722427368
Iteration [36471]: Loss = 0.7041594982147217
Iteration [36472]: Loss = 0.7043558359146118
Iteration [36473]: Loss = 0.7044937610626221
Iteration [36474]: Loss = 0.7045788764953613
Iteration [36475]: Loss = 0.704616367816925
Iteration [36476]: Loss = 4.921905040740967
Iteration [36477]: Loss = 0.7048081159591675
Iteration [36478]: Loss = 0.7049464583396912
Iteration [36479]: Loss = 0.7050321102142334
Iteration [36480]: Loss = 0.7050700187683105
Iteration [36481]: Loss = 4.919558525085449
Iteration [36482]: Loss = 0.705262303352356
Iteration [36483]: Loss = 0.705400824546814
Iteration [36484]: Loss = 4.91738224029541
Iteration [36485]: Loss = 0.705764889717102
Iteration [36486]: Loss = 0.7059765458106995
Iteration [36487]: Loss = 4.914073467254639
Iteration [36488]: Loss = 0.7064655423164368
Iteration [36489]: Loss = 0.7067304253578186
Iteration [36490]: Loss = 0.7069295644760132
Iteration [36491]: Loss = 0.7070700526237488
Iteration [36492]: Loss = 0.7071571946144104
Iteration [36493]: Loss = 4.908575057983398
Iteration [36494]: Loss = 0.7074331045150757
Iteration [36495]: Loss = 0.707606852054596
Iteration [36496]: Loss = 0.7077242136001587
Iteration [36497]: Loss = 0.7077906131744385
Iteration [36498]: Loss = 0.707811176776886
Iteration [36499]: Loss = 4.905524730682373
Iteration [36500]: Loss = 0.7079729437828064
Iteration [36501]: Loss = 0.7080981731414795
Iteration [36502]: Loss = 0.7081716060638428
Iteration [36503]: Loss = 0.7081984877586365
Iteration [36504]: Loss = 0.7081833481788635
Iteration [36505]: Loss = 0.7081304788589478
Iteration [36506]: Loss = 0.7080434560775757
Iteration [36507]: Loss = 0.7079257965087891
Iteration [36508]: Loss = 0.7077805995941162
Iteration [36509]: Loss = 4.906447887420654
Iteration [36510]: Loss = 0.7076593637466431
Iteration [36511]: Loss = 0.7076640129089355
Iteration [36512]: Loss = 0.7076289057731628
Iteration [36513]: Loss = 0.7075580358505249
Iteration [36514]: Loss = 4.907247066497803
Iteration [36515]: Loss = 0.7075638175010681
Iteration [36516]: Loss = 0.7076226472854614
Iteration [36517]: Loss = 0.7076364159584045
Iteration [36518]: Loss = 0.7076094150543213
Iteration [36519]: Loss = 0.707545816898346
Iteration [36520]: Loss = 0.7074493169784546
Iteration [36521]: Loss = 0.7073229551315308
Iteration [36522]: Loss = 0.7071700096130371
Iteration [36523]: Loss = 0.706993043422699
Iteration [36524]: Loss = 0.706794261932373
Iteration [36525]: Loss = 0.7065759897232056
Iteration [36526]: Loss = 0.7063403129577637
Iteration [36527]: Loss = 0.7060887217521667
Iteration [36528]: Loss = 0.7058230638504028
Iteration [36529]: Loss = 4.9170823097229
Iteration [36530]: Loss = 0.7054969072341919
Iteration [36531]: Loss = 0.7054147124290466
Iteration [36532]: Loss = 0.7053015232086182
Iteration [36533]: Loss = 4.919066905975342
Iteration [36534]: Loss = 4.91867733001709
Iteration [36535]: Loss = 0.70550537109375
Iteration [36536]: Loss = 0.7057089805603027
Iteration [36537]: Loss = 0.705853283405304
Iteration [36538]: Loss = 0.7059439420700073
Iteration [36539]: Loss = 0.7059864401817322
Iteration [36540]: Loss = 0.7059853672981262
Iteration [36541]: Loss = 0.7059452533721924
Iteration [36542]: Loss = 0.7058699131011963
Iteration [36543]: Loss = 0.7057628035545349
Iteration [36544]: Loss = 0.7056271433830261
Iteration [36545]: Loss = 0.7054657936096191
Iteration [36546]: Loss = 4.918442726135254
Iteration [36547]: Loss = 0.7053177356719971
Iteration [36548]: Loss = 4.91828727722168
Iteration [36549]: Loss = 0.7055076360702515
Iteration [36550]: Loss = 0.7056453227996826
Iteration [36551]: Loss = 0.705730140209198
Iteration [36552]: Loss = 0.7057672739028931
Iteration [36553]: Loss = 0.7057614922523499
Iteration [36554]: Loss = 0.7057169675827026
Iteration [36555]: Loss = 4.91660213470459
Iteration [36556]: Loss = 0.7057685852050781
Iteration [36557]: Loss = 0.7058472037315369
Iteration [36558]: Loss = 0.7058788537979126
Iteration [36559]: Loss = 4.915413856506348
Iteration [36560]: Loss = 0.7060603499412537
Iteration [36561]: Loss = 9.121271133422852
Iteration [36562]: Loss = 0.7067521810531616
Iteration [36563]: Loss = 0.7072158455848694
Iteration [36564]: Loss = 0.7075945734977722
Iteration [36565]: Loss = 0.7078967094421387
Iteration [36566]: Loss = 0.7081298828125
Iteration [36567]: Loss = 0.7083008885383606
Iteration [36568]: Loss = 0.7084157466888428
Iteration [36569]: Loss = 0.7084801197052002
Iteration [36570]: Loss = 0.708499014377594
Iteration [36571]: Loss = 0.7084768414497375
Iteration [36572]: Loss = 0.7084177732467651
Iteration [36573]: Loss = 0.7083254456520081
Iteration [36574]: Loss = 0.7082031965255737
Iteration [36575]: Loss = 4.904171943664551
Iteration [36576]: Loss = 0.7081202864646912
Iteration [36577]: Loss = 0.7081409692764282
Iteration [36578]: Loss = 9.099539756774902
Iteration [36579]: Loss = 0.7085379958152771
Iteration [36580]: Loss = 0.708875298500061
Iteration [36581]: Loss = 0.7091403007507324
Iteration [36582]: Loss = 0.7093402147293091
Iteration [36583]: Loss = 0.7094813585281372
Iteration [36584]: Loss = 0.7095694541931152
Iteration [36585]: Loss = 0.7096099257469177
Iteration [36586]: Loss = 0.7096074819564819
Iteration [36587]: Loss = 0.7095662355422974
Iteration [36588]: Loss = 0.709490180015564
Iteration [36589]: Loss = 0.7093827128410339
Iteration [36590]: Loss = 0.7092470526695251
Iteration [36591]: Loss = 0.7090858221054077
Iteration [36592]: Loss = 0.7089018225669861
Iteration [36593]: Loss = 0.7086971998214722
Iteration [36594]: Loss = 0.7084740996360779
Iteration [36595]: Loss = 0.7082341909408569
Iteration [36596]: Loss = 0.7079792022705078
Iteration [36597]: Loss = 0.7077109217643738
Iteration [36598]: Loss = 0.7074304223060608
Iteration [36599]: Loss = 0.7071389555931091
Iteration [36600]: Loss = 0.7068377137184143
Iteration [36601]: Loss = 4.912014961242676
Iteration [36602]: Loss = 0.7064491510391235
Iteration [36603]: Loss = 0.7063395977020264
Iteration [36604]: Loss = 4.913692474365234
Iteration [36605]: Loss = 0.7062783241271973
Iteration [36606]: Loss = 0.7063081860542297
Iteration [36607]: Loss = 4.9132080078125
Iteration [36608]: Loss = 0.7064850330352783
Iteration [36609]: Loss = 4.911559104919434
Iteration [36610]: Loss = 0.7069333791732788
Iteration [36611]: Loss = 0.7071802616119385
Iteration [36612]: Loss = 4.907715320587158
Iteration [36613]: Loss = 0.7077279686927795
Iteration [36614]: Loss = 0.7080168724060059
Iteration [36615]: Loss = 4.903224945068359
Iteration [36616]: Loss = 0.7086362838745117
Iteration [36617]: Loss = 0.7089558243751526
Iteration [36618]: Loss = 0.7092047929763794
Iteration [36619]: Loss = 0.7093901038169861
Iteration [36620]: Loss = 0.7095180749893188
Iteration [36621]: Loss = 0.7095943093299866
Iteration [36622]: Loss = 0.7096241116523743
Iteration [36623]: Loss = 9.082776069641113
Iteration [36624]: Loss = 0.7100339531898499
Iteration [36625]: Loss = 0.7103756666183472
Iteration [36626]: Loss = 0.7106446623802185
Iteration [36627]: Loss = 0.7108481526374817
Iteration [36628]: Loss = 0.7109928131103516
Iteration [36629]: Loss = 4.888680458068848
Iteration [36630]: Loss = 0.7113636136054993
Iteration [36631]: Loss = 0.7115764617919922
Iteration [36632]: Loss = 0.7117293477058411
Iteration [36633]: Loss = 0.7118281722068787
Iteration [36634]: Loss = 0.7118783593177795
Iteration [36635]: Loss = 0.7118846774101257
Iteration [36636]: Loss = 0.7118515372276306
Iteration [36637]: Loss = 0.711782693862915
Iteration [36638]: Loss = 4.885638236999512
Iteration [36639]: Loss = 0.7117887139320374
Iteration [36640]: Loss = 0.7118461728096008
Iteration [36641]: Loss = 0.7118590474128723
Iteration [36642]: Loss = 0.7118316888809204
Iteration [36643]: Loss = 0.7117682099342346
Iteration [36644]: Loss = 0.7116721272468567
Iteration [36645]: Loss = 0.7115467190742493
Iteration [36646]: Loss = 0.7113947868347168
Iteration [36647]: Loss = 0.7112191319465637
Iteration [36648]: Loss = 0.711022138595581
Iteration [36649]: Loss = 0.7108058929443359
Iteration [36650]: Loss = 0.7105722427368164
Iteration [36651]: Loss = 0.7103231549263
Iteration [36652]: Loss = 4.893904685974121
Iteration [36653]: Loss = 0.7100216746330261
Iteration [36654]: Loss = 0.7099485397338867
Iteration [36655]: Loss = 0.7098437547683716
Iteration [36656]: Loss = 0.7097106575965881
Iteration [36657]: Loss = 0.7095518708229065
Iteration [36658]: Loss = 0.7093701362609863
Iteration [36659]: Loss = 0.7091678380966187
Iteration [36660]: Loss = 4.899596214294434
Iteration [36661]: Loss = 0.7089465260505676
Iteration [36662]: Loss = 0.7089076638221741
Iteration [36663]: Loss = 0.7088337540626526
Iteration [36664]: Loss = 4.900712966918945
Iteration [36665]: Loss = 0.7088324427604675
Iteration [36666]: Loss = 0.7088870406150818
Iteration [36667]: Loss = 0.708897590637207
Iteration [36668]: Loss = 0.7088682651519775
Iteration [36669]: Loss = 0.7088029980659485
Iteration [36670]: Loss = 0.7087055444717407
Iteration [36671]: Loss = 0.708578884601593
Iteration [36672]: Loss = 0.7084262371063232
Iteration [36673]: Loss = 0.7082499265670776
Iteration [36674]: Loss = 0.7080522775650024
Iteration [36675]: Loss = 0.7078356146812439
Iteration [36676]: Loss = 0.70760178565979
Iteration [36677]: Loss = 0.7073525786399841
Iteration [36678]: Loss = 4.909125328063965
Iteration [36679]: Loss = 0.7070521116256714
Iteration [36680]: Loss = 0.7069797515869141
Iteration [36681]: Loss = 0.7068759202957153
Iteration [36682]: Loss = 0.706743597984314
Iteration [36683]: Loss = 0.7065858840942383
Iteration [36684]: Loss = 0.7064050436019897
Iteration [36685]: Loss = 4.913684844970703
Iteration [36686]: Loss = 0.7062218189239502
Iteration [36687]: Loss = 0.7061995267868042
Iteration [36688]: Loss = 0.7061407566070557
Iteration [36689]: Loss = 0.7060492038726807
Iteration [36690]: Loss = 0.7059279680252075
Iteration [36691]: Loss = 4.915866374969482
Iteration [36692]: Loss = 0.7058467268943787
Iteration [36693]: Loss = 0.7058680057525635
Iteration [36694]: Loss = 0.7058484554290771
Iteration [36695]: Loss = 4.915805816650391
Iteration [36696]: Loss = 0.7059406638145447
Iteration [36697]: Loss = 0.7060357332229614
Iteration [36698]: Loss = 0.7060827016830444
Iteration [36699]: Loss = 0.7060863971710205
Iteration [36700]: Loss = 0.7060509324073792
Iteration [36701]: Loss = 0.7059804201126099
Iteration [36702]: Loss = 0.7058781385421753
Iteration [36703]: Loss = 0.7057472467422485
Iteration [36704]: Loss = 0.7055908441543579
Iteration [36705]: Loss = 0.7054113745689392
Iteration [36706]: Loss = 0.7052109241485596
Iteration [36707]: Loss = 0.7049919366836548
Iteration [36708]: Loss = 0.7047560214996338
Iteration [36709]: Loss = 0.7045049667358398
Iteration [36710]: Loss = 0.7042402029037476
Iteration [36711]: Loss = 0.7039632797241211
Iteration [36712]: Loss = 0.7036754488945007
Iteration [36713]: Loss = 0.7033774852752686
Iteration [36714]: Loss = 0.7030707001686096
Iteration [36715]: Loss = 0.7027560472488403
Iteration [36716]: Loss = 0.7024340629577637
Iteration [36717]: Loss = 0.702105700969696
Iteration [36718]: Loss = 0.7017714977264404
Iteration [36719]: Loss = 0.7014322280883789
Iteration [36720]: Loss = 0.7010883092880249
Iteration [36721]: Loss = 0.7007399797439575
Iteration [36722]: Loss = 0.7003882527351379
Iteration [36723]: Loss = 0.7000328898429871
Iteration [36724]: Loss = 0.699674665927887
Iteration [36725]: Loss = 4.949472427368164
Iteration [36726]: Loss = 0.699190616607666
Iteration [36727]: Loss = 0.6990415453910828
Iteration [36728]: Loss = 0.6988687515258789
Iteration [36729]: Loss = 0.6986749172210693
Iteration [36730]: Loss = 0.6984619498252869
Iteration [36731]: Loss = 0.6982318758964539
Iteration [36732]: Loss = 4.956432819366455
Iteration [36733]: Loss = 0.6979671120643616
Iteration [36734]: Loss = 0.6979115009307861
Iteration [36735]: Loss = 0.6978229880332947
Iteration [36736]: Loss = 0.6977051496505737
Iteration [36737]: Loss = 0.6975604891777039
Iteration [36738]: Loss = 0.6973920464515686
Iteration [36739]: Loss = 0.6972020864486694
Iteration [36740]: Loss = 0.6969926357269287
Iteration [36741]: Loss = 0.6967657804489136
Iteration [36742]: Loss = 0.6965233087539673
Iteration [36743]: Loss = 4.965483665466309
Iteration [36744]: Loss = 0.6962378025054932
Iteration [36745]: Loss = 0.6961736083030701
Iteration [36746]: Loss = 0.6960777044296265
Iteration [36747]: Loss = 0.6959528923034668
Iteration [36748]: Loss = 9.240065574645996
Iteration [36749]: Loss = 0.6961057782173157
Iteration [36750]: Loss = 0.6963412165641785
Iteration [36751]: Loss = 0.6965152621269226
Iteration [36752]: Loss = 0.69663405418396
Iteration [36753]: Loss = 0.6967030763626099
Iteration [36754]: Loss = 9.229385375976562
Iteration [36755]: Loss = 0.697182297706604
Iteration [36756]: Loss = 0.6975547671318054
Iteration [36757]: Loss = 0.697852373123169
Iteration [36758]: Loss = 4.955926895141602
Iteration [36759]: Loss = 0.6984876990318298
Iteration [36760]: Loss = 0.6988145709037781
Iteration [36761]: Loss = 4.950741767883301
Iteration [36762]: Loss = 0.6994997262954712
Iteration [36763]: Loss = 0.6998478174209595
Iteration [36764]: Loss = 0.7001234889030457
Iteration [36765]: Loss = 0.7003339529037476
Iteration [36766]: Loss = 4.9433441162109375
Iteration [36767]: Loss = 0.7008193731307983
Iteration [36768]: Loss = 0.701082170009613
Iteration [36769]: Loss = 0.7012808918952942
Iteration [36770]: Loss = 0.7014219164848328
Iteration [36771]: Loss = 0.7015109658241272
Iteration [36772]: Loss = 0.7015530467033386
Iteration [36773]: Loss = 0.7015530467033386
Iteration [36774]: Loss = 0.7015149593353271
Iteration [36775]: Loss = 0.7014425992965698
Iteration [36776]: Loss = 4.938889980316162
Iteration [36777]: Loss = 0.7014447450637817
Iteration [36778]: Loss = 0.7015014886856079
Iteration [36779]: Loss = 4.937977313995361
Iteration [36780]: Loss = 4.936886310577393
Iteration [36781]: Loss = 0.7021095752716064
Iteration [36782]: Loss = 0.7024189829826355
Iteration [36783]: Loss = 0.7026596665382385
Iteration [36784]: Loss = 0.7028382420539856
Iteration [36785]: Loss = 0.7029611468315125
Iteration [36786]: Loss = 0.7030336260795593
Iteration [36787]: Loss = 0.7030608654022217
Iteration [36788]: Loss = 4.9300079345703125
Iteration [36789]: Loss = 0.7032325267791748
Iteration [36790]: Loss = 0.7033613920211792
Iteration [36791]: Loss = 4.927974700927734
Iteration [36792]: Loss = 0.7037065029144287
Iteration [36793]: Loss = 0.703909158706665
Iteration [36794]: Loss = 0.7040534019470215
Iteration [36795]: Loss = 0.7041453719139099
Iteration [36796]: Loss = 0.7041898369789124
Iteration [36797]: Loss = 0.7041918039321899
Iteration [36798]: Loss = 0.7041551470756531
Iteration [36799]: Loss = 0.7040841579437256
Iteration [36800]: Loss = 0.7039819359779358
Iteration [36801]: Loss = 0.7038516402244568
Iteration [36802]: Loss = 0.7036961317062378
Iteration [36803]: Loss = 0.7035179734230042
Iteration [36804]: Loss = 0.703319251537323
Iteration [36805]: Loss = 0.703102171421051
Iteration [36806]: Loss = 0.7028685808181763
Iteration [36807]: Loss = 0.7026200294494629
Iteration [36808]: Loss = 0.7023581266403198
Iteration [36809]: Loss = 0.7020840644836426
Iteration [36810]: Loss = 0.7017992734909058
Iteration [36811]: Loss = 0.7015047073364258
Iteration [36812]: Loss = 0.7012014985084534
Iteration [36813]: Loss = 0.700890302658081
Iteration [36814]: Loss = 4.942892551422119
Iteration [36815]: Loss = 0.7004850506782532
Iteration [36816]: Loss = 0.7003685235977173
Iteration [36817]: Loss = 0.7002256512641907
Iteration [36818]: Loss = 4.945573329925537
Iteration [36819]: Loss = 0.7001079320907593
Iteration [36820]: Loss = 0.7001138925552368
Iteration [36821]: Loss = 0.7000812292098999
Iteration [36822]: Loss = 0.7000138163566589
Iteration [36823]: Loss = 0.6999149918556213
Iteration [36824]: Loss = 4.9469895362854
Iteration [36825]: Loss = 0.6998726725578308
Iteration [36826]: Loss = 0.6999108195304871
Iteration [36827]: Loss = 0.6999070644378662
Iteration [36828]: Loss = 0.6998658180236816
Iteration [36829]: Loss = 4.946976661682129
Iteration [36830]: Loss = 0.6999216079711914
Iteration [36831]: Loss = 0.7000015377998352
Iteration [36832]: Loss = 4.945694923400879
Iteration [36833]: Loss = 0.700264573097229
Iteration [36834]: Loss = 0.7004327774047852
Iteration [36835]: Loss = 0.7005462646484375
Iteration [36836]: Loss = 0.7006102800369263
Iteration [36837]: Loss = 0.7006300091743469
Iteration [36838]: Loss = 0.700609564781189
Iteration [36839]: Loss = 0.7005531191825867
Iteration [36840]: Loss = 0.7004642486572266
Iteration [36841]: Loss = 0.7003461122512817
Iteration [36842]: Loss = 0.7002015113830566
Iteration [36843]: Loss = 0.7000333070755005
Iteration [36844]: Loss = 4.9466986656188965
Iteration [36845]: Loss = 4.9465484619140625
Iteration [36846]: Loss = 0.700096845626831
Iteration [36847]: Loss = 0.7002609968185425
Iteration [36848]: Loss = 0.7003706097602844
Iteration [36849]: Loss = 0.7004313468933105
Iteration [36850]: Loss = 0.7004479169845581
Iteration [36851]: Loss = 0.7004246115684509
Iteration [36852]: Loss = 0.7003656625747681
Iteration [36853]: Loss = 0.7002744674682617
Iteration [36854]: Loss = 0.7001542448997498
Iteration [36855]: Loss = 0.7000077962875366
Iteration [36856]: Loss = 0.6998379826545715
Iteration [36857]: Loss = 0.6996468305587769
Iteration [36858]: Loss = 4.948827743530273
Iteration [36859]: Loss = 4.948773384094238
Iteration [36860]: Loss = 0.6996553540229797
Iteration [36861]: Loss = 0.6998048424720764
Iteration [36862]: Loss = 0.6999013423919678
Iteration [36863]: Loss = 0.6999501585960388
Iteration [36864]: Loss = 0.6999561786651611
Iteration [36865]: Loss = 0.6999233961105347
Iteration [36866]: Loss = 0.6998558640480042
Iteration [36867]: Loss = 4.947152614593506
Iteration [36868]: Loss = 0.6998668909072876
Iteration [36869]: Loss = 0.6999279260635376
Iteration [36870]: Loss = 4.946169853210449
Iteration [36871]: Loss = 0.7001587152481079
Iteration [36872]: Loss = 4.944243907928467
Iteration [36873]: Loss = 4.94248104095459
Iteration [36874]: Loss = 0.7011523246765137
Iteration [36875]: Loss = 0.7015660405158997
Iteration [36876]: Loss = 0.7019006609916687
Iteration [36877]: Loss = 0.702163815498352
Iteration [36878]: Loss = 0.7023626565933228
Iteration [36879]: Loss = 0.7025036811828613
Iteration [36880]: Loss = 0.7025923728942871
Iteration [36881]: Loss = 0.7026341557502747
Iteration [36882]: Loss = 0.7026333808898926
Iteration [36883]: Loss = 0.7025943994522095
Iteration [36884]: Loss = 4.932741165161133
Iteration [36885]: Loss = 4.932051181793213
Iteration [36886]: Loss = 0.7029711604118347
Iteration [36887]: Loss = 0.7032188177108765
Iteration [36888]: Loss = 0.703403651714325
Iteration [36889]: Loss = 0.7035319805145264
Iteration [36890]: Loss = 0.703609049320221
Iteration [36891]: Loss = 0.7036402225494385
Iteration [36892]: Loss = 4.926985263824463
Iteration [36893]: Loss = 0.7038190364837646
Iteration [36894]: Loss = 0.7039510011672974
Iteration [36895]: Loss = 0.7040315866470337
Iteration [36896]: Loss = 0.7040657997131348
Iteration [36897]: Loss = 0.7040581107139587
Iteration [36898]: Loss = 0.7040129899978638
Iteration [36899]: Loss = 0.7039338946342468
Iteration [36900]: Loss = 0.7038243412971497
Iteration [36901]: Loss = 0.7036873698234558
Iteration [36902]: Loss = 0.7035255432128906
Iteration [36903]: Loss = 0.703341543674469
Iteration [36904]: Loss = 4.929539203643799
Iteration [36905]: Loss = 0.7031530737876892
Iteration [36906]: Loss = 0.7031287550926208
Iteration [36907]: Loss = 0.7030685544013977
Iteration [36908]: Loss = 0.7029759883880615
Iteration [36909]: Loss = 0.7028541564941406
Iteration [36910]: Loss = 0.7027062177658081
Iteration [36911]: Loss = 0.7025347352027893
Iteration [36912]: Loss = 0.7023419737815857
Iteration [36913]: Loss = 4.934773921966553
Iteration [36914]: Loss = 4.934728145599365
Iteration [36915]: Loss = 0.7023454904556274
Iteration [36916]: Loss = 0.7024933099746704
Iteration [36917]: Loss = 4.93239164352417
Iteration [36918]: Loss = 4.930918216705322
Iteration [36919]: Loss = 0.7033252716064453
Iteration [36920]: Loss = 0.7036952972412109
Iteration [36921]: Loss = 0.7039903998374939
Iteration [36922]: Loss = 0.704217791557312
Iteration [36923]: Loss = 0.7043842673301697
Iteration [36924]: Loss = 0.7044957876205444
Iteration [36925]: Loss = 0.7045577764511108
Iteration [36926]: Loss = 0.70457524061203
Iteration [36927]: Loss = 0.7045524716377258
Iteration [36928]: Loss = 0.7044936418533325
Iteration [36929]: Loss = 0.7044021487236023
Iteration [36930]: Loss = 0.7042813301086426
Iteration [36931]: Loss = 4.924374103546143
Iteration [36932]: Loss = 0.7042005658149719
Iteration [36933]: Loss = 4.923919200897217
Iteration [36934]: Loss = 4.922791957855225
Iteration [36935]: Loss = 0.7048335671424866
Iteration [36936]: Loss = 0.7051500082015991
Iteration [36937]: Loss = 0.7053965330123901
Iteration [36938]: Loss = 0.7055801749229431
Iteration [36939]: Loss = 0.7057070732116699
Iteration [36940]: Loss = 0.7057828903198242
Iteration [36941]: Loss = 0.7058125734329224
Iteration [36942]: Loss = 4.9157609939575195
Iteration [36943]: Loss = 4.914793014526367
Iteration [36944]: Loss = 0.7063553929328918
Iteration [36945]: Loss = 0.7066471576690674
Iteration [36946]: Loss = 0.7068715691566467
Iteration [36947]: Loss = 0.7070350646972656
Iteration [36948]: Loss = 0.7071437835693359
Iteration [36949]: Loss = 0.7072032690048218
Iteration [36950]: Loss = 0.7072179913520813
Iteration [36951]: Loss = 0.7071926593780518
Iteration [36952]: Loss = 0.7071313261985779
Iteration [36953]: Loss = 4.909393787384033
Iteration [36954]: Loss = 0.7071512341499329
Iteration [36955]: Loss = 0.7072151899337769
Iteration [36956]: Loss = 0.7072343826293945
Iteration [36957]: Loss = 0.7072129249572754
Iteration [36958]: Loss = 0.7071548700332642
Iteration [36959]: Loss = 4.9092559814453125
Iteration [36960]: Loss = 0.7071807384490967
Iteration [36961]: Loss = 0.707247257232666
Iteration [36962]: Loss = 0.7072685360908508
Iteration [36963]: Loss = 4.908305644989014
Iteration [36964]: Loss = 0.7074297070503235
Iteration [36965]: Loss = 0.7075539231300354
Iteration [36966]: Loss = 0.7076270580291748
Iteration [36967]: Loss = 0.7076542973518372
Iteration [36968]: Loss = 0.7076402902603149
Iteration [36969]: Loss = 0.7075887322425842
Iteration [36970]: Loss = 0.7075038552284241
Iteration [36971]: Loss = 0.7073885798454285
Iteration [36972]: Loss = 4.908319473266602
Iteration [36973]: Loss = 0.7073168754577637
Iteration [36974]: Loss = 0.7073417901992798
Iteration [36975]: Loss = 0.7073255777359009
Iteration [36976]: Loss = 0.7072721719741821
Iteration [36977]: Loss = 4.908630847930908
Iteration [36978]: Loss = 4.908010482788086
Iteration [36979]: Loss = 0.7076128125190735
Iteration [36980]: Loss = 0.7078502774238586
Iteration [36981]: Loss = 0.7080255746841431
Iteration [36982]: Loss = 0.7081446051597595
Iteration [36983]: Loss = 0.7082132697105408
Iteration [36984]: Loss = 4.903236389160156
Iteration [36985]: Loss = 0.7084552049636841
Iteration [36986]: Loss = 0.7086136341094971
Iteration [36987]: Loss = 0.7087176442146301
Iteration [36988]: Loss = 0.7087726593017578
Iteration [36989]: Loss = 0.7087831497192383
Iteration [36990]: Loss = 0.7087541222572327
Iteration [36991]: Loss = 4.900915622711182
Iteration [36992]: Loss = 0.7088289260864258
Iteration [36993]: Loss = 0.7089161276817322
Iteration [36994]: Loss = 4.899548530578613
Iteration [36995]: Loss = 0.7091897130012512
Iteration [36996]: Loss = 0.7093616724014282
Iteration [36997]: Loss = 0.7094776034355164
Iteration [36998]: Loss = 4.896544456481934
Iteration [36999]: Loss = 0.7098003625869751
Iteration [37000]: Loss = 0.7099929451942444
Iteration [37001]: Loss = 0.7101276516914368
Iteration [37002]: Loss = 0.7102100849151611
Iteration [37003]: Loss = 0.710245668888092
Iteration [37004]: Loss = 0.7102386355400085
Iteration [37005]: Loss = 4.893222332000732
Iteration [37006]: Loss = 0.7103510499000549
Iteration [37007]: Loss = 0.7104541063308716
Iteration [37008]: Loss = 0.7105079889297485
Iteration [37009]: Loss = 0.7105175256729126
Iteration [37010]: Loss = 0.7104874849319458
Iteration [37011]: Loss = 0.7104213833808899
Iteration [37012]: Loss = 0.7103229761123657
Iteration [37013]: Loss = 0.7101954221725464
Iteration [37014]: Loss = 0.7100417017936707
Iteration [37015]: Loss = 0.7098643183708191
Iteration [37016]: Loss = 4.895917892456055
Iteration [37017]: Loss = 0.7096860408782959
Iteration [37018]: Loss = 0.7096652984619141
Iteration [37019]: Loss = 4.896214008331299
Iteration [37020]: Loss = 0.7097545266151428
Iteration [37021]: Loss = 0.7098477482795715
Iteration [37022]: Loss = 0.7098929286003113
Iteration [37023]: Loss = 0.7098946571350098
Iteration [37024]: Loss = 0.7098572850227356
Iteration [37025]: Loss = 4.895309925079346
Iteration [37026]: Loss = 0.7099181413650513
Iteration [37027]: Loss = 0.7099992632865906
Iteration [37028]: Loss = 0.7100334763526917
Iteration [37029]: Loss = 0.7100253105163574
Iteration [37030]: Loss = 0.7099791169166565
Iteration [37031]: Loss = 0.7098986506462097
Iteration [37032]: Loss = 0.709787130355835
Iteration [37033]: Loss = 0.7096480131149292
Iteration [37034]: Loss = 4.896849155426025
Iteration [37035]: Loss = 0.7095348238945007
Iteration [37036]: Loss = 0.7095420956611633
Iteration [37037]: Loss = 0.7095094919204712
Iteration [37038]: Loss = 0.7094413638114929
Iteration [37039]: Loss = 0.7093410491943359
Iteration [37040]: Loss = 0.7092119455337524
Iteration [37041]: Loss = 4.899033069610596
Iteration [37042]: Loss = 0.7091161012649536
Iteration [37043]: Loss = 0.7091307640075684
Iteration [37044]: Loss = 0.7091050744056702
Iteration [37045]: Loss = 0.7090429067611694
Iteration [37046]: Loss = 0.7089481949806213
Iteration [37047]: Loss = 4.900225639343262
Iteration [37048]: Loss = 0.7089111804962158
Iteration [37049]: Loss = 0.7089508771896362
Iteration [37050]: Loss = 0.7089478373527527
Iteration [37051]: Loss = 0.7089061737060547
Iteration [37052]: Loss = 0.7088296413421631
Iteration [37053]: Loss = 0.7087219953536987
Iteration [37054]: Loss = 0.7085861563682556
Iteration [37055]: Loss = 0.7084249258041382
Iteration [37056]: Loss = 0.7082408666610718
Iteration [37057]: Loss = 0.7080361843109131
Iteration [37058]: Loss = 0.7078132629394531
Iteration [37059]: Loss = 0.7075734734535217
Iteration [37060]: Loss = 4.907947540283203
Iteration [37061]: Loss = 4.908097267150879
Iteration [37062]: Loss = 0.7074623703956604
Iteration [37063]: Loss = 0.7075791358947754
Iteration [37064]: Loss = 0.7076455354690552
Iteration [37065]: Loss = 0.7076665163040161
Iteration [37066]: Loss = 0.7076465487480164
Iteration [37067]: Loss = 0.7075896859169006
Iteration [37068]: Loss = 0.7074997425079346
Iteration [37069]: Loss = 0.7073798775672913
Iteration [37070]: Loss = 0.7072331309318542
Iteration [37071]: Loss = 0.7070620656013489
Iteration [37072]: Loss = 0.7068692445755005
Iteration [37073]: Loss = 0.7066566944122314
Iteration [37074]: Loss = 4.912536144256592
Iteration [37075]: Loss = 0.7064197659492493
Iteration [37076]: Loss = 0.7063747048377991
Iteration [37077]: Loss = 0.706295371055603
Iteration [37078]: Loss = 0.706184983253479
Iteration [37079]: Loss = 0.7060469388961792
Iteration [37080]: Loss = 0.705883800983429
Iteration [37081]: Loss = 0.7056981325149536
Iteration [37082]: Loss = 0.7054921984672546
Iteration [37083]: Loss = 0.7052679657936096
Iteration [37084]: Loss = 0.7050274014472961
Iteration [37085]: Loss = 0.7047720551490784
Iteration [37086]: Loss = 0.7045034170150757
Iteration [37087]: Loss = 0.7042227387428284
Iteration [37088]: Loss = 0.7039313316345215
Iteration [37089]: Loss = 0.7036303877830505
Iteration [37090]: Loss = 0.7033206820487976
Iteration [37091]: Loss = 0.7030032873153687
Iteration [37092]: Loss = 0.7026787996292114
Iteration [37093]: Loss = 0.7023481130599976
Iteration [37094]: Loss = 0.7020116448402405
Iteration [37095]: Loss = 0.7016701698303223
Iteration [37096]: Loss = 0.7013241648674011
Iteration [37097]: Loss = 0.70097416639328
Iteration [37098]: Loss = 0.7006204724311829
Iteration [37099]: Loss = 0.700263500213623
Iteration [37100]: Loss = 0.6999036073684692
Iteration [37101]: Loss = 0.6995412111282349
Iteration [37102]: Loss = 4.950191497802734
Iteration [37103]: Loss = 0.6990504264831543
Iteration [37104]: Loss = 0.6988983750343323
Iteration [37105]: Loss = 0.6987230777740479
Iteration [37106]: Loss = 4.953596115112305
Iteration [37107]: Loss = 0.6985520720481873
Iteration [37108]: Loss = 4.953546524047852
Iteration [37109]: Loss = 0.6987231969833374
Iteration [37110]: Loss = 0.6988533139228821
Iteration [37111]: Loss = 0.6989319324493408
Iteration [37112]: Loss = 0.6989644169807434
Iteration [37113]: Loss = 0.6989550590515137
Iteration [37114]: Loss = 0.6989083290100098
Iteration [37115]: Loss = 0.6988277435302734
Iteration [37116]: Loss = 0.6987166404724121
Iteration [37117]: Loss = 0.6985782980918884
Iteration [37118]: Loss = 0.6984150409698486
Iteration [37119]: Loss = 0.6982299089431763
Iteration [37120]: Loss = 0.698024570941925
Iteration [37121]: Loss = 0.6978012919425964
Iteration [37122]: Loss = 4.958663463592529
Iteration [37123]: Loss = 4.958732604980469
Iteration [37124]: Loss = 4.957736968994141
Iteration [37125]: Loss = 0.69810950756073
Iteration [37126]: Loss = 0.6984057426452637
Iteration [37127]: Loss = 0.6986340284347534
Iteration [37128]: Loss = 4.952156066894531
Iteration [37129]: Loss = 0.6991525888442993
Iteration [37130]: Loss = 0.6994305849075317
Iteration [37131]: Loss = 0.6996424794197083
Iteration [37132]: Loss = 0.6997950077056885
Iteration [37133]: Loss = 0.6998937726020813
Iteration [37134]: Loss = 0.6999441981315613
Iteration [37135]: Loss = 0.6999512314796448
Iteration [37136]: Loss = 0.6999189853668213
Iteration [37137]: Loss = 0.699851393699646
Iteration [37138]: Loss = 4.947178840637207
Iteration [37139]: Loss = 0.6998637914657593
Iteration [37140]: Loss = 0.6999261975288391
Iteration [37141]: Loss = 0.6999437212944031
Iteration [37142]: Loss = 0.6999210119247437
Iteration [37143]: Loss = 0.6998620629310608
Iteration [37144]: Loss = 0.6997703909873962
Iteration [37145]: Loss = 0.6996493339538574
Iteration [37146]: Loss = 0.6995017528533936
Iteration [37147]: Loss = 0.6993304491043091
Iteration [37148]: Loss = 0.6991375684738159
Iteration [37149]: Loss = 0.6989254951477051
Iteration [37150]: Loss = 0.6986958980560303
Iteration [37151]: Loss = 4.9539947509765625
Iteration [37152]: Loss = 0.698432445526123
Iteration [37153]: Loss = 0.6983774304389954
Iteration [37154]: Loss = 0.6982894539833069
Iteration [37155]: Loss = 0.6981716752052307
Iteration [37156]: Loss = 0.6980271935462952
Iteration [37157]: Loss = 0.6978586912155151
Iteration [37158]: Loss = 0.6976684927940369
Iteration [37159]: Loss = 9.220952987670898
Iteration [37160]: Loss = 0.697710394859314
Iteration [37161]: Loss = 0.6978989839553833
Iteration [37162]: Loss = 0.6980307102203369
Iteration [37163]: Loss = 4.955778121948242
Iteration [37164]: Loss = 0.6983834505081177
Iteration [37165]: Loss = 0.6985905170440674
Iteration [37166]: Loss = 0.698738694190979
Iteration [37167]: Loss = 0.6988341212272644
Iteration [37168]: Loss = 0.6988818049430847
Iteration [37169]: Loss = 0.698886513710022
Iteration [37170]: Loss = 0.6988525986671448
Iteration [37171]: Loss = 0.6987837553024292
Iteration [37172]: Loss = 0.6986834406852722
Iteration [37173]: Loss = 0.6985549330711365
Iteration [37174]: Loss = 0.6984009146690369
Iteration [37175]: Loss = 0.6982239484786987
Iteration [37176]: Loss = 4.956222057342529
Iteration [37177]: Loss = 0.6980496048927307
Iteration [37178]: Loss = 0.6980322599411011
Iteration [37179]: Loss = 0.6979784369468689
Iteration [37180]: Loss = 0.6978918313980103
Iteration [37181]: Loss = 0.6977754831314087
Iteration [37182]: Loss = 0.6976326107978821
Iteration [37183]: Loss = 0.6974656581878662
Iteration [37184]: Loss = 0.6972771286964417
Iteration [37185]: Loss = 0.6970692276954651
Iteration [37186]: Loss = 0.6968437433242798
Iteration [37187]: Loss = 4.963712215423584
Iteration [37188]: Loss = 0.6965871453285217
Iteration [37189]: Loss = 4.96406888961792
Iteration [37190]: Loss = 0.6966888308525085
Iteration [37191]: Loss = 0.6967893242835999
Iteration [37192]: Loss = 0.6968417167663574
Iteration [37193]: Loss = 0.696850597858429
Iteration [37194]: Loss = 0.6968204379081726
Iteration [37195]: Loss = 0.6967551112174988
Iteration [37196]: Loss = 4.9634199142456055
Iteration [37197]: Loss = 0.6967718601226807
Iteration [37198]: Loss = 0.6968361139297485
Iteration [37199]: Loss = 0.696855902671814
Iteration [37200]: Loss = 0.6968353986740112
Iteration [37201]: Loss = 0.6967787742614746
Iteration [37202]: Loss = 0.6966896653175354
Iteration [37203]: Loss = 0.6965712308883667
Iteration [37204]: Loss = 0.6964263916015625
Iteration [37205]: Loss = 0.6962577700614929
Iteration [37206]: Loss = 0.6960676312446594
Iteration [37207]: Loss = 0.6958584785461426
Iteration [37208]: Loss = 0.6956319808959961
Iteration [37209]: Loss = 0.6953898668289185
Iteration [37210]: Loss = 0.695133626461029
Iteration [37211]: Loss = 0.6948649287223816
Iteration [37212]: Loss = 0.6945847868919373
Iteration [37213]: Loss = 9.257522583007812
Iteration [37214]: Loss = 0.6944738030433655
Iteration [37215]: Loss = 0.6945974826812744
Iteration [37216]: Loss = 0.6946709752082825
Iteration [37217]: Loss = 0.6946994066238403
Iteration [37218]: Loss = 0.6946872472763062
Iteration [37219]: Loss = 0.6946384310722351
Iteration [37220]: Loss = 0.6945566534996033
Iteration [37221]: Loss = 0.6944451332092285
Iteration [37222]: Loss = 0.6943067908287048
Iteration [37223]: Loss = 0.6941444873809814
Iteration [37224]: Loss = 0.6939605474472046
Iteration [37225]: Loss = 0.6937569975852966
Iteration [37226]: Loss = 0.6935359835624695
Iteration [37227]: Loss = 0.6932991743087769
Iteration [37228]: Loss = 4.982521057128906
Iteration [37229]: Loss = 0.6930234432220459
Iteration [37230]: Loss = 4.98297119140625
Iteration [37231]: Loss = 0.6931097507476807
Iteration [37232]: Loss = 0.6932038068771362
Iteration [37233]: Loss = 0.6932507753372192
Iteration [37234]: Loss = 0.6932554244995117
Iteration [37235]: Loss = 0.6932216882705688
Iteration [37236]: Loss = 0.6931535005569458
Iteration [37237]: Loss = 0.6930544376373291
Iteration [37238]: Loss = 4.983162879943848
Iteration [37239]: Loss = 0.6930136680603027
Iteration [37240]: Loss = 0.6930537223815918
Iteration [37241]: Loss = 0.6930520534515381
Iteration [37242]: Loss = 4.982709884643555
Iteration [37243]: Loss = 0.6931778192520142
Iteration [37244]: Loss = 0.6932888031005859
Iteration [37245]: Loss = 0.6933509111404419
Iteration [37246]: Loss = 0.6933690309524536
Iteration [37247]: Loss = 4.980930805206299
Iteration [37248]: Loss = 0.6935285925865173
Iteration [37249]: Loss = 0.6936538219451904
Iteration [37250]: Loss = 0.6937289834022522
Iteration [37251]: Loss = 0.6937586665153503
Iteration [37252]: Loss = 0.6937476992607117
Iteration [37253]: Loss = 4.979060649871826
Iteration [37254]: Loss = 0.6938573122024536
Iteration [37255]: Loss = 0.6939613819122314
Iteration [37256]: Loss = 0.6940171718597412
Iteration [37257]: Loss = 0.6940296292304993
Iteration [37258]: Loss = 0.6940029859542847
Iteration [37259]: Loss = 0.693941056728363
Iteration [37260]: Loss = 0.6938475370407104
Iteration [37261]: Loss = 0.6937255263328552
Iteration [37262]: Loss = 4.979710102081299
Iteration [37263]: Loss = 4.979349613189697
Iteration [37264]: Loss = 0.6939067244529724
Iteration [37265]: Loss = 4.976917743682861
Iteration [37266]: Loss = 0.6944814324378967
Iteration [37267]: Loss = 0.6947835683822632
Iteration [37268]: Loss = 0.6950178742408752
Iteration [37269]: Loss = 0.6951910853385925
Iteration [37270]: Loss = 0.6953091025352478
Iteration [37271]: Loss = 0.6953775882720947
Iteration [37272]: Loss = 0.6954011917114258
Iteration [37273]: Loss = 4.97014045715332
Iteration [37274]: Loss = 0.6955698132514954
Iteration [37275]: Loss = 0.6956986784934998
Iteration [37276]: Loss = 0.6957768201828003
Iteration [37277]: Loss = 0.6958091855049133
Iteration [37278]: Loss = 0.6958004236221313
Iteration [37279]: Loss = 4.968186378479004
Iteration [37280]: Loss = 0.6959134340286255
Iteration [37281]: Loss = 4.966792583465576
Iteration [37282]: Loss = 0.6963129043579102
Iteration [37283]: Loss = 0.6965398788452148
Iteration [37284]: Loss = 9.229622840881348
Iteration [37285]: Loss = 4.960103511810303
Iteration [37286]: Loss = 0.6980082988739014
Iteration [37287]: Loss = 0.6986196637153625
Iteration [37288]: Loss = 0.6991328001022339
Iteration [37289]: Loss = 4.948196887969971
Iteration [37290]: Loss = 4.945169448852539
Iteration [37291]: Loss = 0.7008536458015442
Iteration [37292]: Loss = 0.7014621496200562
Iteration [37293]: Loss = 0.7019727826118469
Iteration [37294]: Loss = 0.7023947834968567
Iteration [37295]: Loss = 0.702737033367157
Iteration [37296]: Loss = 0.7030072808265686
Iteration [37297]: Loss = 4.929149150848389
Iteration [37298]: Loss = 0.7035942077636719
Iteration [37299]: Loss = 0.7038997411727905
Iteration [37300]: Loss = 0.7041370272636414
Iteration [37301]: Loss = 0.7043126821517944
Iteration [37302]: Loss = 0.7044326066970825
Iteration [37303]: Loss = 0.7045025825500488
Iteration [37304]: Loss = 0.7045272588729858
Iteration [37305]: Loss = 0.7045113444328308
Iteration [37306]: Loss = 0.7044587731361389
Iteration [37307]: Loss = 0.704373300075531
Iteration [37308]: Loss = 0.7042582035064697
Iteration [37309]: Loss = 4.924466133117676
Iteration [37310]: Loss = 0.704186201095581
Iteration [37311]: Loss = 0.7042111754417419
Iteration [37312]: Loss = 0.7041953802108765
Iteration [37313]: Loss = 0.7041429877281189
Iteration [37314]: Loss = 0.704057514667511
Iteration [37315]: Loss = 0.7039424180984497
Iteration [37316]: Loss = 0.703800618648529
Iteration [37317]: Loss = 0.7036347985267639
Iteration [37318]: Loss = 0.7034472823143005
Iteration [37319]: Loss = 0.7032402753829956
Iteration [37320]: Loss = 0.7030155658721924
Iteration [37321]: Loss = 0.7027751803398132
Iteration [37322]: Loss = 0.7025206685066223
Iteration [37323]: Loss = 0.7022532820701599
Iteration [37324]: Loss = 0.7019745111465454
Iteration [37325]: Loss = 0.7016854286193848
Iteration [37326]: Loss = 4.938642501831055
Iteration [37327]: Loss = 0.701317310333252
Iteration [37328]: Loss = 4.939529895782471
Iteration [37329]: Loss = 0.7013242840766907
Iteration [37330]: Loss = 0.7013831734657288
Iteration [37331]: Loss = 0.7013982534408569
Iteration [37332]: Loss = 0.7013735771179199
Iteration [37333]: Loss = 0.7013133764266968
Iteration [37334]: Loss = 0.7012210488319397
Iteration [37335]: Loss = 4.940139293670654
Iteration [37336]: Loss = 0.7011892199516296
Iteration [37337]: Loss = 0.7012317776679993
Iteration [37338]: Loss = 0.7012318968772888
Iteration [37339]: Loss = 9.178104400634766
Iteration [37340]: Loss = 0.7015905380249023
Iteration [37341]: Loss = 0.7019102573394775
Iteration [37342]: Loss = 0.7021602988243103
Iteration [37343]: Loss = 0.7023477554321289
Iteration [37344]: Loss = 0.7024787664413452
Iteration [37345]: Loss = 0.7025588154792786
Iteration [37346]: Loss = 0.7025930881500244
Iteration [37347]: Loss = 4.932404041290283
Iteration [37348]: Loss = 0.7027761340141296
Iteration [37349]: Loss = 0.7029096484184265
Iteration [37350]: Loss = 0.7029918432235718
Iteration [37351]: Loss = 0.7030280828475952
Iteration [37352]: Loss = 0.7030226588249207
Iteration [37353]: Loss = 0.7029798030853271
Iteration [37354]: Loss = 0.7029033899307251
Iteration [37355]: Loss = 0.7027965188026428
Iteration [37356]: Loss = 0.7026624083518982
Iteration [37357]: Loss = 0.7025036811828613
Iteration [37358]: Loss = 0.7023227214813232
Iteration [37359]: Loss = 0.7021220922470093
Iteration [37360]: Loss = 0.7019032835960388
Iteration [37361]: Loss = 0.7016684412956238
Iteration [37362]: Loss = 4.938475608825684
Iteration [37363]: Loss = 0.7013924717903137
Iteration [37364]: Loss = 0.7013306617736816
Iteration [37365]: Loss = 0.7012370824813843
Iteration [37366]: Loss = 0.70111483335495
Iteration [37367]: Loss = 0.7009669542312622
Iteration [37368]: Loss = 0.7007958889007568
Iteration [37369]: Loss = 0.7006040215492249
Iteration [37370]: Loss = 0.7003933787345886
Iteration [37371]: Loss = 0.700165867805481
Iteration [37372]: Loss = 4.946282863616943
Iteration [37373]: Loss = 0.6999030113220215
Iteration [37374]: Loss = 0.6998469829559326
Iteration [37375]: Loss = 0.6997586488723755
Iteration [37376]: Loss = 0.6996412873268127
Iteration [37377]: Loss = 0.6994978189468384
Iteration [37378]: Loss = 0.6993306875228882
Iteration [37379]: Loss = 0.6991425156593323
Iteration [37380]: Loss = 4.951454162597656
Iteration [37381]: Loss = 0.698947012424469
Iteration [37382]: Loss = 0.6989198327064514
Iteration [37383]: Loss = 0.6988574862480164
Iteration [37384]: Loss = 0.6987636089324951
Iteration [37385]: Loss = 0.6986412405967712
Iteration [37386]: Loss = 0.6984933018684387
Iteration [37387]: Loss = 0.6983222961425781
Iteration [37388]: Loss = 0.6981306076049805
Iteration [37389]: Loss = 4.956780910491943
Iteration [37390]: Loss = 0.6979293823242188
Iteration [37391]: Loss = 0.6978999972343445
Iteration [37392]: Loss = 0.6978356838226318
Iteration [37393]: Loss = 0.6977400183677673
Iteration [37394]: Loss = 0.6976161599159241
Iteration [37395]: Loss = 0.6974668502807617
Iteration [37396]: Loss = 0.6972947120666504
Iteration [37397]: Loss = 0.697101891040802
Iteration [37398]: Loss = 0.696890652179718
Iteration [37399]: Loss = 4.9633965492248535
Iteration [37400]: Loss = 0.6966564059257507
Iteration [37401]: Loss = 0.6966131329536438
Iteration [37402]: Loss = 4.964061260223389
Iteration [37403]: Loss = 0.6966660022735596
Iteration [37404]: Loss = 0.6967449188232422
Iteration [37405]: Loss = 0.6967782974243164
Iteration [37406]: Loss = 0.6967706680297852
Iteration [37407]: Loss = 0.6967261433601379
Iteration [37408]: Loss = 0.6966482996940613
Iteration [37409]: Loss = 0.696540355682373
Iteration [37410]: Loss = 4.964752197265625
Iteration [37411]: Loss = 0.6964830756187439
Iteration [37412]: Loss = 0.6965151429176331
Iteration [37413]: Loss = 4.9642205238342285
Iteration [37414]: Loss = 0.6966967582702637
Iteration [37415]: Loss = 0.6968305110931396
Iteration [37416]: Loss = 4.962075710296631
Iteration [37417]: Loss = 0.6971860527992249
Iteration [37418]: Loss = 0.6973938345909119
Iteration [37419]: Loss = 0.6975432634353638
Iteration [37420]: Loss = 0.6976401209831238
Iteration [37421]: Loss = 0.6976895928382874
Iteration [37422]: Loss = 0.6976962685585022
Iteration [37423]: Loss = 0.6976645588874817
Iteration [37424]: Loss = 0.6975982189178467
Iteration [37425]: Loss = 0.6975006461143494
Iteration [37426]: Loss = 0.6973750591278076
Iteration [37427]: Loss = 4.960439682006836
Iteration [37428]: Loss = 0.6972872018814087
Iteration [37429]: Loss = 4.96000862121582
Iteration [37430]: Loss = 0.697521448135376
Iteration [37431]: Loss = 4.958054542541504
Iteration [37432]: Loss = 0.6980161070823669
Iteration [37433]: Loss = 0.6982832551002502
Iteration [37434]: Loss = 0.6984860301017761
Iteration [37435]: Loss = 0.6986309289932251
Iteration [37436]: Loss = 0.6987234354019165
Iteration [37437]: Loss = 4.952325820922852
Iteration [37438]: Loss = 0.6990081071853638
Iteration [37439]: Loss = 0.6991854310035706
Iteration [37440]: Loss = 0.6993073225021362
Iteration [37441]: Loss = 0.6993792653083801
Iteration [37442]: Loss = 0.6994061470031738
Iteration [37443]: Loss = 0.6993923187255859
Iteration [37444]: Loss = 0.6993420720100403
Iteration [37445]: Loss = 0.6992589831352234
Iteration [37446]: Loss = 0.6991460919380188
Iteration [37447]: Loss = 0.6990066170692444
Iteration [37448]: Loss = 4.951937675476074
Iteration [37449]: Loss = 0.6988946795463562
Iteration [37450]: Loss = 0.6989031434059143
Iteration [37451]: Loss = 0.6988729238510132
Iteration [37452]: Loss = 0.6988078355789185
Iteration [37453]: Loss = 0.6987113356590271
Iteration [37454]: Loss = 0.6985865831375122
Iteration [37455]: Loss = 4.954071521759033
Iteration [37456]: Loss = 0.6984997987747192
Iteration [37457]: Loss = 0.698519229888916
Iteration [37458]: Loss = 0.6984988451004028
Iteration [37459]: Loss = 0.6984425187110901
Iteration [37460]: Loss = 0.6983539462089539
Iteration [37461]: Loss = 0.6982362270355225
Iteration [37462]: Loss = 0.6980924010276794
Iteration [37463]: Loss = 0.6979249119758606
Iteration [37464]: Loss = 0.6977362632751465
Iteration [37465]: Loss = 4.958838939666748
Iteration [37466]: Loss = 0.6975409984588623
Iteration [37467]: Loss = 0.6975142955780029
Iteration [37468]: Loss = 0.6974523663520813
Iteration [37469]: Loss = 0.6973587870597839
Iteration [37470]: Loss = 4.96037483215332
Iteration [37471]: Loss = 0.6973257064819336
Iteration [37472]: Loss = 4.959681987762451
Iteration [37473]: Loss = 0.6976050138473511
Iteration [37474]: Loss = 0.6977804899215698
Iteration [37475]: Loss = 0.6979007124900818
Iteration [37476]: Loss = 0.6979710459709167
Iteration [37477]: Loss = 4.956379413604736
Iteration [37478]: Loss = 0.698218047618866
Iteration [37479]: Loss = 0.6983795762062073
Iteration [37480]: Loss = 0.6984873414039612
Iteration [37481]: Loss = 0.6985464096069336
Iteration [37482]: Loss = 0.6985616087913513
Iteration [37483]: Loss = 0.6985374093055725
Iteration [37484]: Loss = 0.6984777450561523
Iteration [37485]: Loss = 0.6983859539031982
Iteration [37486]: Loss = 4.9549665451049805
Iteration [37487]: Loss = 0.6983559727668762
Iteration [37488]: Loss = 0.6983996033668518
Iteration [37489]: Loss = 0.6984010338783264
Iteration [37490]: Loss = 0.6983642578125
Iteration [37491]: Loss = 0.6982933282852173
Iteration [37492]: Loss = 0.6981914639472961
Iteration [37493]: Loss = 0.6980618238449097
Iteration [37494]: Loss = 0.6979070901870728
Iteration [37495]: Loss = 0.6977298259735107
Iteration [37496]: Loss = 0.6975322365760803
Iteration [37497]: Loss = 0.6973165273666382
Iteration [37498]: Loss = 0.6970844268798828
Iteration [37499]: Loss = 0.696837306022644
Iteration [37500]: Loss = 0.6965771317481995
Iteration [37501]: Loss = 0.6963049173355103
Iteration [37502]: Loss = 0.6960219740867615
Iteration [37503]: Loss = 0.6957293748855591
Iteration [37504]: Loss = 0.6954281330108643
Iteration [37505]: Loss = 4.971545219421387
Iteration [37506]: Loss = 0.6950414180755615
Iteration [37507]: Loss = 0.6949338316917419
Iteration [37508]: Loss = 4.97323751449585
Iteration [37509]: Loss = 0.6948776841163635
Iteration [37510]: Loss = 0.6949107646942139
Iteration [37511]: Loss = 0.694902777671814
Iteration [37512]: Loss = 0.6948577761650085
Iteration [37513]: Loss = 0.6947793960571289
Iteration [37514]: Loss = 0.694671094417572
Iteration [37515]: Loss = 4.974629878997803
Iteration [37516]: Loss = 0.6946141719818115
Iteration [37517]: Loss = 0.6946468949317932
Iteration [37518]: Loss = 0.6946385502815247
Iteration [37519]: Loss = 0.6945931911468506
Iteration [37520]: Loss = 0.6945146918296814
Iteration [37521]: Loss = 0.6944060921669006
Iteration [37522]: Loss = 0.6942705512046814
Iteration [37523]: Loss = 0.6941107511520386
Iteration [37524]: Loss = 0.6939290165901184
Iteration [37525]: Loss = 4.978914260864258
Iteration [37526]: Loss = 0.6937468647956848
Iteration [37527]: Loss = 9.26411247253418
Iteration [37528]: Loss = 0.6941419839859009
Iteration [37529]: Loss = 0.6944788098335266
Iteration [37530]: Loss = 0.6947447657585144
Iteration [37531]: Loss = 0.694946825504303
Iteration [37532]: Loss = 0.6950913667678833
Iteration [37533]: Loss = 0.6951838135719299
Iteration [37534]: Loss = 0.6952295303344727
Iteration [37535]: Loss = 0.695233166217804
Iteration [37536]: Loss = 0.6951989531517029
Iteration [37537]: Loss = 0.695130467414856
Iteration [37538]: Loss = 0.6950311660766602
Iteration [37539]: Loss = 0.6949042081832886
Iteration [37540]: Loss = 0.6947523355484009
Iteration [37541]: Loss = 0.6945778727531433
Iteration [37542]: Loss = 0.6943832039833069
Iteration [37543]: Loss = 0.6941704154014587
Iteration [37544]: Loss = 0.6939411759376526
Iteration [37545]: Loss = 0.6936973929405212
Iteration [37546]: Loss = 0.6934402585029602
Iteration [37547]: Loss = 4.98186731338501
Iteration [37548]: Loss = 0.6931288242340088
Iteration [37549]: Loss = 0.6930531859397888
Iteration [37550]: Loss = 0.6929474472999573
Iteration [37551]: Loss = 4.983761787414551
Iteration [37552]: Loss = 0.6928948163986206
Iteration [37553]: Loss = 4.983152866363525
Iteration [37554]: Loss = 0.6931592226028442
Iteration [37555]: Loss = 0.693328857421875
Iteration [37556]: Loss = 0.6934440732002258
Iteration [37557]: Loss = 4.980066776275635
Iteration [37558]: Loss = 0.6937685608863831
Iteration [37559]: Loss = 0.6939636468887329
Iteration [37560]: Loss = 0.6941019296646118
Iteration [37561]: Loss = 0.6941887736320496
Iteration [37562]: Loss = 0.6942294836044312
Iteration [37563]: Loss = 0.6942285299301147
Iteration [37564]: Loss = 0.6941900849342346
Iteration [37565]: Loss = 0.6941179037094116
Iteration [37566]: Loss = 0.694015383720398
Iteration [37567]: Loss = 0.6938855051994324
Iteration [37568]: Loss = 0.693730890750885
Iteration [37569]: Loss = 0.6935539841651917
Iteration [37570]: Loss = 0.6933572292327881
Iteration [37571]: Loss = 0.6931426525115967
Iteration [37572]: Loss = 0.692911684513092
Iteration [37573]: Loss = 0.6926661729812622
Iteration [37574]: Loss = 0.6924077272415161
Iteration [37575]: Loss = 0.6921374797821045
Iteration [37576]: Loss = 0.6918566226959229
Iteration [37577]: Loss = 0.6915661692619324
Iteration [37578]: Loss = 0.6912673711776733
Iteration [37579]: Loss = 0.690960705280304
Iteration [37580]: Loss = 0.6906471848487854
Iteration [37581]: Loss = 0.6903276443481445
Iteration [37582]: Loss = 0.6900023221969604
Iteration [37583]: Loss = 0.68967205286026
Iteration [37584]: Loss = 0.689337432384491
Iteration [37585]: Loss = 0.6889986991882324
Iteration [37586]: Loss = 0.6886563301086426
Iteration [37587]: Loss = 0.6883108019828796
Iteration [37588]: Loss = 0.6879624128341675
Iteration [37589]: Loss = 0.68761146068573
Iteration [37590]: Loss = 0.6872580647468567
Iteration [37591]: Loss = 0.686902642250061
Iteration [37592]: Loss = 0.6865454316139221
Iteration [37593]: Loss = 0.6861864924430847
Iteration [37594]: Loss = 0.685826301574707
Iteration [37595]: Loss = 0.68546462059021
Iteration [37596]: Loss = 5.025143623352051
Iteration [37597]: Loss = 0.6849775910377502
Iteration [37598]: Loss = 0.684828519821167
Iteration [37599]: Loss = 0.684657096862793
Iteration [37600]: Loss = 0.6844655275344849
Iteration [37601]: Loss = 5.029728889465332
Iteration [37602]: Loss = 5.02965784072876
Iteration [37603]: Loss = 0.6844819784164429
Iteration [37604]: Loss = 0.684636652469635
Iteration [37605]: Loss = 0.6847386956214905
Iteration [37606]: Loss = 0.6847935914993286
Iteration [37607]: Loss = 0.6848057508468628
Iteration [37608]: Loss = 5.026889801025391
Iteration [37609]: Loss = 0.6849570274353027
Iteration [37610]: Loss = 0.6850798726081848
Iteration [37611]: Loss = 5.024866104125977
Iteration [37612]: Loss = 0.6854198575019836
Iteration [37613]: Loss = 5.022324562072754
Iteration [37614]: Loss = 0.6860058903694153
Iteration [37615]: Loss = 0.6863136887550354
Iteration [37616]: Loss = 0.6865537166595459
Iteration [37617]: Loss = 0.6867327094078064
Iteration [37618]: Loss = 0.6868566870689392
Iteration [37619]: Loss = 5.015261650085449
Iteration [37620]: Loss = 0.687198281288147
Iteration [37621]: Loss = 5.012724876403809
Iteration [37622]: Loss = 5.010663032531738
Iteration [37623]: Loss = 0.688328742980957
Iteration [37624]: Loss = 0.6887816786766052
Iteration [37625]: Loss = 0.6891523599624634
Iteration [37626]: Loss = 0.6894489526748657
Iteration [37627]: Loss = 0.6896786689758301
Iteration [37628]: Loss = 0.6898483633995056
Iteration [37629]: Loss = 0.6899635791778564
Iteration [37630]: Loss = 0.6900302171707153
Iteration [37631]: Loss = 0.6900523900985718
Iteration [37632]: Loss = 0.6900351047515869
Iteration [37633]: Loss = 0.6899821162223816
Iteration [37634]: Loss = 4.999328136444092
Iteration [37635]: Loss = 0.6900205016136169
Iteration [37636]: Loss = 9.306448936462402
Iteration [37637]: Loss = 0.6905935406684875
Iteration [37638]: Loss = 0.6910058856010437
Iteration [37639]: Loss = 0.6913403272628784
Iteration [37640]: Loss = 0.6916043758392334
Iteration [37641]: Loss = 0.6918049454689026
Iteration [37642]: Loss = 0.6919482946395874
Iteration [37643]: Loss = 0.6920401453971863
Iteration [37644]: Loss = 0.6920855045318604
Iteration [37645]: Loss = 4.9876227378845215
Iteration [37646]: Loss = 0.6922906637191772
Iteration [37647]: Loss = 0.6924349665641785
Iteration [37648]: Loss = 0.6925275921821594
Iteration [37649]: Loss = 0.692573606967926
Iteration [37650]: Loss = 0.6925777196884155
Iteration [37651]: Loss = 0.692544162273407
Iteration [37652]: Loss = 0.6924765110015869
Iteration [37653]: Loss = 0.6923782229423523
Iteration [37654]: Loss = 9.281256675720215
Iteration [37655]: Loss = 0.6925709843635559
Iteration [37656]: Loss = 0.6928208470344543
Iteration [37657]: Loss = 0.6930087804794312
Iteration [37658]: Loss = 0.693140983581543
Iteration [37659]: Loss = 0.6932229995727539
Iteration [37660]: Loss = 0.6932597160339355
Iteration [37661]: Loss = 0.6932556629180908
Iteration [37662]: Loss = 0.6932147741317749
Iteration [37663]: Loss = 0.6931408643722534
Iteration [37664]: Loss = 0.6930370330810547
Iteration [37665]: Loss = 0.6929064393043518
Iteration [37666]: Loss = 0.6927518844604492
Iteration [37667]: Loss = 4.985035419464111
Iteration [37668]: Loss = 0.6926142573356628
Iteration [37669]: Loss = 0.6926121115684509
Iteration [37670]: Loss = 0.6925731301307678
Iteration [37671]: Loss = 0.6925007700920105
Iteration [37672]: Loss = 0.6923985481262207
Iteration [37673]: Loss = 0.6922692656517029
Iteration [37674]: Loss = 4.987481117248535
Iteration [37675]: Loss = 0.6921755075454712
Iteration [37676]: Loss = 0.692192018032074
Iteration [37677]: Loss = 0.6921699047088623
Iteration [37678]: Loss = 0.6921128630638123
Iteration [37679]: Loss = 0.6920242309570312
Iteration [37680]: Loss = 0.6919073462486267
Iteration [37681]: Loss = 0.6917650699615479
Iteration [37682]: Loss = 4.990231513977051
Iteration [37683]: Loss = 0.6916489005088806
Iteration [37684]: Loss = 0.6916561126708984
Iteration [37685]: Loss = 0.6916254758834839
Iteration [37686]: Loss = 4.990438938140869
Iteration [37687]: Loss = 0.691700279712677
Iteration [37688]: Loss = 0.6917886734008789
Iteration [37689]: Loss = 4.988996982574463
Iteration [37690]: Loss = 0.69206702709198
Iteration [37691]: Loss = 4.986809730529785
Iteration [37692]: Loss = 0.692596435546875
Iteration [37693]: Loss = 0.6928787231445312
Iteration [37694]: Loss = 4.982269287109375
Iteration [37695]: Loss = 4.98018741607666
Iteration [37696]: Loss = 0.6940365433692932
Iteration [37697]: Loss = 0.69449383020401
Iteration [37698]: Loss = 4.972869396209717
Iteration [37699]: Loss = 0.6954018473625183
Iteration [37700]: Loss = 0.6958450675010681
Iteration [37701]: Loss = 4.9657979011535645
Iteration [37702]: Loss = 0.696728527545929
Iteration [37703]: Loss = 0.6971611380577087
Iteration [37704]: Loss = 0.6975135803222656
Iteration [37705]: Loss = 0.6977934241294861
Iteration [37706]: Loss = 0.6980082988739014
Iteration [37707]: Loss = 4.955498695373535
Iteration [37708]: Loss = 0.6985007524490356
Iteration [37709]: Loss = 0.6987662315368652
Iteration [37710]: Loss = 0.6989680528640747
Iteration [37711]: Loss = 0.6991121768951416
Iteration [37712]: Loss = 0.6992045044898987
Iteration [37713]: Loss = 0.6992502212524414
Iteration [37714]: Loss = 0.6992536783218384
Iteration [37715]: Loss = 4.949965476989746
Iteration [37716]: Loss = 4.949100017547607
Iteration [37717]: Loss = 0.6997295022010803
Iteration [37718]: Loss = 0.7000023722648621
Iteration [37719]: Loss = 0.7002108097076416
Iteration [37720]: Loss = 0.7003607153892517
Iteration [37721]: Loss = 0.7004583477973938
Iteration [37722]: Loss = 0.7005085349082947
Iteration [37723]: Loss = 0.7005161046981812
Iteration [37724]: Loss = 0.7004854083061218
Iteration [37725]: Loss = 0.700420081615448
Iteration [37726]: Loss = 0.7003236413002014
Iteration [37727]: Loss = 4.944840908050537
Iteration [37728]: Loss = 0.7002835273742676
Iteration [37729]: Loss = 0.7003220915794373
Iteration [37730]: Loss = 0.7003191709518433
Iteration [37731]: Loss = 0.7002788782119751
Iteration [37732]: Loss = 0.7002049088478088
Iteration [37733]: Loss = 0.7001007199287415
Iteration [37734]: Loss = 0.6999692916870117
Iteration [37735]: Loss = 4.946858882904053
Iteration [37736]: Loss = 0.6998695135116577
Iteration [37737]: Loss = 4.946493148803711
Iteration [37738]: Loss = 0.7000910043716431
Iteration [37739]: Loss = 0.7002409100532532
Iteration [37740]: Loss = 0.7003383040428162
Iteration [37741]: Loss = 4.943851947784424
Iteration [37742]: Loss = 0.7006295919418335
Iteration [37743]: Loss = 0.7008092999458313
Iteration [37744]: Loss = 4.941007137298584
Iteration [37745]: Loss = 0.7012410163879395
Iteration [37746]: Loss = 0.7014804482460022
Iteration [37747]: Loss = 0.7016582489013672
Iteration [37748]: Loss = 4.936590671539307
Iteration [37749]: Loss = 0.7018259763717651
Iteration [37750]: Loss = 9.168177604675293
Iteration [37751]: Loss = 0.7027003169059753
Iteration [37752]: Loss = 0.7032367587089539
Iteration [37753]: Loss = 0.7036826610565186
Iteration [37754]: Loss = 0.7040467858314514
Iteration [37755]: Loss = 4.923321723937988
Iteration [37756]: Loss = 0.7047924399375916
Iteration [37757]: Loss = 4.91904354095459
Iteration [37758]: Loss = 0.7056934237480164
Iteration [37759]: Loss = 9.12197494506836
Iteration [37760]: Loss = 0.7069440484046936
Iteration [37761]: Loss = 0.7076385617256165
Iteration [37762]: Loss = 0.7082269191741943
Iteration [37763]: Loss = 0.7087196111679077
Iteration [37764]: Loss = 0.7091258764266968
Iteration [37765]: Loss = 0.709454357624054
Iteration [37766]: Loss = 4.895678997039795
Iteration [37767]: Loss = 0.7101366519927979
Iteration [37768]: Loss = 0.7104809284210205
Iteration [37769]: Loss = 0.7107535004615784
Iteration [37770]: Loss = 0.7109612226486206
Iteration [37771]: Loss = 0.711110532283783
Iteration [37772]: Loss = 4.888053894042969
Iteration [37773]: Loss = 0.7114863395690918
Iteration [37774]: Loss = 0.7116998434066772
Iteration [37775]: Loss = 0.7118542790412903
Iteration [37776]: Loss = 0.7119556069374084
Iteration [37777]: Loss = 4.883974552154541
Iteration [37778]: Loss = 0.7122491002082825
Iteration [37779]: Loss = 0.7124274969100952
Iteration [37780]: Loss = 0.7125502824783325
Iteration [37781]: Loss = 0.7126230001449585
Iteration [37782]: Loss = 0.7126505374908447
Iteration [37783]: Loss = 0.7126373052597046
Iteration [37784]: Loss = 0.7125875949859619
Iteration [37785]: Loss = 0.7125048041343689
Iteration [37786]: Loss = 0.712392270565033
Iteration [37787]: Loss = 0.7122530341148376
Iteration [37788]: Loss = 0.7120897769927979
Iteration [37789]: Loss = 0.7119048237800598
Iteration [37790]: Loss = 0.7117003202438354
Iteration [37791]: Loss = 0.7114783525466919
Iteration [37792]: Loss = 0.7112406492233276
Iteration [37793]: Loss = 0.7109886407852173
Iteration [37794]: Loss = 0.7107237577438354
Iteration [37795]: Loss = 0.7104475498199463
Iteration [37796]: Loss = 0.710161030292511
Iteration [37797]: Loss = 0.7098652124404907
Iteration [37798]: Loss = 0.7095609903335571
Iteration [37799]: Loss = 0.7092493176460266
Iteration [37800]: Loss = 0.7089309096336365
Iteration [37801]: Loss = 0.7086065411567688
Iteration [37802]: Loss = 4.903029441833496
Iteration [37803]: Loss = 0.7081740498542786
Iteration [37804]: Loss = 0.7080438137054443
Iteration [37805]: Loss = 0.7078888416290283
Iteration [37806]: Loss = 9.104145050048828
Iteration [37807]: Loss = 0.7079749703407288
Iteration [37808]: Loss = 0.7081747651100159
Iteration [37809]: Loss = 0.708317220211029
Iteration [37810]: Loss = 0.708407998085022
Iteration [37811]: Loss = 0.7084522843360901
Iteration [37812]: Loss = 0.7084546089172363
Iteration [37813]: Loss = 0.708419144153595
Iteration [37814]: Loss = 4.902655124664307
Iteration [37815]: Loss = 4.901989936828613
Iteration [37816]: Loss = 0.7087878584861755
Iteration [37817]: Loss = 0.7090283036231995
Iteration [37818]: Loss = 0.7092071771621704
Iteration [37819]: Loss = 0.7093308568000793
Iteration [37820]: Loss = 0.7094046473503113
Iteration [37821]: Loss = 0.709433376789093
Iteration [37822]: Loss = 4.897165775299072
Iteration [37823]: Loss = 4.896237373352051
Iteration [37824]: Loss = 0.7099581360816956
Iteration [37825]: Loss = 0.7102403044700623
Iteration [37826]: Loss = 4.891878604888916
Iteration [37827]: Loss = 4.889909744262695
Iteration [37828]: Loss = 4.8871660232543945
Iteration [37829]: Loss = 0.7120566964149475
Iteration [37830]: Loss = 0.7126274704933167
Iteration [37831]: Loss = 0.7131040692329407
Iteration [37832]: Loss = 0.7134956121444702
Iteration [37833]: Loss = 0.7138105630874634
Iteration [37834]: Loss = 0.7140564918518066
Iteration [37835]: Loss = 0.7142400741577148
Iteration [37836]: Loss = 0.7143675684928894
Iteration [37837]: Loss = 0.7144443988800049
Iteration [37838]: Loss = 0.714475691318512
Iteration [37839]: Loss = 4.87152099609375
Iteration [37840]: Loss = 0.7146487832069397
Iteration [37841]: Loss = 0.7147753238677979
Iteration [37842]: Loss = 0.7148513197898865
Iteration [37843]: Loss = 0.7148818969726562
Iteration [37844]: Loss = 4.869472503662109
Iteration [37845]: Loss = 0.7150533199310303
Iteration [37846]: Loss = 0.7151793241500854
Iteration [37847]: Loss = 0.7152549028396606
Iteration [37848]: Loss = 0.7152848839759827
Iteration [37849]: Loss = 0.7152737975120544
Iteration [37850]: Loss = 0.715225875377655
Iteration [37851]: Loss = 0.7151446342468262
Iteration [37852]: Loss = 0.7150334715843201
Iteration [37853]: Loss = 0.7148953080177307
Iteration [37854]: Loss = 0.7147329449653625
Iteration [37855]: Loss = 0.714548647403717
Iteration [37856]: Loss = 0.7143447995185852
Iteration [37857]: Loss = 0.7141231298446655
Iteration [37858]: Loss = 0.7138856053352356
Iteration [37859]: Loss = 0.7136338353157043
Iteration [37860]: Loss = 0.7133690714836121
Iteration [37861]: Loss = 0.7130928635597229
Iteration [37862]: Loss = 4.879926681518555
Iteration [37863]: Loss = 0.7127410173416138
Iteration [37864]: Loss = 0.7126444578170776
Iteration [37865]: Loss = 0.712519645690918
Iteration [37866]: Loss = 0.7123693227767944
Iteration [37867]: Loss = 0.7121960520744324
Iteration [37868]: Loss = 0.7120020389556885
Iteration [37869]: Loss = 0.7117895483970642
Iteration [37870]: Loss = 0.7115603089332581
Iteration [37871]: Loss = 0.7113159894943237
Iteration [37872]: Loss = 0.7110581994056702
Iteration [37873]: Loss = 0.7107881903648376
Iteration [37874]: Loss = 0.7105073928833008
Iteration [37875]: Loss = 4.8931050300598145
Iteration [37876]: Loss = 0.7101484537124634
Iteration [37877]: Loss = 0.7100493311882019
Iteration [37878]: Loss = 4.894608020782471
Iteration [37879]: Loss = 0.7100008130073547
Iteration [37880]: Loss = 0.7100339531898499
Iteration [37881]: Loss = 0.7100259065628052
Iteration [37882]: Loss = 0.7099809646606445
Iteration [37883]: Loss = 0.7099025249481201
Iteration [37884]: Loss = 0.7097941637039185
Iteration [37885]: Loss = 0.7096587419509888
Iteration [37886]: Loss = 0.709498941898346
Iteration [37887]: Loss = 4.89769983291626
Iteration [37888]: Loss = 0.7093473672866821
Iteration [37889]: Loss = 0.7093365788459778
Iteration [37890]: Loss = 4.897844314575195
Iteration [37891]: Loss = 0.7094394564628601
Iteration [37892]: Loss = 0.7095370888710022
Iteration [37893]: Loss = 0.7095872163772583
Iteration [37894]: Loss = 0.7095944285392761
Iteration [37895]: Loss = 0.7095632553100586
Iteration [37896]: Loss = 0.709497332572937
Iteration [37897]: Loss = 0.7094001770019531
Iteration [37898]: Loss = 0.7092747688293457
Iteration [37899]: Loss = 0.709123969078064
Iteration [37900]: Loss = 0.7089505195617676
Iteration [37901]: Loss = 0.7087565064430237
Iteration [37902]: Loss = 0.7085438966751099
Iteration [37903]: Loss = 4.902833461761475
Iteration [37904]: Loss = 0.7083025574684143
Iteration [37905]: Loss = 0.708253800868988
Iteration [37906]: Loss = 0.708172082901001
Iteration [37907]: Loss = 0.7080608010292053
Iteration [37908]: Loss = 0.7079225778579712
Iteration [37909]: Loss = 0.7077606320381165
Iteration [37910]: Loss = 0.7075768709182739
Iteration [37911]: Loss = 0.7073737382888794
Iteration [37912]: Loss = 0.7071529626846313
Iteration [37913]: Loss = 0.7069166302680969
Iteration [37914]: Loss = 0.7066658735275269
Iteration [37915]: Loss = 0.706402599811554
Iteration [37916]: Loss = 4.91407585144043
Iteration [37917]: Loss = 0.7060750722885132
Iteration [37918]: Loss = 0.7059900760650635
Iteration [37919]: Loss = 0.7058756947517395
Iteration [37920]: Loss = 0.7057350873947144
Iteration [37921]: Loss = 0.7055708765983582
Iteration [37922]: Loss = 0.705385148525238
Iteration [37923]: Loss = 0.7051804065704346
Iteration [37924]: Loss = 0.7049583196640015
Iteration [37925]: Loss = 0.7047207951545715
Iteration [37926]: Loss = 0.7044691443443298
Iteration [37927]: Loss = 0.7042050361633301
Iteration [37928]: Loss = 0.7039296627044678
Iteration [37929]: Loss = 0.7036439776420593
Iteration [37930]: Loss = 0.7033493518829346
Iteration [37931]: Loss = 0.7030463814735413
Iteration [37932]: Loss = 0.7027361989021301
Iteration [37933]: Loss = 0.7024192214012146
Iteration [37934]: Loss = 0.7020964622497559
Iteration [37935]: Loss = 0.7017682790756226
Iteration [37936]: Loss = 0.7014352679252625
Iteration [37937]: Loss = 0.7010980248451233
Iteration [37938]: Loss = 0.7007569670677185
Iteration [37939]: Loss = 0.700412392616272
Iteration [37940]: Loss = 0.7000647783279419
Iteration [37941]: Loss = 0.6997144818305969
Iteration [37942]: Loss = 4.949221134185791
Iteration [37943]: Loss = 0.6992406249046326
Iteration [37944]: Loss = 0.6990941762924194
Iteration [37945]: Loss = 0.6989250183105469
Iteration [37946]: Loss = 0.6987352967262268
Iteration [37947]: Loss = 0.6985270977020264
Iteration [37948]: Loss = 0.6983023285865784
Iteration [37949]: Loss = 0.698062539100647
Iteration [37950]: Loss = 0.6978093385696411
Iteration [37951]: Loss = 0.6975440382957458
Iteration [37952]: Loss = 0.6972677707672119
Iteration [37953]: Loss = 0.6969818472862244
Iteration [37954]: Loss = 0.6966871023178101
Iteration [37955]: Loss = 0.6963844299316406
Iteration [37956]: Loss = 0.6960747241973877
Iteration [37957]: Loss = 4.968164920806885
Iteration [37958]: Loss = 0.6956712603569031
Iteration [37959]: Loss = 0.6955553889274597
Iteration [37960]: Loss = 0.6954138875007629
Iteration [37961]: Loss = 0.6952492594718933
Iteration [37962]: Loss = 0.6950637698173523
Iteration [37963]: Loss = 0.6948596835136414
Iteration [37964]: Loss = 0.6946385502815247
Iteration [37965]: Loss = 0.6944021582603455
Iteration [37966]: Loss = 0.6941522359848022
Iteration [37967]: Loss = 0.6938901543617249
Iteration [37968]: Loss = 0.6936169862747192
Iteration [37969]: Loss = 0.6933337450027466
Iteration [37970]: Loss = 0.6930416822433472
Iteration [37971]: Loss = 0.6927416324615479
Iteration [37972]: Loss = 4.985785484313965
Iteration [37973]: Loss = 0.6923558712005615
Iteration [37974]: Loss = 0.6922480463981628
Iteration [37975]: Loss = 0.6921138167381287
Iteration [37976]: Loss = 4.988332748413086
Iteration [37977]: Loss = 0.6920114159584045
Iteration [37978]: Loss = 0.6920243501663208
Iteration [37979]: Loss = 0.6919988989830017
Iteration [37980]: Loss = 0.6919389367103577
Iteration [37981]: Loss = 0.6918476819992065
Iteration [37982]: Loss = 0.6917286515235901
Iteration [37983]: Loss = 0.6915842294692993
Iteration [37984]: Loss = 0.6914171576499939
Iteration [37985]: Loss = 4.992205619812012
Iteration [37986]: Loss = 0.6912589073181152
Iteration [37987]: Loss = 4.9921064376831055
Iteration [37988]: Loss = 0.6914358139038086
Iteration [37989]: Loss = 0.6915678381919861
Iteration [37990]: Loss = 0.6916497349739075
Iteration [37991]: Loss = 0.6916862726211548
Iteration [37992]: Loss = 0.6916822195053101
Iteration [37993]: Loss = 0.6916413903236389
Iteration [37994]: Loss = 0.691567599773407
Iteration [37995]: Loss = 0.6914640665054321
Iteration [37996]: Loss = 9.291966438293457
Iteration [37997]: Loss = 4.989984035491943
Iteration [37998]: Loss = 0.6921222805976868
Iteration [37999]: Loss = 0.6925145387649536
Iteration [38000]: Loss = 4.980223178863525
Iteration [38001]: Loss = 0.6933102607727051
Iteration [38002]: Loss = 0.6937053799629211
Iteration [38003]: Loss = 0.6940240859985352
Iteration [38004]: Loss = 0.6942746043205261
Iteration [38005]: Loss = 0.6944630742073059
Iteration [38006]: Loss = 0.6945959329605103
Iteration [38007]: Loss = 4.973874568939209
Iteration [38008]: Loss = 0.6949482560157776
Iteration [38009]: Loss = 4.971358776092529
Iteration [38010]: Loss = 0.6955344676971436
Iteration [38011]: Loss = 0.6958398222923279
Iteration [38012]: Loss = 4.9664788246154785
Iteration [38013]: Loss = 4.964322566986084
Iteration [38014]: Loss = 0.6970491409301758
Iteration [38015]: Loss = 0.6975185871124268
Iteration [38016]: Loss = 0.6979045867919922
Iteration [38017]: Loss = 0.6982149481773376
Iteration [38018]: Loss = 0.6984575986862183
Iteration [38019]: Loss = 0.6986388564109802
Iteration [38020]: Loss = 0.6987649202346802
Iteration [38021]: Loss = 0.6988411545753479
Iteration [38022]: Loss = 0.6988726854324341
Iteration [38023]: Loss = 0.6988638639450073
Iteration [38024]: Loss = 4.952065944671631
Iteration [38025]: Loss = 0.6989728212356567
Iteration [38026]: Loss = 4.9507246017456055
Iteration [38027]: Loss = 0.6993606686592102
Iteration [38028]: Loss = 0.6995812058448792
Iteration [38029]: Loss = 0.6997425556182861
Iteration [38030]: Loss = 0.6998505592346191
Iteration [38031]: Loss = 0.699910581111908
Iteration [38032]: Loss = 0.6999272704124451
Iteration [38033]: Loss = 0.6999049186706543
Iteration [38034]: Loss = 0.6998474597930908
Iteration [38035]: Loss = 0.6997584104537964
Iteration [38036]: Loss = 0.6996408104896545
Iteration [38037]: Loss = 0.6994976997375488
Iteration [38038]: Loss = 0.6993314027786255
Iteration [38039]: Loss = 0.6991444230079651
Iteration [38040]: Loss = 0.6989386677742004
Iteration [38041]: Loss = 4.952602863311768
Iteration [38042]: Loss = 0.6987116932868958
Iteration [38043]: Loss = 0.6986704468727112
Iteration [38044]: Loss = 0.6985959410667419
Iteration [38045]: Loss = 0.698491632938385
Iteration [38046]: Loss = 0.6983604431152344
Iteration [38047]: Loss = 0.6982048749923706
Iteration [38048]: Loss = 0.6980275511741638
Iteration [38049]: Loss = 0.6978306770324707
Iteration [38050]: Loss = 0.6976160407066345
Iteration [38051]: Loss = 0.6973855495452881
Iteration [38052]: Loss = 0.6971409320831299
Iteration [38053]: Loss = 4.9622344970703125
Iteration [38054]: Loss = 0.6968478560447693
Iteration [38055]: Loss = 0.6967787742614746
Iteration [38056]: Loss = 0.6966792941093445
Iteration [38057]: Loss = 0.696552574634552
Iteration [38058]: Loss = 0.6964011788368225
Iteration [38059]: Loss = 0.6962276697158813
Iteration [38060]: Loss = 0.6960341930389404
Iteration [38061]: Loss = 0.6958228349685669
Iteration [38062]: Loss = 0.6955952644348145
Iteration [38063]: Loss = 0.6953532099723816
Iteration [38064]: Loss = 0.6950981616973877
Iteration [38065]: Loss = 0.6948312520980835
Iteration [38066]: Loss = 0.6945539116859436
Iteration [38067]: Loss = 0.6942669153213501
Iteration [38068]: Loss = 0.6939715147018433
Iteration [38069]: Loss = 0.6936683654785156
Iteration [38070]: Loss = 0.693358302116394
Iteration [38071]: Loss = 0.6930422186851501
Iteration [38072]: Loss = 0.6927204728126526
Iteration [38073]: Loss = 0.6923937201499939
Iteration [38074]: Loss = 9.283466339111328
Iteration [38075]: Loss = 0.6921955943107605
Iteration [38076]: Loss = 0.6922785639762878
Iteration [38077]: Loss = 0.6923166513442993
Iteration [38078]: Loss = 0.6923140287399292
Iteration [38079]: Loss = 0.692274808883667
Iteration [38080]: Loss = 0.6922028064727783
Iteration [38081]: Loss = 0.6921011805534363
Iteration [38082]: Loss = 0.6919729113578796
Iteration [38083]: Loss = 0.6918205618858337
Iteration [38084]: Loss = 0.6916465759277344
Iteration [38085]: Loss = 0.6914530992507935
Iteration [38086]: Loss = 0.6912421584129333
Iteration [38087]: Loss = 0.6910155415534973
Iteration [38088]: Loss = 0.6907745599746704
Iteration [38089]: Loss = 0.6905210018157959
Iteration [38090]: Loss = 4.997407913208008
Iteration [38091]: Loss = 4.997631072998047
Iteration [38092]: Loss = 4.9967827796936035
Iteration [38093]: Loss = 0.6907109022140503
Iteration [38094]: Loss = 0.6909788846969604
Iteration [38095]: Loss = 0.6911836266517639
Iteration [38096]: Loss = 0.691331148147583
Iteration [38097]: Loss = 0.6914273500442505
Iteration [38098]: Loss = 0.6914771795272827
Iteration [38099]: Loss = 0.6914852261543274
Iteration [38100]: Loss = 0.6914558410644531
Iteration [38101]: Loss = 0.6913925409317017
Iteration [38102]: Loss = 0.6912986636161804
Iteration [38103]: Loss = 0.691177248954773
Iteration [38104]: Loss = 0.691031277179718
Iteration [38105]: Loss = 0.6908630132675171
Iteration [38106]: Loss = 0.6906746625900269
Iteration [38107]: Loss = 0.6904683709144592
Iteration [38108]: Loss = 4.997462272644043
Iteration [38109]: Loss = 0.690242350101471
Iteration [38110]: Loss = 0.6902025938034058
Iteration [38111]: Loss = 0.6901299953460693
Iteration [38112]: Loss = 0.6900278329849243
Iteration [38113]: Loss = 4.999316692352295
Iteration [38114]: Loss = 0.6899799108505249
Iteration [38115]: Loss = 0.6900160312652588
Iteration [38116]: Loss = 0.6900118589401245
Iteration [38117]: Loss = 0.6899712681770325
Iteration [38118]: Loss = 0.6898979544639587
Iteration [38119]: Loss = 0.6897952556610107
Iteration [38120]: Loss = 0.6896659731864929
Iteration [38121]: Loss = 0.6895126104354858
Iteration [38122]: Loss = 0.689337968826294
Iteration [38123]: Loss = 5.003362655639648
Iteration [38124]: Loss = 5.003242015838623
Iteration [38125]: Loss = 0.6893832683563232
Iteration [38126]: Loss = 0.6895418763160706
Iteration [38127]: Loss = 0.689647912979126
Iteration [38128]: Loss = 0.6897066831588745
Iteration [38129]: Loss = 0.6897227764129639
Iteration [38130]: Loss = 0.6897006630897522
Iteration [38131]: Loss = 0.6896438598632812
Iteration [38132]: Loss = 0.6895560026168823
Iteration [38133]: Loss = 5.001774787902832
Iteration [38134]: Loss = 0.6895328164100647
Iteration [38135]: Loss = 0.6895794868469238
Iteration [38136]: Loss = 0.6895847916603088
Iteration [38137]: Loss = 0.6895527243614197
Iteration [38138]: Loss = 5.001523494720459
Iteration [38139]: Loss = 0.6896249055862427
Iteration [38140]: Loss = 0.6897121667861938
Iteration [38141]: Loss = 0.689754068851471
Iteration [38142]: Loss = 0.6897550225257874
Iteration [38143]: Loss = 0.6897190809249878
Iteration [38144]: Loss = 0.6896499395370483
Iteration [38145]: Loss = 0.6895508766174316
Iteration [38146]: Loss = 0.6894248723983765
Iteration [38147]: Loss = 0.6892745494842529
Iteration [38148]: Loss = 5.003584861755371
Iteration [38149]: Loss = 0.6891449689865112
Iteration [38150]: Loss = 5.003349304199219
Iteration [38151]: Loss = 0.6893444657325745
Iteration [38152]: Loss = 5.001528263092041
Iteration [38153]: Loss = 0.6898101568222046
Iteration [38154]: Loss = 0.6900650262832642
Iteration [38155]: Loss = 0.6902579665184021
Iteration [38156]: Loss = 0.6903948783874512
Iteration [38157]: Loss = 0.690481424331665
Iteration [38158]: Loss = 0.690522313117981
Iteration [38159]: Loss = 0.6905224323272705
Iteration [38160]: Loss = 0.6904855966567993
Iteration [38161]: Loss = 0.6904156804084778
Iteration [38162]: Loss = 0.690315842628479
Iteration [38163]: Loss = 0.690189003944397
Iteration [38164]: Loss = 0.6900379657745361
Iteration [38165]: Loss = 0.6898651123046875
Iteration [38166]: Loss = 0.6896725296974182
Iteration [38167]: Loss = 0.6894623637199402
Iteration [38168]: Loss = 0.6892363429069519
Iteration [38169]: Loss = 0.6889961361885071
Iteration [38170]: Loss = 0.6887428164482117
Iteration [38171]: Loss = 0.6884779930114746
Iteration [38172]: Loss = 0.6882026791572571
Iteration [38173]: Loss = 0.6879181861877441
Iteration [38174]: Loss = 0.6876252293586731
Iteration [38175]: Loss = 5.013140678405762
Iteration [38176]: Loss = 0.6872526407241821
Iteration [38177]: Loss = 0.6871510744094849
Iteration [38178]: Loss = 0.6870229244232178
Iteration [38179]: Loss = 0.6868706941604614
Iteration [38180]: Loss = 0.6866970062255859
Iteration [38181]: Loss = 0.6865065693855286
Iteration [38182]: Loss = 0.6863028407096863
Iteration [38183]: Loss = 0.6860837936401367
Iteration [38184]: Loss = 0.6858512163162231
Iteration [38185]: Loss = 0.6856063008308411
Iteration [38186]: Loss = 0.6853503584861755
Iteration [38187]: Loss = 0.6850842833518982
Iteration [38188]: Loss = 0.6848093867301941
Iteration [38189]: Loss = 0.6845265626907349
Iteration [38190]: Loss = 0.6842362880706787
Iteration [38191]: Loss = 0.6839396953582764
Iteration [38192]: Loss = 0.6836371421813965
Iteration [38193]: Loss = 0.6833293437957764
Iteration [38194]: Loss = 5.036459445953369
Iteration [38195]: Loss = 0.6829288601875305
Iteration [38196]: Loss = 0.6828141212463379
Iteration [38197]: Loss = 0.6826754808425903
Iteration [38198]: Loss = 0.6825153231620789
Iteration [38199]: Loss = 0.6823357343673706
Iteration [38200]: Loss = 5.041244029998779
Iteration [38201]: Loss = 0.6821541786193848
Iteration [38202]: Loss = 0.6821328401565552
Iteration [38203]: Loss = 0.6820782423019409
Iteration [38204]: Loss = 0.6819937825202942
Iteration [38205]: Loss = 0.681882381439209
Iteration [38206]: Loss = 0.681746780872345
Iteration [38207]: Loss = 5.044240951538086
Iteration [38208]: Loss = 5.043962478637695
Iteration [38209]: Loss = 0.6818786859512329
Iteration [38210]: Loss = 5.041683673858643
Iteration [38211]: Loss = 0.6824110746383667
Iteration [38212]: Loss = 0.6826938390731812
Iteration [38213]: Loss = 0.6829133033752441
Iteration [38214]: Loss = 0.683075487613678
Iteration [38215]: Loss = 5.035539150238037
Iteration [38216]: Loss = 0.6834776401519775
Iteration [38217]: Loss = 0.6837047934532166
Iteration [38218]: Loss = 0.6838740110397339
Iteration [38219]: Loss = 0.6839910745620728
Iteration [38220]: Loss = 0.6840609312057495
Iteration [38221]: Loss = 0.6840884685516357
Iteration [38222]: Loss = 0.6840779185295105
Iteration [38223]: Loss = 0.6840329170227051
Iteration [38224]: Loss = 0.6839569807052612
Iteration [38225]: Loss = 0.6838531494140625
Iteration [38226]: Loss = 5.032614707946777
Iteration [38227]: Loss = 0.683800458908081
Iteration [38228]: Loss = 0.6838340163230896
Iteration [38229]: Loss = 0.6838286519050598
Iteration [38230]: Loss = 0.6837882995605469
Iteration [38231]: Loss = 0.6837165951728821
Iteration [38232]: Loss = 0.683616578578949
Iteration [38233]: Loss = 0.6834911108016968
Iteration [38234]: Loss = 5.034688949584961
Iteration [38235]: Loss = 0.6834017038345337
Iteration [38236]: Loss = 0.683419406414032
Iteration [38237]: Loss = 0.6834000945091248
Iteration [38238]: Loss = 0.6833471655845642
Iteration [38239]: Loss = 0.6832641363143921
Iteration [38240]: Loss = 0.6831538081169128
Iteration [38241]: Loss = 0.6830191016197205
Iteration [38242]: Loss = 13.746177673339844
Iteration [38243]: Loss = 0.6833576560020447
Iteration [38244]: Loss = 0.6837693452835083
Iteration [38245]: Loss = 0.6841055154800415
Iteration [38246]: Loss = 5.029090404510498
Iteration [38247]: Loss = 0.6848024129867554
Iteration [38248]: Loss = 0.6851538419723511
Iteration [38249]: Loss = 0.6854358315467834
Iteration [38250]: Loss = 0.685654878616333
Iteration [38251]: Loss = 0.6858176589012146
Iteration [38252]: Loss = 0.6859291195869446
Iteration [38253]: Loss = 0.6859949231147766
Iteration [38254]: Loss = 0.6860191822052002
Iteration [38255]: Loss = 0.6860063076019287
Iteration [38256]: Loss = 0.6859596371650696
Iteration [38257]: Loss = 0.6858829259872437
Iteration [38258]: Loss = 0.6857789158821106
Iteration [38259]: Loss = 0.6856504678726196
Iteration [38260]: Loss = 0.6854997873306274
Iteration [38261]: Loss = 0.6853294372558594
Iteration [38262]: Loss = 0.6851410865783691
Iteration [38263]: Loss = 5.026038646697998
Iteration [38264]: Loss = 0.6849414110183716
Iteration [38265]: Loss = 0.6849112510681152
Iteration [38266]: Loss = 9.368179321289062
Iteration [38267]: Loss = 0.6852015852928162
Iteration [38268]: Loss = 0.685484766960144
Iteration [38269]: Loss = 9.358054161071777
Iteration [38270]: Loss = 5.018635272979736
Iteration [38271]: Loss = 0.6870303153991699
Iteration [38272]: Loss = 0.6876489520072937
Iteration [38273]: Loss = 0.6881720423698425
Iteration [38274]: Loss = 0.6886087656021118
Iteration [38275]: Loss = 0.6889678835868835
Iteration [38276]: Loss = 0.6892568469047546
Iteration [38277]: Loss = 0.6894824504852295
Iteration [38278]: Loss = 5.000644683837891
Iteration [38279]: Loss = 4.998842716217041
Iteration [38280]: Loss = 0.6904745101928711
Iteration [38281]: Loss = 0.6895467042922974
Iteration [38282]: Loss = 4.999715328216553
Iteration [38283]: Loss = 0.6904967427253723
Iteration [38284]: Loss = 0.6910237073898315
Iteration [38285]: Loss = 0.6913982033729553
Iteration [38286]: Loss = 0.6916550397872925
Iteration [38287]: Loss = 0.6918517351150513
Iteration [38288]: Loss = 0.6919941306114197
Iteration [38289]: Loss = 4.987630367279053
Iteration [38290]: Loss = 0.6923563480377197
Iteration [38291]: Loss = 0.6925635933876038
Iteration [38292]: Loss = 0.692715585231781
Iteration [38293]: Loss = 0.6928176283836365
Iteration [38294]: Loss = 0.6928747892379761
Iteration [38295]: Loss = 0.6928914785385132
Iteration [38296]: Loss = 0.6928716897964478
Iteration [38297]: Loss = 0.6928190588951111
Iteration [38298]: Loss = 4.984175682067871
Iteration [38299]: Loss = 0.6928479075431824
Iteration [38300]: Loss = 0.6929128766059875
Iteration [38301]: Loss = 0.6929368376731873
Iteration [38302]: Loss = 0.6929235458374023
Iteration [38303]: Loss = 0.6928766965866089
Iteration [38304]: Loss = 0.6927997469902039
Iteration [38305]: Loss = 0.6926956176757812
Iteration [38306]: Loss = 0.6925669312477112
Iteration [38307]: Loss = 0.692416250705719
Iteration [38308]: Loss = 0.6922460198402405
Iteration [38309]: Loss = 0.692057728767395
Iteration [38310]: Loss = 4.988879680633545
Iteration [38311]: Loss = 0.6918550729751587
Iteration [38312]: Loss = 0.6918218731880188
Iteration [38313]: Loss = 0.6917572021484375
Iteration [38314]: Loss = 0.6916641592979431
Iteration [38315]: Loss = 0.6915455460548401
Iteration [38316]: Loss = 4.991276264190674
Iteration [38317]: Loss = 4.990964889526367
Iteration [38318]: Loss = 0.6916995048522949
Iteration [38319]: Loss = 0.6918784976005554
Iteration [38320]: Loss = 4.988071441650391
Iteration [38321]: Loss = 0.6923035383224487
Iteration [38322]: Loss = 4.985235691070557
Iteration [38323]: Loss = 0.692932665348053
Iteration [38324]: Loss = 0.6932538747787476
Iteration [38325]: Loss = 0.6935083270072937
Iteration [38326]: Loss = 0.6937026381492615
Iteration [38327]: Loss = 4.978302955627441
Iteration [38328]: Loss = 0.6941533088684082
Iteration [38329]: Loss = 0.6943982243537903
Iteration [38330]: Loss = 0.6945838332176208
Iteration [38331]: Loss = 0.6947162747383118
Iteration [38332]: Loss = 0.6948003172874451
Iteration [38333]: Loss = 0.6948411464691162
Iteration [38334]: Loss = 0.6948429346084595
Iteration [38335]: Loss = 0.69480961561203
Iteration [38336]: Loss = 0.6947445273399353
Iteration [38337]: Loss = 0.6946509480476379
Iteration [38338]: Loss = 0.6945316791534424
Iteration [38339]: Loss = 0.694389283657074
Iteration [38340]: Loss = 0.6942261457443237
Iteration [38341]: Loss = 0.6940441727638245
Iteration [38342]: Loss = 0.6938453912734985
Iteration [38343]: Loss = 0.6936314105987549
Iteration [38344]: Loss = 0.6934038996696472
Iteration [38345]: Loss = 0.6931638717651367
Iteration [38346]: Loss = 0.6929128766059875
Iteration [38347]: Loss = 0.6926521062850952
Iteration [38348]: Loss = 0.692382276058197
Iteration [38349]: Loss = 0.6921042799949646
Iteration [38350]: Loss = 0.6918192505836487
Iteration [38351]: Loss = 0.6915277242660522
Iteration [38352]: Loss = 0.6912303566932678
Iteration [38353]: Loss = 0.6909277439117432
Iteration [38354]: Loss = 0.6906204223632812
Iteration [38355]: Loss = 0.6903089284896851
Iteration [38356]: Loss = 0.6899936199188232
Iteration [38357]: Loss = 5.00051736831665
Iteration [38358]: Loss = 0.6895751357078552
Iteration [38359]: Loss = 0.6894506216049194
Iteration [38360]: Loss = 0.6893035173416138
Iteration [38361]: Loss = 0.6891364455223083
Iteration [38362]: Loss = 5.004397392272949
Iteration [38363]: Loss = 0.6889711618423462
Iteration [38364]: Loss = 0.6889544129371643
Iteration [38365]: Loss = 0.6889045238494873
Iteration [38366]: Loss = 0.6888248324394226
Iteration [38367]: Loss = 0.688718318939209
Iteration [38368]: Loss = 0.6885876059532166
Iteration [38369]: Loss = 0.6884350180625916
Iteration [38370]: Loss = 5.008092880249023
Iteration [38371]: Loss = 0.6882950663566589
Iteration [38372]: Loss = 0.6882892847061157
Iteration [38373]: Loss = 5.008167266845703
Iteration [38374]: Loss = 0.6883997321128845
Iteration [38375]: Loss = 0.6885005831718445
Iteration [38376]: Loss = 0.6885566711425781
Iteration [38377]: Loss = 0.6885722875595093
Iteration [38378]: Loss = 0.6885517239570618
Iteration [38379]: Loss = 0.6884983777999878
Iteration [38380]: Loss = 0.6884154677391052
Iteration [38381]: Loss = 0.6883059740066528
Iteration [38382]: Loss = 0.6881726384162903
Iteration [38383]: Loss = 5.009410858154297
Iteration [38384]: Loss = 0.6880655884742737
Iteration [38385]: Loss = 0.6880738735198975
Iteration [38386]: Loss = 0.6880464553833008
Iteration [38387]: Loss = 0.6879870295524597
Iteration [38388]: Loss = 0.6878986358642578
Iteration [38389]: Loss = 0.6877843141555786
Iteration [38390]: Loss = 0.6876465678215027
Iteration [38391]: Loss = 0.6874877214431763
Iteration [38392]: Loss = 0.6873098611831665
Iteration [38393]: Loss = 0.687114953994751
Iteration [38394]: Loss = 5.0154032707214355
Iteration [38395]: Loss = 0.6869032382965088
Iteration [38396]: Loss = 0.6868671178817749
Iteration [38397]: Loss = 0.6867997646331787
Iteration [38398]: Loss = 0.6867043972015381
Iteration [38399]: Loss = 5.017135143280029
Iteration [38400]: Loss = 5.016708850860596
Iteration [38401]: Loss = 0.686920702457428
Iteration [38402]: Loss = 5.01425313949585
Iteration [38403]: Loss = 0.6874825358390808
Iteration [38404]: Loss = 5.010711193084717
Iteration [38405]: Loss = 0.688226044178009
Iteration [38406]: Loss = 0.6885970234870911
Iteration [38407]: Loss = 0.6888962984085083
Iteration [38408]: Loss = 0.6891310214996338
Iteration [38409]: Loss = 0.6893076300621033
Iteration [38410]: Loss = 5.0018205642700195
Iteration [38411]: Loss = 0.6897298693656921
Iteration [38412]: Loss = 0.6899635791778564
Iteration [38413]: Loss = 0.69013911485672
Iteration [38414]: Loss = 0.6902621984481812
Iteration [38415]: Loss = 0.6903383135795593
Iteration [38416]: Loss = 0.6903719305992126
Iteration [38417]: Loss = 0.6903669238090515
Iteration [38418]: Loss = 0.6903277039527893
Iteration [38419]: Loss = 0.6902573704719543
Iteration [38420]: Loss = 0.6901589632034302
Iteration [38421]: Loss = 4.998587608337402
Iteration [38422]: Loss = 4.998180389404297
Iteration [38423]: Loss = 0.6903662085533142
Iteration [38424]: Loss = 0.6905608773231506
Iteration [38425]: Loss = 0.6907011866569519
Iteration [38426]: Loss = 0.6907925605773926
Iteration [38427]: Loss = 0.690839946269989
Iteration [38428]: Loss = 4.994246006011963
Iteration [38429]: Loss = 0.6910409927368164
Iteration [38430]: Loss = 0.6911802887916565
Iteration [38431]: Loss = 4.9919867515563965
Iteration [38432]: Loss = 0.6915384531021118
Iteration [38433]: Loss = 0.6917445659637451
Iteration [38434]: Loss = 0.6918951869010925
Iteration [38435]: Loss = 0.6919957399368286
Iteration [38436]: Loss = 0.6920512914657593
Iteration [38437]: Loss = 0.6920663118362427
Iteration [38438]: Loss = 0.6920443773269653
Iteration [38439]: Loss = 0.6919898986816406
Iteration [38440]: Loss = 0.691905677318573
Iteration [38441]: Loss = 0.6917945146560669
Iteration [38442]: Loss = 0.6916594505310059
Iteration [38443]: Loss = 0.6915028691291809
Iteration [38444]: Loss = 0.6913264989852905
Iteration [38445]: Loss = 0.691132664680481
Iteration [38446]: Loss = 4.993841648101807
Iteration [38447]: Loss = 4.993846893310547
Iteration [38448]: Loss = 0.691108226776123
Iteration [38449]: Loss = 0.691240668296814
Iteration [38450]: Loss = 0.6913249492645264
Iteration [38451]: Loss = 0.6913655996322632
Iteration [38452]: Loss = 0.6913672685623169
Iteration [38453]: Loss = 0.6913335919380188
Iteration [38454]: Loss = 0.691268265247345
Iteration [38455]: Loss = 0.6911742091178894
Iteration [38456]: Loss = 0.6910545229911804
Iteration [38457]: Loss = 4.993904113769531
Iteration [38458]: Loss = 0.6909704208374023
Iteration [38459]: Loss = 4.993494033813477
Iteration [38460]: Loss = 0.6911913156509399
Iteration [38461]: Loss = 4.991621017456055
Iteration [38462]: Loss = 4.989916801452637
Iteration [38463]: Loss = 4.987392425537109
Iteration [38464]: Loss = 0.6927444934844971
Iteration [38465]: Loss = 4.981391906738281
Iteration [38466]: Loss = 4.977941513061523
Iteration [38467]: Loss = 0.6946810483932495
Iteration [38468]: Loss = 0.6953399181365967
Iteration [38469]: Loss = 0.6958984732627869
Iteration [38470]: Loss = 0.6963664889335632
Iteration [38471]: Loss = 0.6967528462409973
Iteration [38472]: Loss = 0.6970656514167786
Iteration [38473]: Loss = 0.6973119378089905
Iteration [38474]: Loss = 0.6974983811378479
Iteration [38475]: Loss = 0.6976308822631836
Iteration [38476]: Loss = 4.957859992980957
Iteration [38477]: Loss = 0.6979761719703674
Iteration [38478]: Loss = 0.6981761455535889
Iteration [38479]: Loss = 4.954677104949951
Iteration [38480]: Loss = 0.6986364126205444
Iteration [38481]: Loss = 0.6988853216171265
Iteration [38482]: Loss = 0.6990740299224854
Iteration [38483]: Loss = 0.6992084980010986
Iteration [38484]: Loss = 0.6992940902709961
Iteration [38485]: Loss = 0.699335515499115
Iteration [38486]: Loss = 0.6993373036384583
Iteration [38487]: Loss = 4.949526309967041
Iteration [38488]: Loss = 0.6994587779045105
Iteration [38489]: Loss = 0.6995633244514465
Iteration [38490]: Loss = 0.6996217370033264
Iteration [38491]: Loss = 0.6996387839317322
Iteration [38492]: Loss = 0.6996186375617981
Iteration [38493]: Loss = 0.6995648741722107
Iteration [38494]: Loss = 0.6994807720184326
Iteration [38495]: Loss = 4.9491801261901855
Iteration [38496]: Loss = 0.6994555592536926
Iteration [38497]: Loss = 0.6994976997375488
Iteration [38498]: Loss = 0.6994998455047607
Iteration [38499]: Loss = 9.197879791259766
Iteration [38500]: Loss = 4.946714878082275
Iteration [38501]: Loss = 0.7003613710403442
Iteration [38502]: Loss = 0.7007952332496643
Iteration [38503]: Loss = 0.7011507749557495
Iteration [38504]: Loss = 0.7014356255531311
Iteration [38505]: Loss = 4.93723726272583
Iteration [38506]: Loss = 0.7020396590232849
Iteration [38507]: Loss = 0.7023491859436035
Iteration [38508]: Loss = 4.932369709014893
Iteration [38509]: Loss = 0.7029954195022583
Iteration [38510]: Loss = 0.7033227682113647
Iteration [38511]: Loss = 0.7035821676254272
Iteration [38512]: Loss = 0.7037801742553711
Iteration [38513]: Loss = 4.925468444824219
Iteration [38514]: Loss = 0.7042351961135864
Iteration [38515]: Loss = 0.7044811248779297
Iteration [38516]: Loss = 0.704666793346405
Iteration [38517]: Loss = 0.7047983407974243
Iteration [38518]: Loss = 0.7048811912536621
Iteration [38519]: Loss = 0.7049201726913452
Iteration [38520]: Loss = 4.920310974121094
Iteration [38521]: Loss = 0.7051030397415161
Iteration [38522]: Loss = 0.7052327394485474
Iteration [38523]: Loss = 0.7053139805793762
Iteration [38524]: Loss = 4.918081760406494
Iteration [38525]: Loss = 0.7055688500404358
Iteration [38526]: Loss = 4.916130065917969
Iteration [38527]: Loss = 0.7060573101043701
Iteration [38528]: Loss = 0.706317126750946
Iteration [38529]: Loss = 0.7065153121948242
Iteration [38530]: Loss = 0.706658124923706
Iteration [38531]: Loss = 0.7067508101463318
Iteration [38532]: Loss = 0.7067984342575073
Iteration [38533]: Loss = 0.7068055868148804
Iteration [38534]: Loss = 0.7067762017250061
Iteration [38535]: Loss = 0.7067137360572815
Iteration [38536]: Loss = 0.7066216468811035
Iteration [38537]: Loss = 0.7065029144287109
Iteration [38538]: Loss = 0.7063601016998291
Iteration [38539]: Loss = 0.7061957120895386
Iteration [38540]: Loss = 0.7060117721557617
Iteration [38541]: Loss = 0.7058104276657104
Iteration [38542]: Loss = 0.7055931091308594
Iteration [38543]: Loss = 0.7053617238998413
Iteration [38544]: Loss = 0.7051175236701965
Iteration [38545]: Loss = 0.7048619389533997
Iteration [38546]: Loss = 0.7045959830284119
Iteration [38547]: Loss = 4.923407554626465
Iteration [38548]: Loss = 0.7042586803436279
Iteration [38549]: Loss = 0.7041669487953186
Iteration [38550]: Loss = 0.7040485739707947
Iteration [38551]: Loss = 0.7039061784744263
Iteration [38552]: Loss = 0.703742265701294
Iteration [38553]: Loss = 0.7035589218139648
Iteration [38554]: Loss = 0.7033581733703613
Iteration [38555]: Loss = 0.7031415104866028
Iteration [38556]: Loss = 0.7029107213020325
Iteration [38557]: Loss = 0.7026673555374146
Iteration [38558]: Loss = 0.7024123668670654
Iteration [38559]: Loss = 0.7021470665931702
Iteration [38560]: Loss = 0.7018726468086243
Iteration [38561]: Loss = 0.701589822769165
Iteration [38562]: Loss = 0.7012995481491089
Iteration [38563]: Loss = 0.7010024785995483
Iteration [38564]: Loss = 0.7006993889808655
Iteration [38565]: Loss = 4.943839073181152
Iteration [38566]: Loss = 0.700299859046936
Iteration [38567]: Loss = 0.700182318687439
Iteration [38568]: Loss = 0.7000409364700317
Iteration [38569]: Loss = 0.6998777985572815
Iteration [38570]: Loss = 4.947473526000977
Iteration [38571]: Loss = 0.6997177004814148
Iteration [38572]: Loss = 0.699702262878418
Iteration [38573]: Loss = 0.6996525526046753
Iteration [38574]: Loss = 4.948118209838867
Iteration [38575]: Loss = 0.6996861696243286
Iteration [38576]: Loss = 0.6997531056404114
Iteration [38577]: Loss = 0.6997778415679932
Iteration [38578]: Loss = 0.6997646689414978
Iteration [38579]: Loss = 0.6997168660163879
Iteration [38580]: Loss = 0.6996384263038635
Iteration [38581]: Loss = 0.6995322108268738
Iteration [38582]: Loss = 0.6994008421897888
Iteration [38583]: Loss = 0.6992469429969788
Iteration [38584]: Loss = 0.6990727186203003
Iteration [38585]: Loss = 0.6988803744316101
Iteration [38586]: Loss = 0.6986715793609619
Iteration [38587]: Loss = 0.6984478831291199
Iteration [38588]: Loss = 0.6982108950614929
Iteration [38589]: Loss = 0.6979620456695557
Iteration [38590]: Loss = 0.6977022886276245
Iteration [38591]: Loss = 0.6974331140518188
Iteration [38592]: Loss = 0.6971550583839417
Iteration [38593]: Loss = 4.962307453155518
Iteration [38594]: Loss = 0.6967995166778564
Iteration [38595]: Loss = 0.696701169013977
Iteration [38596]: Loss = 0.696577250957489
Iteration [38597]: Loss = 4.9646220207214355
Iteration [38598]: Loss = 0.6964847445487976
Iteration [38599]: Loss = 0.6964986324310303
Iteration [38600]: Loss = 0.6964754462242126
Iteration [38601]: Loss = 0.6964192390441895
Iteration [38602]: Loss = 4.965134620666504
Iteration [38603]: Loss = 0.6964424252510071
Iteration [38604]: Loss = 4.964224338531494
Iteration [38605]: Loss = 0.6967490315437317
Iteration [38606]: Loss = 0.6969327926635742
Iteration [38607]: Loss = 0.6970627307891846
Iteration [38608]: Loss = 0.6971442699432373
Iteration [38609]: Loss = 0.6971821784973145
Iteration [38610]: Loss = 0.6971807479858398
Iteration [38611]: Loss = 0.6971440315246582
Iteration [38612]: Loss = 0.6970751881599426
Iteration [38613]: Loss = 0.6969777941703796
Iteration [38614]: Loss = 0.6968544125556946
Iteration [38615]: Loss = 0.6967079639434814
Iteration [38616]: Loss = 4.964041233062744
Iteration [38617]: Loss = 4.963847637176514
Iteration [38618]: Loss = 0.6967967748641968
Iteration [38619]: Loss = 0.6969592571258545
Iteration [38620]: Loss = 0.6970700621604919
Iteration [38621]: Loss = 0.6971341967582703
Iteration [38622]: Loss = 4.960795879364014
Iteration [38623]: Loss = 0.6973633170127869
Iteration [38624]: Loss = 0.6975141763687134
Iteration [38625]: Loss = 0.6976142525672913
Iteration [38626]: Loss = 4.958101272583008
Iteration [38627]: Loss = 0.6979048252105713
Iteration [38628]: Loss = 0.6980816125869751
Iteration [38629]: Loss = 0.6982052326202393
Iteration [38630]: Loss = 0.6982809901237488
Iteration [38631]: Loss = 0.6983135938644409
Iteration [38632]: Loss = 0.69830721616745
Iteration [38633]: Loss = 0.6982658505439758
Iteration [38634]: Loss = 0.6981928944587708
Iteration [38635]: Loss = 0.6980915665626526
Iteration [38636]: Loss = 0.6979645490646362
Iteration [38637]: Loss = 0.6972365379333496
Iteration [38638]: Loss = 0.6970662474632263
Iteration [38639]: Loss = 0.6968774199485779
Iteration [38640]: Loss = 0.6966716051101685
Iteration [38641]: Loss = 0.6964508891105652
Iteration [38642]: Loss = 0.6962165236473083
Iteration [38643]: Loss = 0.6959699988365173
Iteration [38644]: Loss = 0.6957123875617981
Iteration [38645]: Loss = 0.6954449415206909
Iteration [38646]: Loss = 0.6951686143875122
Iteration [38647]: Loss = 0.6948843598365784
Iteration [38648]: Loss = 4.974328517913818
Iteration [38649]: Loss = 0.69451904296875
Iteration [38650]: Loss = 0.6944169998168945
Iteration [38651]: Loss = 4.9759345054626465
Iteration [38652]: Loss = 0.694362998008728
Iteration [38653]: Loss = 0.6943936944007874
Iteration [38654]: Loss = 0.694385826587677
Iteration [38655]: Loss = 0.6943432092666626
Iteration [38656]: Loss = 0.6942693591117859
Iteration [38657]: Loss = 0.6941673159599304
Iteration [38658]: Loss = 0.6940400004386902
Iteration [38659]: Loss = 0.6938897967338562
Iteration [38660]: Loss = 0.6937190890312195
Iteration [38661]: Loss = 0.6935297846794128
Iteration [38662]: Loss = 0.6933239698410034
Iteration [38663]: Loss = 0.6931033134460449
Iteration [38664]: Loss = 0.6928690671920776
Iteration [38665]: Loss = 0.6926226019859314
Iteration [38666]: Loss = 4.986152648925781
Iteration [38667]: Loss = 4.986379623413086
Iteration [38668]: Loss = 4.985580921173096
Iteration [38669]: Loss = 0.69279545545578
Iteration [38670]: Loss = 0.6930506229400635
Iteration [38671]: Loss = 0.6932451725006104
Iteration [38672]: Loss = 0.6933847665786743
Iteration [38673]: Loss = 0.6934753060340881
Iteration [38674]: Loss = 0.6935212016105652
Iteration [38675]: Loss = 0.6935270428657532
Iteration [38676]: Loss = 0.6934968829154968
Iteration [38677]: Loss = 4.980471134185791
Iteration [38678]: Loss = 9.265976905822754
Iteration [38679]: Loss = 0.6940909028053284
Iteration [38680]: Loss = 4.974667072296143
Iteration [38681]: Loss = 0.6951082944869995
Iteration [38682]: Loss = 0.6955952644348145
Iteration [38683]: Loss = 0.6959986686706543
Iteration [38684]: Loss = 4.965167045593262
Iteration [38685]: Loss = 0.6968076229095459
Iteration [38686]: Loss = 0.6972054243087769
Iteration [38687]: Loss = 0.6975284218788147
Iteration [38688]: Loss = 0.6977839469909668
Iteration [38689]: Loss = 4.9564738273620605
Iteration [38690]: Loss = 0.6983394622802734
Iteration [38691]: Loss = 0.6986290216445923
Iteration [38692]: Loss = 4.951878070831299
Iteration [38693]: Loss = 4.9498443603515625
Iteration [38694]: Loss = 0.6997768878936768
Iteration [38695]: Loss = 0.700222909450531
Iteration [38696]: Loss = 0.700589120388031
Iteration [38697]: Loss = 0.7008834481239319
Iteration [38698]: Loss = 0.7011129260063171
Iteration [38699]: Loss = 0.7012839317321777
Iteration [38700]: Loss = 4.938562393188477
Iteration [38701]: Loss = 0.7016941905021667
Iteration [38702]: Loss = 0.7019215822219849
Iteration [38703]: Loss = 4.93497896194458
Iteration [38704]: Loss = 0.7024277448654175
Iteration [38705]: Loss = 0.7026958465576172
Iteration [38706]: Loss = 0.7029016017913818
Iteration [38707]: Loss = 4.929986953735352
Iteration [38708]: Loss = 0.7033708095550537
Iteration [38709]: Loss = 0.7036231160163879
Iteration [38710]: Loss = 0.7038144469261169
Iteration [38711]: Loss = 0.7039508819580078
Iteration [38712]: Loss = 0.7040380835533142
Iteration [38713]: Loss = 4.9246506690979
Iteration [38714]: Loss = 0.7043042182922363
Iteration [38715]: Loss = 0.7044698596000671
Iteration [38716]: Loss = 0.7045829892158508
Iteration [38717]: Loss = 0.7046492099761963
Iteration [38718]: Loss = 0.7046726942062378
Iteration [38719]: Loss = 0.7046579718589783
Iteration [38720]: Loss = 0.7046089172363281
Iteration [38721]: Loss = 0.7045287489891052
Iteration [38722]: Loss = 0.7044205665588379
Iteration [38723]: Loss = 0.7042873501777649
Iteration [38724]: Loss = 0.7041313648223877
Iteration [38725]: Loss = 0.7039550542831421
Iteration [38726]: Loss = 0.7037603855133057
Iteration [38727]: Loss = 0.7035492062568665
Iteration [38728]: Loss = 4.928577423095703
Iteration [38729]: Loss = 0.7033060193061829
Iteration [38730]: Loss = 0.7032548189163208
Iteration [38731]: Loss = 0.7031729221343994
Iteration [38732]: Loss = 4.929925441741943
Iteration [38733]: Loss = 0.7031505703926086
Iteration [38734]: Loss = 0.7031934261322021
Iteration [38735]: Loss = 4.929234981536865
Iteration [38736]: Loss = 0.703384518623352
Iteration [38737]: Loss = 0.7035182118415833
Iteration [38738]: Loss = 0.7036027908325195
Iteration [38739]: Loss = 0.7036430239677429
Iteration [38740]: Loss = 0.7036433815956116
Iteration [38741]: Loss = 0.7036077380180359
Iteration [38742]: Loss = 0.7035396695137024
Iteration [38743]: Loss = 0.7034424543380737
Iteration [38744]: Loss = 0.7033190131187439
Iteration [38745]: Loss = 0.7031718492507935
Iteration [38746]: Loss = 0.7030035257339478
Iteration [38747]: Loss = 0.7028160095214844
Iteration [38748]: Loss = 0.7026111483573914
Iteration [38749]: Loss = 0.7023909687995911
Iteration [38750]: Loss = 4.934635162353516
Iteration [38751]: Loss = 4.934759140014648
Iteration [38752]: Loss = 0.7022978067398071
Iteration [38753]: Loss = 0.7024104595184326
Iteration [38754]: Loss = 0.7024760246276855
Iteration [38755]: Loss = 0.7024990916252136
Iteration [38756]: Loss = 0.7024840712547302
Iteration [38757]: Loss = 0.7024345993995667
Iteration [38758]: Loss = 0.7023541927337646
Iteration [38759]: Loss = 4.934171676635742
Iteration [38760]: Loss = 0.702335000038147
Iteration [38761]: Loss = 0.7023794054985046
Iteration [38762]: Loss = 0.7023834586143494
Iteration [38763]: Loss = 0.7023512125015259
Iteration [38764]: Loss = 0.7022863030433655
Iteration [38765]: Loss = 0.7021917104721069
Iteration [38766]: Loss = 0.7020708322525024
Iteration [38767]: Loss = 0.7019259333610535
Iteration [38768]: Loss = 0.7017596960067749
Iteration [38769]: Loss = 4.937668323516846
Iteration [38770]: Loss = 4.937563419342041
Iteration [38771]: Loss = 0.7017985582351685
Iteration [38772]: Loss = 0.7019469738006592
Iteration [38773]: Loss = 0.7020446062088013
Iteration [38774]: Loss = 0.7020968198776245
Iteration [38775]: Loss = 0.7021077871322632
Iteration [38776]: Loss = 0.7020817995071411
Iteration [38777]: Loss = 0.7020223736763
Iteration [38778]: Loss = 0.7019330263137817
Iteration [38779]: Loss = 0.7018166184425354
Iteration [38780]: Loss = 0.7016756534576416
Iteration [38781]: Loss = 0.7015129923820496
Iteration [38782]: Loss = 0.7013305425643921
Iteration [38783]: Loss = 0.7011303305625916
Iteration [38784]: Loss = 0.700914204120636
Iteration [38785]: Loss = 0.7006835341453552
Iteration [38786]: Loss = 4.9435811042785645
Iteration [38787]: Loss = 0.7004088759422302
Iteration [38788]: Loss = 0.7003446817398071
Iteration [38789]: Loss = 0.7002511024475098
Iteration [38790]: Loss = 0.7001309394836426
Iteration [38791]: Loss = 0.6999869346618652
Iteration [38792]: Loss = 0.6998211741447449
Iteration [38793]: Loss = 4.947783470153809
Iteration [38794]: Loss = 0.6996574997901917
Iteration [38795]: Loss = 0.6996408104896545
Iteration [38796]: Loss = 0.6995899081230164
Iteration [38797]: Loss = 0.6995082497596741
Iteration [38798]: Loss = 0.699398934841156
Iteration [38799]: Loss = 0.6992644667625427
Iteration [38800]: Loss = 0.6991077065467834
Iteration [38801]: Loss = 0.6989305019378662
Iteration [38802]: Loss = 0.6987352967262268
Iteration [38803]: Loss = 0.6985235214233398
Iteration [38804]: Loss = 0.6982971429824829
Iteration [38805]: Loss = 0.6980574131011963
Iteration [38806]: Loss = 0.6978057622909546
Iteration [38807]: Loss = 0.6975435018539429
Iteration [38808]: Loss = 4.960191249847412
Iteration [38809]: Loss = 0.6972153782844543
Iteration [38810]: Loss = 0.6971290707588196
Iteration [38811]: Loss = 0.6970157027244568
Iteration [38812]: Loss = 0.6968777179718018
Iteration [38813]: Loss = 0.6967177391052246
Iteration [38814]: Loss = 4.964053630828857
Iteration [38815]: Loss = 0.6965646743774414
Iteration [38816]: Loss = 0.6965530514717102
Iteration [38817]: Loss = 0.6965067982673645
Iteration [38818]: Loss = 0.6964293718338013
Iteration [38819]: Loss = 0.6963239312171936
Iteration [38820]: Loss = 0.6961932182312012
Iteration [38821]: Loss = 0.6960397958755493
Iteration [38822]: Loss = 0.6958658695220947
Iteration [38823]: Loss = 0.6956735253334045
Iteration [38824]: Loss = 0.6954646706581116
Iteration [38825]: Loss = 0.6952407956123352
Iteration [38826]: Loss = 0.6950035691261292
Iteration [38827]: Loss = 0.6947542428970337
Iteration [38828]: Loss = 0.6944939494132996
Iteration [38829]: Loss = 0.6942241191864014
Iteration [38830]: Loss = 0.6939453482627869
Iteration [38831]: Loss = 0.6936588287353516
Iteration [38832]: Loss = 4.980837345123291
Iteration [38833]: Loss = 0.6932907104492188
Iteration [38834]: Loss = 0.693187952041626
Iteration [38835]: Loss = 0.6930599212646484
Iteration [38836]: Loss = 0.6929088234901428
Iteration [38837]: Loss = 0.6927372217178345
Iteration [38838]: Loss = 0.6925471425056458
Iteration [38839]: Loss = 0.6923403739929199
Iteration [38840]: Loss = 0.6921185851097107
Iteration [38841]: Loss = 0.6918830871582031
Iteration [38842]: Loss = 9.288442611694336
Iteration [38843]: Loss = 0.691826581954956
Iteration [38844]: Loss = 0.6919631958007812
Iteration [38845]: Loss = 0.6920508146286011
Iteration [38846]: Loss = 0.6920945644378662
Iteration [38847]: Loss = 0.6920983195304871
Iteration [38848]: Loss = 0.6920665502548218
Iteration [38849]: Loss = 0.6920025944709778
Iteration [38850]: Loss = 4.988580703735352
Iteration [38851]: Loss = 0.6920141577720642
Iteration [38852]: Loss = 0.6920729279518127
Iteration [38853]: Loss = 0.6920905113220215
Iteration [38854]: Loss = 0.6920710206031799
Iteration [38855]: Loss = 0.6920180320739746
Iteration [38856]: Loss = 0.691935122013092
Iteration [38857]: Loss = 0.6918249130249023
Iteration [38858]: Loss = 0.6916903257369995
Iteration [38859]: Loss = 0.6915338039398193
Iteration [38860]: Loss = 4.991523742675781
Iteration [38861]: Loss = 4.991362571716309
Iteration [38862]: Loss = 0.6916027069091797
Iteration [38863]: Loss = 0.6917612552642822
Iteration [38864]: Loss = 4.988798141479492
Iteration [38865]: Loss = 0.6921530961990356
Iteration [38866]: Loss = 0.6923739314079285
Iteration [38867]: Loss = 0.6925376057624817
Iteration [38868]: Loss = 4.984641075134277
Iteration [38869]: Loss = 0.6929379105567932
Iteration [38870]: Loss = 0.6931624412536621
Iteration [38871]: Loss = 4.9810285568237305
Iteration [38872]: Loss = 0.6936665773391724
Iteration [38873]: Loss = 0.6939352750778198
Iteration [38874]: Loss = 0.6941417455673218
Iteration [38875]: Loss = 0.6942923069000244
Iteration [38876]: Loss = 0.6943923830986023
Iteration [38877]: Loss = 0.6944469213485718
Iteration [38878]: Loss = 0.6944605112075806
Iteration [38879]: Loss = 0.6944372653961182
Iteration [38880]: Loss = 0.6943808197975159
Iteration [38881]: Loss = 0.6942943930625916
Iteration [38882]: Loss = 0.6941810250282288
Iteration [38883]: Loss = 0.6940434575080872
Iteration [38884]: Loss = 0.6938840746879578
Iteration [38885]: Loss = 0.6937049031257629
Iteration [38886]: Loss = 0.6935080885887146
Iteration [38887]: Loss = 0.6932952404022217
Iteration [38888]: Loss = 0.693068265914917
Iteration [38889]: Loss = 0.692828357219696
Iteration [38890]: Loss = 0.6925767660140991
Iteration [38891]: Loss = 0.692314863204956
Iteration [38892]: Loss = 0.6920434236526489
Iteration [38893]: Loss = 0.6917636394500732
Iteration [38894]: Loss = 4.9908881187438965
Iteration [38895]: Loss = 0.6914074420928955
Iteration [38896]: Loss = 9.292244911193848
Iteration [38897]: Loss = 0.6916322708129883
Iteration [38898]: Loss = 4.988697052001953
Iteration [38899]: Loss = 0.6923037767410278
Iteration [38900]: Loss = 0.6926437616348267
Iteration [38901]: Loss = 0.6929146647453308
Iteration [38902]: Loss = 4.982120513916016
Iteration [38903]: Loss = 0.6934979557991028
Iteration [38904]: Loss = 0.6938000917434692
Iteration [38905]: Loss = 0.6940369606018066
Iteration [38906]: Loss = 0.6942150592803955
Iteration [38907]: Loss = 0.6943399906158447
Iteration [38908]: Loss = 0.6944172382354736
Iteration [38909]: Loss = 4.975076675415039
Iteration [38910]: Loss = 0.6946690678596497
Iteration [38911]: Loss = 0.6948298215866089
Iteration [38912]: Loss = 4.9724955558776855
Iteration [38913]: Loss = 4.9709882736206055
Iteration [38914]: Loss = 0.6956666111946106
Iteration [38915]: Loss = 0.6960300207138062
Iteration [38916]: Loss = 0.696321964263916
Iteration [38917]: Loss = 0.6965494751930237
Iteration [38918]: Loss = 0.6967189908027649
Iteration [38919]: Loss = 0.6968361139297485
Iteration [38920]: Loss = 0.6969062089920044
Iteration [38921]: Loss = 0.6969336271286011
Iteration [38922]: Loss = 0.6969230771064758
Iteration [38923]: Loss = 0.6968778967857361
Iteration [38924]: Loss = 0.6968016624450684
Iteration [38925]: Loss = 0.6966975927352905
Iteration [38926]: Loss = 4.963893890380859
Iteration [38927]: Loss = 4.963520526885986
Iteration [38928]: Loss = 0.696889340877533
Iteration [38929]: Loss = 0.6970794200897217
Iteration [38930]: Loss = 0.6972150206565857
Iteration [38931]: Loss = 0.6973015666007996
Iteration [38932]: Loss = 0.6973439455032349
Iteration [38933]: Loss = 0.697346568107605
Iteration [38934]: Loss = 0.6973133683204651
Iteration [38935]: Loss = 0.6972479224205017
Iteration [38936]: Loss = 0.6971533298492432
Iteration [38937]: Loss = 0.6970326900482178
Iteration [38938]: Loss = 0.6968885064125061
Iteration [38939]: Loss = 0.6967229247093201
Iteration [38940]: Loss = 0.6965384483337402
Iteration [38941]: Loss = 0.6963366866111755
Iteration [38942]: Loss = 0.6961195468902588
Iteration [38943]: Loss = 4.967479228973389
Iteration [38944]: Loss = 0.6958683729171753
Iteration [38945]: Loss = 0.6958146095275879
Iteration [38946]: Loss = 0.6957309246063232
Iteration [38947]: Loss = 0.6956198811531067
Iteration [38948]: Loss = 0.6954843997955322
Iteration [38949]: Loss = 0.6953268051147461
Iteration [38950]: Loss = 4.971383571624756
Iteration [38951]: Loss = 0.6951777338981628
Iteration [38952]: Loss = 0.6951676607131958
Iteration [38953]: Loss = 0.6951232552528381
Iteration [38954]: Loss = 0.6950474977493286
Iteration [38955]: Loss = 0.6949439644813538
Iteration [38956]: Loss = 0.6948152184486389
Iteration [38957]: Loss = 4.9739532470703125
Iteration [38958]: Loss = 0.6947154402732849
Iteration [38959]: Loss = 0.6947264075279236
Iteration [38960]: Loss = 0.6947008371353149
Iteration [38961]: Loss = 0.6946423649787903
Iteration [38962]: Loss = 0.6945541501045227
Iteration [38963]: Loss = 0.694439172744751
Iteration [38964]: Loss = 0.69430011510849
Iteration [38965]: Loss = 4.976729869842529
Iteration [38966]: Loss = 0.6941830515861511
Iteration [38967]: Loss = 0.6941868662834167
Iteration [38968]: Loss = 0.6941547989845276
Iteration [38969]: Loss = 0.6940903067588806
Iteration [38970]: Loss = 0.6939969062805176
Iteration [38971]: Loss = 0.693877100944519
Iteration [38972]: Loss = 4.978879928588867
Iteration [38973]: Loss = 0.6937932968139648
Iteration [38974]: Loss = 0.693811297416687
Iteration [38975]: Loss = 0.693791925907135
Iteration [38976]: Loss = 0.693739116191864
Iteration [38977]: Loss = 0.6936560869216919
Iteration [38978]: Loss = 4.9798784255981445
Iteration [38979]: Loss = 0.6936347484588623
Iteration [38980]: Loss = 0.6936794519424438
Iteration [38981]: Loss = 0.6936841011047363
Iteration [38982]: Loss = 0.6936529874801636
Iteration [38983]: Loss = 0.693589448928833
Iteration [38984]: Loss = 0.6934966444969177
Iteration [38985]: Loss = 0.6933774948120117
Iteration [38986]: Loss = 0.6932348012924194
Iteration [38987]: Loss = 0.6930708885192871
Iteration [38988]: Loss = 0.6928876638412476
Iteration [38989]: Loss = 0.6926873922348022
Iteration [38990]: Loss = 0.6924713850021362
Iteration [38991]: Loss = 0.6922414898872375
Iteration [38992]: Loss = 0.6919990181922913
Iteration [38993]: Loss = 0.6917453408241272
Iteration [38994]: Loss = 0.6914814710617065
Iteration [38995]: Loss = 0.6912083029747009
Iteration [38996]: Loss = 0.6909270286560059
Iteration [38997]: Loss = 0.6906384825706482
Iteration [38998]: Loss = 0.6903433203697205
Iteration [38999]: Loss = 0.6900420188903809
Iteration [39000]: Loss = 0.6897355914115906
Iteration [39001]: Loss = 0.6894241571426392
Iteration [39002]: Loss = 5.003553867340088
Iteration [39003]: Loss = 0.6890144348144531
Iteration [39004]: Loss = 0.6888946294784546
Iteration [39005]: Loss = 5.005469799041748
Iteration [39006]: Loss = 5.005144119262695
Iteration [39007]: Loss = 5.003838062286377
Iteration [39008]: Loss = 0.6894629597663879
Iteration [39009]: Loss = 0.6897947788238525
Iteration [39010]: Loss = 0.6900584101676941
Iteration [39011]: Loss = 0.6902605891227722
Iteration [39012]: Loss = 4.996598243713379
Iteration [39013]: Loss = 0.690727710723877
Iteration [39014]: Loss = 0.6909810304641724
Iteration [39015]: Loss = 0.6911739706993103
Iteration [39016]: Loss = 0.6913121342658997
Iteration [39017]: Loss = 0.6914010643959045
Iteration [39018]: Loss = 0.6914458870887756
Iteration [39019]: Loss = 0.6914507150650024
Iteration [39020]: Loss = 0.6914196610450745
Iteration [39021]: Loss = 0.6913562417030334
Iteration [39022]: Loss = 0.6912635564804077
Iteration [39023]: Loss = 0.6911448240280151
Iteration [39024]: Loss = 0.6910021901130676
Iteration [39025]: Loss = 0.6908385157585144
Iteration [39026]: Loss = 0.690655529499054
Iteration [39027]: Loss = 0.6904553771018982
Iteration [39028]: Loss = 4.997494220733643
Iteration [39029]: Loss = 0.6902352571487427
Iteration [39030]: Loss = 0.6901960372924805
Iteration [39031]: Loss = 0.6901252865791321
Iteration [39032]: Loss = 0.690026044845581
Iteration [39033]: Loss = 0.6899012327194214
Iteration [39034]: Loss = 0.689753532409668
Iteration [39035]: Loss = 5.0009989738464355
Iteration [39036]: Loss = 0.689623236656189
Iteration [39037]: Loss = 0.6896222829818726
Iteration [39038]: Loss = 0.6895859837532043
Iteration [39039]: Loss = 0.6895178556442261
Iteration [39040]: Loss = 0.6894211769104004
Iteration [39041]: Loss = 0.6892985105514526
Iteration [39042]: Loss = 0.6891529560089111
Iteration [39043]: Loss = 0.6889861822128296
Iteration [39044]: Loss = 0.6888007521629333
Iteration [39045]: Loss = 0.6885983943939209
Iteration [39046]: Loss = 0.6883807182312012
Iteration [39047]: Loss = 0.6881493926048279
Iteration [39048]: Loss = 0.6879057288169861
Iteration [39049]: Loss = 5.0113844871521
Iteration [39050]: Loss = 0.6876123547554016
Iteration [39051]: Loss = 5.011969089508057
Iteration [39052]: Loss = 0.6876693367958069
Iteration [39053]: Loss = 0.687748372554779
Iteration [39054]: Loss = 0.6877841949462891
Iteration [39055]: Loss = 0.6877809762954712
Iteration [39056]: Loss = 0.6877429485321045
Iteration [39057]: Loss = 0.6876732110977173
Iteration [39058]: Loss = 0.687575101852417
Iteration [39059]: Loss = 0.6874513626098633
Iteration [39060]: Loss = 0.6873046159744263
Iteration [39061]: Loss = 0.6871370673179626
Iteration [39062]: Loss = 9.343358039855957
Iteration [39063]: Loss = 0.6871973872184753
Iteration [39064]: Loss = 0.6873845458030701
Iteration [39065]: Loss = 0.6875178813934326
Iteration [39066]: Loss = 0.6876028180122375
Iteration [39067]: Loss = 0.687644362449646
Iteration [39068]: Loss = 0.6876465678215027
Iteration [39069]: Loss = 5.0115861892700195
Iteration [39070]: Loss = 0.6877723336219788
Iteration [39071]: Loss = 0.6878804564476013
Iteration [39072]: Loss = 0.6879426836967468
Iteration [39073]: Loss = 0.6879634857177734
Iteration [39074]: Loss = 0.6879470944404602
Iteration [39075]: Loss = 0.6878971457481384
Iteration [39076]: Loss = 5.0104899406433105
Iteration [39077]: Loss = 0.6879339814186096
Iteration [39078]: Loss = 0.6880040168762207
Iteration [39079]: Loss = 0.6880320906639099
Iteration [39080]: Loss = 0.6880221366882324
Iteration [39081]: Loss = 0.6879780292510986
Iteration [39082]: Loss = 0.6879029870033264
Iteration [39083]: Loss = 0.6878003478050232
Iteration [39084]: Loss = 0.6876727342605591
Iteration [39085]: Loss = 0.6875225901603699
Iteration [39086]: Loss = 0.687352180480957
Iteration [39087]: Loss = 0.6871636509895325
Iteration [39088]: Loss = 0.6869588494300842
Iteration [39089]: Loss = 0.6867391467094421
Iteration [39090]: Loss = 0.6865061521530151
Iteration [39091]: Loss = 0.6862612962722778
Iteration [39092]: Loss = 5.020256042480469
Iteration [39093]: Loss = 0.6859657764434814
Iteration [39094]: Loss = 0.6858945488929749
Iteration [39095]: Loss = 0.6857955455780029
Iteration [39096]: Loss = 5.022063255310059
Iteration [39097]: Loss = 0.6857491731643677
Iteration [39098]: Loss = 0.6857842803001404
Iteration [39099]: Loss = 0.6857806444168091
Iteration [39100]: Loss = 0.6857423186302185
Iteration [39101]: Loss = 5.022055149078369
Iteration [39102]: Loss = 5.021368026733398
Iteration [39103]: Loss = 0.6850531101226807
Iteration [39104]: Loss = 0.6851770281791687
Iteration [39105]: Loss = 0.685145914554596
Iteration [39106]: Loss = 0.6849800944328308
Iteration [39107]: Loss = 0.6846965551376343
Iteration [39108]: Loss = 0.6843101382255554
Iteration [39109]: Loss = 0.683833658695221
Iteration [39110]: Loss = 0.683278501033783
Iteration [39111]: Loss = 5.0384345054626465
Iteration [39112]: Loss = 0.682805061340332
Iteration [39113]: Loss = 0.6828356981277466
Iteration [39114]: Loss = 0.6827588677406311
Iteration [39115]: Loss = 0.6825860738754272
Iteration [39116]: Loss = 0.6823278665542603
Iteration [39117]: Loss = 0.6819933652877808
Iteration [39118]: Loss = 0.6815907955169678
Iteration [39119]: Loss = 0.6811277866363525
Iteration [39120]: Loss = 0.6806106567382812
Iteration [39121]: Loss = 0.6800457835197449
Iteration [39122]: Loss = 0.6794379353523254
Iteration [39123]: Loss = 0.6787923574447632
Iteration [39124]: Loss = 0.6781130433082581
Iteration [39125]: Loss = 5.067205905914307
Iteration [39126]: Loss = 0.6773285865783691
Iteration [39127]: Loss = 0.6771708726882935
Iteration [39128]: Loss = 5.06976842880249
Iteration [39129]: Loss = 0.6772088408470154
Iteration [39130]: Loss = 0.677367627620697
Iteration [39131]: Loss = 5.067079544067383
Iteration [39132]: Loss = 0.6822789907455444
Iteration [39133]: Loss = 0.6782605051994324
Iteration [39134]: Loss = 0.678493082523346
Iteration [39135]: Loss = 0.6786233186721802
Iteration [39136]: Loss = 0.6786614656448364
Iteration [39137]: Loss = 0.6786169409751892
Iteration [39138]: Loss = 0.6784896850585938
Iteration [39139]: Loss = 5.06271505355835
Iteration [39140]: Loss = 0.6785681247711182
Iteration [39141]: Loss = 0.6787221431732178
Iteration [39142]: Loss = 0.678785502910614
Iteration [39143]: Loss = 0.6787670850753784
Iteration [39144]: Loss = 0.6786755919456482
Iteration [39145]: Loss = 0.6785182952880859
Iteration [39146]: Loss = 0.6783018112182617
Iteration [39147]: Loss = 0.6780322790145874
Iteration [39148]: Loss = 0.6777151823043823
Iteration [39149]: Loss = 0.677355170249939
Iteration [39150]: Loss = 0.6769570708274841
Iteration [39151]: Loss = 0.6765244603157043
Iteration [39152]: Loss = 0.6760610938072205
Iteration [39153]: Loss = 0.6755701303482056
Iteration [39154]: Loss = 0.6750543117523193
Iteration [39155]: Loss = 5.083181381225586
Iteration [39156]: Loss = 0.6744464635848999
Iteration [39157]: Loss = 0.6743119955062866
Iteration [39158]: Loss = 0.6741194725036621
Iteration [39159]: Loss = 0.6738749146461487
Iteration [39160]: Loss = 0.6735835075378418
Iteration [39161]: Loss = 0.6732500791549683
Iteration [39162]: Loss = 0.6728788614273071
Iteration [39163]: Loss = 0.6724737286567688
Iteration [39164]: Loss = 0.6720383167266846
Iteration [39165]: Loss = 0.6715756058692932
Iteration [39166]: Loss = 5.102292537689209
Iteration [39167]: Loss = 0.6710488200187683
Iteration [39168]: Loss = 0.6709440350532532
Iteration [39169]: Loss = 0.6707810163497925
Iteration [39170]: Loss = 0.6705654859542847
Iteration [39171]: Loss = 5.10669469833374
Iteration [39172]: Loss = 0.6704484224319458
Iteration [39173]: Loss = 0.6705122590065002
Iteration [39174]: Loss = 0.6705027222633362
Iteration [39175]: Loss = 0.6704272627830505
Iteration [39176]: Loss = 0.6702922582626343
Iteration [39177]: Loss = 5.107809066772461
Iteration [39178]: Loss = 5.106679439544678
Iteration [39179]: Loss = 0.6708426475524902
Iteration [39180]: Loss = 0.6712621450424194
Iteration [39181]: Loss = 0.6715754866600037
Iteration [39182]: Loss = 0.6717933416366577
Iteration [39183]: Loss = 0.6719252467155457
Iteration [39184]: Loss = 0.6719796061515808
Iteration [39185]: Loss = 0.6719644665718079
Iteration [39186]: Loss = 5.097829341888428
Iteration [39187]: Loss = 0.6721699237823486
Iteration [39188]: Loss = 0.6723618507385254
Iteration [39189]: Loss = 5.094563007354736
Iteration [39190]: Loss = 0.6729151010513306
Iteration [39191]: Loss = 0.6732521653175354
Iteration [39192]: Loss = 0.6734934449195862
Iteration [39193]: Loss = 0.6736485362052917
Iteration [39194]: Loss = 5.0875749588012695
Iteration [39195]: Loss = 0.6741352677345276
Iteration [39196]: Loss = 0.6744423508644104
Iteration [39197]: Loss = 0.6746575832366943
Iteration [39198]: Loss = 0.67479008436203
Iteration [39199]: Loss = 0.6748478412628174
Iteration [39200]: Loss = 0.6748386025428772
Iteration [39201]: Loss = 0.6747689247131348
Iteration [39202]: Loss = 0.6746448278427124
Iteration [39203]: Loss = 5.08342981338501
Iteration [39204]: Loss = 0.6746540665626526
Iteration [39205]: Loss = 0.6747575998306274
Iteration [39206]: Loss = 5.081661224365234
Iteration [39207]: Loss = 0.6751507520675659
Iteration [39208]: Loss = 5.078195571899414
Iteration [39209]: Loss = 0.6759783625602722
Iteration [39210]: Loss = 0.676426112651825
Iteration [39211]: Loss = 0.6767699718475342
Iteration [39212]: Loss = 0.6770203709602356
Iteration [39213]: Loss = 0.6771864891052246
Iteration [39214]: Loss = 0.6772767901420593
Iteration [39215]: Loss = 0.6772987842559814
Iteration [39216]: Loss = 0.6772593259811401
Iteration [39217]: Loss = 5.068526744842529
Iteration [39218]: Loss = 0.6774033904075623
Iteration [39219]: Loss = 0.677560031414032
Iteration [39220]: Loss = 0.6776422262191772
Iteration [39221]: Loss = 0.6776576042175293
Iteration [39222]: Loss = 0.6776127219200134
Iteration [39223]: Loss = 5.066600322723389
Iteration [39224]: Loss = 0.677745521068573
Iteration [39225]: Loss = 0.6778962016105652
Iteration [39226]: Loss = 0.677973747253418
Iteration [39227]: Loss = 0.6779853701591492
Iteration [39228]: Loss = 0.6779376268386841
Iteration [39229]: Loss = 5.064821243286133
Iteration [39230]: Loss = 0.678063690662384
Iteration [39231]: Loss = 0.6782105565071106
Iteration [39232]: Loss = 0.6782851219177246
Iteration [39233]: Loss = 0.6782945394515991
Iteration [39234]: Loss = 0.6782453656196594
Iteration [39235]: Loss = 0.6781435608863831
Iteration [39236]: Loss = 0.6779942512512207
Iteration [39237]: Loss = 0.6778020858764648
Iteration [39238]: Loss = 0.6775716543197632
Iteration [39239]: Loss = 0.677306592464447
Iteration [39240]: Loss = 0.6770103573799133
Iteration [39241]: Loss = 0.6766862869262695
Iteration [39242]: Loss = 0.6763371229171753
Iteration [39243]: Loss = 0.6759653687477112
Iteration [39244]: Loss = 0.6755732893943787
Iteration [39245]: Loss = 0.6751630306243896
Iteration [39246]: Loss = 0.6747364401817322
Iteration [39247]: Loss = 0.67429518699646
Iteration [39248]: Loss = 9.500031471252441
Iteration [39249]: Loss = 0.6741148233413696
Iteration [39250]: Loss = 0.6743065118789673
Iteration [39251]: Loss = 0.6744241118431091
Iteration [39252]: Loss = 0.6744751334190369
Iteration [39253]: Loss = 0.6744660139083862
Iteration [39254]: Loss = 0.6744028329849243
Iteration [39255]: Loss = 0.6742908358573914
Iteration [39256]: Loss = 0.674135148525238
Iteration [39257]: Loss = 0.6739400029182434
Iteration [39258]: Loss = 0.6737093329429626
Iteration [39259]: Loss = 0.6734467148780823
Iteration [39260]: Loss = 0.6731553673744202
Iteration [39261]: Loss = 0.6728383302688599
Iteration [39262]: Loss = 0.6724980473518372
Iteration [39263]: Loss = 5.09643030166626
Iteration [39264]: Loss = 0.672118604183197
Iteration [39265]: Loss = 0.6720476150512695
Iteration [39266]: Loss = 0.671929121017456
Iteration [39267]: Loss = 5.098491191864014
Iteration [39268]: Loss = 0.6719264388084412
Iteration [39269]: Loss = 0.6720147728919983
Iteration [39270]: Loss = 0.6720402240753174
Iteration [39271]: Loss = 0.6720090508460999
Iteration [39272]: Loss = 0.6719268560409546
Iteration [39273]: Loss = 0.671798825263977
Iteration [39274]: Loss = 0.6716293096542358
Iteration [39275]: Loss = 0.6714226007461548
Iteration [39276]: Loss = 0.6711825728416443
Iteration [39277]: Loss = 0.6709123849868774
Iteration [39278]: Loss = 0.6706150770187378
Iteration [39279]: Loss = 0.6702935099601746
Iteration [39280]: Loss = 0.6699499487876892
Iteration [39281]: Loss = 0.6695868372917175
Iteration [39282]: Loss = 0.6692059636116028
Iteration [39283]: Loss = 0.6688092350959778
Iteration [39284]: Loss = 0.6683982610702515
Iteration [39285]: Loss = 0.6679744720458984
Iteration [39286]: Loss = 0.6675392389297485
Iteration [39287]: Loss = 0.6670936346054077
Iteration [39288]: Loss = 0.6666388511657715
Iteration [39289]: Loss = 0.6661758422851562
Iteration [39290]: Loss = 0.6657052636146545
Iteration [39291]: Loss = 0.6652281284332275
Iteration [39292]: Loss = 0.6647451519966125
Iteration [39293]: Loss = 0.6642566919326782
Iteration [39294]: Loss = 0.6637634634971619
Iteration [39295]: Loss = 0.6632660031318665
Iteration [39296]: Loss = 0.6627647876739502
Iteration [39297]: Loss = 0.6622602939605713
Iteration [39298]: Loss = 0.6617528200149536
Iteration [39299]: Loss = 0.6612425446510315
Iteration [39300]: Loss = 0.6607299447059631
Iteration [39301]: Loss = 0.6602151989936829
Iteration [39302]: Loss = 0.6596987843513489
Iteration [39303]: Loss = 0.6591805815696716
Iteration [39304]: Loss = 0.658660888671875
Iteration [39305]: Loss = 0.6581401228904724
Iteration [39306]: Loss = 0.6576181650161743
Iteration [39307]: Loss = 5.181949615478516
Iteration [39308]: Loss = 0.6569340229034424
Iteration [39309]: Loss = 0.6567361354827881
Iteration [39310]: Loss = 0.6565051674842834
Iteration [39311]: Loss = 0.6562445163726807
Iteration [39312]: Loss = 9.721134185791016
Iteration [39313]: Loss = 0.6563496589660645
Iteration [39314]: Loss = 0.6566519737243652
Iteration [39315]: Loss = 0.6568732261657715
Iteration [39316]: Loss = 0.6570214629173279
Iteration [39317]: Loss = 0.6571038365364075
Iteration [39318]: Loss = 0.6571269035339355
Iteration [39319]: Loss = 0.6570965647697449
Iteration [39320]: Loss = 0.6570183038711548
Iteration [39321]: Loss = 5.18310022354126
Iteration [39322]: Loss = 5.1820268630981445
Iteration [39323]: Loss = 0.6575397849082947
Iteration [39324]: Loss = 0.6579017043113708
Iteration [39325]: Loss = 0.6581771373748779
Iteration [39326]: Loss = 0.6583744883537292
Iteration [39327]: Loss = 0.658501386642456
Iteration [39328]: Loss = 0.6585652232170105
Iteration [39329]: Loss = 0.658571720123291
Iteration [39330]: Loss = 0.6585270166397095
Iteration [39331]: Loss = 0.6584359407424927
Iteration [39332]: Loss = 5.174966335296631
Iteration [39333]: Loss = 0.6584756970405579
Iteration [39334]: Loss = 0.6585804224014282
Iteration [39335]: Loss = 0.6586242914199829
Iteration [39336]: Loss = 0.6586132049560547
Iteration [39337]: Loss = 0.6585527658462524
Iteration [39338]: Loss = 0.658447802066803
Iteration [39339]: Loss = 5.174968719482422
Iteration [39340]: Loss = 0.6584630608558655
Iteration [39341]: Loss = 0.6585569381713867
Iteration [39342]: Loss = 0.6585913300514221
Iteration [39343]: Loss = 0.6585718393325806
Iteration [39344]: Loss = 5.173807621002197
Iteration [39345]: Loss = 0.658731997013092
Iteration [39346]: Loss = 0.6588871479034424
Iteration [39347]: Loss = 0.6589767336845398
Iteration [39348]: Loss = 0.6590073108673096
Iteration [39349]: Loss = 0.6589847803115845
Iteration [39350]: Loss = 0.6589144468307495
Iteration [39351]: Loss = 0.6588007807731628
Iteration [39352]: Loss = 0.6586484313011169
Iteration [39353]: Loss = 0.6584612131118774
Iteration [39354]: Loss = 0.6582424640655518
Iteration [39355]: Loss = 0.6579954028129578
Iteration [39356]: Loss = 0.6577231287956238
Iteration [39357]: Loss = 0.6574277281761169
Iteration [39358]: Loss = 0.6571119427680969
Iteration [39359]: Loss = 0.6567775011062622
Iteration [39360]: Loss = 5.185823440551758
Iteration [39361]: Loss = 0.6564010381698608
Iteration [39362]: Loss = 0.6563282012939453
Iteration [39363]: Loss = 0.6562129259109497
Iteration [39364]: Loss = 5.187953472137451
Iteration [39365]: Loss = 0.6562092304229736
Iteration [39366]: Loss = 0.656294584274292
Iteration [39367]: Loss = 0.6563220620155334
Iteration [39368]: Loss = 0.6562968492507935
Iteration [39369]: Loss = 0.6574032306671143
Iteration [39370]: Loss = 0.657288670539856
Iteration [39371]: Loss = 0.6571359634399414
Iteration [39372]: Loss = 0.6569487452507019
Iteration [39373]: Loss = 0.6567303538322449
Iteration [39374]: Loss = 9.714493751525879
Iteration [39375]: Loss = 0.6568781137466431
Iteration [39376]: Loss = 0.6571844816207886
Iteration [39377]: Loss = 5.180118083953857
Iteration [39378]: Loss = 0.6567133665084839
Iteration [39379]: Loss = 0.6570987105369568
Iteration [39380]: Loss = 5.180201053619385
Iteration [39381]: Loss = 0.6579434275627136
Iteration [39382]: Loss = 0.6583869457244873
Iteration [39383]: Loss = 0.6587382555007935
Iteration [39384]: Loss = 5.1709113121032715
Iteration [39385]: Loss = 0.6595236659049988
Iteration [39386]: Loss = 0.659941554069519
Iteration [39387]: Loss = 0.6602696776390076
Iteration [39388]: Loss = 0.6605169773101807
Iteration [39389]: Loss = 0.6606913208961487
Iteration [39390]: Loss = 0.660800039768219
Iteration [39391]: Loss = 0.6608495116233826
Iteration [39392]: Loss = 0.6608457565307617
Iteration [39393]: Loss = 0.6607939600944519
Iteration [39394]: Loss = 0.6606991291046143
Iteration [39395]: Loss = 0.6605650782585144
Iteration [39396]: Loss = 0.6603962182998657
Iteration [39397]: Loss = 0.6601958274841309
Iteration [39398]: Loss = 5.1653828620910645
Iteration [39399]: Loss = 0.660038948059082
Iteration [39400]: Loss = 0.6600554585456848
Iteration [39401]: Loss = 0.6600220799446106
Iteration [39402]: Loss = 0.6599438786506653
Iteration [39403]: Loss = 0.659825325012207
Iteration [39404]: Loss = 0.659670352935791
Iteration [39405]: Loss = 0.6594825983047485
Iteration [39406]: Loss = 0.6592654585838318
Iteration [39407]: Loss = 0.6590216159820557
Iteration [39408]: Loss = 0.6587541103363037
Iteration [39409]: Loss = 0.6584650874137878
Iteration [39410]: Loss = 0.6581567525863647
Iteration [39411]: Loss = 0.6578311324119568
Iteration [39412]: Loss = 0.6574897170066833
Iteration [39413]: Loss = 0.6571345925331116
Iteration [39414]: Loss = 0.6567666530609131
Iteration [39415]: Loss = 0.6563873887062073
Iteration [39416]: Loss = 0.6559979915618896
Iteration [39417]: Loss = 0.6555994749069214
Iteration [39418]: Loss = 0.6551927328109741
Iteration [39419]: Loss = 5.195396900177002
Iteration [39420]: Loss = 0.6546860933303833
Iteration [39421]: Loss = 0.6545548439025879
Iteration [39422]: Loss = 5.197666645050049
Iteration [39423]: Loss = 0.6545174717903137
Iteration [39424]: Loss = 0.6545855402946472
Iteration [39425]: Loss = 0.6545991897583008
Iteration [39426]: Loss = 0.6545639038085938
Iteration [39427]: Loss = 5.197110176086426
Iteration [39428]: Loss = 0.6546896696090698
Iteration [39429]: Loss = 0.6548269391059875
Iteration [39430]: Loss = 0.6549031734466553
Iteration [39431]: Loss = 0.6549240946769714
Iteration [39432]: Loss = 0.654895544052124
Iteration [39433]: Loss = 0.6548221707344055
Iteration [39434]: Loss = 0.6547086834907532
Iteration [39435]: Loss = 0.6545587182044983
Iteration [39436]: Loss = 0.6543763875961304
Iteration [39437]: Loss = 0.6541646122932434
Iteration [39438]: Loss = 0.6539264917373657
Iteration [39439]: Loss = 0.6536645889282227
Iteration [39440]: Loss = 0.65338134765625
Iteration [39441]: Loss = 0.6530787944793701
Iteration [39442]: Loss = 0.6527590751647949
Iteration [39443]: Loss = 0.6524236798286438
Iteration [39444]: Loss = 5.211191654205322
Iteration [39445]: Loss = 0.6520383954048157
Iteration [39446]: Loss = 0.651958703994751
Iteration [39447]: Loss = 0.6518397927284241
Iteration [39448]: Loss = 0.651685357093811
Iteration [39449]: Loss = 0.6514990329742432
Iteration [39450]: Loss = 0.6512840986251831
Iteration [39451]: Loss = 0.6510432362556458
Iteration [39452]: Loss = 0.6507791876792908
Iteration [39453]: Loss = 0.6504943370819092
Iteration [39454]: Loss = 0.6501906514167786
Iteration [39455]: Loss = 0.6498700976371765
Iteration [39456]: Loss = 0.649534285068512
Iteration [39457]: Loss = 0.6491848826408386
Iteration [39458]: Loss = 0.6488232016563416
Iteration [39459]: Loss = 0.648450493812561
Iteration [39460]: Loss = 0.648067831993103
Iteration [39461]: Loss = 0.6476764678955078
Iteration [39462]: Loss = 0.6472769379615784
Iteration [39463]: Loss = 0.6468703746795654
Iteration [39464]: Loss = 5.244329929351807
Iteration [39465]: Loss = 0.6463656425476074
Iteration [39466]: Loss = 0.6462362408638
Iteration [39467]: Loss = 0.6460729241371155
Iteration [39468]: Loss = 5.247766971588135
Iteration [39469]: Loss = 0.6459828019142151
Iteration [39470]: Loss = 0.646029531955719
Iteration [39471]: Loss = 0.6460249423980713
Iteration [39472]: Loss = 0.6459740400314331
Iteration [39473]: Loss = 0.6458816528320312
Iteration [39474]: Loss = 0.6457515358924866
Iteration [39475]: Loss = 0.6455878019332886
Iteration [39476]: Loss = 0.6453937888145447
Iteration [39477]: Loss = 0.6451723575592041
Iteration [39478]: Loss = 5.25344181060791
Iteration [39479]: Loss = 0.6449830532073975
Iteration [39480]: Loss = 0.6449875831604004
Iteration [39481]: Loss = 0.6449452638626099
Iteration [39482]: Loss = 5.253833770751953
Iteration [39483]: Loss = 0.6450608968734741
Iteration [39484]: Loss = 0.6451950669288635
Iteration [39485]: Loss = 0.6452694535255432
Iteration [39486]: Loss = 0.6452900171279907
Iteration [39487]: Loss = 9.85761833190918
Iteration [39488]: Loss = 0.6458244323730469
Iteration [39489]: Loss = 5.2453508377075195
Iteration [39490]: Loss = 5.241292953491211
Iteration [39491]: Loss = 0.647850751876831
Iteration [39492]: Loss = 0.6486000418663025
Iteration [39493]: Loss = 0.6492294073104858
Iteration [39494]: Loss = 0.6497509479522705
Iteration [39495]: Loss = 5.22234582901001
Iteration [39496]: Loss = 0.6508234143257141
Iteration [39497]: Loss = 0.6513617038726807
Iteration [39498]: Loss = 0.6518009305000305
Iteration [39499]: Loss = 0.6521509885787964
Iteration [39500]: Loss = 5.209163665771484
Iteration [39501]: Loss = 5.206187725067139
Iteration [39502]: Loss = 0.653651237487793
Iteration [39503]: Loss = 5.198441028594971
Iteration [39504]: Loss = 0.655063807964325
Iteration [39505]: Loss = 0.6557460427284241
Iteration [39506]: Loss = 0.6563149690628052
Iteration [39507]: Loss = 0.6567819714546204
Iteration [39508]: Loss = 0.657156765460968
Iteration [39509]: Loss = 0.6574485898017883
Iteration [39510]: Loss = 0.6576656103134155
Iteration [39511]: Loss = 5.177786350250244
Iteration [39512]: Loss = 0.6582133769989014
Iteration [39513]: Loss = 0.6585263013839722
Iteration [39514]: Loss = 0.6587622761726379
Iteration [39515]: Loss = 0.6589291095733643
Iteration [39516]: Loss = 0.6590332984924316
Iteration [39517]: Loss = 0.6590812802314758
Iteration [39518]: Loss = 0.6590786576271057
Iteration [39519]: Loss = 0.6590303182601929
Iteration [39520]: Loss = 0.6589407920837402
Iteration [39521]: Loss = 0.6588144302368164
Iteration [39522]: Loss = 0.658654510974884
Iteration [39523]: Loss = 0.6584646701812744
Iteration [39524]: Loss = 0.6582478284835815
Iteration [39525]: Loss = 0.6580067873001099
Iteration [39526]: Loss = 0.6577436923980713
Iteration [39527]: Loss = 0.6574611663818359
Iteration [39528]: Loss = 0.6571608185768127
Iteration [39529]: Loss = 5.183401107788086
Iteration [39530]: Loss = 5.18350887298584
Iteration [39531]: Loss = 0.6570731401443481
Iteration [39532]: Loss = 5.181051731109619
Iteration [39533]: Loss = 5.178611755371094
Iteration [39534]: Loss = 0.6583131551742554
Iteration [39535]: Loss = 5.171840667724609
Iteration [39536]: Loss = 0.659584105014801
Iteration [39537]: Loss = 0.6602043509483337
Iteration [39538]: Loss = 5.161071300506592
Iteration [39539]: Loss = 0.6614390015602112
Iteration [39540]: Loss = 0.6620433330535889
Iteration [39541]: Loss = 0.6625422239303589
Iteration [39542]: Loss = 0.6644654870033264
Iteration [39543]: Loss = 0.6647831797599792
Iteration [39544]: Loss = 0.6650235652923584
Iteration [39545]: Loss = 0.6651938557624817
Iteration [39546]: Loss = 0.665301501750946
Iteration [39547]: Loss = 0.6653522849082947
Iteration [39548]: Loss = 0.6653521656990051
Iteration [39549]: Loss = 0.6653060913085938
Iteration [39550]: Loss = 0.6652185320854187
Iteration [39551]: Loss = 0.6650936603546143
Iteration [39552]: Loss = 0.6649351716041565
Iteration [39553]: Loss = 0.6647465825080872
Iteration [39554]: Loss = 0.6645307540893555
Iteration [39555]: Loss = 0.6642903685569763
Iteration [39556]: Loss = 5.142148971557617
Iteration [39557]: Loss = 5.142002582550049
Iteration [39558]: Loss = 5.145796298980713
Iteration [39559]: Loss = 5.142873287200928
Iteration [39560]: Loss = 0.6646201610565186
Iteration [39561]: Loss = 0.665222704410553
Iteration [39562]: Loss = 0.6657198071479797
Iteration [39563]: Loss = 5.130258560180664
Iteration [39564]: Loss = 0.666740894317627
Iteration [39565]: Loss = 0.6672528982162476
Iteration [39566]: Loss = 0.6676684617996216
Iteration [39567]: Loss = 0.6679970026016235
Iteration [39568]: Loss = 0.6682471036911011
Iteration [39569]: Loss = 0.6684265732765198
Iteration [39570]: Loss = 0.6685422658920288
Iteration [39571]: Loss = 5.116260051727295
Iteration [39572]: Loss = 0.668910562992096
Iteration [39573]: Loss = 0.6691439151763916
Iteration [39574]: Loss = 0.6693081259727478
Iteration [39575]: Loss = 0.6694104075431824
Iteration [39576]: Loss = 0.6694563031196594
Iteration [39577]: Loss = 0.6694518327713013
Iteration [39578]: Loss = 0.6694019436836243
Iteration [39579]: Loss = 5.112262725830078
Iteration [39580]: Loss = 0.6694868803024292
Iteration [39581]: Loss = 0.6695994138717651
Iteration [39582]: Loss = 0.669654905796051
Iteration [39583]: Loss = 5.110307216644287
Iteration [39584]: Loss = 5.108844757080078
Iteration [39585]: Loss = 0.6704096794128418
Iteration [39586]: Loss = 5.10387659072876
Iteration [39587]: Loss = 0.6714164018630981
Iteration [39588]: Loss = 9.523350715637207
Iteration [39589]: Loss = 0.6729169487953186
Iteration [39590]: Loss = 0.6737694144248962
Iteration [39591]: Loss = 0.674492359161377
Iteration [39592]: Loss = 5.079953670501709
Iteration [39593]: Loss = 0.6758936047554016
Iteration [39594]: Loss = 0.6765647530555725
Iteration [39595]: Loss = 0.6771241426467896
Iteration [39596]: Loss = 5.066221714019775
Iteration [39597]: Loss = 0.6782444715499878
Iteration [39598]: Loss = 0.6787953972816467
Iteration [39599]: Loss = 0.6792462468147278
Iteration [39600]: Loss = 0.679606556892395
Iteration [39601]: Loss = 5.053563117980957
Iteration [39602]: Loss = 5.050821781158447
Iteration [39603]: Loss = 5.0469970703125
Iteration [39604]: Loss = 0.6819613575935364
Iteration [39605]: Loss = 0.6827055215835571
Iteration [39606]: Loss = 0.6833305358886719
Iteration [39607]: Loss = 0.6838477849960327
Iteration [39608]: Loss = 0.6842678785324097
Iteration [39609]: Loss = 0.6846004724502563
Iteration [39610]: Loss = 5.026486396789551
Iteration [39611]: Loss = 0.6853299736976624
Iteration [39612]: Loss = 9.357963562011719
Iteration [39613]: Loss = 0.6865885853767395
Iteration [39614]: Loss = 0.687332034111023
Iteration [39615]: Loss = 0.6879565119743347
Iteration [39616]: Loss = 0.6884735822677612
Iteration [39617]: Loss = 0.6888935565948486
Iteration [39618]: Loss = 0.6892262101173401
Iteration [39619]: Loss = 0.6894800662994385
Iteration [39620]: Loss = 0.6896628737449646
Iteration [39621]: Loss = 0.6897815465927124
Iteration [39622]: Loss = 0.6898425817489624
Iteration [39623]: Loss = 0.6898516416549683
Iteration [39624]: Loss = 0.6898139119148254
Iteration [39625]: Loss = 0.6897339224815369
Iteration [39626]: Loss = 0.6896160840988159
Iteration [39627]: Loss = 0.6894640326499939
Iteration [39628]: Loss = 0.689281165599823
Iteration [39629]: Loss = 0.6890706419944763
Iteration [39630]: Loss = 0.6888352036476135
Iteration [39631]: Loss = 0.6885773539543152
Iteration [39632]: Loss = 0.6882993578910828
Iteration [39633]: Loss = 5.009489059448242
Iteration [39634]: Loss = 0.687983512878418
Iteration [39635]: Loss = 0.6879200339317322
Iteration [39636]: Loss = 0.6878171563148499
Iteration [39637]: Loss = 0.6876784563064575
Iteration [39638]: Loss = 0.6875080466270447
Iteration [39639]: Loss = 0.6873088479042053
Iteration [39640]: Loss = 5.014439582824707
Iteration [39641]: Loss = 0.6871275901794434
Iteration [39642]: Loss = 0.6871215105056763
Iteration [39643]: Loss = 0.6870703101158142
Iteration [39644]: Loss = 0.6869784593582153
Iteration [39645]: Loss = 0.6868501305580139
Iteration [39646]: Loss = 0.6866888999938965
Iteration [39647]: Loss = 0.6864979267120361
Iteration [39648]: Loss = 0.6862801313400269
Iteration [39649]: Loss = 0.6860385537147522
Iteration [39650]: Loss = 0.6857752799987793
Iteration [39651]: Loss = 0.6854925751686096
Iteration [39652]: Loss = 9.364113807678223
Iteration [39653]: Loss = 0.6854591369628906
Iteration [39654]: Loss = 0.6856541633605957
Iteration [39655]: Loss = 0.6857847571372986
Iteration [39656]: Loss = 5.021058559417725
Iteration [39657]: Loss = 0.6861656308174133
Iteration [39658]: Loss = 0.6863985061645508
Iteration [39659]: Loss = 0.6865630745887756
Iteration [39660]: Loss = 0.686665952205658
Iteration [39661]: Loss = 0.6867133975028992
Iteration [39662]: Loss = 0.6867108345031738
Iteration [39663]: Loss = 0.6866632699966431
Iteration [39664]: Loss = 0.6865749955177307
Iteration [39665]: Loss = 0.6864504814147949
Iteration [39666]: Loss = 0.6862928867340088
Iteration [39667]: Loss = 5.019714832305908
Iteration [39668]: Loss = 0.6861818432807922
Iteration [39669]: Loss = 5.0191779136657715
Iteration [39670]: Loss = 0.6864698529243469
Iteration [39671]: Loss = 0.6866629123687744
Iteration [39672]: Loss = 0.6867915391921997
Iteration [39673]: Loss = 0.6868621706962585
Iteration [39674]: Loss = 0.6868806481361389
Iteration [39675]: Loss = 0.6868518590927124
Iteration [39676]: Loss = 5.016071796417236
Iteration [39677]: Loss = 0.6869604587554932
Iteration [39678]: Loss = 0.6870771646499634
Iteration [39679]: Loss = 0.6871369481086731
Iteration [39680]: Loss = 0.687145471572876
Iteration [39681]: Loss = 0.6871079206466675
Iteration [39682]: Loss = 0.6870288252830505
Iteration [39683]: Loss = 0.6869123578071594
Iteration [39684]: Loss = 0.6867622137069702
Iteration [39685]: Loss = 0.6865817904472351
Iteration [39686]: Loss = 5.018266677856445
Iteration [39687]: Loss = 0.6864312887191772
Iteration [39688]: Loss = 0.6864376664161682
Iteration [39689]: Loss = 0.6863983869552612
Iteration [39690]: Loss = 5.018571376800537
Iteration [39691]: Loss = 5.017647743225098
Iteration [39692]: Loss = 0.6868854761123657
Iteration [39693]: Loss = 0.687197744846344
Iteration [39694]: Loss = 0.6874337196350098
Iteration [39695]: Loss = 0.6876012086868286
Iteration [39696]: Loss = 0.6877068877220154
Iteration [39697]: Loss = 0.6877565979957581
Iteration [39698]: Loss = 0.6877561211585999
Iteration [39699]: Loss = 0.6877105832099915
Iteration [39700]: Loss = 0.6876240372657776
Iteration [39701]: Loss = 0.687501072883606
Iteration [39702]: Loss = 0.6873449087142944
Iteration [39703]: Loss = 0.6871591806411743
Iteration [39704]: Loss = 0.6869465112686157
Iteration [39705]: Loss = 0.6867098808288574
Iteration [39706]: Loss = 5.017847537994385
Iteration [39707]: Loss = 0.686463475227356
Iteration [39708]: Loss = 0.686428964138031
Iteration [39709]: Loss = 0.6863527894020081
Iteration [39710]: Loss = 0.6862388253211975
Iteration [39711]: Loss = 0.6860910654067993
Iteration [39712]: Loss = 5.020756244659424
Iteration [39713]: Loss = 0.6859967708587646
Iteration [39714]: Loss = 9.354253768920898
Iteration [39715]: Loss = 0.6865799427032471
Iteration [39716]: Loss = 0.687033474445343
Iteration [39717]: Loss = 0.6873974204063416
Iteration [39718]: Loss = 9.334771156311035
Iteration [39719]: Loss = 0.6884521245956421
Iteration [39720]: Loss = 0.6891034841537476
Iteration [39721]: Loss = 0.6896456480026245
Iteration [39722]: Loss = 0.6900897026062012
Iteration [39723]: Loss = 4.996395111083984
Iteration [39724]: Loss = 0.6910024285316467
Iteration [39725]: Loss = 0.6914598941802979
Iteration [39726]: Loss = 0.6918271780014038
Iteration [39727]: Loss = 0.69211345911026
Iteration [39728]: Loss = 0.6923266053199768
Iteration [39729]: Loss = 0.6924737691879272
Iteration [39730]: Loss = 0.6925614476203918
Iteration [39731]: Loss = 0.6925957202911377
Iteration [39732]: Loss = 0.6925816535949707
Iteration [39733]: Loss = 0.6925243139266968
Iteration [39734]: Loss = 0.6924278140068054
Iteration [39735]: Loss = 0.692296028137207
Iteration [39736]: Loss = 0.6921325922012329
Iteration [39737]: Loss = 0.6919405460357666
Iteration [39738]: Loss = 0.6917230486869812
Iteration [39739]: Loss = 0.6914823055267334
Iteration [39740]: Loss = 0.691220760345459
Iteration [39741]: Loss = 0.6909404397010803
Iteration [39742]: Loss = 0.6906434893608093
Iteration [39743]: Loss = 0.6903312802314758
Iteration [39744]: Loss = 0.6900054216384888
Iteration [39745]: Loss = 0.6896674036979675
Iteration [39746]: Loss = 0.6893184781074524
Iteration [39747]: Loss = 0.6889595985412598
Iteration [39748]: Loss = 0.6885918974876404
Iteration [39749]: Loss = 0.6882163286209106
Iteration [39750]: Loss = 9.332967758178711
Iteration [39751]: Loss = 0.6880123019218445
Iteration [39752]: Loss = 0.6881288886070251
Iteration [39753]: Loss = 0.6862807273864746
Iteration [39754]: Loss = 0.6862913370132446
Iteration [39755]: Loss = 5.018898963928223
Iteration [39756]: Loss = 0.6864631175994873
Iteration [39757]: Loss = 5.017020225524902
Iteration [39758]: Loss = 0.6869691014289856
Iteration [39759]: Loss = 0.6872532367706299
Iteration [39760]: Loss = 0.6874650716781616
Iteration [39761]: Loss = 0.6876118779182434
Iteration [39762]: Loss = 0.6876997947692871
Iteration [39763]: Loss = 0.6896458864212036
Iteration [39764]: Loss = 0.6896334290504456
Iteration [39765]: Loss = 0.6895776987075806
Iteration [39766]: Loss = 0.6894834041595459
Iteration [39767]: Loss = 0.6893541812896729
Iteration [39768]: Loss = 0.6891934275627136
Iteration [39769]: Loss = 0.6890043020248413
Iteration [39770]: Loss = 0.6887898445129395
Iteration [39771]: Loss = 0.6885524988174438
Iteration [39772]: Loss = 9.32755184173584
Iteration [39773]: Loss = 0.6885794401168823
Iteration [39774]: Loss = 0.6887922286987305
Iteration [39775]: Loss = 5.004456996917725
Iteration [39776]: Loss = 0.6893077492713928
Iteration [39777]: Loss = 0.6895950436592102
Iteration [39778]: Loss = 0.6898099184036255
Iteration [39779]: Loss = 0.6899595856666565
Iteration [39780]: Loss = 4.998507976531982
Iteration [39781]: Loss = 4.996815204620361
Iteration [39782]: Loss = 0.6908853650093079
Iteration [39783]: Loss = 4.99178409576416
Iteration [39784]: Loss = 0.6919230222702026
Iteration [39785]: Loss = 0.6924324631690979
Iteration [39786]: Loss = 0.6928476691246033
Iteration [39787]: Loss = 0.693177342414856
Iteration [39788]: Loss = 4.980491638183594
Iteration [39789]: Loss = 0.6938913464546204
Iteration [39790]: Loss = 0.6942625045776367
Iteration [39791]: Loss = 0.6945528388023376
Iteration [39792]: Loss = 0.6947698593139648
Iteration [39793]: Loss = 0.6949211359024048
Iteration [39794]: Loss = 0.6950132250785828
Iteration [39795]: Loss = 4.97189998626709
Iteration [39796]: Loss = 0.6953202486038208
Iteration [39797]: Loss = 0.6955177783966064
Iteration [39798]: Loss = 0.6956513524055481
Iteration [39799]: Loss = 0.6957273483276367
Iteration [39800]: Loss = 0.6957514882087708
Iteration [39801]: Loss = 0.6957287788391113
Iteration [39802]: Loss = 0.6956639885902405
Iteration [39803]: Loss = 4.969207286834717
Iteration [39804]: Loss = 0.6957029700279236
Iteration [39805]: Loss = 0.6957862377166748
Iteration [39806]: Loss = 0.6958168745040894
Iteration [39807]: Loss = 0.6958001255989075
Iteration [39808]: Loss = 4.968259334564209
Iteration [39809]: Loss = 0.695921003818512
Iteration [39810]: Loss = 0.6960391998291016
Iteration [39811]: Loss = 4.96635627746582
Iteration [39812]: Loss = 4.96483039855957
Iteration [39813]: Loss = 4.96223258972168
Iteration [39814]: Loss = 0.6975595355033875
Iteration [39815]: Loss = 0.6981242299079895
Iteration [39816]: Loss = 4.953271865844727
Iteration [39817]: Loss = 0.6992383599281311
Iteration [39818]: Loss = 0.6997793912887573
Iteration [39819]: Loss = 0.7002223134040833
Iteration [39820]: Loss = 0.7005767822265625
Iteration [39821]: Loss = 0.7008515000343323
Iteration [39822]: Loss = 0.7010542750358582
Iteration [39823]: Loss = 0.7011922001838684
Iteration [39824]: Loss = 0.7012717723846436
Iteration [39825]: Loss = 0.701298713684082
Iteration [39826]: Loss = 0.7012783885002136
Iteration [39827]: Loss = 0.7012152075767517
Iteration [39828]: Loss = 0.7011136412620544
Iteration [39829]: Loss = 0.7009773850440979
Iteration [39830]: Loss = 4.941650867462158
Iteration [39831]: Loss = 0.7008928060531616
Iteration [39832]: Loss = 0.7009224891662598
Iteration [39833]: Loss = 0.7009047269821167
Iteration [39834]: Loss = 0.7008438110351562
Iteration [39835]: Loss = 0.7007443308830261
Iteration [39836]: Loss = 0.7006099224090576
Iteration [39837]: Loss = 0.7004443407058716
Iteration [39838]: Loss = 4.944572448730469
Iteration [39839]: Loss = 0.7003095746040344
Iteration [39840]: Loss = 0.7003180980682373
Iteration [39841]: Loss = 0.7002811431884766
Iteration [39842]: Loss = 0.7002032399177551
Iteration [39843]: Loss = 0.7000883221626282
Iteration [39844]: Loss = 0.6999402046203613
Iteration [39845]: Loss = 0.6997621059417725
Iteration [39846]: Loss = 0.6995570659637451
Iteration [39847]: Loss = 0.6993279457092285
Iteration [39848]: Loss = 0.699076771736145
Iteration [39849]: Loss = 4.9521307945251465
Iteration [39850]: Loss = 0.698796808719635
Iteration [39851]: Loss = 0.6987437009811401
Iteration [39852]: Loss = 4.952942848205566
Iteration [39853]: Loss = 0.6988019943237305
Iteration [39854]: Loss = 0.6988929510116577
Iteration [39855]: Loss = 0.6989303827285767
Iteration [39856]: Loss = 0.6989193558692932
Iteration [39857]: Loss = 0.6988649368286133
Iteration [39858]: Loss = 0.6987712979316711
Iteration [39859]: Loss = 0.6986423134803772
Iteration [39860]: Loss = 0.698481559753418
Iteration [39861]: Loss = 0.6982922554016113
Iteration [39862]: Loss = 0.6980770826339722
Iteration [39863]: Loss = 0.6978387832641602
Iteration [39864]: Loss = 0.6975798010826111
Iteration [39865]: Loss = 0.6973019242286682
Iteration [39866]: Loss = 0.6970072388648987
Iteration [39867]: Loss = 4.963213920593262
Iteration [39868]: Loss = 4.963444709777832
Iteration [39869]: Loss = 0.6968480944633484
Iteration [39870]: Loss = 0.6969788670539856
Iteration [39871]: Loss = 4.9613447189331055
Iteration [39872]: Loss = 0.6973516941070557
Iteration [39873]: Loss = 0.6975771188735962
Iteration [39874]: Loss = 0.6977355480194092
Iteration [39875]: Loss = 0.697833776473999
Iteration [39876]: Loss = 0.6978775858879089
Iteration [39877]: Loss = 0.697872519493103
Iteration [39878]: Loss = 0.6978233456611633
Iteration [39879]: Loss = 0.6977344751358032
Iteration [39880]: Loss = 4.958410739898682
Iteration [39881]: Loss = 0.6977319717407227
Iteration [39882]: Loss = 0.6977973580360413
Iteration [39883]: Loss = 0.6978117227554321
Iteration [39884]: Loss = 0.6977800130844116
Iteration [39885]: Loss = 4.9579010009765625
Iteration [39886]: Loss = 0.6978751420974731
Iteration [39887]: Loss = 0.6979820728302002
Iteration [39888]: Loss = 0.6980338096618652
Iteration [39889]: Loss = 0.6980358362197876
Iteration [39890]: Loss = 0.6979930996894836
Iteration [39891]: Loss = 0.6979098320007324
Iteration [39892]: Loss = 0.6977904438972473
Iteration [39893]: Loss = 0.6976383328437805
Iteration [39894]: Loss = 0.6974565982818604
Iteration [39895]: Loss = 0.6972485184669495
Iteration [39896]: Loss = 0.6970165371894836
Iteration [39897]: Loss = 0.6967631578445435
Iteration [39898]: Loss = 0.6964904069900513
Iteration [39899]: Loss = 0.6962003707885742
Iteration [39900]: Loss = 0.6958946585655212
Iteration [39901]: Loss = 4.969134330749512
Iteration [39902]: Loss = 0.6955227255821228
Iteration [39903]: Loss = 0.6954312324523926
Iteration [39904]: Loss = 0.6953043341636658
Iteration [39905]: Loss = 0.6951455473899841
Iteration [39906]: Loss = 0.6949583292007446
Iteration [39907]: Loss = 0.6947451233863831
Iteration [39908]: Loss = 0.6945089101791382
Iteration [39909]: Loss = 0.6942516565322876
Iteration [39910]: Loss = 4.977598667144775
Iteration [39911]: Loss = 0.6939630508422852
Iteration [39912]: Loss = 0.6939073204994202
Iteration [39913]: Loss = 0.6938127279281616
Iteration [39914]: Loss = 0.6936830282211304
Iteration [39915]: Loss = 0.693522036075592
Iteration [39916]: Loss = 0.6933326721191406
Iteration [39917]: Loss = 0.6931178569793701
Iteration [39918]: Loss = 0.6928800344467163
Iteration [39919]: Loss = 0.692621648311615
Iteration [39920]: Loss = 0.6923444271087646
Iteration [39921]: Loss = 0.6920508146286011
Iteration [39922]: Loss = 0.6917420625686646
Iteration [39923]: Loss = 0.691419780254364
Iteration [39924]: Loss = 0.6910854578018188
Iteration [39925]: Loss = 0.690740168094635
Iteration [39926]: Loss = 0.6903851628303528
Iteration [39927]: Loss = 0.6900212168693542
Iteration [39928]: Loss = 5.0006537437438965
Iteration [39929]: Loss = 0.6895521283149719
Iteration [39930]: Loss = 0.6894204616546631
Iteration [39931]: Loss = 0.6892576217651367
Iteration [39932]: Loss = 0.689067006111145
Iteration [39933]: Loss = 0.6888510584831238
Iteration [39934]: Loss = 0.6886127591133118
Iteration [39935]: Loss = 0.6883538961410522
Iteration [39936]: Loss = 0.6880768537521362
Iteration [39937]: Loss = 0.6877833604812622
Iteration [39938]: Loss = 0.6874749660491943
Iteration [39939]: Loss = 0.6871533393859863
Iteration [39940]: Loss = 0.686819851398468
Iteration [39941]: Loss = 5.017719268798828
Iteration [39942]: Loss = 0.6864034533500671
Iteration [39943]: Loss = 0.6862949132919312
Iteration [39944]: Loss = 5.019460201263428
Iteration [39945]: Loss = 0.6862626671791077
Iteration [39946]: Loss = 0.686317503452301
Iteration [39947]: Loss = 0.6863229274749756
Iteration [39948]: Loss = 5.018754005432129
Iteration [39949]: Loss = 0.6864855289459229
Iteration [39950]: Loss = 5.016920566558838
Iteration [39951]: Loss = 0.686983585357666
Iteration [39952]: Loss = 0.6872641444206238
Iteration [39953]: Loss = 0.6874728798866272
Iteration [39954]: Loss = 5.011567115783691
Iteration [39955]: Loss = 0.6879825592041016
Iteration [39956]: Loss = 5.008066177368164
Iteration [39957]: Loss = 5.005423069000244
Iteration [39958]: Loss = 0.6894379258155823
Iteration [39959]: Loss = 0.6900044679641724
Iteration [39960]: Loss = 0.6904709935188293
Iteration [39961]: Loss = 0.6908472180366516
Iteration [39962]: Loss = 0.6911419630050659
Iteration [39963]: Loss = 4.99149227142334
Iteration [39964]: Loss = 0.6917972564697266
Iteration [39965]: Loss = 0.692143976688385
Iteration [39966]: Loss = 0.692412257194519
Iteration [39967]: Loss = 0.6926094889640808
Iteration [39968]: Loss = 0.6927428245544434
Iteration [39969]: Loss = 0.6928187012672424
Iteration [39970]: Loss = 0.6928426623344421
Iteration [39971]: Loss = 0.6928197741508484
Iteration [39972]: Loss = 0.6927549839019775
Iteration [39973]: Loss = 0.6926521062850952
Iteration [39974]: Loss = 4.985355377197266
Iteration [39975]: Loss = 0.6926278471946716
Iteration [39976]: Loss = 0.6926848888397217
Iteration [39977]: Loss = 0.69269198179245
Iteration [39978]: Loss = 0.692654013633728
Iteration [39979]: Loss = 0.6925754547119141
Iteration [39980]: Loss = 4.985647201538086
Iteration [39981]: Loss = 0.6925926208496094
Iteration [39982]: Loss = 4.984545707702637
Iteration [39983]: Loss = 0.6929698586463928
Iteration [39984]: Loss = 0.6931978464126587
Iteration [39985]: Loss = 0.6933588981628418
Iteration [39986]: Loss = 4.980335712432861
Iteration [39987]: Loss = 0.6937851309776306
Iteration [39988]: Loss = 4.977288722991943
Iteration [39989]: Loss = 0.6944922804832458
Iteration [39990]: Loss = 0.6948608756065369
Iteration [39991]: Loss = 0.695148229598999
Iteration [39992]: Loss = 0.6953627467155457
Iteration [39993]: Loss = 4.9694695472717285
Iteration [39994]: Loss = 4.967525959014893
Iteration [39995]: Loss = 0.696444571018219
Iteration [39996]: Loss = 0.6969091296195984
Iteration [39997]: Loss = 0.6972829699516296
Iteration [39998]: Loss = 0.6975753307342529
Iteration [39999]: Loss = 4.957443714141846
Iteration [40000]: Loss = 0.6982244253158569
Iteration [40001]: Loss = 0.6985675096511841
Iteration [40002]: Loss = 0.6988319754600525
Iteration [40003]: Loss = 0.6990253329277039
Iteration [40004]: Loss = 0.6991548538208008
Iteration [40005]: Loss = 0.6992267966270447
Iteration [40006]: Loss = 0.6992467045783997
Iteration [40007]: Loss = 0.6992200016975403
Iteration [40008]: Loss = 0.6991510391235352
Iteration [40009]: Loss = 0.6990441679954529
Iteration [40010]: Loss = 0.6989032626152039
Iteration [40011]: Loss = 0.6987314820289612
Iteration [40012]: Loss = 0.6985321640968323
Iteration [40013]: Loss = 4.954745292663574
Iteration [40014]: Loss = 4.95457124710083
Iteration [40015]: Loss = 0.698604941368103
Iteration [40016]: Loss = 4.952172756195068
Iteration [40017]: Loss = 0.6992054581642151
Iteration [40018]: Loss = 0.6995276808738708
Iteration [40019]: Loss = 0.6997731328010559
Iteration [40020]: Loss = 0.6999495625495911
Iteration [40021]: Loss = 9.191034317016602
Iteration [40022]: Loss = 0.7006728649139404
Iteration [40023]: Loss = 0.701177179813385
Iteration [40024]: Loss = 0.7015872001647949
Iteration [40025]: Loss = 0.7019118666648865
Iteration [40026]: Loss = 0.7021597027778625
Iteration [40027]: Loss = 0.7023383378982544
Iteration [40028]: Loss = 0.7024545669555664
Iteration [40029]: Loss = 4.932775020599365
Iteration [40030]: Loss = 0.7028002142906189
Iteration [40031]: Loss = 0.7030129432678223
Iteration [40032]: Loss = 0.7031595706939697
Iteration [40033]: Loss = 0.7032472491264343
Iteration [40034]: Loss = 0.7032812237739563
Iteration [40035]: Loss = 0.7032670974731445
Iteration [40036]: Loss = 0.7032096982002258
Iteration [40037]: Loss = 0.7031130790710449
Iteration [40038]: Loss = 0.7029814720153809
Iteration [40039]: Loss = 4.9311981201171875
Iteration [40040]: Loss = 0.7029035091400146
Iteration [40041]: Loss = 0.7029356360435486
Iteration [40042]: Loss = 0.7029200196266174
Iteration [40043]: Loss = 0.7028610110282898
Iteration [40044]: Loss = 0.7027631402015686
Iteration [40045]: Loss = 4.932173252105713
Iteration [40046]: Loss = 0.7027431726455688
Iteration [40047]: Loss = 0.7027999758720398
Iteration [40048]: Loss = 0.7028064727783203
Iteration [40049]: Loss = 4.931459426879883
Iteration [40050]: Loss = 0.7029646635055542
Iteration [40051]: Loss = 0.7030973434448242
Iteration [40052]: Loss = 0.7031720876693726
Iteration [40053]: Loss = 0.7031947374343872
Iteration [40054]: Loss = 0.7031702995300293
Iteration [40055]: Loss = 0.7031034827232361
Iteration [40056]: Loss = 0.7029984593391418
Iteration [40057]: Loss = 0.7028592228889465
Iteration [40058]: Loss = 0.7026888728141785
Iteration [40059]: Loss = 0.7024909257888794
Iteration [40060]: Loss = 0.7022677659988403
Iteration [40061]: Loss = 0.702022135257721
Iteration [40062]: Loss = 0.7017562389373779
Iteration [40063]: Loss = 0.7014720439910889
Iteration [40064]: Loss = 0.7011715769767761
Iteration [40065]: Loss = 4.941409587860107
Iteration [40066]: Loss = 0.7008060812950134
Iteration [40067]: Loss = 0.7007161974906921
Iteration [40068]: Loss = 0.7005907297134399
Iteration [40069]: Loss = 0.7004330158233643
Iteration [40070]: Loss = 4.944594383239746
Iteration [40071]: Loss = 4.9442524909973145
Iteration [40072]: Loss = 0.7006029486656189
Iteration [40073]: Loss = 0.7008208632469177
Iteration [40074]: Loss = 0.700972318649292
Iteration [40075]: Loss = 0.7010642290115356
Iteration [40076]: Loss = 0.7011022567749023
Iteration [40077]: Loss = 0.7010917663574219
Iteration [40078]: Loss = 0.701037585735321
Iteration [40079]: Loss = 9.180956840515137
Iteration [40080]: Loss = 0.701366662979126
Iteration [40081]: Loss = 0.7017029523849487
Iteration [40082]: Loss = 0.7019613981246948
Iteration [40083]: Loss = 0.7021498680114746
Iteration [40084]: Loss = 0.7022751569747925
Iteration [40085]: Loss = 4.933663845062256
Iteration [40086]: Loss = 4.932145118713379
Iteration [40087]: Loss = 0.7031285166740417
Iteration [40088]: Loss = 0.7035282254219055
Iteration [40089]: Loss = 0.7038437128067017
Iteration [40090]: Loss = 0.7040833234786987
Iteration [40091]: Loss = 4.9237494468688965
Iteration [40092]: Loss = 0.7046387195587158
Iteration [40093]: Loss = 0.7049401998519897
Iteration [40094]: Loss = 0.7051669955253601
Iteration [40095]: Loss = 0.7053268551826477
Iteration [40096]: Loss = 0.7054260969161987
Iteration [40097]: Loss = 0.705470621585846
Iteration [40098]: Loss = 0.7054661512374878
Iteration [40099]: Loss = 4.9177398681640625
Iteration [40100]: Loss = 0.7056039571762085
Iteration [40101]: Loss = 0.7057273387908936
Iteration [40102]: Loss = 0.7057937383651733
Iteration [40103]: Loss = 4.9157209396362305
Iteration [40104]: Loss = 0.7060526013374329
Iteration [40105]: Loss = 0.7062274217605591
Iteration [40106]: Loss = 0.7063401937484741
Iteration [40107]: Loss = 0.7063969373703003
Iteration [40108]: Loss = 4.912656784057617
Iteration [40109]: Loss = 0.7066391706466675
Iteration [40110]: Loss = 4.910578727722168
Iteration [40111]: Loss = 0.7071875333786011
Iteration [40112]: Loss = 0.707485556602478
Iteration [40113]: Loss = 0.7077091932296753
Iteration [40114]: Loss = 0.707865834236145
Iteration [40115]: Loss = 0.7079620361328125
Iteration [40116]: Loss = 4.904428958892822
Iteration [40117]: Loss = 0.7082710862159729
Iteration [40118]: Loss = 0.7084671258926392
Iteration [40119]: Loss = 0.7085986137390137
Iteration [40120]: Loss = 0.7086722254753113
Iteration [40121]: Loss = 0.7086935639381409
Iteration [40122]: Loss = 0.7086677551269531
Iteration [40123]: Loss = 0.7085996270179749
Iteration [40124]: Loss = 0.7084930539131165
Iteration [40125]: Loss = 0.7083524465560913
Iteration [40126]: Loss = 0.7081806659698486
Iteration [40127]: Loss = 0.7079810500144958
Iteration [40128]: Loss = 0.7077564001083374
Iteration [40129]: Loss = 0.7075091600418091
Iteration [40130]: Loss = 4.908343315124512
Iteration [40131]: Loss = 0.7072319984436035
Iteration [40132]: Loss = 0.7071785926818848
Iteration [40133]: Loss = 0.7070854902267456
Iteration [40134]: Loss = 0.7069567441940308
Iteration [40135]: Loss = 4.910634994506836
Iteration [40136]: Loss = 0.7068821787834167
Iteration [40137]: Loss = 0.7069149613380432
Iteration [40138]: Loss = 0.7068995833396912
Iteration [40139]: Loss = 0.7068408727645874
Iteration [40140]: Loss = 0.7067431211471558
Iteration [40141]: Loss = 0.7066100835800171
Iteration [40142]: Loss = 0.7064455151557922
Iteration [40143]: Loss = 4.913433074951172
Iteration [40144]: Loss = 0.7063098549842834
Iteration [40145]: Loss = 0.7063167691230774
Iteration [40146]: Loss = 4.91330099105835
Iteration [40147]: Loss = 0.7064741253852844
Iteration [40148]: Loss = 0.706605851650238
Iteration [40149]: Loss = 0.7066795229911804
Iteration [40150]: Loss = 0.7067010402679443
Iteration [40151]: Loss = 9.115833282470703
Iteration [40152]: Loss = 0.7071546316146851
Iteration [40153]: Loss = 0.7075417041778564
Iteration [40154]: Loss = 0.7078458070755005
Iteration [40155]: Loss = 0.7080750465393066
Iteration [40156]: Loss = 0.708236813545227
Iteration [40157]: Loss = 0.7083379030227661
Iteration [40158]: Loss = 0.7083842754364014
Iteration [40159]: Loss = 4.902493476867676
Iteration [40160]: Loss = 0.7086073756217957
Iteration [40161]: Loss = 0.7087663412094116
Iteration [40162]: Loss = 0.7088648080825806
Iteration [40163]: Loss = 0.70890873670578
Iteration [40164]: Loss = 0.708903431892395
Iteration [40165]: Loss = 0.7088539004325867
Iteration [40166]: Loss = 0.7087646126747131
Iteration [40167]: Loss = 0.7086392045021057
Iteration [40168]: Loss = 0.7084817290306091
Iteration [40169]: Loss = 4.902935028076172
Iteration [40170]: Loss = 0.7083566784858704
Iteration [40171]: Loss = 0.7083672881126404
Iteration [40172]: Loss = 0.7083322405815125
Iteration [40173]: Loss = 0.7082558274269104
Iteration [40174]: Loss = 0.7081423401832581
Iteration [40175]: Loss = 4.9044718742370605
Iteration [40176]: Loss = 0.7080925703048706
Iteration [40177]: Loss = 0.7081354260444641
Iteration [40178]: Loss = 0.7081294059753418
Iteration [40179]: Loss = 0.7080790400505066
Iteration [40180]: Loss = 4.904504776000977
Iteration [40181]: Loss = 0.7081375122070312
Iteration [40182]: Loss = 0.7082263231277466
Iteration [40183]: Loss = 0.7082617282867432
Iteration [40184]: Loss = 0.7082486748695374
Iteration [40185]: Loss = 0.7081922292709351
Iteration [40186]: Loss = 0.7080965638160706
Iteration [40187]: Loss = 0.7079656720161438
Iteration [40188]: Loss = 0.707802951335907
Iteration [40189]: Loss = 0.7076117396354675
Iteration [40190]: Loss = 0.7073946595191956
Iteration [40191]: Loss = 0.7071546316146851
Iteration [40192]: Loss = 0.7068935632705688
Iteration [40193]: Loss = 0.7066138982772827
Iteration [40194]: Loss = 0.7063173651695251
Iteration [40195]: Loss = 0.7060056328773499
Iteration [40196]: Loss = 0.705680251121521
Iteration [40197]: Loss = 0.7053428292274475
Iteration [40198]: Loss = 0.704994261264801
Iteration [40199]: Loss = 0.7046357989311218
Iteration [40200]: Loss = 0.7042685747146606
Iteration [40201]: Loss = 0.7038933634757996
Iteration [40202]: Loss = 0.7035109996795654
Iteration [40203]: Loss = 0.7031222581863403
Iteration [40204]: Loss = 0.7027276754379272
Iteration [40205]: Loss = 4.933743953704834
Iteration [40206]: Loss = 0.7022003531455994
Iteration [40207]: Loss = 0.7020411491394043
Iteration [40208]: Loss = 0.7018531560897827
Iteration [40209]: Loss = 0.7016394734382629
Iteration [40210]: Loss = 0.7014025449752808
Iteration [40211]: Loss = 0.7011448740959167
Iteration [40212]: Loss = 0.7008684277534485
Iteration [40213]: Loss = 4.94287633895874
Iteration [40214]: Loss = 0.7005434036254883
Iteration [40215]: Loss = 4.943423271179199
Iteration [40216]: Loss = 0.7006362080574036
Iteration [40217]: Loss = 0.7007409930229187
Iteration [40218]: Loss = 0.7007911801338196
Iteration [40219]: Loss = 0.7007919549942017
Iteration [40220]: Loss = 0.7007481455802917
Iteration [40221]: Loss = 0.7006644606590271
Iteration [40222]: Loss = 0.7005445957183838
Iteration [40223]: Loss = 0.7003923058509827
Iteration [40224]: Loss = 0.7002108097076416
Iteration [40225]: Loss = 0.7000029683113098
Iteration [40226]: Loss = 0.6997714638710022
Iteration [40227]: Loss = 4.948398590087891
Iteration [40228]: Loss = 0.6995235681533813
Iteration [40229]: Loss = 0.6994836330413818
Iteration [40230]: Loss = 0.6994032859802246
Iteration [40231]: Loss = 0.6992865800857544
Iteration [40232]: Loss = 0.6991372108459473
Iteration [40233]: Loss = 0.6989583969116211
Iteration [40234]: Loss = 0.6987530589103699
Iteration [40235]: Loss = 0.698523759841919
Iteration [40236]: Loss = 4.954927444458008
Iteration [40237]: Loss = 0.6982802748680115
Iteration [40238]: Loss = 0.6982424855232239
Iteration [40239]: Loss = 0.6981640458106995
Iteration [40240]: Loss = 0.6980492472648621
Iteration [40241]: Loss = 0.6979015469551086
Iteration [40242]: Loss = 0.6977242827415466
Iteration [40243]: Loss = 0.69752037525177
Iteration [40244]: Loss = 4.960080146789551
Iteration [40245]: Loss = 0.6973204612731934
Iteration [40246]: Loss = 0.6973015069961548
Iteration [40247]: Loss = 0.6972399950027466
Iteration [40248]: Loss = 0.6971404552459717
Iteration [40249]: Loss = 0.6970065832138062
Iteration [40250]: Loss = 0.696841835975647
Iteration [40251]: Loss = 0.6966492533683777
Iteration [40252]: Loss = 0.6964315176010132
Iteration [40253]: Loss = 0.6961914300918579
Iteration [40254]: Loss = 0.6959310173988342
Iteration [40255]: Loss = 0.6956523060798645
Iteration [40256]: Loss = 0.6953572630882263
Iteration [40257]: Loss = 4.971922397613525
Iteration [40258]: Loss = 0.695002555847168
Iteration [40259]: Loss = 0.6949179172515869
Iteration [40260]: Loss = 0.694797694683075
Iteration [40261]: Loss = 4.974050521850586
Iteration [40262]: Loss = 4.973540782928467
Iteration [40263]: Loss = 4.971851825714111
Iteration [40264]: Loss = 0.695580244064331
Iteration [40265]: Loss = 0.6960040330886841
Iteration [40266]: Loss = 0.6963417530059814
Iteration [40267]: Loss = 0.6966017484664917
Iteration [40268]: Loss = 0.6967918276786804
Iteration [40269]: Loss = 0.696918785572052
Iteration [40270]: Loss = 0.6969889402389526
Iteration [40271]: Loss = 0.6970078349113464
Iteration [40272]: Loss = 0.6969805359840393
Iteration [40273]: Loss = 0.6969117522239685
Iteration [40274]: Loss = 4.962644577026367
Iteration [40275]: Loss = 0.696942925453186
Iteration [40276]: Loss = 4.9615020751953125
Iteration [40277]: Loss = 4.959903717041016
Iteration [40278]: Loss = 0.6978311538696289
Iteration [40279]: Loss = 0.6982420086860657
Iteration [40280]: Loss = 0.6985677480697632
Iteration [40281]: Loss = 4.9520745277404785
Iteration [40282]: Loss = 0.699272632598877
Iteration [40283]: Loss = 0.6996389031410217
Iteration [40284]: Loss = 0.6999243497848511
Iteration [40285]: Loss = 0.700137197971344
Iteration [40286]: Loss = 0.7002842426300049
Iteration [40287]: Loss = 0.7003723978996277
Iteration [40288]: Loss = 0.7004073262214661
Iteration [40289]: Loss = 0.7003941535949707
Iteration [40290]: Loss = 0.7003379464149475
Iteration [40291]: Loss = 0.7002426385879517
Iteration [40292]: Loss = 0.7001124620437622
Iteration [40293]: Loss = 0.699950635433197
Iteration [40294]: Loss = 4.9471330642700195
Iteration [40295]: Loss = 0.6998221278190613
Iteration [40296]: Loss = 0.6998331546783447
Iteration [40297]: Loss = 0.699798583984375
Iteration [40298]: Loss = 0.6997230052947998
Iteration [40299]: Loss = 0.6996103525161743
Iteration [40300]: Loss = 0.6994645595550537
Iteration [40301]: Loss = 4.949602127075195
Iteration [40302]: Loss = 0.6993634104728699
Iteration [40303]: Loss = 0.6993861198425293
Iteration [40304]: Loss = 0.6993622183799744
Iteration [40305]: Loss = 0.6992962956428528
Iteration [40306]: Loss = 0.6991922855377197
Iteration [40307]: Loss = 4.950830459594727
Iteration [40308]: Loss = 0.6991629004478455
Iteration [40309]: Loss = 0.6992162466049194
Iteration [40310]: Loss = 4.949963092803955
Iteration [40311]: Loss = 4.948729038238525
Iteration [40312]: Loss = 0.6998991966247559
Iteration [40313]: Loss = 0.7002546191215515
Iteration [40314]: Loss = 4.943111896514893
Iteration [40315]: Loss = 0.7010095715522766
Iteration [40316]: Loss = 0.7013970017433167
Iteration [40317]: Loss = 0.7017014026641846
Iteration [40318]: Loss = 0.7019311785697937
Iteration [40319]: Loss = 4.934964179992676
Iteration [40320]: Loss = 0.7024708390235901
Iteration [40321]: Loss = 4.931468486785889
Iteration [40322]: Loss = 0.7032627463340759
Iteration [40323]: Loss = 0.7036656737327576
Iteration [40324]: Loss = 0.7039839029312134
Iteration [40325]: Loss = 4.9238996505737305
Iteration [40326]: Loss = 0.7046741247177124
Iteration [40327]: Loss = 0.7050336003303528
Iteration [40328]: Loss = 0.7053122520446777
Iteration [40329]: Loss = 0.7055186629295349
Iteration [40330]: Loss = 0.7056596279144287
Iteration [40331]: Loss = 0.7057417035102844
Iteration [40332]: Loss = 0.7057706713676453
Iteration [40333]: Loss = 0.7057519555091858
Iteration [40334]: Loss = 0.7056900262832642
Iteration [40335]: Loss = 0.7055893540382385
Iteration [40336]: Loss = 4.917551040649414
Iteration [40337]: Loss = 0.7055636644363403
Iteration [40338]: Loss = 0.7056176066398621
Iteration [40339]: Loss = 0.7056212425231934
Iteration [40340]: Loss = 0.7055795788764954
Iteration [40341]: Loss = 4.917327880859375
Iteration [40342]: Loss = 0.7056546807289124
Iteration [40343]: Loss = 4.916014671325684
Iteration [40344]: Loss = 0.7060698866844177
Iteration [40345]: Loss = 4.913127899169922
Iteration [40346]: Loss = 0.7067597508430481
Iteration [40347]: Loss = 0.7071186304092407
Iteration [40348]: Loss = 0.7073968052864075
Iteration [40349]: Loss = 0.7076023817062378
Iteration [40350]: Loss = 0.70774245262146
Iteration [40351]: Loss = 0.707823634147644
Iteration [40352]: Loss = 0.7078517079353333
Iteration [40353]: Loss = 0.707831859588623
Iteration [40354]: Loss = 0.7077688574790955
Iteration [40355]: Loss = 0.7076669931411743
Iteration [40356]: Loss = 0.7075302004814148
Iteration [40357]: Loss = 0.7073618769645691
Iteration [40358]: Loss = 0.7071653008460999
Iteration [40359]: Loss = 0.706943154335022
Iteration [40360]: Loss = 0.7066982388496399
Iteration [40361]: Loss = 0.7064324617385864
Iteration [40362]: Loss = 0.7061482667922974
Iteration [40363]: Loss = 0.7058472037315369
Iteration [40364]: Loss = 0.7055312991142273
Iteration [40365]: Loss = 4.91885232925415
Iteration [40366]: Loss = 0.7051381468772888
Iteration [40367]: Loss = 4.9197096824646
Iteration [40368]: Loss = 4.918986797332764
Iteration [40369]: Loss = 0.7055332660675049
Iteration [40370]: Loss = 0.7058101296424866
Iteration [40371]: Loss = 4.914659023284912
Iteration [40372]: Loss = 0.7064295411109924
Iteration [40373]: Loss = 4.910827159881592
Iteration [40374]: Loss = 4.9081196784973145
Iteration [40375]: Loss = 0.7079890370368958
Iteration [40376]: Loss = 4.901483535766602
Iteration [40377]: Loss = 0.7093382477760315
Iteration [40378]: Loss = 0.7099780440330505
Iteration [40379]: Loss = 0.7105093002319336
Iteration [40380]: Loss = 0.710942804813385
Iteration [40381]: Loss = 0.7112879753112793
Iteration [40382]: Loss = 4.886291027069092
Iteration [40383]: Loss = 0.7120225429534912
Iteration [40384]: Loss = 0.7123996615409851
Iteration [40385]: Loss = 0.7126939296722412
Iteration [40386]: Loss = 0.7129136323928833
Iteration [40387]: Loss = 0.7130661010742188
Iteration [40388]: Loss = 4.8781418800354
Iteration [40389]: Loss = 0.7134703993797302
Iteration [40390]: Loss = 0.7137066125869751
Iteration [40391]: Loss = 0.7138737440109253
Iteration [40392]: Loss = 4.8739848136901855
Iteration [40393]: Loss = 0.7143031358718872
Iteration [40394]: Loss = 4.871098041534424
Iteration [40395]: Loss = 0.7150010466575623
Iteration [40396]: Loss = 0.7153621315956116
Iteration [40397]: Loss = 0.7156417965888977
Iteration [40398]: Loss = 0.7158479690551758
Iteration [40399]: Loss = 0.7159879803657532
Iteration [40400]: Loss = 0.7160685062408447
Iteration [40401]: Loss = 0.7160952091217041
Iteration [40402]: Loss = 0.7160735130310059
Iteration [40403]: Loss = 0.7160083651542664
Iteration [40404]: Loss = 0.7159036993980408
Iteration [40405]: Loss = 0.7157638669013977
Iteration [40406]: Loss = 0.7155923247337341
Iteration [40407]: Loss = 0.7153918743133545
Iteration [40408]: Loss = 0.715165913105011
Iteration [40409]: Loss = 0.7149166464805603
Iteration [40410]: Loss = 0.714646577835083
Iteration [40411]: Loss = 0.7143576741218567
Iteration [40412]: Loss = 0.7140519618988037
Iteration [40413]: Loss = 0.713731050491333
Iteration [40414]: Loss = 0.7133966088294983
Iteration [40415]: Loss = 0.7130498290061951
Iteration [40416]: Loss = 0.7126920223236084
Iteration [40417]: Loss = 0.712324321269989
Iteration [40418]: Loss = 0.7119478583335876
Iteration [40419]: Loss = 4.886240005493164
Iteration [40420]: Loss = 0.7114495635032654
Iteration [40421]: Loss = 0.7113016843795776
Iteration [40422]: Loss = 0.711122989654541
Iteration [40423]: Loss = 0.7109165787696838
Iteration [40424]: Loss = 0.7106854319572449
Iteration [40425]: Loss = 0.7104318141937256
Iteration [40426]: Loss = 0.7101579904556274
Iteration [40427]: Loss = 0.709865927696228
Iteration [40428]: Loss = 0.709557831287384
Iteration [40429]: Loss = 4.898121356964111
Iteration [40430]: Loss = 4.898417949676514
Iteration [40431]: Loss = 0.709356427192688
Iteration [40432]: Loss = 0.7094727754592896
Iteration [40433]: Loss = 4.896600723266602
Iteration [40434]: Loss = 0.7098170518875122
Iteration [40435]: Loss = 0.7100282311439514
Iteration [40436]: Loss = 4.893326759338379
Iteration [40437]: Loss = 0.7105345129966736
Iteration [40438]: Loss = 0.7108146548271179
Iteration [40439]: Loss = 0.7110215425491333
Iteration [40440]: Loss = 0.7111624479293823
Iteration [40441]: Loss = 0.7112439274787903
Iteration [40442]: Loss = 0.7112717628479004
Iteration [40443]: Loss = 0.711251437664032
Iteration [40444]: Loss = 0.711187481880188
Iteration [40445]: Loss = 0.7110844254493713
Iteration [40446]: Loss = 0.7109460830688477
Iteration [40447]: Loss = 0.7107760906219482
Iteration [40448]: Loss = 0.7105774879455566
Iteration [40449]: Loss = 4.8924078941345215
Iteration [40450]: Loss = 0.710383415222168
Iteration [40451]: Loss = 0.7103654742240906
Iteration [40452]: Loss = 0.7103036046028137
Iteration [40453]: Loss = 0.7102024555206299
Iteration [40454]: Loss = 4.893874168395996
Iteration [40455]: Loss = 0.7101752161979675
Iteration [40456]: Loss = 0.7102280855178833
Iteration [40457]: Loss = 0.7102302312850952
Iteration [40458]: Loss = 0.7101868391036987
Iteration [40459]: Loss = 0.7101020812988281
Iteration [40460]: Loss = 0.7099803686141968
Iteration [40461]: Loss = 0.7098252773284912
Iteration [40462]: Loss = 0.7096401453018188
Iteration [40463]: Loss = 0.709428071975708
Iteration [40464]: Loss = 4.898342132568359
Iteration [40465]: Loss = 0.709211528301239
Iteration [40466]: Loss = 0.7091840505599976
Iteration [40467]: Loss = 4.898740768432617
Iteration [40468]: Loss = 0.7092828750610352
Iteration [40469]: Loss = 0.7093897461891174
Iteration [40470]: Loss = 4.897069931030273
Iteration [40471]: Loss = 0.7097180485725403
Iteration [40472]: Loss = 0.7099223732948303
Iteration [40473]: Loss = 0.7100611925125122
Iteration [40474]: Loss = 0.7101407647132874
Iteration [40475]: Loss = 0.7101668119430542
Iteration [40476]: Loss = 4.8934712409973145
Iteration [40477]: Loss = 0.7103568315505981
Iteration [40478]: Loss = 0.7105025053024292
Iteration [40479]: Loss = 0.7105880379676819
Iteration [40480]: Loss = 4.891048908233643
Iteration [40481]: Loss = 4.8897223472595215
Iteration [40482]: Loss = 0.7113447785377502
Iteration [40483]: Loss = 0.7117182612419128
Iteration [40484]: Loss = 4.883973598480225
Iteration [40485]: Loss = 0.7125017642974854
Iteration [40486]: Loss = 0.7129000425338745
Iteration [40487]: Loss = 0.7132130265235901
Iteration [40488]: Loss = 0.713449239730835
Iteration [40489]: Loss = 0.7136164307594299
Iteration [40490]: Loss = 0.7137212753295898
Iteration [40491]: Loss = 0.7137699127197266
Iteration [40492]: Loss = 0.713767945766449
Iteration [40493]: Loss = 0.713720440864563
Iteration [40494]: Loss = 0.7136317491531372
Iteration [40495]: Loss = 0.7135063409805298
Iteration [40496]: Loss = 0.7133474349975586
Iteration [40497]: Loss = 4.878138065338135
Iteration [40498]: Loss = 0.7132208347320557
Iteration [40499]: Loss = 4.877771377563477
Iteration [40500]: Loss = 0.7134716510772705
Iteration [40501]: Loss = 0.7136425971984863
Iteration [40502]: Loss = 0.7137508988380432
Iteration [40503]: Loss = 0.7138025760650635
Iteration [40504]: Loss = 0.7138033509254456
Iteration [40505]: Loss = 0.7137581706047058
Iteration [40506]: Loss = 0.7136718034744263
Iteration [40507]: Loss = 0.7135481834411621
Iteration [40508]: Loss = 0.7133910059928894
Iteration [40509]: Loss = 0.7132037878036499
Iteration [40510]: Loss = 0.7129893898963928
Iteration [40511]: Loss = 0.7127504944801331
Iteration [40512]: Loss = 0.7124896049499512
Iteration [40513]: Loss = 0.7122090458869934
Iteration [40514]: Loss = 0.7119107842445374
Iteration [40515]: Loss = 0.7115963697433472
Iteration [40516]: Loss = 0.7112677097320557
Iteration [40517]: Loss = 0.7109261751174927
Iteration [40518]: Loss = 0.7105728387832642
Iteration [40519]: Loss = 4.893141746520996
Iteration [40520]: Loss = 0.7101155519485474
Iteration [40521]: Loss = 0.7099855542182922
Iteration [40522]: Loss = 0.7098230123519897
Iteration [40523]: Loss = 0.7096309065818787
Iteration [40524]: Loss = 0.7094123959541321
Iteration [40525]: Loss = 0.7091701030731201
Iteration [40526]: Loss = 4.899803638458252
Iteration [40527]: Loss = 0.7089024782180786
Iteration [40528]: Loss = 0.708853542804718
Iteration [40529]: Loss = 0.7087637782096863
Iteration [40530]: Loss = 0.7086376547813416
Iteration [40531]: Loss = 0.7084784507751465
Iteration [40532]: Loss = 0.7082895040512085
Iteration [40533]: Loss = 0.7080738544464111
Iteration [40534]: Loss = 0.7078343033790588
Iteration [40535]: Loss = 0.7075729966163635
Iteration [40536]: Loss = 4.908082485198975
Iteration [40537]: Loss = 4.908177852630615
Iteration [40538]: Loss = 0.7074902057647705
Iteration [40539]: Loss = 0.7076396346092224
Iteration [40540]: Loss = 0.707728922367096
Iteration [40541]: Loss = 0.7077637314796448
Iteration [40542]: Loss = 0.7077497243881226
Iteration [40543]: Loss = 0.7076915502548218
Iteration [40544]: Loss = 0.707593560218811
Iteration [40545]: Loss = 0.7074599266052246
Iteration [40546]: Loss = 4.9080729484558105
Iteration [40547]: Loss = 0.7073786854743958
Iteration [40548]: Loss = 0.7074092626571655
Iteration [40549]: Loss = 4.907573223114014
Iteration [40550]: Loss = 0.7076085805892944
Iteration [40551]: Loss = 0.7077586650848389
Iteration [40552]: Loss = 0.707848310470581
Iteration [40553]: Loss = 0.7078836560249329
Iteration [40554]: Loss = 0.7078698873519897
Iteration [40555]: Loss = 4.9054131507873535
Iteration [40556]: Loss = 0.7079932689666748
Iteration [40557]: Loss = 0.7081109881401062
Iteration [40558]: Loss = 0.7081716060638428
Iteration [40559]: Loss = 0.7081804275512695
Iteration [40560]: Loss = 0.7081430554389954
Iteration [40561]: Loss = 4.9041218757629395
Iteration [40562]: Loss = 0.7082258462905884
Iteration [40563]: Loss = 4.902775764465332
Iteration [40564]: Loss = 0.7086493968963623
Iteration [40565]: Loss = 0.7088949084281921
Iteration [40566]: Loss = 0.7090706825256348
Iteration [40567]: Loss = 0.7091832160949707
Iteration [40568]: Loss = 4.89810037612915
Iteration [40569]: Loss = 0.7095220685005188
Iteration [40570]: Loss = 0.7097314596176147
Iteration [40571]: Loss = 0.7098743915557861
Iteration [40572]: Loss = 0.7099573016166687
Iteration [40573]: Loss = 4.8942790031433105
Iteration [40574]: Loss = 0.7102455496788025
Iteration [40575]: Loss = 0.7104331254959106
Iteration [40576]: Loss = 4.89137077331543
Iteration [40577]: Loss = 0.7108997106552124
Iteration [40578]: Loss = 0.7111632823944092
Iteration [40579]: Loss = 4.887300968170166
Iteration [40580]: Loss = 0.7117596864700317
Iteration [40581]: Loss = 0.7120784521102905
Iteration [40582]: Loss = 0.7123198509216309
Iteration [40583]: Loss = 4.881523132324219
Iteration [40584]: Loss = 0.7128777503967285
Iteration [40585]: Loss = 0.7131800651550293
Iteration [40586]: Loss = 0.7134064435958862
Iteration [40587]: Loss = 4.876082897186279
Iteration [40588]: Loss = 0.713938295841217
Iteration [40589]: Loss = 0.7142292261123657
Iteration [40590]: Loss = 0.7144454717636108
Iteration [40591]: Loss = 0.7145941257476807
Iteration [40592]: Loss = 0.7146820425987244
Iteration [40593]: Loss = 0.7147152423858643
Iteration [40594]: Loss = 0.7146990895271301
Iteration [40595]: Loss = 4.8706488609313965
Iteration [40596]: Loss = 0.7148163318634033
Iteration [40597]: Loss = 0.7149304151535034
Iteration [40598]: Loss = 0.71498703956604
Iteration [40599]: Loss = 0.7149920463562012
Iteration [40600]: Loss = 0.7149505019187927
Iteration [40601]: Loss = 4.8694939613342285
Iteration [40602]: Loss = 0.7150242328643799
Iteration [40603]: Loss = 0.7151198387145996
Iteration [40604]: Loss = 0.7151598334312439
Iteration [40605]: Loss = 0.7151497006416321
Iteration [40606]: Loss = 0.7150946259498596
Iteration [40607]: Loss = 4.868829250335693
Iteration [40608]: Loss = 0.7151452302932739
Iteration [40609]: Loss = 0.7152307629585266
Iteration [40610]: Loss = 0.7152618169784546
Iteration [40611]: Loss = 0.7152436971664429
Iteration [40612]: Loss = 0.715181291103363
Iteration [40613]: Loss = 0.7150789499282837
Iteration [40614]: Loss = 0.7149404883384705
Iteration [40615]: Loss = 0.7147699594497681
Iteration [40616]: Loss = 4.870993614196777
Iteration [40617]: Loss = 0.7146234512329102
Iteration [40618]: Loss = 0.714625358581543
Iteration [40619]: Loss = 0.7145808935165405
Iteration [40620]: Loss = 0.7144948244094849
Iteration [40621]: Loss = 0.7143712043762207
Iteration [40622]: Loss = 0.7142139077186584
Iteration [40623]: Loss = 0.7140260934829712
Iteration [40624]: Loss = 0.7138108611106873
Iteration [40625]: Loss = 0.7135711908340454
Iteration [40626]: Loss = 0.7133092284202576
Iteration [40627]: Loss = 4.8788042068481445
Iteration [40628]: Loss = 9.044803619384766
Iteration [40629]: Loss = 0.7134968042373657
Iteration [40630]: Loss = 0.7138921618461609
Iteration [40631]: Loss = 0.7142025828361511
Iteration [40632]: Loss = 0.7144364714622498
Iteration [40633]: Loss = 0.7146013975143433
Iteration [40634]: Loss = 0.714704155921936
Iteration [40635]: Loss = 0.7147508263587952
Iteration [40636]: Loss = 0.7147470712661743
Iteration [40637]: Loss = 0.7146978378295898
Iteration [40638]: Loss = 0.7146077156066895
Iteration [40639]: Loss = 0.7144806981086731
Iteration [40640]: Loss = 0.7143204212188721
Iteration [40641]: Loss = 0.7141304016113281
Iteration [40642]: Loss = 0.7139135003089905
Iteration [40643]: Loss = 0.7136722803115845
Iteration [40644]: Loss = 0.7134094834327698
Iteration [40645]: Loss = 0.7131268978118896
Iteration [40646]: Loss = 0.7128269672393799
Iteration [40647]: Loss = 0.7125110030174255
Iteration [40648]: Loss = 0.7121808528900146
Iteration [40649]: Loss = 0.711837887763977
Iteration [40650]: Loss = 0.7114834785461426
Iteration [40651]: Loss = 0.7111188173294067
Iteration [40652]: Loss = 0.7107447981834412
Iteration [40653]: Loss = 0.7103625535964966
Iteration [40654]: Loss = 4.894350051879883
Iteration [40655]: Loss = 0.7098554968833923
Iteration [40656]: Loss = 4.895720481872559
Iteration [40657]: Loss = 0.7098010778427124
Iteration [40658]: Loss = 0.7098426222801208
Iteration [40659]: Loss = 0.7098345160484314
Iteration [40660]: Loss = 0.7097816467285156
Iteration [40661]: Loss = 0.7096884846687317
Iteration [40662]: Loss = 0.7095590233802795
Iteration [40663]: Loss = 0.7093968987464905
Iteration [40664]: Loss = 0.7092053890228271
Iteration [40665]: Loss = 0.7089874744415283
Iteration [40666]: Loss = 0.7087455987930298
Iteration [40667]: Loss = 4.901974201202393
Iteration [40668]: Loss = 0.7084789276123047
Iteration [40669]: Loss = 0.7084304690361023
Iteration [40670]: Loss = 0.7083413004875183
Iteration [40671]: Loss = 0.7082154154777527
Iteration [40672]: Loss = 4.904157638549805
Iteration [40673]: Loss = 0.7081470489501953
Iteration [40674]: Loss = 0.7081829905509949
Iteration [40675]: Loss = 0.7081699371337891
Iteration [40676]: Loss = 0.7081126570701599
Iteration [40677]: Loss = 0.7080156207084656
Iteration [40678]: Loss = 0.7078826427459717
Iteration [40679]: Loss = 0.7077174186706543
Iteration [40680]: Loss = 0.7075232863426208
Iteration [40681]: Loss = 0.707302987575531
Iteration [40682]: Loss = 0.7070591449737549
Iteration [40683]: Loss = 4.910643577575684
Iteration [40684]: Loss = 4.910665988922119
Iteration [40685]: Loss = 0.707019031047821
Iteration [40686]: Loss = 4.908658981323242
Iteration [40687]: Loss = 0.7075577974319458
Iteration [40688]: Loss = 0.7078524827957153
Iteration [40689]: Loss = 0.7080726027488708
Iteration [40690]: Loss = 0.7082253694534302
Iteration [40691]: Loss = 4.902820587158203
Iteration [40692]: Loss = 0.7086330056190491
Iteration [40693]: Loss = 0.7088716626167297
Iteration [40694]: Loss = 0.7090411186218262
Iteration [40695]: Loss = 4.898564338684082
Iteration [40696]: Loss = 0.7094771862030029
Iteration [40697]: Loss = 0.7097278833389282
Iteration [40698]: Loss = 0.709908127784729
Iteration [40699]: Loss = 4.8940839767456055
Iteration [40700]: Loss = 4.892362117767334
Iteration [40701]: Loss = 0.7108973860740662
Iteration [40702]: Loss = 0.7113339900970459
Iteration [40703]: Loss = 0.7116817235946655
Iteration [40704]: Loss = 0.7119491696357727
Iteration [40705]: Loss = 0.7121443748474121
Iteration [40706]: Loss = 0.712274432182312
Iteration [40707]: Loss = 4.882262706756592
Iteration [40708]: Loss = 4.880758762359619
Iteration [40709]: Loss = 0.7131399512290955
Iteration [40710]: Loss = 0.7135429382324219
Iteration [40711]: Loss = 0.7138599157333374
Iteration [40712]: Loss = 4.873372554779053
Iteration [40713]: Loss = 4.871112823486328
Iteration [40714]: Loss = 0.7151798009872437
Iteration [40715]: Loss = 4.865271091461182
Iteration [40716]: Loss = 0.716406524181366
Iteration [40717]: Loss = 4.858782768249512
Iteration [40718]: Loss = 0.7177518010139465
Iteration [40719]: Loss = 0.7183890342712402
Iteration [40720]: Loss = 0.7189170718193054
Iteration [40721]: Loss = 0.7193466424942017
Iteration [40722]: Loss = 0.7196875214576721
Iteration [40723]: Loss = 0.7199481725692749
Iteration [40724]: Loss = 0.7201366424560547
Iteration [40725]: Loss = 0.7202600836753845
Iteration [40726]: Loss = 0.7203248739242554
Iteration [40727]: Loss = 0.7203369140625
Iteration [40728]: Loss = 0.7203013896942139
Iteration [40729]: Loss = 0.7202228307723999
Iteration [40730]: Loss = 0.7201058864593506
Iteration [40731]: Loss = 0.7199541926383972
Iteration [40732]: Loss = 4.844871520996094
Iteration [40733]: Loss = 0.7198379635810852
Iteration [40734]: Loss = 0.7198517918586731
Iteration [40735]: Loss = 0.7198178768157959
Iteration [40736]: Loss = 0.7197411060333252
Iteration [40737]: Loss = 0.7196254730224609
Iteration [40738]: Loss = 0.7194749116897583
Iteration [40739]: Loss = 0.7192930579185486
Iteration [40740]: Loss = 4.848309516906738
Iteration [40741]: Loss = 0.7191258072853088
Iteration [40742]: Loss = 0.7191178202629089
Iteration [40743]: Loss = 4.84840202331543
Iteration [40744]: Loss = 0.7192478775978088
Iteration [40745]: Loss = 8.97441577911377
Iteration [40746]: Loss = 0.7199767231941223
Iteration [40747]: Loss = 0.7204803228378296
Iteration [40748]: Loss = 0.7208880186080933
Iteration [40749]: Loss = 0.7212091684341431
Iteration [40750]: Loss = 4.836493968963623
Iteration [40751]: Loss = 0.7218999266624451
Iteration [40752]: Loss = 0.7222570180892944
Iteration [40753]: Loss = 0.722532331943512
Iteration [40754]: Loss = 4.830202579498291
Iteration [40755]: Loss = 0.7230705618858337
Iteration [40756]: Loss = 0.7233473062515259
Iteration [40757]: Loss = 0.7235570549964905
Iteration [40758]: Loss = 0.7237063050270081
Iteration [40759]: Loss = 4.824845790863037
Iteration [40760]: Loss = 4.823455810546875
Iteration [40761]: Loss = 0.7245303392410278
Iteration [40762]: Loss = 0.7248945236206055
Iteration [40763]: Loss = 4.818020820617676
Iteration [40764]: Loss = 0.725637674331665
Iteration [40765]: Loss = 0.7260076999664307
Iteration [40766]: Loss = 0.7263011932373047
Iteration [40767]: Loss = 0.726525604724884
Iteration [40768]: Loss = 0.7266879081726074
Iteration [40769]: Loss = 0.7267941832542419
Iteration [40770]: Loss = 0.7268500328063965
Iteration [40771]: Loss = 0.7268602848052979
Iteration [40772]: Loss = 0.7268298268318176
Iteration [40773]: Loss = 0.7267622947692871
Iteration [40774]: Loss = 0.7266615629196167
Iteration [40775]: Loss = 0.7265307903289795
Iteration [40776]: Loss = 0.7263731360435486
Iteration [40777]: Loss = 4.81305456161499
Iteration [40778]: Loss = 0.7262243032455444
Iteration [40779]: Loss = 0.7262139320373535
Iteration [40780]: Loss = 0.726164698600769
Iteration [40781]: Loss = 4.813601016998291
Iteration [40782]: Loss = 0.7262009978294373
Iteration [40783]: Loss = 0.7262694835662842
Iteration [40784]: Loss = 0.726291298866272
Iteration [40785]: Loss = 0.7262710928916931
Iteration [40786]: Loss = 0.7262127995491028
Iteration [40787]: Loss = 0.7261204123497009
Iteration [40788]: Loss = 4.814009666442871
Iteration [40789]: Loss = 4.813587665557861
Iteration [40790]: Loss = 0.7263561487197876
Iteration [40791]: Loss = 0.7265622019767761
Iteration [40792]: Loss = 0.7267077565193176
Iteration [40793]: Loss = 4.810067653656006
Iteration [40794]: Loss = 0.7270769476890564
Iteration [40795]: Loss = 0.727287232875824
Iteration [40796]: Loss = 0.7274368405342102
Iteration [40797]: Loss = 0.727531373500824
Iteration [40798]: Loss = 4.806251525878906
Iteration [40799]: Loss = 0.7278130650520325
Iteration [40800]: Loss = 4.804244041442871
Iteration [40801]: Loss = 0.7283375859260559
Iteration [40802]: Loss = 0.7286138534545898
Iteration [40803]: Loss = 0.7288228869438171
Iteration [40804]: Loss = 4.799426078796387
Iteration [40805]: Loss = 0.7292996048927307
Iteration [40806]: Loss = 0.729555606842041
Iteration [40807]: Loss = 0.7297461628913879
Iteration [40808]: Loss = 0.7298773527145386
Iteration [40809]: Loss = 0.7299554944038391
Iteration [40810]: Loss = 4.7944722175598145
Iteration [40811]: Loss = 0.7302084565162659
Iteration [40812]: Loss = 0.7303690314292908
Iteration [40813]: Loss = 4.792096138000488
Iteration [40814]: Loss = 0.7307627201080322
Iteration [40815]: Loss = 0.7309831976890564
Iteration [40816]: Loss = 0.7311415672302246
Iteration [40817]: Loss = 0.7312438488006592
Iteration [40818]: Loss = 4.788094520568848
Iteration [40819]: Loss = 0.7315376996994019
Iteration [40820]: Loss = 0.7317155599594116
Iteration [40821]: Loss = 0.7318353652954102
Iteration [40822]: Loss = 0.7319030165672302
Iteration [40823]: Loss = 4.785044193267822
Iteration [40824]: Loss = 0.7321375012397766
Iteration [40825]: Loss = 0.7322899699211121
Iteration [40826]: Loss = 0.7323868870735168
Iteration [40827]: Loss = 0.7324336767196655
Iteration [40828]: Loss = 0.7324354648590088
Iteration [40829]: Loss = 0.7323965430259705
Iteration [40830]: Loss = 0.7323212027549744
Iteration [40831]: Loss = 0.7322128415107727
Iteration [40832]: Loss = 0.7320748567581177
Iteration [40833]: Loss = 0.7319101691246033
Iteration [40834]: Loss = 0.7317213416099548
Iteration [40835]: Loss = 0.7315109968185425
Iteration [40836]: Loss = 0.7312812209129333
Iteration [40837]: Loss = 0.7310339212417603
Iteration [40838]: Loss = 0.7307708859443665
Iteration [40839]: Loss = 0.7304936647415161
Iteration [40840]: Loss = 0.7302037477493286
Iteration [40841]: Loss = 4.794878959655762
Iteration [40842]: Loss = 0.7298282384872437
Iteration [40843]: Loss = 0.7297213077545166
Iteration [40844]: Loss = 4.79642915725708
Iteration [40845]: Loss = 0.7296583652496338
Iteration [40846]: Loss = 0.7296844124794006
Iteration [40847]: Loss = 4.796023368835449
Iteration [40848]: Loss = 0.7298489212989807
Iteration [40849]: Loss = 0.7299719452857971
Iteration [40850]: Loss = 0.7300423383712769
Iteration [40851]: Loss = 0.7300654649734497
Iteration [40852]: Loss = 4.794178485870361
Iteration [40853]: Loss = 0.7302247881889343
Iteration [40854]: Loss = 4.792718410491943
Iteration [40855]: Loss = 0.7306501865386963
Iteration [40856]: Loss = 0.7308843731880188
Iteration [40857]: Loss = 4.789265155792236
Iteration [40858]: Loss = 0.7314043641090393
Iteration [40859]: Loss = 0.7316784858703613
Iteration [40860]: Loss = 4.7852301597595215
Iteration [40861]: Loss = 0.7322667837142944
Iteration [40862]: Loss = 0.7325701713562012
Iteration [40863]: Loss = 0.7328029274940491
Iteration [40864]: Loss = 0.7329721450805664
Iteration [40865]: Loss = 4.779418468475342
Iteration [40866]: Loss = 0.7333804368972778
Iteration [40867]: Loss = 0.7336068749427795
Iteration [40868]: Loss = 0.7337702512741089
Iteration [40869]: Loss = 0.7338767647743225
Iteration [40870]: Loss = 0.7339321374893188
Iteration [40871]: Loss = 0.7339414358139038
Iteration [40872]: Loss = 0.733909010887146
Iteration [40873]: Loss = 0.7338392734527588
Iteration [40874]: Loss = 0.7337357401847839
Iteration [40875]: Loss = 0.7336018681526184
Iteration [40876]: Loss = 0.733440637588501
Iteration [40877]: Loss = 0.7332549095153809
Iteration [40878]: Loss = 0.7330470681190491
Iteration [40879]: Loss = 0.7328191995620728
Iteration [40880]: Loss = 0.7325735092163086
Iteration [40881]: Loss = 4.783160209655762
Iteration [40882]: Loss = 0.7322732210159302
Iteration [40883]: Loss = 4.783712387084961
Iteration [40884]: Loss = 0.7323269844055176
Iteration [40885]: Loss = 0.7324026226997375
Iteration [40886]: Loss = 0.7324301600456238
Iteration [40887]: Loss = 4.782662868499756
Iteration [40888]: Loss = 0.7325966954231262
Iteration [40889]: Loss = 0.7327203154563904
Iteration [40890]: Loss = 0.732791006565094
Iteration [40891]: Loss = 4.780725002288818
Iteration [40892]: Loss = 0.733031153678894
Iteration [40893]: Loss = 0.7331862449645996
Iteration [40894]: Loss = 0.7332853078842163
Iteration [40895]: Loss = 0.7333338260650635
Iteration [40896]: Loss = 0.7333368062973022
Iteration [40897]: Loss = 0.7332987785339355
Iteration [40898]: Loss = 0.7332238554954529
Iteration [40899]: Loss = 0.7331157922744751
Iteration [40900]: Loss = 4.779932498931885
Iteration [40901]: Loss = 0.7330504059791565
Iteration [40902]: Loss = 4.7794599533081055
Iteration [40903]: Loss = 0.7332940697669983
Iteration [40904]: Loss = 0.7334505915641785
Iteration [40905]: Loss = 0.733551025390625
Iteration [40906]: Loss = 0.7336004972457886
Iteration [40907]: Loss = 0.7336044907569885
Iteration [40908]: Loss = 0.7335672378540039
Iteration [40909]: Loss = 8.821382522583008
Iteration [40910]: Loss = 0.7338576316833496
Iteration [40911]: Loss = 0.7341455817222595
Iteration [40912]: Loss = 0.7343644499778748
Iteration [40913]: Loss = 0.7345211505889893
Iteration [40914]: Loss = 0.7346217632293701
Iteration [40915]: Loss = 0.7346717715263367
Iteration [40916]: Loss = 0.73467618227005
Iteration [40917]: Loss = 0.7346396446228027
Iteration [40918]: Loss = 0.7345662117004395
Iteration [40919]: Loss = 0.7344595193862915
Iteration [40920]: Loss = 0.7343228459358215
Iteration [40921]: Loss = 0.7341591715812683
Iteration [40922]: Loss = 0.7339712381362915
Iteration [40923]: Loss = 0.7337615489959717
Iteration [40924]: Loss = 0.7335320115089417
Iteration [40925]: Loss = 0.7332850098609924
Iteration [40926]: Loss = 0.7330219745635986
Iteration [40927]: Loss = 0.7327446341514587
Iteration [40928]: Loss = 4.782467842102051
Iteration [40929]: Loss = 4.782780170440674
Iteration [40930]: Loss = 4.782110214233398
Iteration [40931]: Loss = 0.7328481078147888
Iteration [40932]: Loss = 0.7330957055091858
Iteration [40933]: Loss = 0.7332783341407776
Iteration [40934]: Loss = 0.7334021925926208
Iteration [40935]: Loss = 0.7334733009338379
Iteration [40936]: Loss = 0.7334967851638794
Iteration [40937]: Loss = 0.7334774136543274
Iteration [40938]: Loss = 0.7334192991256714
Iteration [40939]: Loss = 0.7333264946937561
Iteration [40940]: Loss = 0.7332023978233337
Iteration [40941]: Loss = 0.7330500483512878
Iteration [40942]: Loss = 0.7328723073005676
Iteration [40943]: Loss = 8.830157279968262
Iteration [40944]: Loss = 0.7329226136207581
Iteration [40945]: Loss = 0.7331083416938782
Iteration [40946]: Loss = 0.7332354187965393
Iteration [40947]: Loss = 0.7333096265792847
Iteration [40948]: Loss = 0.7333359122276306
Iteration [40949]: Loss = 4.778278827667236
Iteration [40950]: Loss = 4.777407646179199
Iteration [40951]: Loss = 0.7338557839393616
Iteration [40952]: Loss = 0.7341364026069641
Iteration [40953]: Loss = 0.7343489527702332
Iteration [40954]: Loss = 4.772573471069336
Iteration [40955]: Loss = 4.770979881286621
Iteration [40956]: Loss = 0.7353214621543884
Iteration [40957]: Loss = 0.7357236742973328
Iteration [40958]: Loss = 0.7360455393791199
Iteration [40959]: Loss = 4.76392936706543
Iteration [40960]: Loss = 0.7367133498191833
Iteration [40961]: Loss = 0.7370498776435852
Iteration [40962]: Loss = 4.759045124053955
Iteration [40963]: Loss = 0.73774254322052
Iteration [40964]: Loss = 0.7380893230438232
Iteration [40965]: Loss = 0.7383611798286438
Iteration [40966]: Loss = 0.7385652661323547
Iteration [40967]: Loss = 0.7387086153030396
Iteration [40968]: Loss = 0.7387969493865967
Iteration [40969]: Loss = 0.7388357520103455
Iteration [40970]: Loss = 0.7388299107551575
Iteration [40971]: Loss = 0.7387839555740356
Iteration [40972]: Loss = 0.7387018799781799
Iteration [40973]: Loss = 0.7385871410369873
Iteration [40974]: Loss = 0.73844313621521
Iteration [40975]: Loss = 0.7382726669311523
Iteration [40976]: Loss = 0.7380784749984741
Iteration [40977]: Loss = 0.7378629446029663
Iteration [40978]: Loss = 0.7376281023025513
Iteration [40979]: Loss = 0.7373759746551514
Iteration [40980]: Loss = 0.7371084094047546
Iteration [40981]: Loss = 0.7368266582489014
Iteration [40982]: Loss = 0.73653244972229
Iteration [40983]: Loss = 0.7362268567085266
Iteration [40984]: Loss = 0.7359111309051514
Iteration [40985]: Loss = 0.7355862259864807
Iteration [40986]: Loss = 0.7352533340454102
Iteration [40987]: Loss = 0.7349128127098083
Iteration [40988]: Loss = 0.7345657348632812
Iteration [40989]: Loss = 4.773959636688232
Iteration [40990]: Loss = 0.734091579914093
Iteration [40991]: Loss = 0.7339417934417725
Iteration [40992]: Loss = 0.733766496181488
Iteration [40993]: Loss = 0.733568012714386
Iteration [40994]: Loss = 0.7333489656448364
Iteration [40995]: Loss = 0.7331112027168274
Iteration [40996]: Loss = 0.7328566312789917
Iteration [40997]: Loss = 0.7325870394706726
Iteration [40998]: Loss = 0.7323038578033447
Iteration [40999]: Loss = 0.7320083379745483
Iteration [41000]: Loss = 0.7317020297050476
Iteration [41001]: Loss = 0.7313857674598694
Iteration [41002]: Loss = 4.789237022399902
Iteration [41003]: Loss = 4.789701461791992
Iteration [41004]: Loss = 4.78916597366333
Iteration [41005]: Loss = 4.7877326011657715
Iteration [41006]: Loss = 0.7318304777145386
Iteration [41007]: Loss = 0.7322051525115967
Iteration [41008]: Loss = 0.7325022220611572
Iteration [41009]: Loss = 0.7327293753623962
Iteration [41010]: Loss = 0.7328935861587524
Iteration [41011]: Loss = 0.7330010533332825
Iteration [41012]: Loss = 4.779547214508057
Iteration [41013]: Loss = 0.7333035469055176
Iteration [41014]: Loss = 0.7334848642349243
Iteration [41015]: Loss = 0.7336075901985168
Iteration [41016]: Loss = 0.7336776256561279
Iteration [41017]: Loss = 0.7337002158164978
Iteration [41018]: Loss = 0.7336798310279846
Iteration [41019]: Loss = 0.7336211204528809
Iteration [41020]: Loss = 0.7335275411605835
Iteration [41021]: Loss = 0.7334027886390686
Iteration [41022]: Loss = 0.7332499027252197
Iteration [41023]: Loss = 4.779477596282959
Iteration [41024]: Loss = 4.779304027557373
Iteration [41025]: Loss = 0.7333357930183411
Iteration [41026]: Loss = 0.7335008382797241
Iteration [41027]: Loss = 0.7336089611053467
Iteration [41028]: Loss = 0.7336658239364624
Iteration [41029]: Loss = 0.7336763739585876
Iteration [41030]: Loss = 0.7336452007293701
Iteration [41031]: Loss = 0.7335767149925232
Iteration [41032]: Loss = 0.7334743142127991
Iteration [41033]: Loss = 0.7333415150642395
Iteration [41034]: Loss = 0.7331814169883728
Iteration [41035]: Loss = 0.7329966425895691
Iteration [41036]: Loss = 0.7327896356582642
Iteration [41037]: Loss = 0.7325627207756042
Iteration [41038]: Loss = 0.7323179841041565
Iteration [41039]: Loss = 0.7320569157600403
Iteration [41040]: Loss = 4.785733222961426
Iteration [41041]: Loss = 0.7317306399345398
Iteration [41042]: Loss = 0.7316443920135498
Iteration [41043]: Loss = 0.7315261960029602
Iteration [41044]: Loss = 0.7313792109489441
Iteration [41045]: Loss = 0.7312064170837402
Iteration [41046]: Loss = 0.7310104370117188
Iteration [41047]: Loss = 0.7307934165000916
Iteration [41048]: Loss = 4.791686058044434
Iteration [41049]: Loss = 0.7305424213409424
Iteration [41050]: Loss = 4.79202127456665
Iteration [41051]: Loss = 0.7306368350982666
Iteration [41052]: Loss = 4.79084587097168
Iteration [41053]: Loss = 0.7310101985931396
Iteration [41054]: Loss = 0.7312220335006714
Iteration [41055]: Loss = 0.7313725352287292
Iteration [41056]: Loss = 0.7314674854278564
Iteration [41057]: Loss = 0.7315126061439514
Iteration [41058]: Loss = 0.7315125465393066
Iteration [41059]: Loss = 0.7314720749855042
Iteration [41060]: Loss = 0.7313949465751648
Iteration [41061]: Loss = 0.7312850952148438
Iteration [41062]: Loss = 4.78882360458374
Iteration [41063]: Loss = 4.788475513458252
Iteration [41064]: Loss = 0.7314780354499817
Iteration [41065]: Loss = 0.7316726446151733
Iteration [41066]: Loss = 0.7318072319030762
Iteration [41067]: Loss = 0.7318879961967468
Iteration [41068]: Loss = 0.7319201231002808
Iteration [41069]: Loss = 0.7319085597991943
Iteration [41070]: Loss = 0.731857419013977
Iteration [41071]: Loss = 0.7317707538604736
Iteration [41072]: Loss = 0.7316522002220154
Iteration [41073]: Loss = 4.7870774269104
Iteration [41074]: Loss = 0.7315694689750671
Iteration [41075]: Loss = 0.7315870523452759
Iteration [41076]: Loss = 0.7315623760223389
Iteration [41077]: Loss = 0.7314993143081665
Iteration [41078]: Loss = 0.7314020991325378
Iteration [41079]: Loss = 0.7312740683555603
Iteration [41080]: Loss = 0.7311181426048279
Iteration [41081]: Loss = 0.730937123298645
Iteration [41082]: Loss = 0.7307335138320923
Iteration [41083]: Loss = 0.7305096387863159
Iteration [41084]: Loss = 0.7302674651145935
Iteration [41085]: Loss = 0.7300089597702026
Iteration [41086]: Loss = 0.7297356128692627
Iteration [41087]: Loss = 0.7294491529464722
Iteration [41088]: Loss = 0.7291505336761475
Iteration [41089]: Loss = 4.8000593185424805
Iteration [41090]: Loss = 0.7287614941596985
Iteration [41091]: Loss = 0.7286489605903625
Iteration [41092]: Loss = 0.7285072803497314
Iteration [41093]: Loss = 0.7283391952514648
Iteration [41094]: Loss = 0.7281474471092224
Iteration [41095]: Loss = 0.7279343008995056
Iteration [41096]: Loss = 0.7277020215988159
Iteration [41097]: Loss = 0.7274523973464966
Iteration [41098]: Loss = 0.7271872162818909
Iteration [41099]: Loss = 0.7269081473350525
Iteration [41100]: Loss = 4.810965061187744
Iteration [41101]: Loss = 0.7265528440475464
Iteration [41102]: Loss = 0.7264550924301147
Iteration [41103]: Loss = 0.7263268232345581
Iteration [41104]: Loss = 0.7261707782745361
Iteration [41105]: Loss = 0.7259901762008667
Iteration [41106]: Loss = 0.7257870435714722
Iteration [41107]: Loss = 0.7255639433860779
Iteration [41108]: Loss = 0.7253226041793823
Iteration [41109]: Loss = 0.7250649929046631
Iteration [41110]: Loss = 0.7247928977012634
Iteration [41111]: Loss = 4.821354389190674
Iteration [41112]: Loss = 0.7244500517845154
Iteration [41113]: Loss = 0.7243580222129822
Iteration [41114]: Loss = 0.7242348194122314
Iteration [41115]: Loss = 0.724083662033081
Iteration [41116]: Loss = 0.7239073514938354
Iteration [41117]: Loss = 0.7237083911895752
Iteration [41118]: Loss = 8.929290771484375
Iteration [41119]: Loss = 0.7237280607223511
Iteration [41120]: Loss = 0.7239034175872803
Iteration [41121]: Loss = 4.823755741119385
Iteration [41122]: Loss = 0.7243248224258423
Iteration [41123]: Loss = 0.7245580554008484
Iteration [41124]: Loss = 0.7247281670570374
Iteration [41125]: Loss = 0.7248412370681763
Iteration [41126]: Loss = 0.7249031662940979
Iteration [41127]: Loss = 0.724918782711029
Iteration [41128]: Loss = 0.724892795085907
Iteration [41129]: Loss = 0.7248293161392212
Iteration [41130]: Loss = 4.820245742797852
Iteration [41131]: Loss = 0.7248422503471375
Iteration [41132]: Loss = 0.7249014377593994
Iteration [41133]: Loss = 0.7249146103858948
Iteration [41134]: Loss = 0.724886417388916
Iteration [41135]: Loss = 0.7248207926750183
Iteration [41136]: Loss = 0.7247219085693359
Iteration [41137]: Loss = 4.820934295654297
Iteration [41138]: Loss = 0.7246740460395813
Iteration [41139]: Loss = 0.7247073650360107
Iteration [41140]: Loss = 0.7246972918510437
Iteration [41141]: Loss = 0.7246481776237488
Iteration [41142]: Loss = 0.724563717842102
Iteration [41143]: Loss = 4.821649074554443
Iteration [41144]: Loss = 0.724541187286377
Iteration [41145]: Loss = 0.7245853543281555
Iteration [41146]: Loss = 0.7245849967002869
Iteration [41147]: Loss = 8.917798042297363
Iteration [41148]: Loss = 0.7249404191970825
Iteration [41149]: Loss = 0.7252572178840637
Iteration [41150]: Loss = 0.7255028486251831
Iteration [41151]: Loss = 0.7256841063499451
Iteration [41152]: Loss = 4.814943313598633
Iteration [41153]: Loss = 4.8134331703186035
Iteration [41154]: Loss = 0.7265862226486206
Iteration [41155]: Loss = 4.809220790863037
Iteration [41156]: Loss = 0.7275133728981018
Iteration [41157]: Loss = 0.7279616594314575
Iteration [41158]: Loss = 4.802583694458008
Iteration [41159]: Loss = 0.7288479804992676
Iteration [41160]: Loss = 4.797922134399414
Iteration [41161]: Loss = 0.7298612594604492
Iteration [41162]: Loss = 0.7303460240364075
Iteration [41163]: Loss = 0.7307425737380981
Iteration [41164]: Loss = 0.7310596704483032
Iteration [41165]: Loss = 4.78804874420166
Iteration [41166]: Loss = 0.7317208647727966
Iteration [41167]: Loss = 0.7320551872253418
Iteration [41168]: Loss = 8.833962440490723
Iteration [41169]: Loss = 8.82690715789795
Iteration [41170]: Loss = 0.7339879870414734
Iteration [41171]: Loss = 0.7348605990409851
Iteration [41172]: Loss = 0.7356071472167969
Iteration [41173]: Loss = 0.736240029335022
Iteration [41174]: Loss = 4.761646270751953
Iteration [41175]: Loss = 0.7374389171600342
Iteration [41176]: Loss = 0.73800128698349
Iteration [41177]: Loss = 0.7384679913520813
Iteration [41178]: Loss = 0.7388479709625244
Iteration [41179]: Loss = 0.7391502857208252
Iteration [41180]: Loss = 0.7393820881843567
Iteration [41181]: Loss = 0.739550769329071
Iteration [41182]: Loss = 0.7396621704101562
Iteration [41183]: Loss = 4.747521877288818
Iteration [41184]: Loss = 0.7399682998657227
Iteration [41185]: Loss = 0.7401456832885742
Iteration [41186]: Loss = 0.7402490377426147
Iteration [41187]: Loss = 0.7403080463409424
Iteration [41188]: Loss = 0.7403272390365601
Iteration [41189]: Loss = 0.740310549736023
Iteration [41190]: Loss = 0.740261435508728
Iteration [41191]: Loss = 0.7401831746101379
Iteration [41192]: Loss = 0.740078866481781
Iteration [41193]: Loss = 4.746432781219482
Iteration [41194]: Loss = 0.7399976253509521
Iteration [41195]: Loss = 4.746169090270996
Iteration [41196]: Loss = 4.745364189147949
Iteration [41197]: Loss = 0.7404883503913879
Iteration [41198]: Loss = 0.7407368421554565
Iteration [41199]: Loss = 4.741786956787109
Iteration [41200]: Loss = 0.7412586212158203
Iteration [41201]: Loss = 0.7415236830711365
Iteration [41202]: Loss = 0.7417282462120056
Iteration [41203]: Loss = 0.7418785691261292
Iteration [41204]: Loss = 0.7419798374176025
Iteration [41205]: Loss = 0.7420369386672974
Iteration [41206]: Loss = 4.736432075500488
Iteration [41207]: Loss = 4.735592365264893
Iteration [41208]: Loss = 0.7425505518913269
Iteration [41209]: Loss = 0.7427886724472046
Iteration [41210]: Loss = 0.7429713606834412
Iteration [41211]: Loss = 0.7431039214134216
Iteration [41212]: Loss = 0.7431912422180176
Iteration [41213]: Loss = 0.7432380318641663
Iteration [41214]: Loss = 0.743247926235199
Iteration [41215]: Loss = 0.7432249784469604
Iteration [41216]: Loss = 0.7431723475456238
Iteration [41217]: Loss = 0.7430928945541382
Iteration [41218]: Loss = 0.7429893612861633
Iteration [41219]: Loss = 0.7428640723228455
Iteration [41220]: Loss = 0.742719292640686
Iteration [41221]: Loss = 0.7425569295883179
Iteration [41222]: Loss = 0.7423787117004395
Iteration [41223]: Loss = 0.7421862483024597
Iteration [41224]: Loss = 0.7419810891151428
Iteration [41225]: Loss = 0.7417641878128052
Iteration [41226]: Loss = 0.7415370941162109
Iteration [41227]: Loss = 0.7413007020950317
Iteration [41228]: Loss = 0.7410558462142944
Iteration [41229]: Loss = 0.7408033609390259
Iteration [41230]: Loss = 0.7405443787574768
Iteration [41231]: Loss = 0.7402790188789368
Iteration [41232]: Loss = 0.7400084137916565
Iteration [41233]: Loss = 0.7397328615188599
Iteration [41234]: Loss = 0.7394528985023499
Iteration [41235]: Loss = 4.750162601470947
Iteration [41236]: Loss = 0.7390660047531128
Iteration [41237]: Loss = 0.7389414310455322
Iteration [41238]: Loss = 0.7387974262237549
Iteration [41239]: Loss = 0.7386360168457031
Iteration [41240]: Loss = 0.7384587526321411
Iteration [41241]: Loss = 0.7382673025131226
Iteration [41242]: Loss = 0.7380631566047668
Iteration [41243]: Loss = 8.775114059448242
Iteration [41244]: Loss = 0.737989068031311
Iteration [41245]: Loss = 0.7380849719047546
Iteration [41246]: Loss = 0.7381396889686584
Iteration [41247]: Loss = 0.7381572723388672
Iteration [41248]: Loss = 0.7381415963172913
Iteration [41249]: Loss = 0.7380958199501038
Iteration [41250]: Loss = 0.7380229830741882
Iteration [41251]: Loss = 0.73792564868927
Iteration [41252]: Loss = 0.7378063201904297
Iteration [41253]: Loss = 0.737667441368103
Iteration [41254]: Loss = 0.7375105619430542
Iteration [41255]: Loss = 0.7373376488685608
Iteration [41256]: Loss = 4.759821891784668
Iteration [41257]: Loss = 0.737133800983429
Iteration [41258]: Loss = 0.737087070941925
Iteration [41259]: Loss = 0.737013578414917
Iteration [41260]: Loss = 0.7369157075881958
Iteration [41261]: Loss = 0.7367959022521973
Iteration [41262]: Loss = 0.7366564273834229
Iteration [41263]: Loss = 0.7364993095397949
Iteration [41264]: Loss = 4.7637786865234375
Iteration [41265]: Loss = 0.736322283744812
Iteration [41266]: Loss = 4.763965606689453
Iteration [41267]: Loss = 0.7364075779914856
Iteration [41268]: Loss = 4.76301908493042
Iteration [41269]: Loss = 4.761960983276367
Iteration [41270]: Loss = 0.7370541095733643
Iteration [41271]: Loss = 0.7373373508453369
Iteration [41272]: Loss = 0.7375609278678894
Iteration [41273]: Loss = 4.757040977478027
Iteration [41274]: Loss = 0.7380344867706299
Iteration [41275]: Loss = 0.7382765412330627
Iteration [41276]: Loss = 0.7384628653526306
Iteration [41277]: Loss = 0.7385989427566528
Iteration [41278]: Loss = 0.7386898994445801
Iteration [41279]: Loss = 0.7387399077415466
Iteration [41280]: Loss = 0.7387532591819763
Iteration [41281]: Loss = 0.7387335896492004
Iteration [41282]: Loss = 0.7386840581893921
Iteration [41283]: Loss = 0.7386077046394348
Iteration [41284]: Loss = 4.753324031829834
Iteration [41285]: Loss = 4.753030776977539
Iteration [41286]: Loss = 0.7387751340866089
Iteration [41287]: Loss = 0.7389296293258667
Iteration [41288]: Loss = 0.7390367984771729
Iteration [41289]: Loss = 0.7391017079353333
Iteration [41290]: Loss = 0.7391284108161926
Iteration [41291]: Loss = 0.7391205430030823
Iteration [41292]: Loss = 4.7505784034729
Iteration [41293]: Loss = 0.7391984462738037
Iteration [41294]: Loss = 4.74967098236084
Iteration [41295]: Loss = 0.7394893169403076
Iteration [41296]: Loss = 8.756046295166016
Iteration [41297]: Loss = 4.745569229125977
Iteration [41298]: Loss = 0.7407123446464539
Iteration [41299]: Loss = 0.7412039041519165
Iteration [41300]: Loss = 4.738515853881836
Iteration [41301]: Loss = 0.7421348094940186
Iteration [41302]: Loss = 0.7425714731216431
Iteration [41303]: Loss = 0.7429329752922058
Iteration [41304]: Loss = 0.7432270050048828
Iteration [41305]: Loss = 0.7434599995613098
Iteration [41306]: Loss = 0.7436380386352539
Iteration [41307]: Loss = 4.728326797485352
Iteration [41308]: Loss = 0.7440322637557983
Iteration [41309]: Loss = 0.7442398071289062
Iteration [41310]: Loss = 0.7443948984146118
Iteration [41311]: Loss = 0.7445025444030762
Iteration [41312]: Loss = 0.7445676326751709
Iteration [41313]: Loss = 0.7445942759513855
Iteration [41314]: Loss = 0.7445862293243408
Iteration [41315]: Loss = 0.7445470690727234
Iteration [41316]: Loss = 0.7444798350334167
Iteration [41317]: Loss = 0.7443872094154358
Iteration [41318]: Loss = 0.7442720532417297
Iteration [41319]: Loss = 0.7441361546516418
Iteration [41320]: Loss = 0.7439818978309631
Iteration [41321]: Loss = 0.7438111901283264
Iteration [41322]: Loss = 0.7436253428459167
Iteration [41323]: Loss = 0.7434261441230774
Iteration [41324]: Loss = 0.7432148456573486
Iteration [41325]: Loss = 0.7429925203323364
Iteration [41326]: Loss = 0.7427605986595154
Iteration [41327]: Loss = 0.742519736289978
Iteration [41328]: Loss = 0.7422710657119751
Iteration [41329]: Loss = 0.7420152425765991
Iteration [41330]: Loss = 0.7417531609535217
Iteration [41331]: Loss = 4.739132881164551
Iteration [41332]: Loss = 0.7413958311080933
Iteration [41333]: Loss = 4.740090847015381
Iteration [41334]: Loss = 0.7413339018821716
Iteration [41335]: Loss = 0.7413472533226013
Iteration [41336]: Loss = 0.7413276433944702
Iteration [41337]: Loss = 0.7412778735160828
Iteration [41338]: Loss = 0.7412012815475464
Iteration [41339]: Loss = 0.7411004900932312
Iteration [41340]: Loss = 0.7409778237342834
Iteration [41341]: Loss = 4.742219924926758
Iteration [41342]: Loss = 0.7408590316772461
Iteration [41343]: Loss = 0.7408485412597656
Iteration [41344]: Loss = 0.7408069968223572
Iteration [41345]: Loss = 0.7407378554344177
Iteration [41346]: Loss = 4.743133068084717
Iteration [41347]: Loss = 0.7407104969024658
Iteration [41348]: Loss = 0.7407387495040894
Iteration [41349]: Loss = 4.742710113525391
Iteration [41350]: Loss = 0.7408780455589294
Iteration [41351]: Loss = 4.7415452003479
Iteration [41352]: Loss = 0.7412179112434387
Iteration [41353]: Loss = 0.7414025664329529
Iteration [41354]: Loss = 0.7415372133255005
Iteration [41355]: Loss = 0.7416263818740845
Iteration [41356]: Loss = 0.7416748404502869
Iteration [41357]: Loss = 0.7416865825653076
Iteration [41358]: Loss = 0.7416651844978333
Iteration [41359]: Loss = 0.7416138648986816
Iteration [41360]: Loss = 0.7415359616279602
Iteration [41361]: Loss = 0.7414336204528809
Iteration [41362]: Loss = 0.741309642791748
Iteration [41363]: Loss = 0.7411660552024841
Iteration [41364]: Loss = 0.7410048246383667
Iteration [41365]: Loss = 0.740827739238739
Iteration [41366]: Loss = 4.743167877197266
Iteration [41367]: Loss = 0.7406160831451416
Iteration [41368]: Loss = 4.74350118637085
Iteration [41369]: Loss = 0.7406728863716125
Iteration [41370]: Loss = 4.74268913269043
Iteration [41371]: Loss = 0.7409462928771973
Iteration [41372]: Loss = 0.7411027550697327
Iteration [41373]: Loss = 4.7404303550720215
Iteration [41374]: Loss = 0.7414613962173462
Iteration [41375]: Loss = 0.7416541576385498
Iteration [41376]: Loss = 4.73765754699707
Iteration [41377]: Loss = 4.736334800720215
Iteration [41378]: Loss = 0.7424765229225159
Iteration [41379]: Loss = 4.732866287231445
Iteration [41380]: Loss = 0.7432544231414795
Iteration [41381]: Loss = 0.7436258792877197
Iteration [41382]: Loss = 0.7439286112785339
Iteration [41383]: Loss = 0.7441691756248474
Iteration [41384]: Loss = 0.7443537712097168
Iteration [41385]: Loss = 0.7444878816604614
Iteration [41386]: Loss = 4.724502086639404
Iteration [41387]: Loss = 0.7448075413703918
Iteration [41388]: Loss = 0.744983434677124
Iteration [41389]: Loss = 0.7451096177101135
Iteration [41390]: Loss = 0.7451913356781006
Iteration [41391]: Loss = 4.721410751342773
Iteration [41392]: Loss = 0.7454209327697754
Iteration [41393]: Loss = 4.719877243041992
Iteration [41394]: Loss = 0.7458333969116211
Iteration [41395]: Loss = 0.7460486888885498
Iteration [41396]: Loss = 0.7462105751037598
Iteration [41397]: Loss = 0.7463239431381226
Iteration [41398]: Loss = 0.7463938593864441
Iteration [41399]: Loss = 0.7464245557785034
Iteration [41400]: Loss = 0.7464197278022766
Iteration [41401]: Loss = 0.7463834285736084
Iteration [41402]: Loss = 0.7402215600013733
Iteration [41403]: Loss = 8.7235746383667
Iteration [41404]: Loss = 4.715557098388672
Iteration [41405]: Loss = 4.7137980461120605
Iteration [41406]: Loss = 0.7473395466804504
Iteration [41407]: Loss = 0.7477580308914185
Iteration [41408]: Loss = 0.7481212019920349
Iteration [41409]: Loss = 4.706500053405762
Iteration [41410]: Loss = 0.7488459348678589
Iteration [41411]: Loss = 0.7492002844810486
Iteration [41412]: Loss = 0.7471179366111755
Iteration [41413]: Loss = 0.7473477125167847
Iteration [41414]: Loss = 0.7475098371505737
Iteration [41415]: Loss = 0.7476111650466919
Iteration [41416]: Loss = 0.7476575970649719
Iteration [41417]: Loss = 0.7476547956466675
Iteration [41418]: Loss = 0.7469401359558105
Iteration [41419]: Loss = 0.7468804121017456
Iteration [41420]: Loss = 0.7467890977859497
Iteration [41421]: Loss = 0.7466694116592407
Iteration [41422]: Loss = 4.715336799621582
Iteration [41423]: Loss = 0.7386895418167114
Iteration [41424]: Loss = 0.7324832081794739
Iteration [41425]: Loss = 0.7276639938354492
Iteration [41426]: Loss = 0.7316628694534302
Iteration [41427]: Loss = 0.7265827655792236
Iteration [41428]: Loss = 0.7223303914070129
Iteration [41429]: Loss = 0.7246190309524536
Iteration [41430]: Loss = 0.7222891449928284
Iteration [41431]: Loss = 0.7127895951271057
Iteration [41432]: Loss = 0.7106260061264038
Iteration [41433]: Loss = 0.7087293863296509
Iteration [41434]: Loss = 0.7020581960678101
Iteration [41435]: Loss = 0.6998530030250549
Iteration [41436]: Loss = 4.854942321777344
Iteration [41437]: Loss = 0.7012774348258972
Iteration [41438]: Loss = 0.6885305643081665
Iteration [41439]: Loss = 4.959066867828369
Iteration [41440]: Loss = 4.839473247528076
Iteration [41441]: Loss = 0.7170550227165222
Iteration [41442]: Loss = 0.7275298833847046
Iteration [41443]: Loss = 0.7106907963752747
Iteration [41444]: Loss = 0.7121958136558533
Iteration [41445]: Loss = 0.7105498313903809
Iteration [41446]: Loss = 0.7068113684654236
Iteration [41447]: Loss = 0.6868194937705994
Iteration [41448]: Loss = 0.6895256042480469
Iteration [41449]: Loss = 4.967964172363281
Iteration [41450]: Loss = 0.702102541923523
Iteration [41451]: Loss = 0.7013120651245117
Iteration [41452]: Loss = 0.7007611393928528
Iteration [41453]: Loss = 0.6854840517044067
Iteration [41454]: Loss = 0.6846762299537659
Iteration [41455]: Loss = 0.6779261231422424
Iteration [41456]: Loss = 0.676743745803833
Iteration [41457]: Loss = 0.6774806976318359
Iteration [41458]: Loss = 0.6790927648544312
Iteration [41459]: Loss = 0.6775215864181519
Iteration [41460]: Loss = 0.6722510457038879
Iteration [41461]: Loss = 5.10569953918457
Iteration [41462]: Loss = 0.674330472946167
Iteration [41463]: Loss = 0.6798080205917358
Iteration [41464]: Loss = 0.6793698072433472
Iteration [41465]: Loss = 5.059782028198242
Iteration [41466]: Loss = 0.6804544925689697
Iteration [41467]: Loss = 0.6802976131439209
Iteration [41468]: Loss = 0.6804059743881226
Iteration [41469]: Loss = 0.6803061962127686
Iteration [41470]: Loss = 0.6800200343132019
Iteration [41471]: Loss = 0.6795674562454224
Iteration [41472]: Loss = 0.678966224193573
Iteration [41473]: Loss = 0.678232729434967
Iteration [41474]: Loss = 0.6773813366889954
Iteration [41475]: Loss = 0.6764251589775085
Iteration [41476]: Loss = 0.675375759601593
Iteration [41477]: Loss = 0.6742438077926636
Iteration [41478]: Loss = 0.6730386018753052
Iteration [41479]: Loss = 0.6717687845230103
Iteration [41480]: Loss = 0.6704419255256653
Iteration [41481]: Loss = 0.6690692901611328
Iteration [41482]: Loss = 0.667783260345459
Iteration [41483]: Loss = 5.128332614898682
Iteration [41484]: Loss = 0.6662424206733704
Iteration [41485]: Loss = 0.665891706943512
Iteration [41486]: Loss = 0.6654236912727356
Iteration [41487]: Loss = 0.663439154624939
Iteration [41488]: Loss = 0.6658948659896851
Iteration [41489]: Loss = 0.6684595942497253
Iteration [41490]: Loss = 0.667553186416626
Iteration [41491]: Loss = 0.6665693521499634
Iteration [41492]: Loss = 0.6655166149139404
Iteration [41493]: Loss = 5.140016555786133
Iteration [41494]: Loss = 0.6643635034561157
Iteration [41495]: Loss = 0.6641708016395569
Iteration [41496]: Loss = 0.663840651512146
Iteration [41497]: Loss = 0.6633872985839844
Iteration [41498]: Loss = 0.6628235578536987
Iteration [41499]: Loss = 5.152801513671875
Iteration [41500]: Loss = 0.6624404191970825
Iteration [41501]: Loss = 0.6625441908836365
Iteration [41502]: Loss = 0.6624904274940491
Iteration [41503]: Loss = 0.6622952818870544
Iteration [41504]: Loss = 0.6619733572006226
Iteration [41505]: Loss = 0.6615375280380249
Iteration [41506]: Loss = 0.6609998941421509
Iteration [41507]: Loss = 0.6603710055351257
Iteration [41508]: Loss = 0.6596603393554688
Iteration [41509]: Loss = 0.657298743724823
Iteration [41510]: Loss = 0.6564531922340393
Iteration [41511]: Loss = 0.6555495858192444
Iteration [41512]: Loss = 0.6545943021774292
Iteration [41513]: Loss = 0.6535929441452026
Iteration [41514]: Loss = 5.208400726318359
Iteration [41515]: Loss = 0.6524525880813599
Iteration [41516]: Loss = 0.6522285342216492
Iteration [41517]: Loss = 0.6518916487693787
Iteration [41518]: Loss = 0.6514801383018494
Iteration [41519]: Loss = 0.6510040760040283
Iteration [41520]: Loss = 0.6504546403884888
Iteration [41521]: Loss = 0.6498395800590515
Iteration [41522]: Loss = 0.6491657495498657
Iteration [41523]: Loss = 0.6484392881393433
Iteration [41524]: Loss = 0.6476658582687378
Iteration [41525]: Loss = 0.6468504667282104
Iteration [41526]: Loss = 0.6459976434707642
Iteration [41527]: Loss = 0.6451114416122437
Iteration [41528]: Loss = 0.6441954970359802
Iteration [41529]: Loss = 5.263436794281006
Iteration [41530]: Loss = 0.6431239247322083
Iteration [41531]: Loss = 0.6428935527801514
Iteration [41532]: Loss = 0.642572283744812
Iteration [41533]: Loss = 0.6421696543693542
Iteration [41534]: Loss = 0.6416937112808228
Iteration [41535]: Loss = 5.276045799255371
Iteration [41536]: Loss = 0.6413412094116211
Iteration [41537]: Loss = 0.6414016485214233
Iteration [41538]: Loss = 0.6413466930389404
Iteration [41539]: Loss = 0.6411880254745483
Iteration [41540]: Loss = 0.640936017036438
Iteration [41541]: Loss = 0.640600323677063
Iteration [41542]: Loss = 0.6401895880699158
Iteration [41543]: Loss = 0.639714241027832
Iteration [41544]: Loss = 0.6391895413398743
Iteration [41545]: Loss = 0.6386187076568604
Iteration [41546]: Loss = 5.294985771179199
Iteration [41547]: Loss = 5.294548988342285
Iteration [41548]: Loss = 0.6387285590171814
Iteration [41549]: Loss = 5.2877655029296875
Iteration [41550]: Loss = 0.6401895880699158
Iteration [41551]: Loss = 0.640979528427124
Iteration [41552]: Loss = 0.6421061754226685
Iteration [41553]: Loss = 0.6425619125366211
Iteration [41554]: Loss = 0.6428760886192322
Iteration [41555]: Loss = 0.6430739164352417
Iteration [41556]: Loss = 0.6431592702865601
Iteration [41557]: Loss = 0.6431431174278259
Iteration [41558]: Loss = 5.264740943908691
Iteration [41559]: Loss = 5.262056827545166
Iteration [41560]: Loss = 0.6444078087806702
Iteration [41561]: Loss = 0.6451511383056641
Iteration [41562]: Loss = 0.6457316875457764
Iteration [41563]: Loss = 5.246063709259033
Iteration [41564]: Loss = 0.6470645070075989
Iteration [41565]: Loss = 0.6477869749069214
Iteration [41566]: Loss = 0.6483502984046936
Iteration [41567]: Loss = 0.6487702131271362
Iteration [41568]: Loss = 5.228914260864258
Iteration [41569]: Loss = 0.6498224139213562
Iteration [41570]: Loss = 0.6504225134849548
Iteration [41571]: Loss = 0.6508769392967224
Iteration [41572]: Loss = 0.6512002944946289
Iteration [41573]: Loss = 0.6514054536819458
Iteration [41574]: Loss = 0.6515042781829834
Iteration [41575]: Loss = 5.214516639709473
Iteration [41576]: Loss = 0.6520043611526489
Iteration [41577]: Loss = 0.6523675918579102
Iteration [41578]: Loss = 0.652610182762146
Iteration [41579]: Loss = 0.6527439951896667
Iteration [41580]: Loss = 0.6527801752090454
Iteration [41581]: Loss = 0.6527281999588013
Iteration [41582]: Loss = 0.6525971293449402
Iteration [41583]: Loss = 0.6523948907852173
Iteration [41584]: Loss = 5.210874557495117
Iteration [41585]: Loss = 5.209412574768066
Iteration [41586]: Loss = 0.6530759930610657
Iteration [41587]: Loss = 0.6536229848861694
Iteration [41588]: Loss = 0.6540336012840271
Iteration [41589]: Loss = 0.6543217301368713
Iteration [41590]: Loss = 0.6544994711875916
Iteration [41591]: Loss = 0.6545776128768921
Iteration [41592]: Loss = 5.196633815765381
Iteration [41593]: Loss = 0.6550248265266418
Iteration [41594]: Loss = 0.6553570032119751
Iteration [41595]: Loss = 0.655575692653656
Iteration [41596]: Loss = 5.190087795257568
Iteration [41597]: Loss = 0.6562559008598328
Iteration [41598]: Loss = 0.6566844582557678
Iteration [41599]: Loss = 0.6569907665252686
Iteration [41600]: Loss = 5.1814188957214355
Iteration [41601]: Loss = 0.6578150391578674
Iteration [41602]: Loss = 0.6583022475242615
Iteration [41603]: Loss = 0.6586621999740601
Iteration [41604]: Loss = 0.6589075922966003
Iteration [41605]: Loss = 0.6590498089790344
Iteration [41606]: Loss = 0.6590990424156189
Iteration [41607]: Loss = 0.6590645909309387
Iteration [41608]: Loss = 0.6589548587799072
Iteration [41609]: Loss = 0.6587772965431213
Iteration [41610]: Loss = 0.6585389375686646
Iteration [41611]: Loss = 0.6582456827163696
Iteration [41612]: Loss = 5.177276611328125
Iteration [41613]: Loss = 0.6580471992492676
Iteration [41614]: Loss = 0.6580992341041565
Iteration [41615]: Loss = 0.6580684185028076
Iteration [41616]: Loss = 0.6579631567001343
Iteration [41617]: Loss = 0.657791018486023
Iteration [41618]: Loss = 5.179269313812256
Iteration [41619]: Loss = 0.6577941179275513
Iteration [41620]: Loss = 5.177122116088867
Iteration [41621]: Loss = 0.65848708152771
Iteration [41622]: Loss = 0.6589130759239197
Iteration [41623]: Loss = 0.6592210531234741
Iteration [41624]: Loss = 5.168514728546143
Iteration [41625]: Loss = 0.6600328683853149
Iteration [41626]: Loss = 0.6605075001716614
Iteration [41627]: Loss = 5.1602559089660645
Iteration [41628]: Loss = 0.6615989804267883
Iteration [41629]: Loss = 0.6621905565261841
Iteration [41630]: Loss = 9.637380599975586
Iteration [41631]: Loss = 0.6635197401046753
Iteration [41632]: Loss = 5.138948440551758
Iteration [41633]: Loss = 0.6659458875656128
Iteration [41634]: Loss = 0.6670967936515808
Iteration [41635]: Loss = 0.6680632829666138
Iteration [41636]: Loss = 0.66886305809021
Iteration [41637]: Loss = 0.6695128679275513
Iteration [41638]: Loss = 0.6700268983840942
Iteration [41639]: Loss = 0.6704187989234924
Iteration [41640]: Loss = 0.6707006692886353
Iteration [41641]: Loss = 0.6708832383155823
Iteration [41642]: Loss = 0.670976459980011
Iteration [41643]: Loss = 0.6709891557693481
Iteration [41644]: Loss = 0.6709293723106384
Iteration [41645]: Loss = 0.6708042621612549
Iteration [41646]: Loss = 0.6706204414367676
Iteration [41647]: Loss = 0.6703839302062988
Iteration [41648]: Loss = 0.6700998544692993
Iteration [41649]: Loss = 0.6697731018066406
Iteration [41650]: Loss = 0.669407844543457
Iteration [41651]: Loss = 0.6690081357955933
Iteration [41652]: Loss = 0.6685773730278015
Iteration [41653]: Loss = 0.668118953704834
Iteration [41654]: Loss = 5.121700763702393
Iteration [41655]: Loss = 0.6676007509231567
Iteration [41656]: Loss = 0.6674994826316833
Iteration [41657]: Loss = 0.6673378944396973
Iteration [41658]: Loss = 0.6671223640441895
Iteration [41659]: Loss = 0.6668581366539001
Iteration [41660]: Loss = 0.6665502190589905
Iteration [41661]: Loss = 0.6662029027938843
Iteration [41662]: Loss = 0.6658203601837158
Iteration [41663]: Loss = 0.6654059886932373
Iteration [41664]: Loss = 0.6649630069732666
Iteration [41665]: Loss = 0.664494514465332
Iteration [41666]: Loss = 5.14229154586792
Iteration [41667]: Loss = 0.663959264755249
Iteration [41668]: Loss = 0.6638504266738892
Iteration [41669]: Loss = 0.663683295249939
Iteration [41670]: Loss = 0.6634635329246521
Iteration [41671]: Loss = 0.6631965637207031
Iteration [41672]: Loss = 0.6628871560096741
Iteration [41673]: Loss = 0.6625396013259888
Iteration [41674]: Loss = 0.6621575951576233
Iteration [41675]: Loss = 0.6617447733879089
Iteration [41676]: Loss = 0.661304235458374
Iteration [41677]: Loss = 0.6608388423919678
Iteration [41678]: Loss = 5.163175106048584
Iteration [41679]: Loss = 0.6607553958892822
Iteration [41680]: Loss = 0.660648763179779
Iteration [41681]: Loss = 5.162409782409668
Iteration [41682]: Loss = 0.6607269048690796
Iteration [41683]: Loss = 0.6618990302085876
Iteration [41684]: Loss = 5.153915882110596
Iteration [41685]: Loss = 0.6624122262001038
Iteration [41686]: Loss = 0.6627463698387146
Iteration [41687]: Loss = 0.6629796624183655
Iteration [41688]: Loss = 0.6631220579147339
Iteration [41689]: Loss = 0.6631826162338257
Iteration [41690]: Loss = 0.6631695628166199
Iteration [41691]: Loss = 0.663090169429779
Iteration [41692]: Loss = 0.6629509925842285
Iteration [41693]: Loss = 0.6627581119537354
Iteration [41694]: Loss = 0.6625168323516846
Iteration [41695]: Loss = 0.6622322201728821
Iteration [41696]: Loss = 0.6619083285331726
Iteration [41697]: Loss = 0.6615492701530457
Iteration [41698]: Loss = 0.6611588001251221
Iteration [41699]: Loss = 5.160943508148193
Iteration [41700]: Loss = 0.6607497930526733
Iteration [41701]: Loss = 0.6606919169425964
Iteration [41702]: Loss = 0.6605729460716248
Iteration [41703]: Loss = 0.6603989005088806
Iteration [41704]: Loss = 0.6601753830909729
Iteration [41705]: Loss = 0.659907341003418
Iteration [41706]: Loss = 0.6595991849899292
Iteration [41707]: Loss = 0.6592550277709961
Iteration [41708]: Loss = 0.65887850522995
Iteration [41709]: Loss = 0.6584728956222534
Iteration [41710]: Loss = 0.6580411195755005
Iteration [41711]: Loss = 5.179110050201416
Iteration [41712]: Loss = 0.6575620770454407
Iteration [41713]: Loss = 0.6574743986129761
Iteration [41714]: Loss = 0.6573293805122375
Iteration [41715]: Loss = 0.6571327447891235
Iteration [41716]: Loss = 0.6568896174430847
Iteration [41717]: Loss = 0.6566048264503479
Iteration [41718]: Loss = 0.656282365322113
Iteration [41719]: Loss = 0.6559261083602905
Iteration [41720]: Loss = 5.190972328186035
Iteration [41721]: Loss = 0.6555748581886292
Iteration [41722]: Loss = 0.6555410623550415
Iteration [41723]: Loss = 0.6554452180862427
Iteration [41724]: Loss = 0.6552935242652893
Iteration [41725]: Loss = 0.655091404914856
Iteration [41726]: Loss = 0.6548442840576172
Iteration [41727]: Loss = 5.196692943572998
Iteration [41728]: Loss = 0.6546770930290222
Iteration [41729]: Loss = 9.736745834350586
Iteration [41730]: Loss = 0.6555498838424683
Iteration [41731]: Loss = 5.1869401931762695
Iteration [41732]: Loss = 0.6572073101997375
Iteration [41733]: Loss = 0.6580218076705933
Iteration [41734]: Loss = 0.6586930751800537
Iteration [41735]: Loss = 5.1695942878723145
Iteration [41736]: Loss = 5.164741516113281
Iteration [41737]: Loss = 0.6611893773078918
Iteration [41738]: Loss = 5.152988433837891
Iteration [41739]: Loss = 0.6633224487304688
Iteration [41740]: Loss = 0.664336621761322
Iteration [41741]: Loss = 0.6651883125305176
Iteration [41742]: Loss = 0.6658933758735657
Iteration [41743]: Loss = 0.6664660573005676
Iteration [41744]: Loss = 0.6658884882926941
Iteration [41745]: Loss = 5.129627227783203
Iteration [41746]: Loss = 0.6668931245803833
Iteration [41747]: Loss = 0.6674252152442932
Iteration [41748]: Loss = 0.6678422689437866
Iteration [41749]: Loss = 0.6681555509567261
Iteration [41750]: Loss = 0.668375551700592
Iteration [41751]: Loss = 0.6685112118721008
Iteration [41752]: Loss = 0.6685709357261658
Iteration [41753]: Loss = 0.6685623526573181
Iteration [41754]: Loss = 0.6684921979904175
Iteration [41755]: Loss = 0.6683666110038757
Iteration [41756]: Loss = 0.668191134929657
Iteration [41757]: Loss = 0.6679707169532776
Iteration [41758]: Loss = 5.121279239654541
Iteration [41759]: Loss = 0.6678268313407898
Iteration [41760]: Loss = 0.6678698658943176
Iteration [41761]: Loss = 0.6678464412689209
Iteration [41762]: Loss = 0.6677634716033936
Iteration [41763]: Loss = 0.667626678943634
Iteration [41764]: Loss = 0.6674414873123169
Iteration [41765]: Loss = 0.6672126650810242
Iteration [41766]: Loss = 0.6669447422027588
Iteration [41767]: Loss = 0.6666414737701416
Iteration [41768]: Loss = 0.6663066744804382
Iteration [41769]: Loss = 5.1312713623046875
Iteration [41770]: Loss = 0.6659674048423767
Iteration [41771]: Loss = 5.131361961364746
Iteration [41772]: Loss = 0.6662384867668152
Iteration [41773]: Loss = 0.66645747423172
Iteration [41774]: Loss = 0.6665933132171631
Iteration [41775]: Loss = 0.6661884188652039
Iteration [41776]: Loss = 0.6661818623542786
Iteration [41777]: Loss = 0.6661146879196167
Iteration [41778]: Loss = 5.130991458892822
Iteration [41779]: Loss = 0.6662290096282959
Iteration [41780]: Loss = 0.6663810014724731
Iteration [41781]: Loss = 5.128364086151123
Iteration [41782]: Loss = 0.6668680310249329
Iteration [41783]: Loss = 0.667177677154541
Iteration [41784]: Loss = 5.123055458068848
Iteration [41785]: Loss = 0.6679326295852661
Iteration [41786]: Loss = 0.6683555841445923
Iteration [41787]: Loss = 0.66867595911026
Iteration [41788]: Loss = 0.6689035892486572
Iteration [41789]: Loss = 0.6690479516983032
Iteration [41790]: Loss = 0.6691170930862427
Iteration [41791]: Loss = 0.6691185235977173
Iteration [41792]: Loss = 0.6690590977668762
Iteration [41793]: Loss = 0.6689445972442627
Iteration [41794]: Loss = 0.6687806844711304
Iteration [41795]: Loss = 0.6685725450515747
Iteration [41796]: Loss = 5.117817401885986
Iteration [41797]: Loss = 0.6684426665306091
Iteration [41798]: Loss = 0.6684889197349548
Iteration [41799]: Loss = 5.116995811462402
Iteration [41800]: Loss = 0.6687920093536377
Iteration [41801]: Loss = 0.6690218448638916
Iteration [41802]: Loss = 0.6691684126853943
Iteration [41803]: Loss = 9.556082725524902
Iteration [41804]: Loss = 0.6700219511985779
Iteration [41805]: Loss = 0.6706675291061401
Iteration [41806]: Loss = 0.6711901426315308
Iteration [41807]: Loss = 0.6716018319129944
Iteration [41808]: Loss = 0.6719134449958801
Iteration [41809]: Loss = 0.6721352934837341
Iteration [41810]: Loss = 0.6722755432128906
Iteration [41811]: Loss = 0.6723428964614868
Iteration [41812]: Loss = 0.6723441481590271
Iteration [41813]: Loss = 0.6722860336303711
Iteration [41814]: Loss = 0.6721746325492859
Iteration [41815]: Loss = 0.6720150113105774
Iteration [41816]: Loss = 0.6718121767044067
Iteration [41817]: Loss = 0.6715703010559082
Iteration [41818]: Loss = 0.6712934374809265
Iteration [41819]: Loss = 0.6709849834442139
Iteration [41820]: Loss = 0.6706482768058777
Iteration [41821]: Loss = 0.6702860593795776
Iteration [41822]: Loss = 0.6699008345603943
Iteration [41823]: Loss = 0.6694951057434082
Iteration [41824]: Loss = 0.669070839881897
Iteration [41825]: Loss = 0.668630063533783
Iteration [41826]: Loss = 0.6681743264198303
Iteration [41827]: Loss = 0.6677053570747375
Iteration [41828]: Loss = 0.6672243475914001
Iteration [41829]: Loss = 0.6667325496673584
Iteration [41830]: Loss = 0.6662312150001526
Iteration [41831]: Loss = 0.6657211780548096
Iteration [41832]: Loss = 0.6652034521102905
Iteration [41833]: Loss = 5.1384477615356445
Iteration [41834]: Loss = 5.139230251312256
Iteration [41835]: Loss = 0.6647483110427856
Iteration [41836]: Loss = 5.137322902679443
Iteration [41837]: Loss = 5.134803771972656
Iteration [41838]: Loss = 0.6660448908805847
Iteration [41839]: Loss = 5.127326965332031
Iteration [41840]: Loss = 5.122474193572998
Iteration [41841]: Loss = 0.6685917377471924
Iteration [41842]: Loss = 0.6695194840431213
Iteration [41843]: Loss = 0.6702980399131775
Iteration [41844]: Loss = 0.6709415912628174
Iteration [41845]: Loss = 0.671463668346405
Iteration [41846]: Loss = 0.6718759536743164
Iteration [41847]: Loss = 0.6721892356872559
Iteration [41848]: Loss = 0.6724135875701904
Iteration [41849]: Loss = 0.6725575923919678
Iteration [41850]: Loss = 0.6726291179656982
Iteration [41851]: Loss = 0.672635555267334
Iteration [41852]: Loss = 0.6725831031799316
Iteration [41853]: Loss = 0.6724779009819031
Iteration [41854]: Loss = 0.6723249554634094
Iteration [41855]: Loss = 0.6721294522285461
Iteration [41856]: Loss = 0.6718951463699341
Iteration [41857]: Loss = 0.6716261506080627
Iteration [41858]: Loss = 0.6713261604309082
Iteration [41859]: Loss = 0.6709980964660645
Iteration [41860]: Loss = 0.6706447005271912
Iteration [41861]: Loss = 0.6702686548233032
Iteration [41862]: Loss = 0.6698722839355469
Iteration [41863]: Loss = 0.6694576144218445
Iteration [41864]: Loss = 0.6690264940261841
Iteration [41865]: Loss = 0.6685806512832642
Iteration [41866]: Loss = 0.6681215763092041
Iteration [41867]: Loss = 0.6676505208015442
Iteration [41868]: Loss = 0.6671689748764038
Iteration [41869]: Loss = 0.6666778326034546
Iteration [41870]: Loss = 0.6661781072616577
Iteration [41871]: Loss = 0.6656708717346191
Iteration [41872]: Loss = 0.6651565432548523
Iteration [41873]: Loss = 5.138689041137695
Iteration [41874]: Loss = 0.6644961833953857
Iteration [41875]: Loss = 0.6643127202987671
Iteration [41876]: Loss = 0.6640903353691101
Iteration [41877]: Loss = 0.6638329029083252
Iteration [41878]: Loss = 0.6635438799858093
Iteration [41879]: Loss = 0.6632265448570251
Iteration [41880]: Loss = 0.6628836393356323
Iteration [41881]: Loss = 5.150762557983398
Iteration [41882]: Loss = 5.150775909423828
Iteration [41883]: Loss = 0.6628369092941284
Iteration [41884]: Loss = 0.6630697250366211
Iteration [41885]: Loss = 5.146739482879639
Iteration [41886]: Loss = 0.6636816263198853
Iteration [41887]: Loss = 0.6640385985374451
Iteration [41888]: Loss = 0.6643035411834717
Iteration [41889]: Loss = 0.6644853353500366
Iteration [41890]: Loss = 0.6645923852920532
Iteration [41891]: Loss = 0.6646319627761841
Iteration [41892]: Loss = 5.138833999633789
Iteration [41893]: Loss = 0.6649132370948792
Iteration [41894]: Loss = 0.6651288866996765
Iteration [41895]: Loss = 0.6652664542198181
Iteration [41896]: Loss = 0.6653339266777039
Iteration [41897]: Loss = 0.665337860584259
Iteration [41898]: Loss = 0.6652848720550537
Iteration [41899]: Loss = 9.606016159057617
Iteration [41900]: Loss = 0.6657723188400269
Iteration [41901]: Loss = 0.6662500500679016
Iteration [41902]: Loss = 0.6666248440742493
Iteration [41903]: Loss = 0.6669068932533264
Iteration [41904]: Loss = 0.6671051979064941
Iteration [41905]: Loss = 0.6672281622886658
Iteration [41906]: Loss = 0.667283296585083
Iteration [41907]: Loss = 0.6672772169113159
Iteration [41908]: Loss = 0.6672160029411316
Iteration [41909]: Loss = 0.6671051979064941
Iteration [41910]: Loss = 0.6669496893882751
Iteration [41911]: Loss = 0.6667540669441223
Iteration [41912]: Loss = 0.6665223240852356
Iteration [41913]: Loss = 0.6662578582763672
Iteration [41914]: Loss = 0.6659641861915588
Iteration [41915]: Loss = 0.6656442284584045
Iteration [41916]: Loss = 0.6653006672859192
Iteration [41917]: Loss = 0.6649355888366699
Iteration [41918]: Loss = 0.6645515561103821
Iteration [41919]: Loss = 0.6641502976417542
Iteration [41920]: Loss = 5.143826961517334
Iteration [41921]: Loss = 0.6636754274368286
Iteration [41922]: Loss = 0.6635676622390747
Iteration [41923]: Loss = 0.6634154319763184
Iteration [41924]: Loss = 0.6632230281829834
Iteration [41925]: Loss = 5.148040771484375
Iteration [41926]: Loss = 0.6631038784980774
Iteration [41927]: Loss = 0.6631473898887634
Iteration [41928]: Loss = 0.6631315350532532
Iteration [41929]: Loss = 0.6630618572235107
Iteration [41930]: Loss = 0.6629443168640137
Iteration [41931]: Loss = 0.6627832651138306
Iteration [41932]: Loss = 0.6625832319259644
Iteration [41933]: Loss = 0.6623479127883911
Iteration [41934]: Loss = 0.6620810031890869
Iteration [41935]: Loss = 0.6617857217788696
Iteration [41936]: Loss = 0.6614648103713989
Iteration [41937]: Loss = 5.158758163452148
Iteration [41938]: Loss = 0.6611271500587463
Iteration [41939]: Loss = 0.6610777974128723
Iteration [41940]: Loss = 0.6609785556793213
Iteration [41941]: Loss = 0.6608344912528992
Iteration [41942]: Loss = 0.6606497764587402
Iteration [41943]: Loss = 0.6604287624359131
Iteration [41944]: Loss = 0.660175085067749
Iteration [41945]: Loss = 0.6598917841911316
Iteration [41946]: Loss = 0.6595819592475891
Iteration [41947]: Loss = 0.6592483520507812
Iteration [41948]: Loss = 0.6588934063911438
Iteration [41949]: Loss = 0.6585189700126648
Iteration [41950]: Loss = 9.69383716583252
Iteration [41951]: Loss = 0.6584541201591492
Iteration [41952]: Loss = 5.172706604003906
Iteration [41953]: Loss = 5.169689178466797
Iteration [41954]: Loss = 5.165224552154541
Iteration [41955]: Loss = 0.6609957814216614
Iteration [41956]: Loss = 0.6618448495864868
Iteration [41957]: Loss = 0.662556529045105
Iteration [41958]: Loss = 0.6631442904472351
Iteration [41959]: Loss = 0.6636202335357666
Iteration [41960]: Loss = 0.6639954447746277
Iteration [41961]: Loss = 0.6642798185348511
Iteration [41962]: Loss = 0.6644821763038635
Iteration [41963]: Loss = 0.664610743522644
Iteration [41964]: Loss = 0.6646727919578552
Iteration [41965]: Loss = 0.6646749973297119
Iteration [41966]: Loss = 0.6646232008934021
Iteration [41967]: Loss = 0.6645229458808899
Iteration [41968]: Loss = 0.6643787622451782
Iteration [41969]: Loss = 0.6641952395439148
Iteration [41970]: Loss = 0.66397625207901
Iteration [41971]: Loss = 0.6637253165245056
Iteration [41972]: Loss = 0.6634459495544434
Iteration [41973]: Loss = 0.6631406545639038
Iteration [41974]: Loss = 0.6628120541572571
Iteration [41975]: Loss = 0.6624627113342285
Iteration [41976]: Loss = 0.6620944738388062
Iteration [41977]: Loss = 0.6617094874382019
Iteration [41978]: Loss = 0.6613094210624695
Iteration [41979]: Loss = 0.6608956456184387
Iteration [41980]: Loss = 0.6604697704315186
Iteration [41981]: Loss = 0.6600328683853149
Iteration [41982]: Loss = 0.6595860123634338
Iteration [41983]: Loss = 0.6591306328773499
Iteration [41984]: Loss = 0.6586671471595764
Iteration [41985]: Loss = 0.6581966280937195
Iteration [41986]: Loss = 0.6577197909355164
Iteration [41987]: Loss = 0.6572372913360596
Iteration [41988]: Loss = 0.6567497849464417
Iteration [41989]: Loss = 0.6562577486038208
Iteration [41990]: Loss = 0.6557616591453552
Iteration [41991]: Loss = 5.192585468292236
Iteration [41992]: Loss = 0.6551223397254944
Iteration [41993]: Loss = 0.6549438834190369
Iteration [41994]: Loss = 0.6547300815582275
Iteration [41995]: Loss = 5.197109222412109
Iteration [41996]: Loss = 0.6545721292495728
Iteration [41997]: Loss = 0.6545979380607605
Iteration [41998]: Loss = 0.6545684933662415
Iteration [41999]: Loss = 0.6544890999794006
Iteration [42000]: Loss = 0.6543648838996887
Iteration [42001]: Loss = 0.6542001962661743
Iteration [42002]: Loss = 0.6539990901947021
Iteration [42003]: Loss = 0.6537653207778931
Iteration [42004]: Loss = 0.6535020470619202
Iteration [42005]: Loss = 0.6532122492790222
Iteration [42006]: Loss = 5.206366539001465
Iteration [42007]: Loss = 5.206212997436523
Iteration [42008]: Loss = 0.6532546281814575
Iteration [42009]: Loss = 0.6534990668296814
Iteration [42010]: Loss = 0.6536668539047241
Iteration [42011]: Loss = 0.6537654995918274
Iteration [42012]: Loss = 5.20109224319458
Iteration [42013]: Loss = 5.199122905731201
Iteration [42014]: Loss = 0.6547460556030273
Iteration [42015]: Loss = 0.6552402973175049
Iteration [42016]: Loss = 0.6556333303451538
Iteration [42017]: Loss = 0.6559349298477173
Iteration [42018]: Loss = 5.187403678894043
Iteration [42019]: Loss = 5.184507369995117
Iteration [42020]: Loss = 5.180167198181152
Iteration [42021]: Loss = 5.174545764923096
Iteration [42022]: Loss = 0.6595486402511597
Iteration [42023]: Loss = 0.6605532169342041
Iteration [42024]: Loss = 0.6614065170288086
Iteration [42025]: Loss = 0.6621232032775879
Iteration [42026]: Loss = 0.6601395010948181
Iteration [42027]: Loss = 0.6606194972991943
Iteration [42028]: Loss = 0.6609996557235718
Iteration [42029]: Loss = 0.6612897515296936
Iteration [42030]: Loss = 0.6614989042282104
Iteration [42031]: Loss = 0.6616348028182983
Iteration [42032]: Loss = 0.661704957485199
Iteration [42033]: Loss = 5.155350685119629
Iteration [42034]: Loss = 0.6631261706352234
Iteration [42035]: Loss = 0.6633512377738953
Iteration [42036]: Loss = 5.145148754119873
Iteration [42037]: Loss = 0.6639339327812195
Iteration [42038]: Loss = 5.140766620635986
Iteration [42039]: Loss = 0.6648700833320618
Iteration [42040]: Loss = 0.6653574705123901
Iteration [42041]: Loss = 5.132399559020996
Iteration [42042]: Loss = 0.666386604309082
Iteration [42043]: Loss = 5.125781536102295
Iteration [42044]: Loss = 0.6676800847053528
Iteration [42045]: Loss = 0.6683188676834106
Iteration [42046]: Loss = 0.668842077255249
Iteration [42047]: Loss = 0.6692611575126648
Iteration [42048]: Loss = 0.6695860624313354
Iteration [42049]: Loss = 0.6698262691497803
Iteration [42050]: Loss = 0.6699901819229126
Iteration [42051]: Loss = 0.670085072517395
Iteration [42052]: Loss = 0.6701181530952454
Iteration [42053]: Loss = 0.6700952649116516
Iteration [42054]: Loss = 0.670022189617157
Iteration [42055]: Loss = 0.6699036359786987
Iteration [42056]: Loss = 5.109827518463135
Iteration [42057]: Loss = 0.6698958873748779
Iteration [42058]: Loss = 0.6699798107147217
Iteration [42059]: Loss = 0.6700030565261841
Iteration [42060]: Loss = 0.6699713468551636
Iteration [42061]: Loss = 5.109008312225342
Iteration [42062]: Loss = 0.6701112985610962
Iteration [42063]: Loss = 0.6702580451965332
Iteration [42064]: Loss = 0.6703376173973083
Iteration [42065]: Loss = 0.6703569889068604
Iteration [42066]: Loss = 0.670322060585022
Iteration [42067]: Loss = 0.6702379584312439
Iteration [42068]: Loss = 0.6701099276542664
Iteration [42069]: Loss = 0.669942319393158
Iteration [42070]: Loss = 5.109858989715576
Iteration [42071]: Loss = 0.6698499321937561
Iteration [42072]: Loss = 5.1089677810668945
Iteration [42073]: Loss = 5.107086658477783
Iteration [42074]: Loss = 0.6708253026008606
Iteration [42075]: Loss = 0.6713070273399353
Iteration [42076]: Loss = 5.098935127258301
Iteration [42077]: Loss = 0.6723217964172363
Iteration [42078]: Loss = 0.6728401184082031
Iteration [42079]: Loss = 5.09019660949707
Iteration [42080]: Loss = 0.6739168167114258
Iteration [42081]: Loss = 0.6744610667228699
Iteration [42082]: Loss = 0.6748990416526794
Iteration [42083]: Loss = 0.6752412915229797
Iteration [42084]: Loss = 5.077743053436279
Iteration [42085]: Loss = 5.074872016906738
Iteration [42086]: Loss = 0.6767691373825073
Iteration [42087]: Loss = 0.6773958802223206
Iteration [42088]: Loss = 0.677908182144165
Iteration [42089]: Loss = 0.6783174276351929
Iteration [42090]: Loss = 0.6786336302757263
Iteration [42091]: Loss = 5.059157371520996
Iteration [42092]: Loss = 0.6793617010116577
Iteration [42093]: Loss = 5.0542731285095215
Iteration [42094]: Loss = 0.6803960204124451
Iteration [42095]: Loss = 0.6809203624725342
Iteration [42096]: Loss = 0.6813402771949768
Iteration [42097]: Loss = 0.6816661953926086
Iteration [42098]: Loss = 0.6819071769714355
Iteration [42099]: Loss = 9.401148796081543
Iteration [42100]: Loss = 0.6828325986862183
Iteration [42101]: Loss = 0.6834666728973389
Iteration [42102]: Loss = 0.683975100517273
Iteration [42103]: Loss = 0.6843767166137695
Iteration [42104]: Loss = 0.6846882700920105
Iteration [42105]: Loss = 0.6849187016487122
Iteration [42106]: Loss = 5.025285243988037
Iteration [42107]: Loss = 0.6854884624481201
Iteration [42108]: Loss = 0.6858099699020386
Iteration [42109]: Loss = 0.6860492825508118
Iteration [42110]: Loss = 0.6862144470214844
Iteration [42111]: Loss = 0.6863126754760742
Iteration [42112]: Loss = 0.6863507032394409
Iteration [42113]: Loss = 0.6863345503807068
Iteration [42114]: Loss = 0.6862695813179016
Iteration [42115]: Loss = 0.6861605048179626
Iteration [42116]: Loss = 0.6860119104385376
Iteration [42117]: Loss = 0.6858276724815369
Iteration [42118]: Loss = 0.6856113076210022
Iteration [42119]: Loss = 0.6853659749031067
Iteration [42120]: Loss = 0.6850947737693787
Iteration [42121]: Loss = 0.6848002076148987
Iteration [42122]: Loss = 0.684484601020813
Iteration [42123]: Loss = 0.684150218963623
Iteration [42124]: Loss = 0.683798611164093
Iteration [42125]: Loss = 5.03420352935791
Iteration [42126]: Loss = 0.6833760738372803
Iteration [42127]: Loss = 0.6832753419876099
Iteration [42128]: Loss = 0.6831345558166504
Iteration [42129]: Loss = 0.6829575300216675
Iteration [42130]: Loss = 0.6827479004859924
Iteration [42131]: Loss = 5.039226055145264
Iteration [42132]: Loss = 5.038907527923584
Iteration [42133]: Loss = 0.6828917264938354
Iteration [42134]: Loss = 0.6831340789794922
Iteration [42135]: Loss = 0.683302104473114
Iteration [42136]: Loss = 0.6834033131599426
Iteration [42137]: Loss = 0.6834444403648376
Iteration [42138]: Loss = 0.6834312677383423
Iteration [42139]: Loss = 0.6833694577217102
Iteration [42140]: Loss = 0.6832635402679443
Iteration [42141]: Loss = 5.035909652709961
Iteration [42142]: Loss = 0.6832594871520996
Iteration [42143]: Loss = 0.6833367943763733
Iteration [42144]: Loss = 0.6833563446998596
Iteration [42145]: Loss = 0.6833238005638123
Iteration [42146]: Loss = 0.683244526386261
Iteration [42147]: Loss = 0.6831231117248535
Iteration [42148]: Loss = 0.6829636693000793
Iteration [42149]: Loss = 0.6827699542045593
Iteration [42150]: Loss = 0.6825456619262695
Iteration [42151]: Loss = 0.6822936534881592
Iteration [42152]: Loss = 0.6820166707038879
Iteration [42153]: Loss = 0.6817173361778259
Iteration [42154]: Loss = 0.6813977956771851
Iteration [42155]: Loss = 0.6810601949691772
Iteration [42156]: Loss = 0.6807064414024353
Iteration [42157]: Loss = 0.6803379058837891
Iteration [42158]: Loss = 0.6799564361572266
Iteration [42159]: Loss = 0.6795628666877747
Iteration [42160]: Loss = 5.057547569274902
Iteration [42161]: Loss = 0.6790696978569031
Iteration [42162]: Loss = 0.678939700126648
Iteration [42163]: Loss = 5.059669494628906
Iteration [42164]: Loss = 0.678895890712738
Iteration [42165]: Loss = 0.678956925868988
Iteration [42166]: Loss = 0.6789623498916626
Iteration [42167]: Loss = 0.6789173483848572
Iteration [42168]: Loss = 0.6788272857666016
Iteration [42169]: Loss = 0.6786965727806091
Iteration [42170]: Loss = 0.6785290241241455
Iteration [42171]: Loss = 9.44589614868164
Iteration [42172]: Loss = 0.6787381172180176
Iteration [42173]: Loss = 0.6790580153465271
Iteration [42174]: Loss = 0.6792970895767212
Iteration [42175]: Loss = 5.055877208709717
Iteration [42176]: Loss = 0.6798810958862305
Iteration [42177]: Loss = 5.051793098449707
Iteration [42178]: Loss = 0.6807697415351868
Iteration [42179]: Loss = 0.6812267899513245
Iteration [42180]: Loss = 5.044240951538086
Iteration [42181]: Loss = 0.6821819543838501
Iteration [42182]: Loss = 0.6826668381690979
Iteration [42183]: Loss = 0.683054506778717
Iteration [42184]: Loss = 5.034623622894287
Iteration [42185]: Loss = 0.6838904619216919
Iteration [42186]: Loss = 0.6843240261077881
Iteration [42187]: Loss = 0.6846655011177063
Iteration [42188]: Loss = 0.6849238872528076
Iteration [42189]: Loss = 0.6851073503494263
Iteration [42190]: Loss = 5.0244879722595215
Iteration [42191]: Loss = 0.6855932474136353
Iteration [42192]: Loss = 0.6858773231506348
Iteration [42193]: Loss = 0.6860837936401367
Iteration [42194]: Loss = 0.6862205862998962
Iteration [42195]: Loss = 0.686294436454773
Iteration [42196]: Loss = 0.6863114833831787
Iteration [42197]: Loss = 5.018786907196045
Iteration [42198]: Loss = 0.68651282787323
Iteration [42199]: Loss = 0.6866755485534668
Iteration [42200]: Loss = 0.6867727041244507
Iteration [42201]: Loss = 0.6868108510971069
Iteration [42202]: Loss = 0.686795711517334
Iteration [42203]: Loss = 0.686732828617096
Iteration [42204]: Loss = 5.016901969909668
Iteration [42205]: Loss = 0.6867973804473877
Iteration [42206]: Loss = 5.015420436859131
Iteration [42207]: Loss = 0.6872603297233582
Iteration [42208]: Loss = 5.012012004852295
Iteration [42209]: Loss = 0.688044548034668
Iteration [42210]: Loss = 9.325666427612305
Iteration [42211]: Loss = 0.6893891096115112
Iteration [42212]: Loss = 0.6901823282241821
Iteration [42213]: Loss = 0.690848171710968
Iteration [42214]: Loss = 0.6913993954658508
Iteration [42215]: Loss = 0.6918469667434692
Iteration [42216]: Loss = 0.6922013163566589
Iteration [42217]: Loss = 0.6924712657928467
Iteration [42218]: Loss = 0.6926654577255249
Iteration [42219]: Loss = 0.6927911639213562
Iteration [42220]: Loss = 0.6928552389144897
Iteration [42221]: Loss = 4.983500957489014
Iteration [42222]: Loss = 0.6931320428848267
Iteration [42223]: Loss = 0.6922721266746521
Iteration [42224]: Loss = 0.6923797726631165
Iteration [42225]: Loss = 0.6924341320991516
Iteration [42226]: Loss = 4.985754013061523
Iteration [42227]: Loss = 0.6926723718643188
Iteration [42228]: Loss = 0.692838728427887
Iteration [42229]: Loss = 0.6929457783699036
Iteration [42230]: Loss = 0.6929996013641357
Iteration [42231]: Loss = 0.6930055618286133
Iteration [42232]: Loss = 0.6929681897163391
Iteration [42233]: Loss = 0.6928919553756714
Iteration [42234]: Loss = 0.6927804350852966
Iteration [42235]: Loss = 0.69263756275177
Iteration [42236]: Loss = 4.985616683959961
Iteration [42237]: Loss = 0.6925387978553772
Iteration [42238]: Loss = 0.692561686038971
Iteration [42239]: Loss = 0.692539632320404
Iteration [42240]: Loss = 0.6924772262573242
Iteration [42241]: Loss = 0.6923782229423523
Iteration [42242]: Loss = 0.692246675491333
Iteration [42243]: Loss = 0.6920855045318604
Iteration [42244]: Loss = 0.6918978095054626
Iteration [42245]: Loss = 0.6916862726211548
Iteration [42246]: Loss = 0.6914530992507935
Iteration [42247]: Loss = 0.6912007331848145
Iteration [42248]: Loss = 0.6909308433532715
Iteration [42249]: Loss = 0.6906453967094421
Iteration [42250]: Loss = 0.6903456449508667
Iteration [42251]: Loss = 0.690033495426178
Iteration [42252]: Loss = 0.6897098422050476
Iteration [42253]: Loss = 0.6893759369850159
Iteration [42254]: Loss = 5.003958702087402
Iteration [42255]: Loss = 0.6889528036117554
Iteration [42256]: Loss = 0.6888378858566284
Iteration [42257]: Loss = 0.6886922717094421
Iteration [42258]: Loss = 0.6885187029838562
Iteration [42259]: Loss = 0.6883201003074646
Iteration [42260]: Loss = 0.6880987882614136
Iteration [42261]: Loss = 0.6878571510314941
Iteration [42262]: Loss = 5.011673450469971
Iteration [42263]: Loss = 0.6875916719436646
Iteration [42264]: Loss = 0.6875443458557129
Iteration [42265]: Loss = 0.6874592900276184
Iteration [42266]: Loss = 0.6873404383659363
Iteration [42267]: Loss = 0.6871912479400635
Iteration [42268]: Loss = 0.6870145201683044
Iteration [42269]: Loss = 0.6868130564689636
Iteration [42270]: Loss = 5.017103672027588
Iteration [42271]: Loss = 0.6866164207458496
Iteration [42272]: Loss = 0.686598539352417
Iteration [42273]: Loss = 0.6865401864051819
Iteration [42274]: Loss = 0.6864453554153442
Iteration [42275]: Loss = 0.6863177418708801
Iteration [42276]: Loss = 0.6861605644226074
Iteration [42277]: Loss = 0.6859769225120544
Iteration [42278]: Loss = 0.6857693195343018
Iteration [42279]: Loss = 0.6855401396751404
Iteration [42280]: Loss = 0.6852916479110718
Iteration [42281]: Loss = 0.685025691986084
Iteration [42282]: Loss = 0.6847440600395203
Iteration [42283]: Loss = 0.6844483017921448
Iteration [42284]: Loss = 0.6841399669647217
Iteration [42285]: Loss = 0.6838201880455017
Iteration [42286]: Loss = 0.6834901571273804
Iteration [42287]: Loss = 0.6831509470939636
Iteration [42288]: Loss = 0.6828035116195679
Iteration [42289]: Loss = 0.6824486255645752
Iteration [42290]: Loss = 0.6820870637893677
Iteration [42291]: Loss = 0.6817196607589722
Iteration [42292]: Loss = 0.6813467144966125
Iteration [42293]: Loss = 5.047630310058594
Iteration [42294]: Loss = 0.6808596253395081
Iteration [42295]: Loss = 5.048997402191162
Iteration [42296]: Loss = 0.6808217167854309
Iteration [42297]: Loss = 0.6808723211288452
Iteration [42298]: Loss = 0.6808760762214661
Iteration [42299]: Loss = 0.6808375120162964
Iteration [42300]: Loss = 5.048768520355225
Iteration [42301]: Loss = 0.6809206604957581
Iteration [42302]: Loss = 0.6810227036476135
Iteration [42303]: Loss = 0.6810728311538696
Iteration [42304]: Loss = 0.6810760498046875
Iteration [42305]: Loss = 0.681037187576294
Iteration [42306]: Loss = 0.6809602379798889
Iteration [42307]: Loss = 0.680849015712738
Iteration [42308]: Loss = 0.6807070970535278
Iteration [42309]: Loss = 0.6805374026298523
Iteration [42310]: Loss = 0.6803426742553711
Iteration [42311]: Loss = 9.424367904663086
Iteration [42312]: Loss = 5.050598621368408
Iteration [42313]: Loss = 0.6809223294258118
Iteration [42314]: Loss = 0.681327760219574
Iteration [42315]: Loss = 0.6816515922546387
Iteration [42316]: Loss = 0.6819018721580505
Iteration [42317]: Loss = 0.6820858716964722
Iteration [42318]: Loss = 0.6822101473808289
Iteration [42319]: Loss = 0.6822807192802429
Iteration [42320]: Loss = 0.6823026537895203
Iteration [42321]: Loss = 0.682280957698822
Iteration [42322]: Loss = 0.6822200417518616
Iteration [42323]: Loss = 0.682123601436615
Iteration [42324]: Loss = 0.6819952726364136
Iteration [42325]: Loss = 0.6818382740020752
Iteration [42326]: Loss = 9.406105995178223
Iteration [42327]: Loss = 0.6819807887077332
Iteration [42328]: Loss = 0.6822329759597778
Iteration [42329]: Loss = 5.0397162437438965
Iteration [42330]: Loss = 5.03759241104126
Iteration [42331]: Loss = 5.034477233886719
Iteration [42332]: Loss = 0.6841177344322205
Iteration [42333]: Loss = 0.6847401261329651
Iteration [42334]: Loss = 0.685259997844696
Iteration [42335]: Loss = 0.6856873035430908
Iteration [42336]: Loss = 0.6860311031341553
Iteration [42337]: Loss = 0.6862995624542236
Iteration [42338]: Loss = 0.6865001916885376
Iteration [42339]: Loss = 0.6866399049758911
Iteration [42340]: Loss = 0.6867244243621826
Iteration [42341]: Loss = 0.6867592334747314
Iteration [42342]: Loss = 0.6867494583129883
Iteration [42343]: Loss = 0.6866993308067322
Iteration [42344]: Loss = 0.6866129040718079
Iteration [42345]: Loss = 0.6864939332008362
Iteration [42346]: Loss = 5.018420696258545
Iteration [42347]: Loss = 0.6864344477653503
Iteration [42348]: Loss = 0.6864733099937439
Iteration [42349]: Loss = 0.686467170715332
Iteration [42350]: Loss = 0.6864203214645386
Iteration [42351]: Loss = 0.6863370537757874
Iteration [42352]: Loss = 0.6862208247184753
Iteration [42353]: Loss = 0.68607497215271
Iteration [42354]: Loss = 0.6859022974967957
Iteration [42355]: Loss = 0.6857057213783264
Iteration [42356]: Loss = 0.6854874491691589
Iteration [42357]: Loss = 0.6852498054504395
Iteration [42358]: Loss = 0.6849946975708008
Iteration [42359]: Loss = 0.6847238540649414
Iteration [42360]: Loss = 0.6844387650489807
Iteration [42361]: Loss = 5.030352592468262
Iteration [42362]: Loss = 0.6840965747833252
Iteration [42363]: Loss = 0.6840155720710754
Iteration [42364]: Loss = 0.6839015483856201
Iteration [42365]: Loss = 0.6837577223777771
Iteration [42366]: Loss = 0.6835871934890747
Iteration [42367]: Loss = 0.6833925843238831
Iteration [42368]: Loss = 0.6831762194633484
Iteration [42369]: Loss = 0.6829403638839722
Iteration [42370]: Loss = 5.03825569152832
Iteration [42371]: Loss = 0.6826827526092529
Iteration [42372]: Loss = 0.6826380491256714
Iteration [42373]: Loss = 0.6825565099716187
Iteration [42374]: Loss = 0.6824422478675842
Iteration [42375]: Loss = 0.6822984218597412
Iteration [42376]: Loss = 0.6821277737617493
Iteration [42377]: Loss = 0.6819332242012024
Iteration [42378]: Loss = 0.6817170977592468
Iteration [42379]: Loss = 0.6814814209938049
Iteration [42380]: Loss = 0.6812282204627991
Iteration [42381]: Loss = 0.6809595227241516
Iteration [42382]: Loss = 0.6806764602661133
Iteration [42383]: Loss = 0.6803807616233826
Iteration [42384]: Loss = 0.6800734996795654
Iteration [42385]: Loss = 0.6797560453414917
Iteration [42386]: Loss = 0.6794294118881226
Iteration [42387]: Loss = 0.6790943145751953
Iteration [42388]: Loss = 0.6787519454956055
Iteration [42389]: Loss = 0.6784027814865112
Iteration [42390]: Loss = 0.6780474781990051
Iteration [42391]: Loss = 0.6776869297027588
Iteration [42392]: Loss = 0.6773215532302856
Iteration [42393]: Loss = 0.6769518256187439
Iteration [42394]: Loss = 0.6765782237052917
Iteration [42395]: Loss = 0.6762011051177979
Iteration [42396]: Loss = 0.6758208870887756
Iteration [42397]: Loss = 5.078073024749756
Iteration [42398]: Loss = 0.6753194332122803
Iteration [42399]: Loss = 0.6751722097396851
Iteration [42400]: Loss = 0.6749989986419678
Iteration [42401]: Loss = 0.6748022437095642
Iteration [42402]: Loss = 0.6745846271514893
Iteration [42403]: Loss = 0.674347996711731
Iteration [42404]: Loss = 0.6740943193435669
Iteration [42405]: Loss = 0.6738253235816956
Iteration [42406]: Loss = 0.6735424995422363
Iteration [42407]: Loss = 5.090238571166992
Iteration [42408]: Loss = 0.6732080578804016
Iteration [42409]: Loss = 0.6731322407722473
Iteration [42410]: Loss = 0.6730234622955322
Iteration [42411]: Loss = 5.092257499694824
Iteration [42412]: Loss = 0.6729860305786133
Iteration [42413]: Loss = 0.673036515712738
Iteration [42414]: Loss = 0.6730414032936096
Iteration [42415]: Loss = 0.6730055212974548
Iteration [42416]: Loss = 0.6729326844215393
Iteration [42417]: Loss = 5.092583656311035
Iteration [42418]: Loss = 0.6729564666748047
Iteration [42419]: Loss = 0.6730330586433411
Iteration [42420]: Loss = 5.091273784637451
Iteration [42421]: Loss = 0.6733118891716003
Iteration [42422]: Loss = 5.08884859085083
Iteration [42423]: Loss = 0.6738876104354858
Iteration [42424]: Loss = 0.6741989850997925
Iteration [42425]: Loss = 0.6744389533996582
Iteration [42426]: Loss = 5.082635879516602
Iteration [42427]: Loss = 5.104706764221191
Iteration [42428]: Loss = 0.6783341765403748
Iteration [42429]: Loss = 0.6826759576797485
Iteration [42430]: Loss = 0.6864620447158813
Iteration [42431]: Loss = 0.6718924641609192
Iteration [42432]: Loss = 0.6675373911857605
Iteration [42433]: Loss = 0.6698298454284668
Iteration [42434]: Loss = 5.147492408752441
Iteration [42435]: Loss = 0.6645607352256775
Iteration [42436]: Loss = 0.6583157777786255
Iteration [42437]: Loss = 5.089330673217773
Iteration [42438]: Loss = 0.6609050631523132
Iteration [42439]: Loss = 0.6671006679534912
Iteration [42440]: Loss = 0.6632676720619202
Iteration [42441]: Loss = 0.6666784286499023
Iteration [42442]: Loss = 0.6668739914894104
Iteration [42443]: Loss = 0.6637521386146545
Iteration [42444]: Loss = 0.6629346609115601
Iteration [42445]: Loss = 0.6668053269386292
Iteration [42446]: Loss = 0.6668363809585571
Iteration [42447]: Loss = 5.146886825561523
Iteration [42448]: Loss = 0.6741282939910889
Iteration [42449]: Loss = 0.6883795261383057
Iteration [42450]: Loss = 0.6784372329711914
Iteration [42451]: Loss = 0.6737709045410156
Iteration [42452]: Loss = 0.670470654964447
Iteration [42453]: Loss = 5.017793655395508
Iteration [42454]: Loss = 0.6928646564483643
Iteration [42455]: Loss = 0.6793050765991211
Iteration [42456]: Loss = 0.6755744218826294
Iteration [42457]: Loss = 0.697416365146637
Iteration [42458]: Loss = 0.6926895380020142
Iteration [42459]: Loss = 0.6763630509376526
Iteration [42460]: Loss = 0.6688567996025085
Iteration [42461]: Loss = 0.6625485420227051
Iteration [42462]: Loss = 5.223084449768066
Iteration [42463]: Loss = 0.6571685075759888
Iteration [42464]: Loss = 0.6531911492347717
Iteration [42465]: Loss = 0.6598405838012695
Iteration [42466]: Loss = 0.6748464107513428
Iteration [42467]: Loss = 0.6788709759712219
Iteration [42468]: Loss = 0.6872581243515015
Iteration [42469]: Loss = 0.6774705648422241
Iteration [42470]: Loss = 0.6764689087867737
Iteration [42471]: Loss = 0.6560720205307007
Iteration [42472]: Loss = 5.174493312835693
Iteration [42473]: Loss = 0.6843457818031311
Iteration [42474]: Loss = 0.6664316058158875
Iteration [42475]: Loss = 0.6612918972969055
Iteration [42476]: Loss = 0.6534702777862549
Iteration [42477]: Loss = 5.144482135772705
Iteration [42478]: Loss = 0.6698952913284302
Iteration [42479]: Loss = 0.6658456325531006
Iteration [42480]: Loss = 0.6598283052444458
Iteration [42481]: Loss = 0.6644378900527954
Iteration [42482]: Loss = 0.6637253165245056
Iteration [42483]: Loss = 0.6774504780769348
Iteration [42484]: Loss = 0.6793164014816284
Iteration [42485]: Loss = 0.6766998767852783
Iteration [42486]: Loss = 0.6812211275100708
Iteration [42487]: Loss = 0.6737808585166931
Iteration [42488]: Loss = 0.6729214787483215
Iteration [42489]: Loss = 0.6691526174545288
Iteration [42490]: Loss = 0.6721694469451904
Iteration [42491]: Loss = 0.6674866676330566
Iteration [42492]: Loss = 0.6651394963264465
Iteration [42493]: Loss = 0.6628438234329224
Iteration [42494]: Loss = 0.6625910997390747
Iteration [42495]: Loss = 0.6627670526504517
Iteration [42496]: Loss = 0.6593809127807617
Iteration [42497]: Loss = 0.6529151797294617
Iteration [42498]: Loss = 0.6565671563148499
Iteration [42499]: Loss = 0.654956579208374
Iteration [42500]: Loss = 0.6532931923866272
Iteration [42501]: Loss = 0.6504022479057312
Iteration [42502]: Loss = 0.6494772434234619
Iteration [42503]: Loss = 0.6477354764938354
Iteration [42504]: Loss = 0.6602584719657898
Iteration [42505]: Loss = 0.6498674154281616
Iteration [42506]: Loss = 5.230573654174805
Iteration [42507]: Loss = 5.23777961730957
Iteration [42508]: Loss = 0.6588289737701416
Iteration [42509]: Loss = 0.6643177270889282
Iteration [42510]: Loss = 5.2120819091796875
Iteration [42511]: Loss = 5.169869422912598
Iteration [42512]: Loss = 0.6728601455688477
Iteration [42513]: Loss = 0.6853363513946533
Iteration [42514]: Loss = 0.6684247255325317
Iteration [42515]: Loss = 0.63863205909729
Iteration [42516]: Loss = 0.6656025648117065
Iteration [42517]: Loss = 0.6421948671340942
Iteration [42518]: Loss = 0.6513091325759888
Iteration [42519]: Loss = 0.6859750151634216
Iteration [42520]: Loss = 0.6727096438407898
Iteration [42521]: Loss = 5.175293922424316
Iteration [42522]: Loss = 0.6540201902389526
Iteration [42523]: Loss = 0.6495997309684753
Iteration [42524]: Loss = 9.67083740234375
Iteration [42525]: Loss = 0.665458083152771
Iteration [42526]: Loss = 0.6512256264686584
Iteration [42527]: Loss = 0.651912271976471
Iteration [42528]: Loss = 0.6469511389732361
Iteration [42529]: Loss = 0.653149425983429
Iteration [42530]: Loss = 0.644451379776001
Iteration [42531]: Loss = 0.6593899726867676
Iteration [42532]: Loss = 0.6488445997238159
Iteration [42533]: Loss = 0.6547050476074219
Iteration [42534]: Loss = 0.6515488028526306
Iteration [42535]: Loss = 5.190500736236572
Iteration [42536]: Loss = 0.6457379460334778
Iteration [42537]: Loss = 0.6576288342475891
Iteration [42538]: Loss = 0.6471449136734009
Iteration [42539]: Loss = 0.6467869281768799
Iteration [42540]: Loss = 0.6567301750183105
Iteration [42541]: Loss = 0.6518872380256653
Iteration [42542]: Loss = 0.6522053480148315
Iteration [42543]: Loss = 0.6514945030212402
Iteration [42544]: Loss = 0.6504513621330261
Iteration [42545]: Loss = 0.6498486399650574
Iteration [42546]: Loss = 0.649048388004303
Iteration [42547]: Loss = 0.64803147315979
Iteration [42548]: Loss = 0.6471390128135681
Iteration [42549]: Loss = 0.6509871482849121
Iteration [42550]: Loss = 0.6497971415519714
Iteration [42551]: Loss = 0.6485403776168823
Iteration [42552]: Loss = 0.6497010588645935
Iteration [42553]: Loss = 0.6486526727676392
Iteration [42554]: Loss = 0.6476795077323914
Iteration [42555]: Loss = 0.6466801166534424
Iteration [42556]: Loss = 0.6456580758094788
Iteration [42557]: Loss = 0.6510761380195618
Iteration [42558]: Loss = 0.6497765183448792
Iteration [42559]: Loss = 0.6511768102645874
Iteration [42560]: Loss = 0.6499285697937012
Iteration [42561]: Loss = 0.6498874425888062
Iteration [42562]: Loss = 0.6479088068008423
Iteration [42563]: Loss = 0.6465457081794739
Iteration [42564]: Loss = 0.6451454162597656
Iteration [42565]: Loss = 0.6437126398086548
Iteration [42566]: Loss = 0.6422516703605652
Iteration [42567]: Loss = 5.2783708572387695
Iteration [42568]: Loss = 0.6404962539672852
Iteration [42569]: Loss = 0.6400895118713379
Iteration [42570]: Loss = 0.6395599842071533
Iteration [42571]: Loss = 0.6389206647872925
Iteration [42572]: Loss = 0.638183057308197
Iteration [42573]: Loss = 0.6373577117919922
Iteration [42574]: Loss = 0.6364541053771973
Iteration [42575]: Loss = 0.6354807019233704
Iteration [42576]: Loss = 0.6344451308250427
Iteration [42577]: Loss = 0.6334003210067749
Iteration [42578]: Loss = 0.6323162913322449
Iteration [42579]: Loss = 10.042243957519531
Iteration [42580]: Loss = 0.632027804851532
Iteration [42581]: Loss = 0.6326540112495422
Iteration [42582]: Loss = 0.6330910921096802
Iteration [42583]: Loss = 0.633357584476471
Iteration [42584]: Loss = 5.32270622253418
Iteration [42585]: Loss = 0.6343275904655457
Iteration [42586]: Loss = 0.6349754929542542
Iteration [42587]: Loss = 0.6354349255561829
Iteration [42588]: Loss = 0.6357244253158569
Iteration [42589]: Loss = 0.6358609199523926
Iteration [42590]: Loss = 0.6358595490455627
Iteration [42591]: Loss = 0.6357343792915344
Iteration [42592]: Loss = 0.6354976892471313
Iteration [42593]: Loss = 0.6351609230041504
Iteration [42594]: Loss = 0.6347340941429138
Iteration [42595]: Loss = 0.6342267990112305
Iteration [42596]: Loss = 0.633647084236145
Iteration [42597]: Loss = 0.6330024003982544
Iteration [42598]: Loss = 5.32989501953125
Iteration [42599]: Loss = 0.631699800491333
Iteration [42600]: Loss = 0.631688117980957
Iteration [42601]: Loss = 0.6315579414367676
Iteration [42602]: Loss = 5.335920333862305
Iteration [42603]: Loss = 0.6318340301513672
Iteration [42604]: Loss = 0.6321786642074585
Iteration [42605]: Loss = 0.6323716640472412
Iteration [42606]: Loss = 0.6324281692504883
Iteration [42607]: Loss = 0.6323617696762085
Iteration [42608]: Loss = 0.6321847438812256
Iteration [42609]: Loss = 0.6319082975387573
Iteration [42610]: Loss = 0.6315426230430603
Iteration [42611]: Loss = 0.6310968995094299
Iteration [42612]: Loss = 0.630578875541687
Iteration [42613]: Loss = 0.6299965977668762
Iteration [42614]: Loss = 0.629356324672699
Iteration [42615]: Loss = 0.6286641955375671
Iteration [42616]: Loss = 0.6279258131980896
Iteration [42617]: Loss = 0.6271458864212036
Iteration [42618]: Loss = 0.6263290643692017
Iteration [42619]: Loss = 0.6255576014518738
Iteration [42620]: Loss = 0.6248124837875366
Iteration [42621]: Loss = 0.6240450739860535
Iteration [42622]: Loss = 0.6232576370239258
Iteration [42623]: Loss = 5.391190052032471
Iteration [42624]: Loss = 0.622341513633728
Iteration [42625]: Loss = 0.6221466064453125
Iteration [42626]: Loss = 0.6218761801719666
Iteration [42627]: Loss = 0.6215377449989319
Iteration [42628]: Loss = 0.6211385130882263
Iteration [42629]: Loss = 0.6206844449043274
Iteration [42630]: Loss = 5.4055399894714355
Iteration [42631]: Loss = 0.6203256845474243
Iteration [42632]: Loss = 0.6203627586364746
Iteration [42633]: Loss = 0.6218671202659607
Iteration [42634]: Loss = 0.6217252016067505
Iteration [42635]: Loss = 0.6215075254440308
Iteration [42636]: Loss = 0.6212217211723328
Iteration [42637]: Loss = 0.6208746433258057
Iteration [42638]: Loss = 0.6204725503921509
Iteration [42639]: Loss = 0.6200499534606934
Iteration [42640]: Loss = 0.6196535229682922
Iteration [42641]: Loss = 0.6192251443862915
Iteration [42642]: Loss = 0.6187680959701538
Iteration [42643]: Loss = 0.6182854175567627
Iteration [42644]: Loss = 0.617779552936554
Iteration [42645]: Loss = 0.6172530651092529
Iteration [42646]: Loss = 0.616707980632782
Iteration [42647]: Loss = 0.6161463856697083
Iteration [42648]: Loss = 0.6155698299407959
Iteration [42649]: Loss = 0.6149800419807434
Iteration [42650]: Loss = 0.6143784523010254
Iteration [42651]: Loss = 0.613766074180603
Iteration [42652]: Loss = 0.6131443977355957
Iteration [42653]: Loss = 0.6125161051750183
Iteration [42654]: Loss = 0.6118850708007812
Iteration [42655]: Loss = 0.6112473607063293
Iteration [42656]: Loss = 0.610603928565979
Iteration [42657]: Loss = 0.6099553108215332
Iteration [42658]: Loss = 0.6093021035194397
Iteration [42659]: Loss = 0.6086448431015015
Iteration [42660]: Loss = 0.6079840064048767
Iteration [42661]: Loss = 0.6073200106620789
Iteration [42662]: Loss = 0.6066533923149109
Iteration [42663]: Loss = 0.6059843301773071
Iteration [42664]: Loss = 5.501514434814453
Iteration [42665]: Loss = 0.605166494846344
Iteration [42666]: Loss = 0.6049661636352539
Iteration [42667]: Loss = 5.505434036254883
Iteration [42668]: Loss = 0.6049402356147766
Iteration [42669]: Loss = 0.6050732135772705
Iteration [42670]: Loss = 0.6051256060600281
Iteration [42671]: Loss = 0.605105459690094
Iteration [42672]: Loss = 0.605019748210907
Iteration [42673]: Loss = 0.6048753261566162
Iteration [42674]: Loss = 0.6046779155731201
Iteration [42675]: Loss = 0.6044330596923828
Iteration [42676]: Loss = 0.6041451692581177
Iteration [42677]: Loss = 0.6038188338279724
Iteration [42678]: Loss = 0.6034579873085022
Iteration [42679]: Loss = 0.6030659079551697
Iteration [42680]: Loss = 0.602645993232727
Iteration [42681]: Loss = 5.5220627784729
Iteration [42682]: Loss = 0.6044394969940186
Iteration [42683]: Loss = 0.6044124960899353
Iteration [42684]: Loss = 0.6043213605880737
Iteration [42685]: Loss = 0.6041727662086487
Iteration [42686]: Loss = 0.6039724349975586
Iteration [42687]: Loss = 0.6037254929542542
Iteration [42688]: Loss = 0.6034366488456726
Iteration [42689]: Loss = 0.6031101942062378
Iteration [42690]: Loss = 0.6027498841285706
Iteration [42691]: Loss = 0.6023591756820679
Iteration [42692]: Loss = 0.6019410490989685
Iteration [42693]: Loss = 0.6014984846115112
Iteration [42694]: Loss = 0.6010338068008423
Iteration [42695]: Loss = 0.6005493402481079
Iteration [42696]: Loss = 0.6000473499298096
Iteration [42697]: Loss = 0.5995293855667114
Iteration [42698]: Loss = 0.5989971160888672
Iteration [42699]: Loss = 0.5984522104263306
Iteration [42700]: Loss = 0.5978958606719971
Iteration [42701]: Loss = 0.597329318523407
Iteration [42702]: Loss = 0.596753716468811
Iteration [42703]: Loss = 0.5961698889732361
Iteration [42704]: Loss = 0.5955789089202881
Iteration [42705]: Loss = 0.5949960947036743
Iteration [42706]: Loss = 0.5944113731384277
Iteration [42707]: Loss = 5.57819128036499
Iteration [42708]: Loss = 0.5937227010726929
Iteration [42709]: Loss = 0.59357088804245
Iteration [42710]: Loss = 0.5933713912963867
Iteration [42711]: Loss = 0.5931292772293091
Iteration [42712]: Loss = 0.592848539352417
Iteration [42713]: Loss = 5.586928367614746
Iteration [42714]: Loss = 0.5926734209060669
Iteration [42715]: Loss = 0.5927377939224243
Iteration [42716]: Loss = 5.585566520690918
Iteration [42717]: Loss = 0.593146026134491
Iteration [42718]: Loss = 0.5934559106826782
Iteration [42719]: Loss = 5.579192638397217
Iteration [42720]: Loss = 0.5942787528038025
Iteration [42721]: Loss = 0.594762921333313
Iteration [42722]: Loss = 0.5951381325721741
Iteration [42723]: Loss = 0.5954150557518005
Iteration [42724]: Loss = 0.5956034660339355
Iteration [42725]: Loss = 0.5957120060920715
Iteration [42726]: Loss = 0.5957488417625427
Iteration [42727]: Loss = 0.5957207679748535
Iteration [42728]: Loss = 0.5956344604492188
Iteration [42729]: Loss = 0.5954958200454712
Iteration [42730]: Loss = 0.5953099131584167
Iteration [42731]: Loss = 0.5950814485549927
Iteration [42732]: Loss = 0.5948148369789124
Iteration [42733]: Loss = 0.5945138931274414
Iteration [42734]: Loss = 0.594182014465332
Iteration [42735]: Loss = 0.5938223600387573
Iteration [42736]: Loss = 0.5934377908706665
Iteration [42737]: Loss = 0.5930308103561401
Iteration [42738]: Loss = 0.5926038026809692
Iteration [42739]: Loss = 0.5921586155891418
Iteration [42740]: Loss = 0.5916972160339355
Iteration [42741]: Loss = 0.591221272945404
Iteration [42742]: Loss = 0.5907323360443115
Iteration [42743]: Loss = 0.590231716632843
Iteration [42744]: Loss = 0.5897207260131836
Iteration [42745]: Loss = 0.5892002582550049
Iteration [42746]: Loss = 0.5886714458465576
Iteration [42747]: Loss = 0.5881351232528687
Iteration [42748]: Loss = 0.5875921845436096
Iteration [42749]: Loss = 0.587043285369873
Iteration [42750]: Loss = 5.628299713134766
Iteration [42751]: Loss = 0.5864071846008301
Iteration [42752]: Loss = 0.5862739682197571
Iteration [42753]: Loss = 0.5860943794250488
Iteration [42754]: Loss = 0.5858731269836426
Iteration [42755]: Loss = 0.5856143832206726
Iteration [42756]: Loss = 0.5853220224380493
Iteration [42757]: Loss = 0.5849993228912354
Iteration [42758]: Loss = 0.5846493244171143
Iteration [42759]: Loss = 0.5842748880386353
Iteration [42760]: Loss = 5.646366596221924
Iteration [42761]: Loss = 0.5839338898658752
Iteration [42762]: Loss = 0.5839250087738037
Iteration [42763]: Loss = 0.583858072757721
Iteration [42764]: Loss = 0.5837390422821045
Iteration [42765]: Loss = 0.5835731029510498
Iteration [42766]: Loss = 0.5833649635314941
Iteration [42767]: Loss = 0.5831187963485718
Iteration [42768]: Loss = 0.5828384160995483
Iteration [42769]: Loss = 0.5825272798538208
Iteration [42770]: Loss = 0.5821885466575623
Iteration [42771]: Loss = 0.5818249583244324
Iteration [42772]: Loss = 0.5814390778541565
Iteration [42773]: Loss = 0.5810331106185913
Iteration [42774]: Loss = 0.580609142780304
Iteration [42775]: Loss = 0.5801690816879272
Iteration [42776]: Loss = 0.5797145366668701
Iteration [42777]: Loss = 0.5792468786239624
Iteration [42778]: Loss = 0.5787676572799683
Iteration [42779]: Loss = 5.685539245605469
Iteration [42780]: Loss = 0.5782492160797119
Iteration [42781]: Loss = 0.5781655311584473
Iteration [42782]: Loss = 0.5780323147773743
Iteration [42783]: Loss = 0.5778548717498779
Iteration [42784]: Loss = 0.5776371955871582
Iteration [42785]: Loss = 0.5773833990097046
Iteration [42786]: Loss = 0.5771048069000244
Iteration [42787]: Loss = 0.576798677444458
Iteration [42788]: Loss = 0.5764670968055725
Iteration [42789]: Loss = 5.700836658477783
Iteration [42790]: Loss = 5.700290203094482
Iteration [42791]: Loss = 0.5766468644142151
Iteration [42792]: Loss = 0.577003538608551
Iteration [42793]: Loss = 5.69265079498291
Iteration [42794]: Loss = 5.688261032104492
Iteration [42795]: Loss = 5.672694683074951
Iteration [42796]: Loss = 5.66370964050293
Iteration [42797]: Loss = 5.652608871459961
Iteration [42798]: Loss = 0.5860515236854553
Iteration [42799]: Loss = 0.5875207185745239
Iteration [42800]: Loss = 0.5888559818267822
Iteration [42801]: Loss = 0.5902474522590637
Iteration [42802]: Loss = 0.5912066698074341
Iteration [42803]: Loss = 0.5920333862304688
Iteration [42804]: Loss = 0.592713475227356
Iteration [42805]: Loss = 0.5932556390762329
Iteration [42806]: Loss = 0.5936722755432129
Iteration [42807]: Loss = 0.5939756631851196
Iteration [42808]: Loss = 0.5941769480705261
Iteration [42809]: Loss = 0.594286322593689
Iteration [42810]: Loss = 0.5943129062652588
Iteration [42811]: Loss = 0.5942647457122803
Iteration [42812]: Loss = 0.594149649143219
Iteration [42813]: Loss = 0.5939739346504211
Iteration [42814]: Loss = 5.578717231750488
Iteration [42815]: Loss = 0.5940210819244385
Iteration [42816]: Loss = 0.5941994190216064
Iteration [42817]: Loss = 0.5942886471748352
Iteration [42818]: Loss = 0.5942976474761963
Iteration [42819]: Loss = 0.5942344069480896
Iteration [42820]: Loss = 0.5941061973571777
Iteration [42821]: Loss = 0.5939193964004517
Iteration [42822]: Loss = 0.5936800241470337
Iteration [42823]: Loss = 0.5933932065963745
Iteration [42824]: Loss = 0.5930639505386353
Iteration [42825]: Loss = 5.585821151733398
Iteration [42826]: Loss = 0.5928473472595215
Iteration [42827]: Loss = 0.5929129123687744
Iteration [42828]: Loss = 0.592901349067688
Iteration [42829]: Loss = 0.5928202867507935
Iteration [42830]: Loss = 0.5926767587661743
Iteration [42831]: Loss = 0.5924770832061768
Iteration [42832]: Loss = 0.5922448635101318
Iteration [42833]: Loss = 0.5919818878173828
Iteration [42834]: Loss = 0.5916855335235596
Iteration [42835]: Loss = 10.598505973815918
Iteration [42836]: Loss = 0.5919479727745056
Iteration [42837]: Loss = 5.5876922607421875
Iteration [42838]: Loss = 0.5932492613792419
Iteration [42839]: Loss = 0.5939359664916992
Iteration [42840]: Loss = 0.5944945216178894
Iteration [42841]: Loss = 5.570646286010742
Iteration [42842]: Loss = 0.5957371592521667
Iteration [42843]: Loss = 0.5963975787162781
Iteration [42844]: Loss = 0.5969326496124268
Iteration [42845]: Loss = 0.5973545908927917
Iteration [42846]: Loss = 0.5976746082305908
Iteration [42847]: Loss = 0.5979026556015015
Iteration [42848]: Loss = 5.5497331619262695
Iteration [42849]: Loss = 0.5985782742500305
Iteration [42850]: Loss = 0.5989960432052612
Iteration [42851]: Loss = 0.5993124842643738
Iteration [42852]: Loss = 0.5995374321937561
Iteration [42853]: Loss = 0.5996798872947693
Iteration [42854]: Loss = 5.538369178771973
Iteration [42855]: Loss = 5.535308361053467
Iteration [42856]: Loss = 0.6006029844284058
Iteration [42857]: Loss = 0.6012688279151917
Iteration [42858]: Loss = 0.601809024810791
Iteration [42859]: Loss = 5.521828651428223
Iteration [42860]: Loss = 5.512455463409424
Iteration [42861]: Loss = 0.6049703359603882
Iteration [42862]: Loss = 0.6059661507606506
Iteration [42863]: Loss = 0.6067343354225159
Iteration [42864]: Loss = 5.488044261932373
Iteration [42865]: Loss = 0.6083217859268188
Iteration [42866]: Loss = 0.6091227531433105
Iteration [42867]: Loss = 0.6097849011421204
Iteration [42868]: Loss = 0.6103215217590332
Iteration [42869]: Loss = 0.6107450723648071
Iteration [42870]: Loss = 0.6110666990280151
Iteration [42871]: Loss = 0.6112962961196899
Iteration [42872]: Loss = 0.611443042755127
Iteration [42873]: Loss = 0.6115152835845947
Iteration [42874]: Loss = 0.6115200519561768
Iteration [42875]: Loss = 0.6114642024040222
Iteration [42876]: Loss = 0.6113539338111877
Iteration [42877]: Loss = 0.6111944913864136
Iteration [42878]: Loss = 0.6109908819198608
Iteration [42879]: Loss = 0.6107474565505981
Iteration [42880]: Loss = 0.6104682683944702
Iteration [42881]: Loss = 0.6101568937301636
Iteration [42882]: Loss = 0.6098166704177856
Iteration [42883]: Loss = 0.6094503402709961
Iteration [42884]: Loss = 0.6090607047080994
Iteration [42885]: Loss = 5.479662895202637
Iteration [42886]: Loss = 0.6086713075637817
Iteration [42887]: Loss = 5.479788303375244
Iteration [42888]: Loss = 0.6089811325073242
Iteration [42889]: Loss = 5.475836753845215
Iteration [42890]: Loss = 5.4718427658081055
Iteration [42891]: Loss = 0.6107829809188843
Iteration [42892]: Loss = 0.6115638613700867
Iteration [42893]: Loss = 0.612208366394043
Iteration [42894]: Loss = 0.6127299070358276
Iteration [42895]: Loss = 0.6131404042243958
Iteration [42896]: Loss = 0.6134508848190308
Iteration [42897]: Loss = 0.6136711239814758
Iteration [42898]: Loss = 0.6138100624084473
Iteration [42899]: Loss = 0.6138758063316345
Iteration [42900]: Loss = 0.6138753890991211
Iteration [42901]: Loss = 5.446194648742676
Iteration [42902]: Loss = 0.6141374707221985
Iteration [42903]: Loss = 5.442778587341309
Iteration [42904]: Loss = 0.6148702502250671
Iteration [42905]: Loss = 0.6152895092964172
Iteration [42906]: Loss = 0.6156147718429565
Iteration [42907]: Loss = 5.433098793029785
Iteration [42908]: Loss = 0.6164050698280334
Iteration [42909]: Loss = 0.6168480515480042
Iteration [42910]: Loss = 0.6171948313713074
Iteration [42911]: Loss = 0.6174544095993042
Iteration [42912]: Loss = 0.6176358461380005
Iteration [42913]: Loss = 0.6177467107772827
Iteration [42914]: Loss = 0.6177938580513
Iteration [42915]: Loss = 0.6177836656570435
Iteration [42916]: Loss = 0.6177220940589905
Iteration [42917]: Loss = 0.6176139116287231
Iteration [42918]: Loss = 5.422814846038818
Iteration [42919]: Loss = 0.6176635026931763
Iteration [42920]: Loss = 0.6177908182144165
Iteration [42921]: Loss = 0.6178529858589172
Iteration [42922]: Loss = 0.6178566217422485
Iteration [42923]: Loss = 0.6178074479103088
Iteration [42924]: Loss = 0.6177108287811279
Iteration [42925]: Loss = 0.617571234703064
Iteration [42926]: Loss = 0.6173931360244751
Iteration [42927]: Loss = 0.617180347442627
Iteration [42928]: Loss = 0.6169363260269165
Iteration [42929]: Loss = 0.6166644096374512
Iteration [42930]: Loss = 0.6163672208786011
Iteration [42931]: Loss = 0.616047203540802
Iteration [42932]: Loss = 0.6157068014144897
Iteration [42933]: Loss = 0.6153481602668762
Iteration [42934]: Loss = 0.6149730086326599
Iteration [42935]: Loss = 0.6145830154418945
Iteration [42936]: Loss = 0.6141798496246338
Iteration [42937]: Loss = 0.6137645840644836
Iteration [42938]: Loss = 0.6133385896682739
Iteration [42939]: Loss = 0.6129031181335449
Iteration [42940]: Loss = 0.612459123134613
Iteration [42941]: Loss = 0.6120072603225708
Iteration [42942]: Loss = 0.6115486025810242
Iteration [42943]: Loss = 0.6110836863517761
Iteration [42944]: Loss = 0.6106133460998535
Iteration [42945]: Loss = 0.6101379990577698
Iteration [42946]: Loss = 10.336533546447754
Iteration [42947]: Loss = 5.471220970153809
Iteration [42948]: Loss = 0.6105324625968933
Iteration [42949]: Loss = 5.464321136474609
Iteration [42950]: Loss = 0.6117630004882812
Iteration [42951]: Loss = 0.6123911738395691
Iteration [42952]: Loss = 0.6129069328308105
Iteration [42953]: Loss = 0.6133208274841309
Iteration [42954]: Loss = 0.6136431694030762
Iteration [42955]: Loss = 0.613882839679718
Iteration [42956]: Loss = 0.6140480041503906
Iteration [42957]: Loss = 0.6141461133956909
Iteration [42958]: Loss = 0.6141836643218994
Iteration [42959]: Loss = 0.6141668558120728
Iteration [42960]: Loss = 0.6141009330749512
Iteration [42961]: Loss = 0.6139907836914062
Iteration [42962]: Loss = 0.6138409376144409
Iteration [42963]: Loss = 0.6136552095413208
Iteration [42964]: Loss = 5.448631286621094
Iteration [42965]: Loss = 0.6119368076324463
Iteration [42966]: Loss = 5.457887649536133
Iteration [42967]: Loss = 0.6123867034912109
Iteration [42968]: Loss = 0.6126819252967834
Iteration [42969]: Loss = 0.6128975749015808
Iteration [42970]: Loss = 0.6130415201187134
Iteration [42971]: Loss = 0.6131209135055542
Iteration [42972]: Loss = 0.6131420731544495
Iteration [42973]: Loss = 0.6131108403205872
Iteration [42974]: Loss = 0.6130324006080627
Iteration [42975]: Loss = 0.6129113435745239
Iteration [42976]: Loss = 0.6127520799636841
Iteration [42977]: Loss = 0.6125584244728088
Iteration [42978]: Loss = 0.6123338341712952
Iteration [42979]: Loss = 5.457383632659912
Iteration [42980]: Loss = 0.6121788024902344
Iteration [42981]: Loss = 5.456508636474609
Iteration [42982]: Loss = 0.6107239127159119
Iteration [42983]: Loss = 0.6109867095947266
Iteration [42984]: Loss = 0.611166775226593
Iteration [42985]: Loss = 0.6112722158432007
Iteration [42986]: Loss = 0.6113106608390808
Iteration [42987]: Loss = 0.6112884283065796
Iteration [42988]: Loss = 0.6112117171287537
Iteration [42989]: Loss = 0.6110860109329224
Iteration [42990]: Loss = 5.464928150177002
Iteration [42991]: Loss = 0.6111298203468323
Iteration [42992]: Loss = 0.6103116273880005
Iteration [42993]: Loss = 5.468422889709473
Iteration [42994]: Loss = 0.6108006238937378
Iteration [42995]: Loss = 0.6111255884170532
Iteration [42996]: Loss = 0.611362099647522
Iteration [42997]: Loss = 0.6115187406539917
Iteration [42998]: Loss = 0.6116034984588623
Iteration [42999]: Loss = 5.460345268249512
Iteration [43000]: Loss = 0.6120043992996216
Iteration [43001]: Loss = 0.6122913956642151
Iteration [43002]: Loss = 0.61247718334198
Iteration [43003]: Loss = 0.6125923991203308
Iteration [43004]: Loss = 0.6126466989517212
Iteration [43005]: Loss = 0.6126460433006287
Iteration [43006]: Loss = 0.6125960946083069
Iteration [43007]: Loss = 0.6125013828277588
Iteration [43008]: Loss = 0.6123666763305664
Iteration [43009]: Loss = 0.6121959090232849
Iteration [43010]: Loss = 0.611992597579956
Iteration [43011]: Loss = 0.611760139465332
Iteration [43012]: Loss = 0.6115012764930725
Iteration [43013]: Loss = 0.6112186908721924
Iteration [43014]: Loss = 0.6109150648117065
Iteration [43015]: Loss = 0.6105921268463135
Iteration [43016]: Loss = 0.6102520823478699
Iteration [43017]: Loss = 0.6098964214324951
Iteration [43018]: Loss = 5.473950386047363
Iteration [43019]: Loss = 0.6095162630081177
Iteration [43020]: Loss = 0.6094573736190796
Iteration [43021]: Loss = 5.475069522857666
Iteration [43022]: Loss = 0.6095821261405945
Iteration [43023]: Loss = 0.6097376942634583
Iteration [43024]: Loss = 0.6098286509513855
Iteration [43025]: Loss = 0.6098614931106567
Iteration [43026]: Loss = 0.60984206199646
Iteration [43027]: Loss = 0.6097754836082458
Iteration [43028]: Loss = 0.6096664071083069
Iteration [43029]: Loss = 10.338486671447754
Iteration [43030]: Loss = 0.6100618839263916
Iteration [43031]: Loss = 0.6105027794837952
Iteration [43032]: Loss = 0.6108517050743103
Iteration [43033]: Loss = 0.6111178994178772
Iteration [43034]: Loss = 5.46237850189209
Iteration [43035]: Loss = 0.6117920875549316
Iteration [43036]: Loss = 0.6121788024902344
Iteration [43037]: Loss = 0.6124790906906128
Iteration [43038]: Loss = 0.6127011179924011
Iteration [43039]: Loss = 0.6128529906272888
Iteration [43040]: Loss = 0.6129413843154907
Iteration [43041]: Loss = 0.6129727363586426
Iteration [43042]: Loss = 0.6129526495933533
Iteration [43043]: Loss = 0.6128861904144287
Iteration [43044]: Loss = 0.6127781271934509
Iteration [43045]: Loss = 0.6126325726509094
Iteration [43046]: Loss = 0.6124532222747803
Iteration [43047]: Loss = 0.6122432947158813
Iteration [43048]: Loss = 0.6120060682296753
Iteration [43049]: Loss = 5.459563732147217
Iteration [43050]: Loss = 0.6118207573890686
Iteration [43051]: Loss = 0.61184161901474
Iteration [43052]: Loss = 0.6118122935295105
Iteration [43053]: Loss = 0.6117377281188965
Iteration [43054]: Loss = 0.6116223931312561
Iteration [43055]: Loss = 0.6114704012870789
Iteration [43056]: Loss = 0.6112854480743408
Iteration [43057]: Loss = 0.6110708117485046
Iteration [43058]: Loss = 0.6108294129371643
Iteration [43059]: Loss = 0.6105639934539795
Iteration [43060]: Loss = 5.469074726104736
Iteration [43061]: Loss = 5.468724250793457
Iteration [43062]: Loss = 0.6106891632080078
Iteration [43063]: Loss = 0.6109640002250671
Iteration [43064]: Loss = 5.463323593139648
Iteration [43065]: Loss = 0.6116513013839722
Iteration [43066]: Loss = 0.6120427250862122
Iteration [43067]: Loss = 0.6123476624488831
Iteration [43068]: Loss = 0.6125744581222534
Iteration [43069]: Loss = 0.612730860710144
Iteration [43070]: Loss = 0.6128238439559937
Iteration [43071]: Loss = 0.6128596067428589
Iteration [43072]: Loss = 5.452455997467041
Iteration [43073]: Loss = 0.6131378412246704
Iteration [43074]: Loss = 0.6133546233177185
Iteration [43075]: Loss = 0.6135022044181824
Iteration [43076]: Loss = 0.6135872602462769
Iteration [43077]: Loss = 5.44748067855835
Iteration [43078]: Loss = 0.6139485239982605
Iteration [43079]: Loss = 0.6142004132270813
Iteration [43080]: Loss = 0.6143794655799866
Iteration [43081]: Loss = 0.6144928932189941
Iteration [43082]: Loss = 5.441488742828369
Iteration [43083]: Loss = 0.6149020195007324
Iteration [43084]: Loss = 5.437465667724609
Iteration [43085]: Loss = 0.6157222986221313
Iteration [43086]: Loss = 0.6161687970161438
Iteration [43087]: Loss = 0.6165233254432678
Iteration [43088]: Loss = 0.6167949438095093
Iteration [43089]: Loss = 0.6169918179512024
Iteration [43090]: Loss = 0.6171212792396545
Iteration [43091]: Loss = 0.6171901226043701
Iteration [43092]: Loss = 5.424471855163574
Iteration [43093]: Loss = 0.6175209879875183
Iteration [43094]: Loss = 0.6177586913108826
Iteration [43095]: Loss = 0.6179248094558716
Iteration [43096]: Loss = 0.6180267333984375
Iteration [43097]: Loss = 0.6180707812309265
Iteration [43098]: Loss = 0.6180626153945923
Iteration [43099]: Loss = 0.6180074214935303
Iteration [43100]: Loss = 0.617909848690033
Iteration [43101]: Loss = 0.617774248123169
Iteration [43102]: Loss = 0.61760413646698
Iteration [43103]: Loss = 0.6174033284187317
Iteration [43104]: Loss = 0.6171746850013733
Iteration [43105]: Loss = 0.6169211268424988
Iteration [43106]: Loss = 0.6166450381278992
Iteration [43107]: Loss = 0.6163486242294312
Iteration [43108]: Loss = 0.6160341501235962
Iteration [43109]: Loss = 0.6157031655311584
Iteration [43110]: Loss = 0.6153576970100403
Iteration [43111]: Loss = 10.262178421020508
Iteration [43112]: Loss = 0.6153295636177063
Iteration [43113]: Loss = 0.6155804991722107
Iteration [43114]: Loss = 0.6157596707344055
Iteration [43115]: Loss = 0.615874171257019
Iteration [43116]: Loss = 0.6159303784370422
Iteration [43117]: Loss = 0.6166583299636841
Iteration [43118]: Loss = 0.6166147589683533
Iteration [43119]: Loss = 0.6165282726287842
Iteration [43120]: Loss = 0.6164035201072693
Iteration [43121]: Loss = 0.6162442564964294
Iteration [43122]: Loss = 0.6160537004470825
Iteration [43123]: Loss = 0.6158353090286255
Iteration [43124]: Loss = 0.6155915856361389
Iteration [43125]: Loss = 0.6153252720832825
Iteration [43126]: Loss = 0.6150385737419128
Iteration [43127]: Loss = 0.6147335767745972
Iteration [43128]: Loss = 0.6144119501113892
Iteration [43129]: Loss = 5.444520950317383
Iteration [43130]: Loss = 0.6140749454498291
Iteration [43131]: Loss = 0.6140275597572327
Iteration [43132]: Loss = 0.61393803358078
Iteration [43133]: Loss = 5.446225166320801
Iteration [43134]: Loss = 0.6139966249465942
Iteration [43135]: Loss = 0.6141172647476196
Iteration [43136]: Loss = 0.6141793131828308
Iteration [43137]: Loss = 0.614188551902771
Iteration [43138]: Loss = 0.6141501069068909
Iteration [43139]: Loss = 0.6140686273574829
Iteration [43140]: Loss = 0.6139488220214844
Iteration [43141]: Loss = 0.613794207572937
Iteration [43142]: Loss = 0.613608181476593
Iteration [43143]: Loss = 0.613394021987915
Iteration [43144]: Loss = 0.6131545305252075
Iteration [43145]: Loss = 0.6128923296928406
Iteration [43146]: Loss = 0.6126095652580261
Iteration [43147]: Loss = 5.455915451049805
Iteration [43148]: Loss = 0.6123387813568115
Iteration [43149]: Loss = 0.6123195886611938
Iteration [43150]: Loss = 0.6122558116912842
Iteration [43151]: Loss = 5.456926345825195
Iteration [43152]: Loss = 5.455592155456543
Iteration [43153]: Loss = 0.6128418445587158
Iteration [43154]: Loss = 0.6132311820983887
Iteration [43155]: Loss = 5.447999000549316
Iteration [43156]: Loss = 0.6141056418418884
Iteration [43157]: Loss = 0.6145731806755066
Iteration [43158]: Loss = 0.6149478554725647
Iteration [43159]: Loss = 0.615239143371582
Iteration [43160]: Loss = 0.6154549717903137
Iteration [43161]: Loss = 0.6156030297279358
Iteration [43162]: Loss = 0.615689754486084
Iteration [43163]: Loss = 0.6157214641571045
Iteration [43164]: Loss = 5.434069633483887
Iteration [43165]: Loss = 0.6159842014312744
Iteration [43166]: Loss = 0.6161905527114868
Iteration [43167]: Loss = 0.6163300275802612
Iteration [43168]: Loss = 5.429553031921387
Iteration [43169]: Loss = 0.6167761087417603
Iteration [43170]: Loss = 0.6170603036880493
Iteration [43171]: Loss = 0.61726975440979
Iteration [43172]: Loss = 0.6174120903015137
Iteration [43173]: Loss = 5.4226250648498535
Iteration [43174]: Loss = 5.420275688171387
Iteration [43175]: Loss = 0.6184866428375244
Iteration [43176]: Loss = 0.6190031170845032
Iteration [43177]: Loss = 0.6194220781326294
Iteration [43178]: Loss = 0.6197530031204224
Iteration [43179]: Loss = 0.6200047731399536
Iteration [43180]: Loss = 5.405517101287842
Iteration [43181]: Loss = 0.6206398606300354
Iteration [43182]: Loss = 0.621003270149231
Iteration [43183]: Loss = 0.6212841272354126
Iteration [43184]: Loss = 0.6214907169342041
Iteration [43185]: Loss = 0.6216301918029785
Iteration [43186]: Loss = 0.621709406375885
Iteration [43187]: Loss = 0.6217340230941772
Iteration [43188]: Loss = 0.6217098236083984
Iteration [43189]: Loss = 5.396306037902832
Iteration [43190]: Loss = 0.6218729019165039
Iteration [43191]: Loss = 0.6220349073410034
Iteration [43192]: Loss = 0.6221344470977783
Iteration [43193]: Loss = 0.6221773624420166
Iteration [43194]: Loss = 5.392971038818359
Iteration [43195]: Loss = 0.6224550008773804
Iteration [43196]: Loss = 5.3898468017578125
Iteration [43197]: Loss = 0.6231456398963928
Iteration [43198]: Loss = 0.6235318183898926
Iteration [43199]: Loss = 0.6238332390785217
Iteration [43200]: Loss = 0.6240583062171936
Iteration [43201]: Loss = 0.6242145299911499
Iteration [43202]: Loss = 0.6243087649345398
Iteration [43203]: Loss = 0.6243469715118408
Iteration [43204]: Loss = 0.6243348717689514
Iteration [43205]: Loss = 0.6242774724960327
Iteration [43206]: Loss = 0.6241792440414429
Iteration [43207]: Loss = 0.6240443587303162
Iteration [43208]: Loss = 0.62387615442276
Iteration [43209]: Loss = 0.6236782670021057
Iteration [43210]: Loss = 0.6234534978866577
Iteration [43211]: Loss = 0.6232046484947205
Iteration [43212]: Loss = 0.6229341626167297
Iteration [43213]: Loss = 5.389981269836426
Iteration [43214]: Loss = 0.6226760149002075
Iteration [43215]: Loss = 0.6226583123207092
Iteration [43216]: Loss = 0.622596025466919
Iteration [43217]: Loss = 0.6224935054779053
Iteration [43218]: Loss = 0.6223549246788025
Iteration [43219]: Loss = 5.392883777618408
Iteration [43220]: Loss = 0.6223215460777283
Iteration [43221]: Loss = 0.6223995685577393
Iteration [43222]: Loss = 0.6224234104156494
Iteration [43223]: Loss = 5.391528606414795
Iteration [43224]: Loss = 0.6226670742034912
Iteration [43225]: Loss = 0.6228627562522888
Iteration [43226]: Loss = 0.6229926943778992
Iteration [43227]: Loss = 0.6230635046958923
Iteration [43228]: Loss = 0.6230809688568115
Iteration [43229]: Loss = 0.623050332069397
Iteration [43230]: Loss = 0.622976541519165
Iteration [43231]: Loss = 5.388599395751953
Iteration [43232]: Loss = 0.6230530142784119
Iteration [43233]: Loss = 0.6231773495674133
Iteration [43234]: Loss = 0.6232430338859558
Iteration [43235]: Loss = 0.6232559084892273
Iteration [43236]: Loss = 0.6232212781906128
Iteration [43237]: Loss = 0.6231437921524048
Iteration [43238]: Loss = 0.6230278015136719
Iteration [43239]: Loss = 0.6228771209716797
Iteration [43240]: Loss = 0.6226951479911804
Iteration [43241]: Loss = 0.6224851012229919
Iteration [43242]: Loss = 0.6222497224807739
Iteration [43243]: Loss = 0.6219915747642517
Iteration [43244]: Loss = 5.395853519439697
Iteration [43245]: Loss = 0.621753990650177
Iteration [43246]: Loss = 0.6217448115348816
Iteration [43247]: Loss = 0.621690571308136
Iteration [43248]: Loss = 0.6215954422950745
Iteration [43249]: Loss = 0.6214638352394104
Iteration [43250]: Loss = 0.6212990283966064
Iteration [43251]: Loss = 5.399695873260498
Iteration [43252]: Loss = 0.6212208867073059
Iteration [43253]: Loss = 0.6212795972824097
Iteration [43254]: Loss = 0.6212863326072693
Iteration [43255]: Loss = 5.398799419403076
Iteration [43256]: Loss = 0.6215004920959473
Iteration [43257]: Loss = 5.39603853225708
Iteration [43258]: Loss = 0.6221364140510559
Iteration [43259]: Loss = 0.6224987506866455
Iteration [43260]: Loss = 0.6227790117263794
Iteration [43261]: Loss = 0.6229855418205261
Iteration [43262]: Loss = 0.6231256723403931
Iteration [43263]: Loss = 0.6232057809829712
Iteration [43264]: Loss = 0.6232317686080933
Iteration [43265]: Loss = 5.386425018310547
Iteration [43266]: Loss = 0.6234776973724365
Iteration [43267]: Loss = 0.6236734390258789
Iteration [43268]: Loss = 0.6238037347793579
Iteration [43269]: Loss = 0.623875081539154
Iteration [43270]: Loss = 5.38212776184082
Iteration [43271]: Loss = 0.6241974830627441
Iteration [43272]: Loss = 0.6244255304336548
Iteration [43273]: Loss = 0.6245850324630737
Iteration [43274]: Loss = 0.6246826648712158
Iteration [43275]: Loss = 0.6247245669364929
Iteration [43276]: Loss = 0.6247162222862244
Iteration [43277]: Loss = 5.377301216125488
Iteration [43278]: Loss = 0.6249022483825684
Iteration [43279]: Loss = 0.6250719428062439
Iteration [43280]: Loss = 5.374069690704346
Iteration [43281]: Loss = 5.371676445007324
Iteration [43282]: Loss = 0.6261904835700989
Iteration [43283]: Loss = 0.626711368560791
Iteration [43284]: Loss = 0.6271347999572754
Iteration [43285]: Loss = 0.6274701952934265
Iteration [43286]: Loss = 0.6277264952659607
Iteration [43287]: Loss = 0.6279112696647644
Iteration [43288]: Loss = 0.6280315518379211
Iteration [43289]: Loss = 0.628093957901001
Iteration [43290]: Loss = 0.6281039118766785
Iteration [43291]: Loss = 0.628066897392273
Iteration [43292]: Loss = 0.6279874444007874
Iteration [43293]: Loss = 0.627869725227356
Iteration [43294]: Loss = 0.6277176141738892
Iteration [43295]: Loss = 0.6275346279144287
Iteration [43296]: Loss = 0.6273238062858582
Iteration [43297]: Loss = 0.6270879507064819
Iteration [43298]: Loss = 0.6268293857574463
Iteration [43299]: Loss = 0.626550555229187
Iteration [43300]: Loss = 0.6262536644935608
Iteration [43301]: Loss = 0.6259403228759766
Iteration [43302]: Loss = 0.6256120204925537
Iteration [43303]: Loss = 0.6252707242965698
Iteration [43304]: Loss = 0.6249173283576965
Iteration [43305]: Loss = 0.6245533227920532
Iteration [43306]: Loss = 0.6241797804832458
Iteration [43307]: Loss = 0.6237974762916565
Iteration [43308]: Loss = 0.6234074831008911
Iteration [43309]: Loss = 5.387674808502197
Iteration [43310]: Loss = 0.6229426860809326
Iteration [43311]: Loss = 0.6228357553482056
Iteration [43312]: Loss = 0.622693657875061
Iteration [43313]: Loss = 0.6225199103355408
Iteration [43314]: Loss = 0.622317910194397
Iteration [43315]: Loss = 0.6220901608467102
Iteration [43316]: Loss = 0.6218394041061401
Iteration [43317]: Loss = 0.6215680241584778
Iteration [43318]: Loss = 0.6212779879570007
Iteration [43319]: Loss = 0.6209710836410522
Iteration [43320]: Loss = 0.6206492781639099
Iteration [43321]: Loss = 0.6203137636184692
Iteration [43322]: Loss = 0.6199661493301392
Iteration [43323]: Loss = 0.6196077466011047
Iteration [43324]: Loss = 0.6192394495010376
Iteration [43325]: Loss = 0.6188622713088989
Iteration [43326]: Loss = 0.6184772849082947
Iteration [43327]: Loss = 0.6180851459503174
Iteration [43328]: Loss = 0.6176865696907043
Iteration [43329]: Loss = 0.6172824501991272
Iteration [43330]: Loss = 5.426587104797363
Iteration [43331]: Loss = 0.6167958974838257
Iteration [43332]: Loss = 0.6166809797286987
Iteration [43333]: Loss = 0.6165321469306946
Iteration [43334]: Loss = 5.429912567138672
Iteration [43335]: Loss = 0.6164811253547668
Iteration [43336]: Loss = 0.6165514588356018
Iteration [43337]: Loss = 0.616569459438324
Iteration [43338]: Loss = 5.428712844848633
Iteration [43339]: Loss = 0.6168028116226196
Iteration [43340]: Loss = 0.6169939041137695
Iteration [43341]: Loss = 5.425004959106445
Iteration [43342]: Loss = 0.6175221800804138
Iteration [43343]: Loss = 0.6178386211395264
Iteration [43344]: Loss = 0.6180785894393921
Iteration [43345]: Loss = 5.417809963226318
Iteration [43346]: Loss = 0.6186893582344055
Iteration [43347]: Loss = 0.6190406084060669
Iteration [43348]: Loss = 0.6193118095397949
Iteration [43349]: Loss = 0.6195108890533447
Iteration [43350]: Loss = 5.408940315246582
Iteration [43351]: Loss = 0.6200511455535889
Iteration [43352]: Loss = 5.404332160949707
Iteration [43353]: Loss = 0.6209449172019958
Iteration [43354]: Loss = 0.6214159727096558
Iteration [43355]: Loss = 0.6217952370643616
Iteration [43356]: Loss = 0.6220914721488953
Iteration [43357]: Loss = 0.6223131418228149
Iteration [43358]: Loss = 0.6224674582481384
Iteration [43359]: Loss = 0.622560977935791
Iteration [43360]: Loss = 0.6225998997688293
Iteration [43361]: Loss = 5.39032506942749
Iteration [43362]: Loss = 0.6228652000427246
Iteration [43363]: Loss = 0.62306809425354
Iteration [43364]: Loss = 0.6232056021690369
Iteration [43365]: Loss = 5.385955810546875
Iteration [43366]: Loss = 0.623638391494751
Iteration [43367]: Loss = 0.6239124536514282
Iteration [43368]: Loss = 0.6241139769554138
Iteration [43369]: Loss = 0.624250054359436
Iteration [43370]: Loss = 0.6243273019790649
Iteration [43371]: Loss = 0.624351441860199
Iteration [43372]: Loss = 0.6243278980255127
Iteration [43373]: Loss = 5.379818916320801
Iteration [43374]: Loss = 0.6244852542877197
Iteration [43375]: Loss = 0.6246415972709656
Iteration [43376]: Loss = 0.6247371435165405
Iteration [43377]: Loss = 0.6247779130935669
Iteration [43378]: Loss = 0.6247691512107849
Iteration [43379]: Loss = 5.376967906951904
Iteration [43380]: Loss = 0.6249516010284424
Iteration [43381]: Loss = 0.6251184940338135
Iteration [43382]: Loss = 0.6252235174179077
Iteration [43383]: Loss = 0.6252726912498474
Iteration [43384]: Loss = 0.6252716779708862
Iteration [43385]: Loss = 0.6252254843711853
Iteration [43386]: Loss = 0.6251383423805237
Iteration [43387]: Loss = 0.62501460313797
Iteration [43388]: Loss = 0.6248577237129211
Iteration [43389]: Loss = 0.624671220779419
Iteration [43390]: Loss = 5.3785858154296875
Iteration [43391]: Loss = 0.6245499849319458
Iteration [43392]: Loss = 0.6245877742767334
Iteration [43393]: Loss = 0.6245765686035156
Iteration [43394]: Loss = 0.6245211362838745
Iteration [43395]: Loss = 5.378785610198975
Iteration [43396]: Loss = 0.6246236562728882
Iteration [43397]: Loss = 5.37671422958374
Iteration [43398]: Loss = 5.374200820922852
Iteration [43399]: Loss = 0.6257995367050171
Iteration [43400]: Loss = 0.6263325214385986
Iteration [43401]: Loss = 0.6267676949501038
Iteration [43402]: Loss = 0.6271142959594727
Iteration [43403]: Loss = 0.627381443977356
Iteration [43404]: Loss = 0.6275767087936401
Iteration [43405]: Loss = 0.6277073621749878
Iteration [43406]: Loss = 0.6277796030044556
Iteration [43407]: Loss = 0.6277992725372314
Iteration [43408]: Loss = 0.6277717351913452
Iteration [43409]: Loss = 0.6277015209197998
Iteration [43410]: Loss = 0.6275929808616638
Iteration [43411]: Loss = 0.6274497509002686
Iteration [43412]: Loss = 0.6272755265235901
Iteration [43413]: Loss = 0.627073347568512
Iteration [43414]: Loss = 0.6268458366394043
Iteration [43415]: Loss = 0.6265958547592163
Iteration [43416]: Loss = 0.6263253688812256
Iteration [43417]: Loss = 0.626036524772644
Iteration [43418]: Loss = 0.6257312297821045
Iteration [43419]: Loss = 0.6254110336303711
Iteration [43420]: Loss = 0.6250776052474976
Iteration [43421]: Loss = 0.6247321963310242
Iteration [43422]: Loss = 0.6243759393692017
Iteration [43423]: Loss = 0.6240099668502808
Iteration [43424]: Loss = 0.623635470867157
Iteration [43425]: Loss = 5.386148929595947
Iteration [43426]: Loss = 0.6231938004493713
Iteration [43427]: Loss = 0.6230950951576233
Iteration [43428]: Loss = 0.6229612827301025
Iteration [43429]: Loss = 0.6227956414222717
Iteration [43430]: Loss = 0.6226014494895935
Iteration [43431]: Loss = 0.6223816275596619
Iteration [43432]: Loss = 0.6221385598182678
Iteration [43433]: Loss = 0.6218748688697815
Iteration [43434]: Loss = 5.396615028381348
Iteration [43435]: Loss = 0.6216224431991577
Iteration [43436]: Loss = 0.6216045618057251
Iteration [43437]: Loss = 0.6215436458587646
Iteration [43438]: Loss = 0.6214438676834106
Iteration [43439]: Loss = 0.6213090419769287
Iteration [43440]: Loss = 0.6211428046226501
Iteration [43441]: Loss = 0.620948076248169
Iteration [43442]: Loss = 0.6207277774810791
Iteration [43443]: Loss = 0.6204847097396851
Iteration [43444]: Loss = 0.620220959186554
Iteration [43445]: Loss = 5.407077789306641
Iteration [43446]: Loss = 0.6199690103530884
Iteration [43447]: Loss = 0.6199517846107483
Iteration [43448]: Loss = 5.407376289367676
Iteration [43449]: Loss = 0.6201204061508179
Iteration [43450]: Loss = 0.6202819347381592
Iteration [43451]: Loss = 0.62038254737854
Iteration [43452]: Loss = 0.6204286217689514
Iteration [43453]: Loss = 0.6204251646995544
Iteration [43454]: Loss = 0.620377242565155
Iteration [43455]: Loss = 5.4048542976379395
Iteration [43456]: Loss = 10.186631202697754
Iteration [43457]: Loss = 0.6212736964225769
Iteration [43458]: Loss = 0.6219329237937927
Iteration [43459]: Loss = 5.390997886657715
Iteration [43460]: Loss = 0.6232534050941467
Iteration [43461]: Loss = 0.6239038109779358
Iteration [43462]: Loss = 0.6244455575942993
Iteration [43463]: Loss = 0.6248894333839417
Iteration [43464]: Loss = 0.6252449154853821
Iteration [43465]: Loss = 0.6255208253860474
Iteration [43466]: Loss = 5.370654582977295
Iteration [43467]: Loss = 0.6261845231056213
Iteration [43468]: Loss = 0.6265544891357422
Iteration [43469]: Loss = 0.6268431544303894
Iteration [43470]: Loss = 0.6270586252212524
Iteration [43471]: Loss = 0.6272084712982178
Iteration [43472]: Loss = 0.6272987723350525
Iteration [43473]: Loss = 5.360607624053955
Iteration [43474]: Loss = 0.6276448965072632
Iteration [43475]: Loss = 0.6278790235519409
Iteration [43476]: Loss = 0.6280453205108643
Iteration [43477]: Loss = 0.6281507015228271
Iteration [43478]: Loss = 0.6282010674476624
Iteration [43479]: Loss = 0.6282018423080444
Iteration [43480]: Loss = 0.6244940757751465
